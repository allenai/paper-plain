{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a6b83cc9",
   "metadata": {},
   "source": [
    "# Example notebook for running extractive QA\n",
    "\n",
    "We manually ran this script for collecting answer sections for the key questions. \n",
    "\n",
    "Basically this is getting the text of the paper into a squad like format than manually inspecting the output\n",
    "\n",
    "Uses this BioASQ QA model: https://github.com/dmis-lab/bioasq-biobert, follow the instructions for downloading and place in ``BIOASQ_DIR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7192a54c",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# notebook for formatting questions + context in bioasq/squad \n",
    "\n",
    "import json\n",
    "import sys\n",
    "import os\n",
    "import copy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "55c3dda6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# set up context for lupus peptides paper\n",
    "\n",
    "lupus_peptides = {\"introduction\": \"\", \"background\": \"\", \"discussion\": \"\", \"results\":\"\", \"conclusion\":\"\"}\n",
    "lupus_peptides[\"introduction\"] = \"Systemic lupus erythematosus (SLE) is the prototypical autoimmune connective tissue disease, affecting 5 million individuals worldwide, mainly women during the fertile age [1]. Clinical presentation broadly varies from patient to patient, with kidney and central nervous system (CNS) involvement representing the most severe complications [2]. The disease has usually an unpredictable course with phases of activity followed by phases of remission, and patients with a low disease activity can experience during their life disease flares following triggering events, like infections.  SLE is characterized by a multifactorial pathogenesis, in which the combination of a favorable genetics and the intervention of external agents may induce the chronic activation of the innate (neutrophils, macrophages, complement system) and the adaptive (T and B lymphocytes, plasma cells, auto- antibodies) immune system. The most salient events include an impaired apoptosis of dying cells, a type I interferon (IFN) signature, the uncontrolled activation of T and B lymphocytes and the production of autoantibodies mainly directed against nucleic acids or ribonucleoproteins (RNP), Figure 1 [3–7].  Contrary to other autoimmune diseases, such as rheumatoid arthritis (RA) or spondyloarthritis, whose prognosis has noteworthy been improved by the advent of biologic agents and small molecules, the treatment of SLE still relies on the combination of traditional and symptomatic drugs and usually shows less successful results, Figure 2 [8]. Several immunologic pathways are, in fact, concomitantly activated in SLE, and this justifies the use of medications like steroids, immunosuppressants and disease-modifying anti-rheumatic drugs (DMARDs), which unselectively counteract the immune response. Such a combo-therapy can indeed have many summing side effects that can be further exacerbated by SLE-related organ failure, coagulopathy, or cytopenia. In addition, some drugs, like anti-epileptic agents, can induce lupus-like skin manifestations or the production of antinuclear antibodies (ANA), and worsen the cutaneous or serologic manifestations of SLE [9]. To date, the use of biological agents, having higher specificity for a molecular target, is limited to belimumab, a human monoclonal antibody that neutralizes B-lymphocyte stimulator (BLyS) and inhibits B cell survival and function [10]. Despite the failure of previous randomized controlled trials (RCTs) [11–14], the results of more recent studies testing novel classes of biologic agents in SLE appear overall positive [15–17]. Similar encouraging data have been reported in clinical trials with the use of the small molecules Janus kinases (JAK)-inhibitors [18,19]. The advancement in the knowledge of SLE pathogenesis will indeed provide novel potential targets to be specifically addressed by medications. The latter may include drugs neutralizing or interfering with the proteasome of B cells, complement fragments, toll-like receptors (TLR), or metabolic pathways [20]. Target selectivity should result in a better efficacy profile and in a low risk of widespread side effects.  In this light, the formulation of human-derived or synthetic peptides, able to prevent specific steps of the immunologic cascade occurring in SLE, appears a fascinating alternative way to address this complicated disease. Therapeutic peptides consist of short amino acid chains [21] synthesized on the basis of a known human genetic sequence and designed in order to mimic the functional portion of native endogenous proteins or specific epitopes. This class of medications shows many favorable aspects, like the high target selectivity, the cost-effectiveness, the easily manufacturing, and an acceptable safety profile [22].  Thanks to genetic engineering and proteomics, it has been possible to build libraries containing a large collection of human peptides, all potentially screenable for the use in disease. In SLE, attention focuses on disease-specific T or B immunogenic amino acid fragments or epitopes. Epitopes, identified by epitope mapping, play a crucial role in the activation of the adaptive immune system by binding the T cell receptor (TCR) of T cells, the major histocompatibility complex (MHC) cleft of antigen-presenting cells (APC) or the combining site of autoantibodies [23]. Therapeutic peptides mimicking self-epitopes may modulate the immune response, counteracting the expansion of autoreactive cell clones.  The aim of this review is to report the evidence concern- ing the rationale, the efficacy, and the safety of therapeutic peptides developed or under development for SLE, and to discuss the future place in therapy of these innovative drugs.\"\n",
    "lupus_peptides[\"background\"] = \"Therapeutic peptides include a class of pharmaceutical compounds consisting of amino acid chains of various length (usually less than 40 amino acids) [21], isolated from natural sources, or artificially synthesized [24]. Though having its roots in the past, the panorama of therapeutic peptides appears highly dynamic and continuously evolving. In more recent times, therapeutic peptides are easily obtained by means of recombinant DNA technology (like microbial fermentation) and more than 100 therapeutic peptides, having various clinical indications, have already been approved worldwide [25]. The rationale for using therapeutic peptides in SLE lies in the cost-effective production, high potency, target selectivity, low toxicity, and a peculiar mechanism of action mainly based on the induction of immune tolerance [26]. These compounds share, in fact, some characteristics with both small molecules and biologic agents. Like small molecules, they can be chemically produced in the laboratory; however, contrary to them, are usually parenterally administered and show a negligible risk of drug–drug interaction and of off-target binding [21]. On the other hand, peptides share with biologic agents the high selectivity and the route of delivery, but have a more rapid clearance and a lower risk of tissue accumulation [22,27]. Globally, these features confer to pure peptides a unique pharmacologic profile, characterized by a high affinity for the target and a good safety profile, but, at the same time, a high metabolic instability, a poor membrane permeability, a scarce oral bioavailability and an accelerated biodegradation. These issues have partly been solved through drug engineering. Consequently, according to chemical properties, therapeutic peptides can be subdivided into native, analog, and heterologous peptides [24]. While unmodified native peptides, iso- lated from tissues or artificially synthesized, are used as replacing therapy in deficient patients affected by genetic or metabolic diseases, analogs, which consist of modified native peptides, and heterologous peptides, derived from synthetic library screening or phage display techniques, have also found a place in the experimental and clinical treatment of autoimmune diseases [24]. In many cases, peptides paved the way for the formulation of peptidomimetic oral small molecules, able to interact with peptide receptors [28]. In addition, peptides can be conjugated to the fragment crystallizable (Fc) of human immunoglobulins (Ig), cytotoxic payloads and poly- ethylene glycol (PEG), and acquire a better pharmacokinetic and pharmacodynamic profile [29].  Given the high specificity for their target and the low toxicity, therapeutic peptides would ideally represent the therapy of choice in SLE patients. Therapeutic peptides may, in fact, selectively counteract several steps of the immunological cascade aberrantly activated in SLE, meanwhile preserving the normal biologic functions of the immune cells. Most therapeutic peptides designed for SLE treatment are synthesized on the basis of SLE-specific immunodominant epitope sequences. When given at high concentrations in already sick animals, these peptides exert an immunomodulatory effect, which is explicated through the direct interaction with MHC molecules, B cell receptors and TCR, leading to the polarization of plasmacytoid dendritic cells (pDC) or lymphocytes toward a tolerant phenotype, Figure 3. In addition, they can induce tolerance spreading, a phenomenon amplifying the tolerance of the immune cells to other structurally related peptides. Being designed on the basis of epitopes that are pathogenic in SLE alone, peptides should not affect the normal immune response against pathogens, but, on the other hand, they may display less efficacy in the quite common cases of overlapping clinical syndromes (like anti- phospholipid syndrome, APS). Furthermore, thanks to the recent advancements in proteomics and genomics, it is expected that this kind of therapy will be tailored on specific groups of patients who could have the highest beneficial effects. However, some uncertainties still exist on bioavailability, best route of administration, doses, and targets [30]. Modifications in their chemical structure may ameliorate the physicochemical profile and influence their biological activity, strengthening also the immunomodulatory function. For instance, the conjugation to albumin or the introduction of D-amino acids may increase half-life and stability, by reducing glomerular clearance and proteolysis, respectively. Nevertheless, some of these modifications may paradoxically result disadvantageous to therapeutic peptides designed for SLE patients. An active glomerulonephritis may accelerate the elimination of analog peptides conjugated to albumin, thus shortening their half-life. Similarly, the addition of D-amino acids in order to prevent proteolysis can stress immunogenicity, which is usually more pronounced in autoimmune dis- eases, due to the hyper-activation of the immune system. The conjugation of peptides to the Fc domain in the attempt to increase molecular stability may, instead, stimulate the immune cells bearing the Fc receptors (FcR) and accelerate the clearance of these drugs. To date, no therapeutic peptide has been licensed and marketed for the use in SLE patients, although some of them have entered the phase II or III of drug development.  The next paragraphs report and discuss the current evidence concerning unconjugated and conjugated therapeutic peptides under preclinical and clinical investigation, and potential novel candidates for SLE treatment. Results and targets are resumed and illustrated in Table1, Table2 and Figure 4. Following the diagnosis of SLE, patients are assessed for disease activity and organ involvement, both of which dictate the most appropriate therapy. SLE patients with a mild involvement can be easily managed with a low dose of oral steroids (to be discontinued as soon as possible), hydroxychloroquine, and symptomatic drugs. Moderate to severe manifestations usually require the addition of DMARDs and immunosuppressants, like methotrexate, mofetil mycophenolate, cyclophosphamide and azathioprine, or the administration of intravenous immunoglobulins. The use of biologic agents (belimumab or rituximab) is indicated in refractory forms of disease. SLE flares are treated with intravenous steroid pulses and prevented with long-term low doses of oral glucocorticoids. In addition, symptomatic or organ-specific drugs, like analgesics, antihypertensive or antiepileptic agents, are often co-prescribed. In case of a concomitant APS diagnosis, anti-thrombotic and anti-coagulant drugs, and, in severe forms, plasma exchange, may also be needed. Darker color in the bars indicates higher doses or a more common use of the referred medications.\"\n",
    "lupus_peptides[\"discussion\"] = \"Human derived or artificially synthesized therapeutic peptides might appear a safe and efficacious alternative to conven-tional agents currently considered the gold-standard treat-ment for SLE. Their main strength lies in the capability of specifically targeting unbalanced pathways in disease [26] and in an overall immunomodulatory rather than immunosup-pressive effect. Additionally, some of them (DWEYS peptide, glatiramer acetate, blisibimod, and romiplostim) have a peculiar mechanism of action and are consequently able to prevent specific organ involvements or pathogenic pathways either in SLE or other immune-mediated diseases.For most of these compounds research is still ongoing at a preclinical stage, while only two peptides (the 21-mer peptide P140 and the CDR1-based peptide) and a peptibody (blisibimod) entered the clinical phase of the investigation. Of note, the suc-cessful results obtained in preclinical studies were not paralleled by similarly enthusiastic findings in RCTs. This may be due to several reasons.Firstly, any comparison between preclinical and clinical data is indeed very risky and challenging, since the two con-texts noteworthy differ in drug doses and routes of delivery, disease phenotype, serology, co-medications, assessment methods, study design, time of observation and statistical analysis. For instance, in preclinical studies on MRL/LPR mouse models, the 21-mer peptide P140 in saline solution was intravenously given at a high dose (5 mg/kg), whilst the s.c. route was inefficacious [38]. On the contrary, in humans, the i.v. administration of the 21-mer peptide P140 was not tested and the s.c. dose used was considerably lower (3 mcg/ kg). Moreover, additives and excipients may also account for different pharmacologic properties of peptides in vivo and indirectly influence the biologic effects in organisms [41]. Secondly, the endpoints of preclinical and clinical studies were often unmatchable, as in the first case they focused on peripheral blood hyper-cellularity, glomerulonephritis, autoan-tibody titers, neuronal damage, perivascular inflammatory infiltrates, and survival of SLE animal models, whereas, in the second case, they were based on the overall clinical improvement, measured through validated scoring systems at prefixed time-points. A prolonged survival of experimentally treated SLE individuals is obviously unpredictable with phase II and phase III studies; moreover, patients with severe renal and CNS involvement were excluded from clinical trials and renal biopsies not performed. Thirdly, SLE patients represent a non-homogeneous cate-gory with polyhedral manifestations reflecting the numerous pathogenic pathways being simultaneously activated. The achievement of a complete remission of the disease, which should be the ultimate goal of treatments, is still a matter of debate in clinical trials and in real-life [8,136], while the achievement of a low disease activity seems to be more realistic [137]. As a consequence, the design of RCTs for SLE cohorts of patients is often challenging and prefixed outcomes are less likely to be satisfied. Post-hoc analyses reported a better efficacy of clinically tested peptides in selected SLE cohorts, namely those patients having anti-dsDNA antibody positivity. Anti-dsDNA antibodies represent a marker of disease activity, being associated with some mani-festations like glomerulonephritis and CNS symptoms [69]. Anti- dsDNA may, in fact, cross-react with several autoantigens, includ-ing components of the extracellular matrix of glomeruli or neu-ronal receptors and be responsible for organ-specific clinical manifestations [69,138]. However, it must be underlined that anti-dsDNA antibody titers broadly vary during the course of the disease, and that methodology for their measurement may further differ according to the laboratory (e.g. qualitative vs. quantitative methods) [139]. In addition, anti-dsDNA antibodies include Ig with variable isotypes and targets [140]. For instance, it has been shown that anti-dsDNA IgM are often associated with  skin manifestations, presumably due to the deposition of immune complexes, whereas the isotype IgG seems to be directly involved in the renal damage [141]. Also, it is debated whether antibodies binding DNA in its native conformation might have a true pathogenic role in SLE nephritis, or rather be a heterogeneous group of antibodies cross-reacting with native DNA and other components of glomeruli [140].A separate story, instead, lies below the disappointing results observed during the clinical experimentation of the peptibody blisibimod [101,104]. This peptibody has an extre-mely different pharmacokinetic and pharmacodynamic profile compared to simple peptides. Differences include the mechanism of action, molecular structure, half-life, stability, and immunogenicity risk. In this regard, it may be argued that blisibimod, by counteracting the expansion and the acti-vation of B cells, would constrain the synthesis of antibodies [101], including ADA. Nevertheless, immunogenicity is a complex matter, often involving immunologic mechanisms other than the solely humoral response [142]. In SLE, the engagement of the Fc of therapeutics with the FcR of phago-cytic cells may unleash, through an impaired phagocytosis, the cascade of events leading to type I IFN production, and amplify, through this pathway, inflammation and tissue damage.\"\n",
    "lupus_peptides[\"conclusion\"] = \"Better knowledge of the pathogenesis of SLE is expected to enrich the therapeutic armamentarium and facilitate the man- agement of the disease. The use of peptides, specifically designed to target SLE-related epitopes or crucial pathways, may represent a novel fascinating opportunity. Given their good safety profile and immunomodulatory properties, ther- apeutic peptides could be added to standard of care, and, perhaps, allow the sparing of conventional drugs. In addition, their prescription might be tailored to specific subsets of patients having the highest likelihood of response. Nevertheless, despite the successful results observed in preclinical studies, RCTs showed a controversial efficacy profile concerning the use of these compounds in SLE. It is expected that future research, aiming at the amelioration of their physicochemical properties and at the improvement in the design of clinical trials, will bring more encouraging data on this innovative therapeutic panorama. The treatment of SLE still relies on a conservative approach, combining multiple unselective immunosuppressive agents [8] and, consecutively, increasing the risk of unwanted side effects. Unlike other rheumatic diseases, the licensed use of biologic agents, which electively inhibit a specific target, has been solely limited to belimumab. Rituximab failed to achieve the primary endpoints in RCTs conducted in SLE patients [12,13,143] but, due to encouraging real-life data [11], its off- label use is advised in resistant severe manifestations [8]. The potential use of novel biological agents and small molecules in SLE is still an object of clinical investigation [15–18]. Furthermore, several preliminary data on other small molecules acting as IFN receptor, NF-kB, or CXCR4 antagonists [115,144,145] spur research in this direction. Despite promising preliminary data, the immunogenicity of big molecules, like monoclonal antibodies, and the unselective effect of small molecules might represent a disadvantage in SLE. In the meantime, other innovative pharmaceutical compounds, including IL-2, artificially synthesized oligodeoxynucleotide (ASO) and retinoids, have been developed and tested in pre- clinical and clinical studies with encouraging results [146–149]. In this effervescent panorama, therapeutic peptides, able to interfere with the most crucial steps of SLE immunopathogenesis, may represent an additional intriguing pharmacologic strategy. Therapeutic peptides consist of short chains of amino acids displaying high target selectivity and potency, low toxicity, and a negligible risk of organ accumulation. On the other hand, due to their protein nature, these compounds are metabolically unstable, poorly bioavailable per os, rapidly biodegraded, and unable to cross plasma membranes [22,24]. Peptides can be easily produced from a known nucleotide sequence by means of recombinant DNA technology and then modified in order to enhance their pharmacologic properties. Most of therapeutic peptides designed for SLE treatment are synthesized on the basis of immunodominant epitope sequences that are pathogenic in SLE alone. Therefore, they exert an immunomodulatory effect on auto- reactive pDC and lymphocytes, without affecting, instead, the immune response against pathogens [26]. To date, no therapeutic peptide has been licensed and marketed for the use in SLE patients. The 21-mer peptide P140 is the only one entering phase III RCTs, and, despite controversial results [36,40,41,43], its development is still ongoing. Edratide, synthesized on the basis of the hCDR1 expressing the major idiotype 16/6 Id, showed promising results in preclinical studies [48,50,54,55], but failed to meet the primary endpoint in a phase II RCT [57], with the following interruption of further clinical development. Both the two peptides appeared more effective in anti-dsDNA seropositive patients, and, although data are lacking, a beneficial role may be supposed in those SLE manifestations related to anti- dsDNA antibodies, such as glomerulonephritis. Other peptides (pConsensus, laminin-derived peptide, nucleosomal peptides, DWEYS peptide, glatiramer acetate, TP-5) have been tested in SLE preclinical models, with promising findings [65,73,78,85,89,94]. The preliminary evidence gathered from these studies showed the amelioration of glomerulonephritis, the reduction in serum autoantibody titers, the prevention of neuronal damage, and a prolonged survival rate of SLE animal models. Whether these successful results may be translated in humans is an uncertain issue that needs to be addressed in future research. The discovery of novel molecular targets is expected to enrich, in the next years, the panorama of therapeutic peptides for SLE, among which CXCR4 and STING antagonists and virus- derived peptides seem promising candidates [116,119,135]. Meanwhile, research is focusing on the optimization of the physicochemical structure of preexisting peptides with the intention to improve their pharmacologic properties, including bioavailability and half-life. One of these efforts consists of the generation of peptidase-resistant compounds that could be administered per os, with a considerable impact on treatment adherence [67]. Additionally, the high target selectivity of peptides can be combined with the molecular stability and the optimal oral bioavailability of small molecules, thus giving rise to the formulation of hybrid compounds, known as peptidomimetic small molecules. Peptibodies, consisting of fusion proteins retaining a peptide sequence grafted onto the Fc portion of a Ig, represent another fair example of peptide molecular engineer- ing [29]. However, in spite of a reduced clearance and a better chemical stability, the interaction of the Fc of peptibodies with the FcR of immune cells may increase inflammation, trigger immunogenicity, and favor the removal of the drug by the reticuloendothelial system. This may explain the controversial efficacy profile in SLE of the peptibody blisibimod observed in RCTs [101,104]. However, despite failing to achieve the primary endpoints in clinical investigation, blisibimod showed some interesting aspects, including the steroid sparing effect, the effectiveness in more severe forms of disease, and the capability of ameliorating some laboratory parameters, including proteinuria, anti-dsDNA and anti-cardiolipin antibody titers and hypo-complementemia. Although immunogenicity of peptibodies may represent a warning, RCTs on blisibimod showed no safety issues compared to placebo. Unconjugated peptides might appear even safer than conjugated peptides, as they undergo a rapid proteolysis, generating harmless simple amino acids [40,57].  Based on these considerations, therapeutic peptides would eventually offer several advantages in SLE treatment that may be resumed in the following scenarios: 1) according to mechanism of action, they could be used for selected populations of SLE patients, like those characterized by active glomerulonephritis, CNS involvement [85] or high autoantibody titers, thus allowing a personalized medicine; 2) they could synergistically strengthen the efficacy of steroids, conventional DMARDs, and immunosuppressants [61,62], allowing dose- reduction or even discontinuation of these drugs once a low disease activity is achieved; 3) given their rapid catabolism, they could temporary be used to manage SLE flares, avoiding the risk of drug accumulation and undesired toxicity during the remission phases of the disease [57,119]; 4) they could be combined in a cocktail to be administered as a vaccine in subjects at risk of SLE, in order to restore the immune tolerance and prevent disease development [80]; 5) thanks to the acceptable safety profile, they could be associated with other conventional medications in those patients being concomitantly diagnosed with SLE and another autoimmune disorder, who may less benefit from highly SLE-specific compounds [56]. Finally, the introduction in future pipelines of more sophisticated hybrid compounds like peptibodies or peptidomimetic small molecules is expected to rewrite the chapter of SLE peptide therapy, providing renewed drugs with a better pharmacologic profile and increased efficacy. A hypothetical list of specific therapeutic indications of the peptides designed or designable for SLE, whose preclinical and clinical evidence has been discussed in this review, is provided in Table3.\"\n",
    "lupus_peptides[\"results\"] = \"\"\n",
    "\n",
    "\n",
    "ldh_surgery = {\"introduction\": \"\", \"method\": \"\", \"discussion\": \"\"}\n",
    "ldh_surgery[\"introduction\"] = \"Lumbar disc herniation (LDH) is one of the most frequently diagnosed causes of low back pain and is a common cause of radiculopathy.[1–3] Although most patients with LDH can achieve satisfying clinical and functional outcomes with conservative treatment, a few patients do not respond effectively to conservative treatment and eventually require surgical treatment.[4,5]  There are several main surgical options: open lumbar micro- discectomy (OLM),[6] microendoscopic discectomy (MED),[7,8] minimally invasive transforaminal lumbar interbody fusion (MIS- TLIF),[9] and percutaneous endoscopic lumbar discectomy (PELD).[10,11] OLM has been regarded as the most commonly recommended surgical option for recurrent LDH;[12,13] however, it was associated with several complications, including muscle damage, nerve retraction, and the removal of yellow liga- ment,[14,15] which can result in instability and scarring of the epidural space.[16,17] MED uses a microendoscope for visualiza- tion, and the paraspinous muscles are handled by muscle splitting through dilators;[18] thus, the muscle and soft tissue are minimally injured.[19] MIS-TLIF is a well-accepted operation method for recurrent LDH. And it has the advantages of less iatrogenic soft tissue injury, lower risk of postoperative radiculitis, and decreased retraction of dural sac.[20,21] PELD is a more minimally invasive surgery because the posterior column structures are pre- served.[22,23] It has gained interest for its potential advantage in the reduced risk of facet joints injury, fewer postoperative complications, a shorter hospital stay and lower cost.[24,25] Previous studies have reported that PELD is an effective and safe treatment for LDH.[26,27] However, whether PELD is superior to other surgical options remains controversial. Thus, we conducted this meta-analysis to compare the clinical, radiologic, and complications of PELD and other surgeries for patients with LDH.\"\n",
    "ldh_surgery[\"method\"] = \"We conducted this meta-analysis in compliance with the Preferred Reporting Items for Systematic Reviews and Meta- analysis (PRISMA) statement guidelines.[28] Multiple databases, including PubMed, Embase, and Web of Science were systemati- cally searched before February 2018. The structured search strategies were listed as followings: ((“lumbosacral region”[- MeSH Terms] OR (“lumbosacral”[All Fields] AND “region”[All Fields]) OR “lumbosacral region”[All Fields] OR “lumbar”[All Fields]) AND disc[All Fields] AND (“hernia”[MeSH Terms] OR “hernia”[All Fields] OR “herniation”[All Fields])) AND (percu- taneous[All Fields] AND (“endoscopy”[MeSH Terms] OR “endoscopy”[All Fields] OR “endoscopic”[All Fields]) AND (“lumbosacral region”[MeSH Terms] OR (“lumbosacral”[All Fields] AND “region”[All Fields]) OR “lumbosacral region”[All Fields] OR “lumbar”[All Fields]) AND (“diskectomy”[MeSH Terms] OR “diskectomy”[All Fields] OR “discectomy”[All Fields])). This search was limited to human subjects, and no language or publication status was imposed. In addition, we also manually searched the reference lists of the included studies and previous review, systematic review and meta-analysis to identify potential studies until no additional articles could be found. The inclusion criteria were as follows: \t.\t(1)  study design: randomized control trial (RCT), cohort study, or case-control study; (2)  population: patients who were diagnosed with LDH  (3)  intervention: PELD;  (4)  comparison: other surgical approaches; (5)  outcome measures: one of the followings: success rate, recurrence rate, complication rate, operation time, hospital stay, blood loss, visual analog scale (VAS) score for back pain and leg pain, 12-item Short Form Health Survey (SF12) physical component score (PCS), mental component score (MCS), Japanese Orthopaedic Association Score (JOA), Oswestry Disability Index (ODI). Two independent investigators extracted the following data from the included studies: first author’ name, publication year, study design, country, number of patients in each group, patients’ characteristics, and outcome data (success rate, recurrence rate, complication rate, operation time, hospital stay, blood loss, VAS scores for back pain and leg pain, JOA, SF12-MCS/PCS, and ODI). If the study did not provide the important data, we would contact the corresponding authors for the missing information. We evaluated the risk of bias in RCTs with the method recommended by Cochrane Collaboration.[29] Five items, including blinding, method of randomization, allocation con- cealment, follow-up, and intention-to-treat analysis were used to assess the quality of study.[29] And each study was classified as high, low, or unclear risk of bias.  We evaluated the methodological quality of non-randomized studies (cohort study, or case-control study) using the modified Newcastle-Ottawa scale.[30] The total scale of this method was 9 points, and higher point indicated better quality.[30] Any study was considered to be high quality if the score was more than 5 points. Two independent investigators used the STATA version 12.0 (Stata Corporation, College Station, TX, USA) to perform the statistical analysis. Success rate, recurrence rate, and complica- tion rate, were treated as dichotomous variables and were expressed as relative risk (RR) with 95% confidence intervals. Operation time, hospital stay, blood loss, back-pain VAS score, leg-pain VAS score, JOA score, and SF12-MCS/PCS, were treated as continuous variables, thus they were expressed as weighted mean difference (WMD) with 95% confidence intervals. Before the data were pooled, Q-statistic and I2 statistic were used to detect the heterogeneity among the studies, in which a P value < .10 or I2 > 50% were defined as significant heterogeneity. Pooled estimates were generated by using a fixed-effects model (Mantel–Haenszel method)[31] or random-effect model (DerSi- monian–Laird method),[32] depending on the heterogeneity among the included studies. When heterogeneity was identified, we conducted sensitivity analysis by omitting one study at each turn to explore the influence of each individual study on the overall risk estimate. We also performed subgroup analysis based on the comparators and duration of following-up to explore the sources of heterogeneity and the impacts of these variables on the overall estimates. Publication bias was assessed by the Begg[33] and Egger test.[34] A 2-tailed P value <.05 was considered statistically significant except where a certain P-value had been specified. This is meta-analysis, so ethic approval is not required. Figure 1. Eligibility of studies for inclusion in meta-analysis. Baseline characteristics of patients in the trials included in the meta-analysis. \"\n",
    "ldh_surgery[\"discussion\"] = \"The present meta-analysis of 14 trials involving 2,528 patients provided evidence that PELD had favorable clinical outcomes for LDF, including shorter operation time and hospital stay, less blood loss, and improved SF12-MCS and SF12-PCS score. However, it also was associated with a significantly higher rate of recurrent disc herniation. In the present study, we found that patients who underwent PELD had a significantly higher recurrence rate than those treated with other surgical interventions. However, in the subgroup analysis based on the comparators, the higher rate of recurrent dis herniation was only observed in the comparison with MIS-TLIF. Yao Y, et al.[45] performed a retrospective cohort study to compare the outcomes of three minimally invasive spine surgeries (MIS- TLIF, MED, and PELD) in the treatment of recurrent herniation. At the follow-up duration of 12months, no patients (0.0%) in the MIS-TLIF group, 3 patients (15.0%) in the MED group, and 7 patients (25.0%) in the PELD group developed recurrence.[45] The recurrence rate in the PELD group was significantly higher than that in the MIS-TLIF group. Similarly, in their another recently published trial,[54] they also reported a higher recurrence rate of PELD than MIS-TLIF. In that study, the authors enrolled 105 patients who underwent either PELD (n = 47) or MIS-TLIF (n = 58) for revision of MED recurrence.[54] At the 12-month follow-up, patients who underwent PELD had a significantly higher recurrence rate (10.64%) than those treated with MIS-TLIF (0.0%).[54] The authors attributed the findings to the following reasons: (1) there was some risk factors that were predictive of recurrence in PELD patients. For example, old age, obesity, and Modic change have been identified as significant risk factors for the PELD recur- rence.[58,59] And the 5 patients who experienced recurrence in the PELD group were all relatively old (≥60 years old) and obese; thus, they were at high risk of recurrent herniation.[54] (2) 3 of the 5 patients had herniated fragment that were highly migrated, and this made the surgery more difficult.[60] The residual fragment would result in unsuccessful surgical outcomes.[58,61] (3) After the primary MED surgery, the artificial cracks in annulus fibrosus would change the laminate structure, and make the annulus be more easily to delamination.[54] Based on the damage in annulus fibrosus, the recurrent herniation easily occurred.[62] Therefore, it is unable for PELD to solve this problem thoroughly, and a through interbody fusion (MIS-TLIF) might be a better choice.[54] The success rate in the PELD group and other surgical intervention group were 7.2% and 4.1%, respectively. Although patients treated with PELD achieved a significantly higher success rate than those with other surgeries, the difference between them was not significant. Lee SH, et al[46] performed a matched cohort study evaluation of 60 consecutive patients with LDH. Of them, 30 patients were underwent PELD, and 30 were treated with OLM.[46] At the follow-up duration of 36months, 96.7% of patients in the PELD group and 93.3% of patients in the OLM group achieved good or excellent results.[46] For microsurgical discectomy, our result also showed a similar success rate with PELD. Rutten S, et al[48] performed a prospective randomized study to compare the clinical outcomes of PELD with microsurgical technique. In that study, 95% of patients with PELD reported subjective satisfaction as compared with 86% of patients with microsurgical technique. However, the difference between them was not significant. In contrast to the lower success rates of OLM and microsurgical discectomy, MIS-TLIF seemed to have a higher success rate than PELD. Liu C, et al[52] reported a prospective cohort study of 401 patients with recurrent LDH who were treated with PELD (n = 209) or MIS-TLIF (n = 192). At the mean duration follow-up of 46.5 months, the success rate in the two groups was 91.3% and 95.2%, respectively.[52] MIS-TLIF resulted in a higher success rate than PELD, however, there was no significant difference between them. Regarding the operation time, the present study demonstrated that patients treated with PELD had 18.14 minutes less of operation time than those with other surgical interventions. However, the reduced operation time of PELD was only observed in the comparison with OLM, MIS-TLIF, microsurgical discectomy and microdiscectomy. Compared with these surgical approaches, PELD had 11.66 minutes, 75.23 minutes, 23.21 minutes, and 17 minutes less of operation time, respectively. Kim MJ, et al.[44] compared the clinical outcomes of PELD with OLM, and they found the operation time in these two groups was 53.0 ± 13.0 minutes and 64.6 ± 28.7 minutes, respectively (P < 0.001). Yao Y, et al.[45] assessed the three minimally invasive spine surgical approaches (PELD, MIS-TLIF, and MED) for recurrent herniation, and the mean operation time between them was 75.0 ± 31.56 minutes, 146.54 ± 38.07 minutes, and 85.25 ± 41.60 minutes, respectively. PELD had a significantly less operation time than MIS-TLIF, but a comparable operation time with MED.  The functional outcomes were assessed by the VAS scores for back pain and leg pain. Our results suggested that patients treated with PELD had comparable postoperation VAS scores for back pain and leg pain with those treated with other surgeries. Our result was in consistent with the previous findings.[50,52,54] Yao Y, et al[54] reported that the preoperative VAS scores for back pain and leg pain were 5.88 ± 1.24 and 7.05 ± 1.08 in the MIS- TLIF group, 5.92 ± 1.33 and 7.13 ± 1.09 respectively in the PELD group (P = .888).[54] At the follow-up duration of 12 months, the VAS scores significantly reduced in the two groups as compared with preoperative values. However, there was no significant differences between the them in the postoperation VAS scores for back pain and leg pain.[54] The authors attributed the results to the relatively larger injury of soft tissue and disruption of spinal stability, which were caused by the interbody fusion than discectomy.[54]  There were several potential limitations in this meta-analysis. First, for some outcomes, the data analysis was based on relatively small number of included studies and sample size; thus, the conclusions about the outcomes should be interpreted with caution. Second, most of the included studies were retrospective cohort study, and the grade evidence was inferior to that of RCTs. Third, despite we performed sensitivity analysis and subgroup analysis to explore the derivation of heterogeneity, no valuable information was found. We thought that some potential reasons may account for the great heterogeneity, including patients’ characteristics (age, sex, BMI, type of disc herniation, and surgical segment), duration of follow-up, case definition, and surgical approaches. These factors may have an impact on our results. thus, considering these limitations, caution is advised when interpreting our findings and applying them into the clinical practice. In conclusion, the present meta-analysis of 14 studies suggested that, PELD was associated with better effects and similar complications with other surgeries in the treatment of LDH. However, it also resulted in a higher recurrence rate. Considering the potential limitations in the present study, further large-scale, well-performed randomized trials are needed to verify our findings.\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "487fee0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "qas_dict = {\"introduction\": [], \"method\": [], \"discussion\": []}\n",
    "\n",
    "\n",
    "qas_dict['introduction'] = [\n",
    "    {\n",
    "      \"question\": \"What did the paper want to find out?\", \n",
    "      \"id\": \"1\"\n",
    "    }, \n",
    "    {\n",
    "      \"question\": \"What condition does the paper study?\", \n",
    "      \"id\": \"2\"\n",
    "    },\n",
    "    {\n",
    "      \"question\": \"How is the condition usually treated?\", \n",
    "      \"id\": \"5\"\n",
    "    },\n",
    "    {\n",
    "      \"question\": \"What are ways to manage this condition?\", \n",
    "      \"id\": \"5-1\"\n",
    "    },\n",
    "    {\n",
    "      \"question\": \"What were the new treatment(s) this paper looked into?\", \n",
    "      \"id\": \"4\"\n",
    "    }\n",
    "]\n",
    "\n",
    "qas_dict['method'] = [\n",
    "    {\n",
    "      \"question\": \"What did the paper do?\", \n",
    "      \"id\": \"3\"\n",
    "    },\n",
    "    {\n",
    "      \"question\": \"Are the findings different depending on a person's demographics?\", \n",
    "      \"id\": \"7-1\"\n",
    "    },\n",
    "]\n",
    "\n",
    "\n",
    "qas_dict['discussion'] = [\n",
    "    {\n",
    "      \"question\": \"What did the paper find?\", \n",
    "      \"id\": \"6\"\n",
    "    },\n",
    "    {\n",
    "      \"question\": \"Do the findings depend on patient demographics?\", \n",
    "      \"id\": \"7\"\n",
    "    },\n",
    "    {\n",
    "      \"question\": \"What are the limitations of the findings?\", \n",
    "      \"id\": \"8\"\n",
    "    } \n",
    "] \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "313be2ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "# make the squadlike data\n",
    "squad_like_context_qas_template = {\n",
    "  \"version\": \"BioASQ6b\", \n",
    "  \"data\": [\n",
    "    {\n",
    "      \"title\": \"BioASQ6b\", \n",
    "      \"paragraphs\": []\n",
    "    }\n",
    "  ]\n",
    "}\n",
    "\n",
    "# squad_like_context_qas_lupus = copy.deepcopy(squad_like_context_qas_template)\n",
    "squad_like_context_qas_ldh = copy.deepcopy(squad_like_context_qas_template)\n",
    "\n",
    "# for k in lupus_peptides.keys():\n",
    "#     squad_like_context_qas_lupus['data'][0]['paragraphs'].append({'context':lupus_peptides[k], 'qas':qas_dict[k]})\n",
    "\n",
    "for k in ldh_surgery.keys():\n",
    "    squad_like_context_qas_ldh['data'][0]['paragraphs'].append({'context':ldh_surgery[k], 'qas':qas_dict[k]})\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3e9a2f5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# save the data\n",
    "with open('test_predict_lupus.json', 'w') as f:\n",
    "    json.dump(squad_like_context_qas_lupus, f)\n",
    "    \n",
    "# save the data\n",
    "with open('test_predict_ldh.json', 'w') as f:\n",
    "    json.dump(squad_like_context_qas_ldh, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "96755a32",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/tala/s2-simplify/bioasq-biobert/optimization.py:87: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\n",
      "\n",
      "WARNING:tensorflow:From /home/tala/s2-simplify/bioasq-biobert/run_factoid.py:1290: The name tf.app.run is deprecated. Please use tf.compat.v1.app.run instead.\n",
      "\n",
      "WARNING:tensorflow:From /home/tala/s2-simplify/bioasq-biobert/run_factoid.py:1134: The name tf.logging.set_verbosity is deprecated. Please use tf.compat.v1.logging.set_verbosity instead.\n",
      "\n",
      "W1208 12:27:36.003039 139883775852736 module_wrapper.py:139] From /home/tala/s2-simplify/bioasq-biobert/run_factoid.py:1134: The name tf.logging.set_verbosity is deprecated. Please use tf.compat.v1.logging.set_verbosity instead.\n",
      "\n",
      "WARNING:tensorflow:From /home/tala/s2-simplify/bioasq-biobert/run_factoid.py:1134: The name tf.logging.INFO is deprecated. Please use tf.compat.v1.logging.INFO instead.\n",
      "\n",
      "W1208 12:27:36.003150 139883775852736 module_wrapper.py:139] From /home/tala/s2-simplify/bioasq-biobert/run_factoid.py:1134: The name tf.logging.INFO is deprecated. Please use tf.compat.v1.logging.INFO instead.\n",
      "\n",
      "WARNING:tensorflow:From /home/tala/s2-simplify/bioasq-biobert/modeling.py:92: The name tf.gfile.GFile is deprecated. Please use tf.io.gfile.GFile instead.\n",
      "\n",
      "W1208 12:27:36.003241 139883775852736 module_wrapper.py:139] From /home/tala/s2-simplify/bioasq-biobert/modeling.py:92: The name tf.gfile.GFile is deprecated. Please use tf.io.gfile.GFile instead.\n",
      "\n",
      "WARNING:tensorflow:From /home/tala/s2-simplify/bioasq-biobert/run_factoid.py:1140: The name tf.gfile.MakeDirs is deprecated. Please use tf.io.gfile.makedirs instead.\n",
      "\n",
      "W1208 12:27:36.003989 139883775852736 module_wrapper.py:139] From /home/tala/s2-simplify/bioasq-biobert/run_factoid.py:1140: The name tf.gfile.MakeDirs is deprecated. Please use tf.io.gfile.makedirs instead.\n",
      "\n",
      "WARNING:tensorflow:\n",
      "The TensorFlow contrib module will not be included in TensorFlow 2.0.\n",
      "For more information, please see:\n",
      "  * https://github.com/tensorflow/community/blob/master/rfcs/20180907-contrib-sunset.md\n",
      "  * https://github.com/tensorflow/addons\n",
      "  * https://github.com/tensorflow/io (for I/O related ops)\n",
      "If you depend on functionality not listed there, please file an issue.\n",
      "\n",
      "W1208 12:27:36.065065 139883775852736 lazy_loader.py:50] \n",
      "The TensorFlow contrib module will not be included in TensorFlow 2.0.\n",
      "For more information, please see:\n",
      "  * https://github.com/tensorflow/community/blob/master/rfcs/20180907-contrib-sunset.md\n",
      "  * https://github.com/tensorflow/addons\n",
      "  * https://github.com/tensorflow/io (for I/O related ops)\n",
      "If you depend on functionality not listed there, please file an issue.\n",
      "\n",
      "WARNING:tensorflow:Estimator's model_fn (<function model_fn_builder.<locals>.model_fn at 0x7f36487038c8>) includes params argument, but params are not passed to Estimator.\n",
      "W1208 12:27:36.956516 139883775852736 estimator.py:1994] Estimator's model_fn (<function model_fn_builder.<locals>.model_fn at 0x7f36487038c8>) includes params argument, but params are not passed to Estimator.\n",
      "INFO:tensorflow:Using config: {'_model_dir': '/home/tala/s2-simplify/bioasq-biobert/output/', '_tf_random_seed': None, '_save_summary_steps': 100, '_save_checkpoints_steps': 1000, '_save_checkpoints_secs': None, '_session_config': allow_soft_placement: true\n",
      "graph_options {\n",
      "  rewrite_options {\n",
      "    meta_optimizer_iterations: ONE\n",
      "  }\n",
      "}\n",
      ", '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': None, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_experimental_max_worker_delay_secs': None, '_session_creation_timeout_secs': 7200, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x7f363d929b00>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1, '_tpu_config': TPUConfig(iterations_per_loop=1000, num_shards=8, num_cores_per_replica=None, per_host_input_for_training=3, tpu_job_name=None, initial_infeed_sleep_secs=None, input_partition_dims=None, eval_training_input_configuration=2, experimental_host_call_every_n_steps=1), '_cluster': None}\n",
      "I1208 12:27:36.957737 139883775852736 estimator.py:212] Using config: {'_model_dir': '/home/tala/s2-simplify/bioasq-biobert/output/', '_tf_random_seed': None, '_save_summary_steps': 100, '_save_checkpoints_steps': 1000, '_save_checkpoints_secs': None, '_session_config': allow_soft_placement: true\n",
      "graph_options {\n",
      "  rewrite_options {\n",
      "    meta_optimizer_iterations: ONE\n",
      "  }\n",
      "}\n",
      ", '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': None, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_experimental_max_worker_delay_secs': None, '_session_creation_timeout_secs': 7200, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x7f363d929b00>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1, '_tpu_config': TPUConfig(iterations_per_loop=1000, num_shards=8, num_cores_per_replica=None, per_host_input_for_training=3, tpu_job_name=None, initial_infeed_sleep_secs=None, input_partition_dims=None, eval_training_input_configuration=2, experimental_host_call_every_n_steps=1), '_cluster': None}\n",
      "INFO:tensorflow:_TPUContext: eval_on_tpu True\n",
      "I1208 12:27:36.958204 139883775852736 tpu_context.py:220] _TPUContext: eval_on_tpu True\n",
      "WARNING:tensorflow:eval_on_tpu ignored because use_tpu is False.\n",
      "W1208 12:27:36.958529 139883775852736 tpu_context.py:222] eval_on_tpu ignored because use_tpu is False.\n",
      "WARNING:tensorflow:From /home/tala/s2-simplify/bioasq-biobert/run_factoid.py:231: The name tf.gfile.Open is deprecated. Please use tf.io.gfile.GFile instead.\n",
      "\n",
      "W1208 12:27:36.958665 139883775852736 module_wrapper.py:139] From /home/tala/s2-simplify/bioasq-biobert/run_factoid.py:231: The name tf.gfile.Open is deprecated. Please use tf.io.gfile.GFile instead.\n",
      "\n",
      "WARNING:tensorflow:From /home/tala/s2-simplify/bioasq-biobert/run_factoid.py:1072: The name tf.python_io.TFRecordWriter is deprecated. Please use tf.io.TFRecordWriter instead.\n",
      "\n",
      "W1208 12:27:36.963893 139883775852736 module_wrapper.py:139] From /home/tala/s2-simplify/bioasq-biobert/run_factoid.py:1072: The name tf.python_io.TFRecordWriter is deprecated. Please use tf.io.TFRecordWriter instead.\n",
      "\n",
      "WARNING:tensorflow:From /home/tala/s2-simplify/bioasq-biobert/run_factoid.py:438: The name tf.logging.info is deprecated. Please use tf.compat.v1.logging.info instead.\n",
      "\n",
      "W1208 12:27:36.970093 139883775852736 module_wrapper.py:139] From /home/tala/s2-simplify/bioasq-biobert/run_factoid.py:438: The name tf.logging.info is deprecated. Please use tf.compat.v1.logging.info instead.\n",
      "\n",
      "INFO:tensorflow:*** Example ***\n",
      "I1208 12:27:36.970175 139883775852736 run_factoid.py:438] *** Example ***\n",
      "INFO:tensorflow:unique_id: 1000000000\n",
      "I1208 12:27:36.970220 139883775852736 run_factoid.py:439] unique_id: 1000000000\n",
      "INFO:tensorflow:example_index: 0\n",
      "I1208 12:27:36.970256 139883775852736 run_factoid.py:440] example_index: 0\n",
      "INFO:tensorflow:doc_span_index: 0\n",
      "I1208 12:27:36.970292 139883775852736 run_factoid.py:441] doc_span_index: 0\n",
      "INFO:tensorflow:tokens: [CLS] What did the paper want to find out ? [SEP] Lu ##mba ##r disc her ##nia ##tion ( L ##D ##H ) is one of the most frequently diagnosed causes of low back pain and is a common cause of r ##adi ##cu ##lop ##athy . [ 1 – 3 ] Although most patients with L ##D ##H can achieve satisfying clinical and functional outcomes with conservative treatment , a few patients do not respond effectively to conservative treatment and eventually require surgical treatment . [ 4 , 5 ] There are several main surgical options : open l ##umba ##r micro - disc ##ec ##tom ##y ( O ##LM ) , [ 6 ] micro ##end ##os ##copic disc ##ec ##tom ##y ( ME ##D ) , [ 7 , 8 ] minimal ##ly invasive trans ##fo ##ram ##inal l ##umba ##r inter ##body fusion ( MI ##S - T ##L ##IF ) , [ 9 ] and per ##cut ##aneous end ##os ##copic l ##umba ##r disc ##ec ##tom ##y ( P ##EL ##D ) . [ 10 , 11 ] O ##LM has been regarded as the most commonly recommended surgical option for re ##current L ##D ##H ; [ 12 , 13 ] however , it was associated with several complications , including muscle damage , nerve re ##traction , and the removal of yellow l ##iga - men ##t , [ 14 , 15 ] which can result in instability and scar ##ring of the e ##pid ##ural space . [ 16 , 17 ] ME ##D uses a micro ##end ##os ##cope for visual ##iza - t ##ion , and the para ##sp ##ino ##us muscles are handled by muscle splitting through di ##lator ##s ; [ 18 ] thus , the muscle and soft tissue are minimal ##ly injured . [ 19 ] MI ##S - T ##L ##IF is a well - accepted operation method for re ##current L ##D ##H . And it has the advantages of less i ##at ##rogen ##ic soft tissue injury , lower risk of post ##oper ##ative r ##adi ##cu ##lit ##is , and decreased re ##traction of du ##ral sa ##c . [ 20 , 21 ] P ##EL ##D is a more minimal ##ly invasive surgery [SEP]\n",
      "I1208 12:27:36.970411 139883775852736 run_factoid.py:443] tokens: [CLS] What did the paper want to find out ? [SEP] Lu ##mba ##r disc her ##nia ##tion ( L ##D ##H ) is one of the most frequently diagnosed causes of low back pain and is a common cause of r ##adi ##cu ##lop ##athy . [ 1 – 3 ] Although most patients with L ##D ##H can achieve satisfying clinical and functional outcomes with conservative treatment , a few patients do not respond effectively to conservative treatment and eventually require surgical treatment . [ 4 , 5 ] There are several main surgical options : open l ##umba ##r micro - disc ##ec ##tom ##y ( O ##LM ) , [ 6 ] micro ##end ##os ##copic disc ##ec ##tom ##y ( ME ##D ) , [ 7 , 8 ] minimal ##ly invasive trans ##fo ##ram ##inal l ##umba ##r inter ##body fusion ( MI ##S - T ##L ##IF ) , [ 9 ] and per ##cut ##aneous end ##os ##copic l ##umba ##r disc ##ec ##tom ##y ( P ##EL ##D ) . [ 10 , 11 ] O ##LM has been regarded as the most commonly recommended surgical option for re ##current L ##D ##H ; [ 12 , 13 ] however , it was associated with several complications , including muscle damage , nerve re ##traction , and the removal of yellow l ##iga - men ##t , [ 14 , 15 ] which can result in instability and scar ##ring of the e ##pid ##ural space . [ 16 , 17 ] ME ##D uses a micro ##end ##os ##cope for visual ##iza - t ##ion , and the para ##sp ##ino ##us muscles are handled by muscle splitting through di ##lator ##s ; [ 18 ] thus , the muscle and soft tissue are minimal ##ly injured . [ 19 ] MI ##S - T ##L ##IF is a well - accepted operation method for re ##current L ##D ##H . And it has the advantages of less i ##at ##rogen ##ic soft tissue injury , lower risk of post ##oper ##ative r ##adi ##cu ##lit ##is , and decreased re ##traction of du ##ral sa ##c . [ 20 , 21 ] P ##EL ##D is a more minimal ##ly invasive surgery [SEP]\n",
      "INFO:tensorflow:token_to_orig_map: 11:0 12:0 13:0 14:1 15:2 16:2 17:2 18:3 19:3 20:3 21:3 22:3 23:4 24:5 25:6 26:7 27:8 28:9 29:10 30:11 31:12 32:13 33:14 34:15 35:16 36:17 37:18 38:19 39:20 40:21 41:22 42:22 43:22 44:22 45:22 46:22 47:22 48:22 49:22 50:22 51:22 52:23 53:24 54:25 55:26 56:27 57:27 58:27 59:28 60:29 61:30 62:31 63:32 64:33 65:34 66:35 67:36 68:37 69:37 70:38 71:39 72:40 73:41 74:42 75:43 76:44 77:45 78:46 79:47 80:48 81:49 82:50 83:51 84:52 85:52 86:52 87:52 88:52 89:52 90:52 91:53 92:54 93:55 94:56 95:57 96:58 97:58 98:59 99:60 100:60 101:60 102:61 103:61 104:62 105:62 106:62 107:62 108:63 109:63 110:63 111:63 112:63 113:63 114:63 115:63 116:64 117:64 118:64 119:64 120:65 121:65 122:65 123:65 124:66 125:66 126:66 127:66 128:66 129:66 130:66 131:66 132:66 133:66 134:67 135:67 136:68 137:69 138:69 139:69 140:69 141:70 142:70 143:70 144:71 145:71 146:72 147:73 148:73 149:73 150:73 151:74 152:74 153:74 154:74 155:74 156:74 157:74 158:74 159:75 160:76 161:76 162:76 163:77 164:77 165:77 166:78 167:78 168:78 169:79 170:79 171:79 172:79 173:80 174:80 175:80 176:80 177:80 178:80 179:80 180:80 181:80 182:80 183:80 184:81 185:81 186:82 187:83 188:84 189:85 190:86 191:87 192:88 193:89 194:90 195:91 196:92 197:93 198:93 199:94 200:94 201:94 202:94 203:94 204:94 205:94 206:94 207:94 208:95 209:95 210:96 211:97 212:98 213:99 214:100 215:101 216:101 217:102 218:103 219:104 220:104 221:105 222:106 223:106 224:106 225:107 226:108 227:109 228:110 229:111 230:112 231:112 232:112 233:113 234:113 235:113 236:113 237:113 238:113 239:113 240:113 241:114 242:115 243:116 244:117 245:118 246:119 247:120 248:120 249:121 250:122 251:123 252:123 253:123 254:124 255:124 256:124 257:124 258:124 259:124 260:124 261:125 262:125 263:126 264:127 265:128 266:128 267:128 268:128 269:129 270:130 271:130 272:130 273:131 274:131 275:131 276:132 277:133 278:134 279:134 280:134 281:134 282:135 283:136 284:137 285:138 286:139 287:140 288:141 289:142 290:142 291:142 292:142 293:142 294:142 295:142 296:143 297:143 298:144 299:145 300:146 301:147 302:148 303:149 304:150 305:150 306:151 307:151 308:151 309:151 310:151 311:152 312:152 313:152 314:152 315:152 316:152 317:153 318:154 319:155 320:155 321:155 322:156 323:157 324:158 325:159 326:159 327:160 328:160 329:160 330:160 331:161 332:162 333:163 334:164 335:165 336:166 337:167 338:168 339:168 340:168 341:168 342:169 343:170 344:171 345:171 346:172 347:173 348:174 349:175 350:175 351:175 352:176 353:176 354:176 355:176 356:176 357:176 358:177 359:178 360:179 361:179 362:180 363:181 364:181 365:182 366:182 367:182 368:182 369:182 370:182 371:182 372:182 373:183 374:183 375:183 376:184 377:185 378:186 379:187 380:187 381:188 382:189\n",
      "I1208 12:27:36.970529 139883775852736 run_factoid.py:445] token_to_orig_map: 11:0 12:0 13:0 14:1 15:2 16:2 17:2 18:3 19:3 20:3 21:3 22:3 23:4 24:5 25:6 26:7 27:8 28:9 29:10 30:11 31:12 32:13 33:14 34:15 35:16 36:17 37:18 38:19 39:20 40:21 41:22 42:22 43:22 44:22 45:22 46:22 47:22 48:22 49:22 50:22 51:22 52:23 53:24 54:25 55:26 56:27 57:27 58:27 59:28 60:29 61:30 62:31 63:32 64:33 65:34 66:35 67:36 68:37 69:37 70:38 71:39 72:40 73:41 74:42 75:43 76:44 77:45 78:46 79:47 80:48 81:49 82:50 83:51 84:52 85:52 86:52 87:52 88:52 89:52 90:52 91:53 92:54 93:55 94:56 95:57 96:58 97:58 98:59 99:60 100:60 101:60 102:61 103:61 104:62 105:62 106:62 107:62 108:63 109:63 110:63 111:63 112:63 113:63 114:63 115:63 116:64 117:64 118:64 119:64 120:65 121:65 122:65 123:65 124:66 125:66 126:66 127:66 128:66 129:66 130:66 131:66 132:66 133:66 134:67 135:67 136:68 137:69 138:69 139:69 140:69 141:70 142:70 143:70 144:71 145:71 146:72 147:73 148:73 149:73 150:73 151:74 152:74 153:74 154:74 155:74 156:74 157:74 158:74 159:75 160:76 161:76 162:76 163:77 164:77 165:77 166:78 167:78 168:78 169:79 170:79 171:79 172:79 173:80 174:80 175:80 176:80 177:80 178:80 179:80 180:80 181:80 182:80 183:80 184:81 185:81 186:82 187:83 188:84 189:85 190:86 191:87 192:88 193:89 194:90 195:91 196:92 197:93 198:93 199:94 200:94 201:94 202:94 203:94 204:94 205:94 206:94 207:94 208:95 209:95 210:96 211:97 212:98 213:99 214:100 215:101 216:101 217:102 218:103 219:104 220:104 221:105 222:106 223:106 224:106 225:107 226:108 227:109 228:110 229:111 230:112 231:112 232:112 233:113 234:113 235:113 236:113 237:113 238:113 239:113 240:113 241:114 242:115 243:116 244:117 245:118 246:119 247:120 248:120 249:121 250:122 251:123 252:123 253:123 254:124 255:124 256:124 257:124 258:124 259:124 260:124 261:125 262:125 263:126 264:127 265:128 266:128 267:128 268:128 269:129 270:130 271:130 272:130 273:131 274:131 275:131 276:132 277:133 278:134 279:134 280:134 281:134 282:135 283:136 284:137 285:138 286:139 287:140 288:141 289:142 290:142 291:142 292:142 293:142 294:142 295:142 296:143 297:143 298:144 299:145 300:146 301:147 302:148 303:149 304:150 305:150 306:151 307:151 308:151 309:151 310:151 311:152 312:152 313:152 314:152 315:152 316:152 317:153 318:154 319:155 320:155 321:155 322:156 323:157 324:158 325:159 326:159 327:160 328:160 329:160 330:160 331:161 332:162 333:163 334:164 335:165 336:166 337:167 338:168 339:168 340:168 341:168 342:169 343:170 344:171 345:171 346:172 347:173 348:174 349:175 350:175 351:175 352:176 353:176 354:176 355:176 356:176 357:176 358:177 359:178 360:179 361:179 362:180 363:181 364:181 365:182 366:182 367:182 368:182 369:182 370:182 371:182 372:182 373:183 374:183 375:183 376:184 377:185 378:186 379:187 380:187 381:188 382:189\n",
      "INFO:tensorflow:token_is_max_context: 11:True 12:True 13:True 14:True 15:True 16:True 17:True 18:True 19:True 20:True 21:True 22:True 23:True 24:True 25:True 26:True 27:True 28:True 29:True 30:True 31:True 32:True 33:True 34:True 35:True 36:True 37:True 38:True 39:True 40:True 41:True 42:True 43:True 44:True 45:True 46:True 47:True 48:True 49:True 50:True 51:True 52:True 53:True 54:True 55:True 56:True 57:True 58:True 59:True 60:True 61:True 62:True 63:True 64:True 65:True 66:True 67:True 68:True 69:True 70:True 71:True 72:True 73:True 74:True 75:True 76:True 77:True 78:True 79:True 80:True 81:True 82:True 83:True 84:True 85:True 86:True 87:True 88:True 89:True 90:True 91:True 92:True 93:True 94:True 95:True 96:True 97:True 98:True 99:True 100:True 101:True 102:True 103:True 104:True 105:True 106:True 107:True 108:True 109:True 110:True 111:True 112:True 113:True 114:True 115:True 116:True 117:True 118:True 119:True 120:True 121:True 122:True 123:True 124:True 125:True 126:True 127:True 128:True 129:True 130:True 131:True 132:True 133:True 134:True 135:True 136:True 137:True 138:True 139:True 140:True 141:True 142:True 143:True 144:True 145:True 146:True 147:True 148:True 149:True 150:True 151:True 152:True 153:True 154:True 155:True 156:True 157:True 158:True 159:True 160:True 161:True 162:True 163:True 164:True 165:True 166:True 167:True 168:True 169:True 170:True 171:True 172:True 173:True 174:True 175:True 176:True 177:True 178:True 179:True 180:True 181:True 182:True 183:True 184:True 185:True 186:True 187:True 188:True 189:True 190:True 191:True 192:True 193:True 194:True 195:True 196:True 197:True 198:True 199:True 200:True 201:True 202:True 203:True 204:True 205:True 206:True 207:True 208:True 209:True 210:True 211:True 212:True 213:True 214:True 215:True 216:True 217:True 218:True 219:True 220:True 221:True 222:True 223:True 224:True 225:True 226:True 227:True 228:True 229:True 230:True 231:True 232:True 233:True 234:True 235:True 236:True 237:True 238:True 239:True 240:True 241:True 242:True 243:True 244:True 245:True 246:True 247:True 248:True 249:True 250:True 251:True 252:True 253:True 254:True 255:True 256:True 257:True 258:True 259:True 260:True 261:False 262:False 263:False 264:False 265:False 266:False 267:False 268:False 269:False 270:False 271:False 272:False 273:False 274:False 275:False 276:False 277:False 278:False 279:False 280:False 281:False 282:False 283:False 284:False 285:False 286:False 287:False 288:False 289:False 290:False 291:False 292:False 293:False 294:False 295:False 296:False 297:False 298:False 299:False 300:False 301:False 302:False 303:False 304:False 305:False 306:False 307:False 308:False 309:False 310:False 311:False 312:False 313:False 314:False 315:False 316:False 317:False 318:False 319:False 320:False 321:False 322:False 323:False 324:False 325:False 326:False 327:False 328:False 329:False 330:False 331:False 332:False 333:False 334:False 335:False 336:False 337:False 338:False 339:False 340:False 341:False 342:False 343:False 344:False 345:False 346:False 347:False 348:False 349:False 350:False 351:False 352:False 353:False 354:False 355:False 356:False 357:False 358:False 359:False 360:False 361:False 362:False 363:False 364:False 365:False 366:False 367:False 368:False 369:False 370:False 371:False 372:False 373:False 374:False 375:False 376:False 377:False 378:False 379:False 380:False 381:False 382:False\n",
      "I1208 12:27:36.970638 139883775852736 run_factoid.py:447] token_is_max_context: 11:True 12:True 13:True 14:True 15:True 16:True 17:True 18:True 19:True 20:True 21:True 22:True 23:True 24:True 25:True 26:True 27:True 28:True 29:True 30:True 31:True 32:True 33:True 34:True 35:True 36:True 37:True 38:True 39:True 40:True 41:True 42:True 43:True 44:True 45:True 46:True 47:True 48:True 49:True 50:True 51:True 52:True 53:True 54:True 55:True 56:True 57:True 58:True 59:True 60:True 61:True 62:True 63:True 64:True 65:True 66:True 67:True 68:True 69:True 70:True 71:True 72:True 73:True 74:True 75:True 76:True 77:True 78:True 79:True 80:True 81:True 82:True 83:True 84:True 85:True 86:True 87:True 88:True 89:True 90:True 91:True 92:True 93:True 94:True 95:True 96:True 97:True 98:True 99:True 100:True 101:True 102:True 103:True 104:True 105:True 106:True 107:True 108:True 109:True 110:True 111:True 112:True 113:True 114:True 115:True 116:True 117:True 118:True 119:True 120:True 121:True 122:True 123:True 124:True 125:True 126:True 127:True 128:True 129:True 130:True 131:True 132:True 133:True 134:True 135:True 136:True 137:True 138:True 139:True 140:True 141:True 142:True 143:True 144:True 145:True 146:True 147:True 148:True 149:True 150:True 151:True 152:True 153:True 154:True 155:True 156:True 157:True 158:True 159:True 160:True 161:True 162:True 163:True 164:True 165:True 166:True 167:True 168:True 169:True 170:True 171:True 172:True 173:True 174:True 175:True 176:True 177:True 178:True 179:True 180:True 181:True 182:True 183:True 184:True 185:True 186:True 187:True 188:True 189:True 190:True 191:True 192:True 193:True 194:True 195:True 196:True 197:True 198:True 199:True 200:True 201:True 202:True 203:True 204:True 205:True 206:True 207:True 208:True 209:True 210:True 211:True 212:True 213:True 214:True 215:True 216:True 217:True 218:True 219:True 220:True 221:True 222:True 223:True 224:True 225:True 226:True 227:True 228:True 229:True 230:True 231:True 232:True 233:True 234:True 235:True 236:True 237:True 238:True 239:True 240:True 241:True 242:True 243:True 244:True 245:True 246:True 247:True 248:True 249:True 250:True 251:True 252:True 253:True 254:True 255:True 256:True 257:True 258:True 259:True 260:True 261:False 262:False 263:False 264:False 265:False 266:False 267:False 268:False 269:False 270:False 271:False 272:False 273:False 274:False 275:False 276:False 277:False 278:False 279:False 280:False 281:False 282:False 283:False 284:False 285:False 286:False 287:False 288:False 289:False 290:False 291:False 292:False 293:False 294:False 295:False 296:False 297:False 298:False 299:False 300:False 301:False 302:False 303:False 304:False 305:False 306:False 307:False 308:False 309:False 310:False 311:False 312:False 313:False 314:False 315:False 316:False 317:False 318:False 319:False 320:False 321:False 322:False 323:False 324:False 325:False 326:False 327:False 328:False 329:False 330:False 331:False 332:False 333:False 334:False 335:False 336:False 337:False 338:False 339:False 340:False 341:False 342:False 343:False 344:False 345:False 346:False 347:False 348:False 349:False 350:False 351:False 352:False 353:False 354:False 355:False 356:False 357:False 358:False 359:False 360:False 361:False 362:False 363:False 364:False 365:False 366:False 367:False 368:False 369:False 370:False 371:False 372:False 373:False 374:False 375:False 376:False 377:False 378:False 379:False 380:False 381:False 382:False\n",
      "INFO:tensorflow:input_ids: 101 1327 1225 1103 2526 1328 1106 1525 1149 136 102 14557 10806 1197 6187 1123 5813 2116 113 149 2137 3048 114 1110 1141 1104 1103 1211 3933 11534 4680 1104 1822 1171 2489 1105 1110 170 1887 2612 1104 187 14230 10182 13200 23610 119 164 122 782 124 166 1966 1211 4420 1114 149 2137 3048 1169 5515 18330 7300 1105 8458 13950 1114 6588 3252 117 170 1374 4420 1202 1136 6297 5877 1106 6588 3252 1105 2028 4752 13467 3252 119 164 125 117 126 166 1247 1132 1317 1514 13467 6665 131 1501 181 25509 1197 17599 118 6187 10294 18778 1183 113 152 22074 114 117 164 127 166 17599 6696 2155 22258 6187 10294 18778 1183 113 22157 2137 114 117 164 128 117 129 166 10298 1193 19849 14715 14467 4515 14196 181 25509 1197 9455 14637 11970 113 26574 1708 118 157 2162 15499 114 117 164 130 166 1105 1679 12734 13064 1322 2155 22258 181 25509 1197 6187 10294 18778 1183 113 153 21678 2137 114 119 164 1275 117 1429 166 152 22074 1144 1151 4485 1112 1103 1211 3337 6315 13467 5146 1111 1231 21754 149 2137 3048 132 164 1367 117 1492 166 1649 117 1122 1108 2628 1114 1317 13522 117 1259 6484 3290 117 9071 1231 27539 117 1105 1103 8116 1104 3431 181 13499 118 1441 1204 117 164 1489 117 1405 166 1134 1169 1871 1107 20482 1105 14161 3384 1104 1103 174 25786 12602 2000 119 164 1479 117 1542 166 22157 2137 2745 170 17599 6696 2155 16260 1111 5173 23228 118 189 1988 117 1105 1103 18311 20080 4559 1361 6130 1132 8630 1118 6484 15601 1194 4267 13389 1116 132 164 1407 166 2456 117 1103 6484 1105 2991 7918 1132 10298 1193 4475 119 164 1627 166 26574 1708 118 157 2162 15499 1110 170 1218 118 3134 2805 3442 1111 1231 21754 149 2137 3048 119 1262 1122 1144 1103 13300 1104 1750 178 2980 26767 1596 2991 7918 3773 117 2211 3187 1104 2112 19807 5838 187 14230 10182 12888 1548 117 1105 10558 1231 27539 1104 3840 4412 21718 1665 119 164 1406 117 1626 166 153 21678 2137 1110 170 1167 10298 1193 19849 6059 102\n",
      "I1208 12:27:36.970752 139883775852736 run_factoid.py:449] input_ids: 101 1327 1225 1103 2526 1328 1106 1525 1149 136 102 14557 10806 1197 6187 1123 5813 2116 113 149 2137 3048 114 1110 1141 1104 1103 1211 3933 11534 4680 1104 1822 1171 2489 1105 1110 170 1887 2612 1104 187 14230 10182 13200 23610 119 164 122 782 124 166 1966 1211 4420 1114 149 2137 3048 1169 5515 18330 7300 1105 8458 13950 1114 6588 3252 117 170 1374 4420 1202 1136 6297 5877 1106 6588 3252 1105 2028 4752 13467 3252 119 164 125 117 126 166 1247 1132 1317 1514 13467 6665 131 1501 181 25509 1197 17599 118 6187 10294 18778 1183 113 152 22074 114 117 164 127 166 17599 6696 2155 22258 6187 10294 18778 1183 113 22157 2137 114 117 164 128 117 129 166 10298 1193 19849 14715 14467 4515 14196 181 25509 1197 9455 14637 11970 113 26574 1708 118 157 2162 15499 114 117 164 130 166 1105 1679 12734 13064 1322 2155 22258 181 25509 1197 6187 10294 18778 1183 113 153 21678 2137 114 119 164 1275 117 1429 166 152 22074 1144 1151 4485 1112 1103 1211 3337 6315 13467 5146 1111 1231 21754 149 2137 3048 132 164 1367 117 1492 166 1649 117 1122 1108 2628 1114 1317 13522 117 1259 6484 3290 117 9071 1231 27539 117 1105 1103 8116 1104 3431 181 13499 118 1441 1204 117 164 1489 117 1405 166 1134 1169 1871 1107 20482 1105 14161 3384 1104 1103 174 25786 12602 2000 119 164 1479 117 1542 166 22157 2137 2745 170 17599 6696 2155 16260 1111 5173 23228 118 189 1988 117 1105 1103 18311 20080 4559 1361 6130 1132 8630 1118 6484 15601 1194 4267 13389 1116 132 164 1407 166 2456 117 1103 6484 1105 2991 7918 1132 10298 1193 4475 119 164 1627 166 26574 1708 118 157 2162 15499 1110 170 1218 118 3134 2805 3442 1111 1231 21754 149 2137 3048 119 1262 1122 1144 1103 13300 1104 1750 178 2980 26767 1596 2991 7918 3773 117 2211 3187 1104 2112 19807 5838 187 14230 10182 12888 1548 117 1105 10558 1231 27539 1104 3840 4412 21718 1665 119 164 1406 117 1626 166 153 21678 2137 1110 170 1167 10298 1193 19849 6059 102\n",
      "INFO:tensorflow:input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      "I1208 12:27:36.970843 139883775852736 run_factoid.py:451] input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      "INFO:tensorflow:segment_ids: 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      "I1208 12:27:36.970932 139883775852736 run_factoid.py:453] segment_ids: 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      "INFO:tensorflow:*** Example ***\n",
      "I1208 12:27:36.971890 139883775852736 run_factoid.py:438] *** Example ***\n",
      "INFO:tensorflow:unique_id: 1000000001\n",
      "I1208 12:27:36.971952 139883775852736 run_factoid.py:439] unique_id: 1000000001\n",
      "INFO:tensorflow:example_index: 0\n",
      "I1208 12:27:36.971990 139883775852736 run_factoid.py:440] example_index: 0\n",
      "INFO:tensorflow:doc_span_index: 1\n",
      "I1208 12:27:36.972024 139883775852736 run_factoid.py:441] doc_span_index: 1\n",
      "INFO:tensorflow:tokens: [CLS] What did the paper want to find out ? [SEP] ##ram ##inal l ##umba ##r inter ##body fusion ( MI ##S - T ##L ##IF ) , [ 9 ] and per ##cut ##aneous end ##os ##copic l ##umba ##r disc ##ec ##tom ##y ( P ##EL ##D ) . [ 10 , 11 ] O ##LM has been regarded as the most commonly recommended surgical option for re ##current L ##D ##H ; [ 12 , 13 ] however , it was associated with several complications , including muscle damage , nerve re ##traction , and the removal of yellow l ##iga - men ##t , [ 14 , 15 ] which can result in instability and scar ##ring of the e ##pid ##ural space . [ 16 , 17 ] ME ##D uses a micro ##end ##os ##cope for visual ##iza - t ##ion , and the para ##sp ##ino ##us muscles are handled by muscle splitting through di ##lator ##s ; [ 18 ] thus , the muscle and soft tissue are minimal ##ly injured . [ 19 ] MI ##S - T ##L ##IF is a well - accepted operation method for re ##current L ##D ##H . And it has the advantages of less i ##at ##rogen ##ic soft tissue injury , lower risk of post ##oper ##ative r ##adi ##cu ##lit ##is , and decreased re ##traction of du ##ral sa ##c . [ 20 , 21 ] P ##EL ##D is a more minimal ##ly invasive surgery because the posterior column structures are pre - served . [ 22 , 23 ] It has gained interest for its potential advantage in the reduced risk of face ##t joints injury , fewer post ##oper ##ative complications , a shorter hospital stay and lower cost . [ 24 , 25 ] Previous studies have reported that P ##EL ##D is an effective and safe treatment for L ##D ##H . [ 26 , 27 ] However , whether P ##EL ##D is superior to other surgical options remains controversial . Thus , we conducted this meta - analysis to compare the clinical , radio ##log ##ic , and complications of P ##EL ##D and other surge ##ries for patients with L ##D ##H . [SEP]\n",
      "I1208 12:27:36.972135 139883775852736 run_factoid.py:443] tokens: [CLS] What did the paper want to find out ? [SEP] ##ram ##inal l ##umba ##r inter ##body fusion ( MI ##S - T ##L ##IF ) , [ 9 ] and per ##cut ##aneous end ##os ##copic l ##umba ##r disc ##ec ##tom ##y ( P ##EL ##D ) . [ 10 , 11 ] O ##LM has been regarded as the most commonly recommended surgical option for re ##current L ##D ##H ; [ 12 , 13 ] however , it was associated with several complications , including muscle damage , nerve re ##traction , and the removal of yellow l ##iga - men ##t , [ 14 , 15 ] which can result in instability and scar ##ring of the e ##pid ##ural space . [ 16 , 17 ] ME ##D uses a micro ##end ##os ##cope for visual ##iza - t ##ion , and the para ##sp ##ino ##us muscles are handled by muscle splitting through di ##lator ##s ; [ 18 ] thus , the muscle and soft tissue are minimal ##ly injured . [ 19 ] MI ##S - T ##L ##IF is a well - accepted operation method for re ##current L ##D ##H . And it has the advantages of less i ##at ##rogen ##ic soft tissue injury , lower risk of post ##oper ##ative r ##adi ##cu ##lit ##is , and decreased re ##traction of du ##ral sa ##c . [ 20 , 21 ] P ##EL ##D is a more minimal ##ly invasive surgery because the posterior column structures are pre - served . [ 22 , 23 ] It has gained interest for its potential advantage in the reduced risk of face ##t joints injury , fewer post ##oper ##ative complications , a shorter hospital stay and lower cost . [ 24 , 25 ] Previous studies have reported that P ##EL ##D is an effective and safe treatment for L ##D ##H . [ 26 , 27 ] However , whether P ##EL ##D is superior to other surgical options remains controversial . Thus , we conducted this meta - analysis to compare the clinical , radio ##log ##ic , and complications of P ##EL ##D and other surge ##ries for patients with L ##D ##H . [SEP]\n",
      "INFO:tensorflow:token_to_orig_map: 11:69 12:69 13:70 14:70 15:70 16:71 17:71 18:72 19:73 20:73 21:73 22:73 23:74 24:74 25:74 26:74 27:74 28:74 29:74 30:74 31:75 32:76 33:76 34:76 35:77 36:77 37:77 38:78 39:78 40:78 41:79 42:79 43:79 44:79 45:80 46:80 47:80 48:80 49:80 50:80 51:80 52:80 53:80 54:80 55:80 56:81 57:81 58:82 59:83 60:84 61:85 62:86 63:87 64:88 65:89 66:90 67:91 68:92 69:93 70:93 71:94 72:94 73:94 74:94 75:94 76:94 77:94 78:94 79:94 80:95 81:95 82:96 83:97 84:98 85:99 86:100 87:101 88:101 89:102 90:103 91:104 92:104 93:105 94:106 95:106 96:106 97:107 98:108 99:109 100:110 101:111 102:112 103:112 104:112 105:113 106:113 107:113 108:113 109:113 110:113 111:113 112:113 113:114 114:115 115:116 116:117 117:118 118:119 119:120 120:120 121:121 122:122 123:123 124:123 125:123 126:124 127:124 128:124 129:124 130:124 131:124 132:124 133:125 134:125 135:126 136:127 137:128 138:128 139:128 140:128 141:129 142:130 143:130 144:130 145:131 146:131 147:131 148:132 149:133 150:134 151:134 152:134 153:134 154:135 155:136 156:137 157:138 158:139 159:140 160:141 161:142 162:142 163:142 164:142 165:142 166:142 167:142 168:143 169:143 170:144 171:145 172:146 173:147 174:148 175:149 176:150 177:150 178:151 179:151 180:151 181:151 182:151 183:152 184:152 185:152 186:152 187:152 188:152 189:153 190:154 191:155 192:155 193:155 194:156 195:157 196:158 197:159 198:159 199:160 200:160 201:160 202:160 203:161 204:162 205:163 206:164 207:165 208:166 209:167 210:168 211:168 212:168 213:168 214:169 215:170 216:171 217:171 218:172 219:173 220:174 221:175 222:175 223:175 224:176 225:176 226:176 227:176 228:176 229:176 230:177 231:178 232:179 233:179 234:180 235:181 236:181 237:182 238:182 239:182 240:182 241:182 242:182 243:182 244:182 245:183 246:183 247:183 248:184 249:185 250:186 251:187 252:187 253:188 254:189 255:190 256:191 257:192 258:193 259:194 260:195 261:196 262:196 263:197 264:197 265:197 266:197 267:197 268:197 269:197 270:198 271:199 272:200 273:201 274:202 275:203 276:204 277:205 278:206 279:207 280:208 281:209 282:210 283:211 284:211 285:212 286:213 287:213 288:214 289:215 290:215 291:215 292:216 293:216 294:217 295:218 296:219 297:220 298:221 299:222 300:223 301:223 302:223 303:223 304:223 305:223 306:223 307:224 308:225 309:226 310:227 311:228 312:229 313:229 314:229 315:230 316:231 317:232 318:233 319:234 320:235 321:236 322:237 323:237 324:237 325:237 326:237 327:237 328:237 329:237 330:237 331:238 332:238 333:239 334:240 335:240 336:240 337:241 338:242 339:243 340:244 341:245 342:246 343:247 344:248 345:248 346:249 347:249 348:250 349:251 350:252 351:253 352:253 353:253 354:254 355:255 356:256 357:257 358:257 359:258 360:258 361:258 362:258 363:259 364:260 365:261 366:262 367:262 368:262 369:263 370:264 371:265 372:265 373:266 374:267 375:268 376:269 377:269 378:269 379:269\n",
      "I1208 12:27:36.972247 139883775852736 run_factoid.py:445] token_to_orig_map: 11:69 12:69 13:70 14:70 15:70 16:71 17:71 18:72 19:73 20:73 21:73 22:73 23:74 24:74 25:74 26:74 27:74 28:74 29:74 30:74 31:75 32:76 33:76 34:76 35:77 36:77 37:77 38:78 39:78 40:78 41:79 42:79 43:79 44:79 45:80 46:80 47:80 48:80 49:80 50:80 51:80 52:80 53:80 54:80 55:80 56:81 57:81 58:82 59:83 60:84 61:85 62:86 63:87 64:88 65:89 66:90 67:91 68:92 69:93 70:93 71:94 72:94 73:94 74:94 75:94 76:94 77:94 78:94 79:94 80:95 81:95 82:96 83:97 84:98 85:99 86:100 87:101 88:101 89:102 90:103 91:104 92:104 93:105 94:106 95:106 96:106 97:107 98:108 99:109 100:110 101:111 102:112 103:112 104:112 105:113 106:113 107:113 108:113 109:113 110:113 111:113 112:113 113:114 114:115 115:116 116:117 117:118 118:119 119:120 120:120 121:121 122:122 123:123 124:123 125:123 126:124 127:124 128:124 129:124 130:124 131:124 132:124 133:125 134:125 135:126 136:127 137:128 138:128 139:128 140:128 141:129 142:130 143:130 144:130 145:131 146:131 147:131 148:132 149:133 150:134 151:134 152:134 153:134 154:135 155:136 156:137 157:138 158:139 159:140 160:141 161:142 162:142 163:142 164:142 165:142 166:142 167:142 168:143 169:143 170:144 171:145 172:146 173:147 174:148 175:149 176:150 177:150 178:151 179:151 180:151 181:151 182:151 183:152 184:152 185:152 186:152 187:152 188:152 189:153 190:154 191:155 192:155 193:155 194:156 195:157 196:158 197:159 198:159 199:160 200:160 201:160 202:160 203:161 204:162 205:163 206:164 207:165 208:166 209:167 210:168 211:168 212:168 213:168 214:169 215:170 216:171 217:171 218:172 219:173 220:174 221:175 222:175 223:175 224:176 225:176 226:176 227:176 228:176 229:176 230:177 231:178 232:179 233:179 234:180 235:181 236:181 237:182 238:182 239:182 240:182 241:182 242:182 243:182 244:182 245:183 246:183 247:183 248:184 249:185 250:186 251:187 252:187 253:188 254:189 255:190 256:191 257:192 258:193 259:194 260:195 261:196 262:196 263:197 264:197 265:197 266:197 267:197 268:197 269:197 270:198 271:199 272:200 273:201 274:202 275:203 276:204 277:205 278:206 279:207 280:208 281:209 282:210 283:211 284:211 285:212 286:213 287:213 288:214 289:215 290:215 291:215 292:216 293:216 294:217 295:218 296:219 297:220 298:221 299:222 300:223 301:223 302:223 303:223 304:223 305:223 306:223 307:224 308:225 309:226 310:227 311:228 312:229 313:229 314:229 315:230 316:231 317:232 318:233 319:234 320:235 321:236 322:237 323:237 324:237 325:237 326:237 327:237 328:237 329:237 330:237 331:238 332:238 333:239 334:240 335:240 336:240 337:241 338:242 339:243 340:244 341:245 342:246 343:247 344:248 345:248 346:249 347:249 348:250 349:251 350:252 351:253 352:253 353:253 354:254 355:255 356:256 357:257 358:257 359:258 360:258 361:258 362:258 363:259 364:260 365:261 366:262 367:262 368:262 369:263 370:264 371:265 372:265 373:266 374:267 375:268 376:269 377:269 378:269 379:269\n",
      "INFO:tensorflow:token_is_max_context: 11:False 12:False 13:False 14:False 15:False 16:False 17:False 18:False 19:False 20:False 21:False 22:False 23:False 24:False 25:False 26:False 27:False 28:False 29:False 30:False 31:False 32:False 33:False 34:False 35:False 36:False 37:False 38:False 39:False 40:False 41:False 42:False 43:False 44:False 45:False 46:False 47:False 48:False 49:False 50:False 51:False 52:False 53:False 54:False 55:False 56:False 57:False 58:False 59:False 60:False 61:False 62:False 63:False 64:False 65:False 66:False 67:False 68:False 69:False 70:False 71:False 72:False 73:False 74:False 75:False 76:False 77:False 78:False 79:False 80:False 81:False 82:False 83:False 84:False 85:False 86:False 87:False 88:False 89:False 90:False 91:False 92:False 93:False 94:False 95:False 96:False 97:False 98:False 99:False 100:False 101:False 102:False 103:False 104:False 105:False 106:False 107:False 108:False 109:False 110:False 111:False 112:False 113:False 114:False 115:False 116:False 117:False 118:False 119:False 120:False 121:False 122:False 123:False 124:False 125:False 126:False 127:False 128:False 129:False 130:False 131:False 132:False 133:True 134:True 135:True 136:True 137:True 138:True 139:True 140:True 141:True 142:True 143:True 144:True 145:True 146:True 147:True 148:True 149:True 150:True 151:True 152:True 153:True 154:True 155:True 156:True 157:True 158:True 159:True 160:True 161:True 162:True 163:True 164:True 165:True 166:True 167:True 168:True 169:True 170:True 171:True 172:True 173:True 174:True 175:True 176:True 177:True 178:True 179:True 180:True 181:True 182:True 183:True 184:True 185:True 186:True 187:True 188:True 189:True 190:True 191:True 192:True 193:True 194:True 195:True 196:True 197:True 198:True 199:True 200:True 201:True 202:True 203:True 204:True 205:True 206:True 207:True 208:True 209:True 210:True 211:True 212:True 213:True 214:True 215:True 216:True 217:True 218:True 219:True 220:True 221:True 222:True 223:True 224:True 225:True 226:True 227:True 228:True 229:True 230:True 231:True 232:True 233:True 234:True 235:True 236:True 237:True 238:True 239:True 240:True 241:True 242:True 243:True 244:True 245:True 246:True 247:True 248:True 249:True 250:True 251:True 252:True 253:True 254:True 255:True 256:True 257:True 258:True 259:True 260:True 261:True 262:True 263:True 264:True 265:True 266:True 267:True 268:True 269:True 270:True 271:True 272:True 273:True 274:True 275:True 276:True 277:True 278:True 279:True 280:True 281:True 282:True 283:True 284:True 285:True 286:True 287:True 288:True 289:True 290:True 291:True 292:True 293:True 294:True 295:True 296:True 297:True 298:True 299:True 300:True 301:True 302:True 303:True 304:True 305:True 306:True 307:True 308:True 309:True 310:True 311:True 312:True 313:True 314:True 315:True 316:True 317:True 318:True 319:True 320:True 321:True 322:True 323:True 324:True 325:True 326:True 327:True 328:True 329:True 330:True 331:True 332:True 333:True 334:True 335:True 336:True 337:True 338:True 339:True 340:True 341:True 342:True 343:True 344:True 345:True 346:True 347:True 348:True 349:True 350:True 351:True 352:True 353:True 354:True 355:True 356:True 357:True 358:True 359:True 360:True 361:True 362:True 363:True 364:True 365:True 366:True 367:True 368:True 369:True 370:True 371:True 372:True 373:True 374:True 375:True 376:True 377:True 378:True 379:True\n",
      "I1208 12:27:36.972355 139883775852736 run_factoid.py:447] token_is_max_context: 11:False 12:False 13:False 14:False 15:False 16:False 17:False 18:False 19:False 20:False 21:False 22:False 23:False 24:False 25:False 26:False 27:False 28:False 29:False 30:False 31:False 32:False 33:False 34:False 35:False 36:False 37:False 38:False 39:False 40:False 41:False 42:False 43:False 44:False 45:False 46:False 47:False 48:False 49:False 50:False 51:False 52:False 53:False 54:False 55:False 56:False 57:False 58:False 59:False 60:False 61:False 62:False 63:False 64:False 65:False 66:False 67:False 68:False 69:False 70:False 71:False 72:False 73:False 74:False 75:False 76:False 77:False 78:False 79:False 80:False 81:False 82:False 83:False 84:False 85:False 86:False 87:False 88:False 89:False 90:False 91:False 92:False 93:False 94:False 95:False 96:False 97:False 98:False 99:False 100:False 101:False 102:False 103:False 104:False 105:False 106:False 107:False 108:False 109:False 110:False 111:False 112:False 113:False 114:False 115:False 116:False 117:False 118:False 119:False 120:False 121:False 122:False 123:False 124:False 125:False 126:False 127:False 128:False 129:False 130:False 131:False 132:False 133:True 134:True 135:True 136:True 137:True 138:True 139:True 140:True 141:True 142:True 143:True 144:True 145:True 146:True 147:True 148:True 149:True 150:True 151:True 152:True 153:True 154:True 155:True 156:True 157:True 158:True 159:True 160:True 161:True 162:True 163:True 164:True 165:True 166:True 167:True 168:True 169:True 170:True 171:True 172:True 173:True 174:True 175:True 176:True 177:True 178:True 179:True 180:True 181:True 182:True 183:True 184:True 185:True 186:True 187:True 188:True 189:True 190:True 191:True 192:True 193:True 194:True 195:True 196:True 197:True 198:True 199:True 200:True 201:True 202:True 203:True 204:True 205:True 206:True 207:True 208:True 209:True 210:True 211:True 212:True 213:True 214:True 215:True 216:True 217:True 218:True 219:True 220:True 221:True 222:True 223:True 224:True 225:True 226:True 227:True 228:True 229:True 230:True 231:True 232:True 233:True 234:True 235:True 236:True 237:True 238:True 239:True 240:True 241:True 242:True 243:True 244:True 245:True 246:True 247:True 248:True 249:True 250:True 251:True 252:True 253:True 254:True 255:True 256:True 257:True 258:True 259:True 260:True 261:True 262:True 263:True 264:True 265:True 266:True 267:True 268:True 269:True 270:True 271:True 272:True 273:True 274:True 275:True 276:True 277:True 278:True 279:True 280:True 281:True 282:True 283:True 284:True 285:True 286:True 287:True 288:True 289:True 290:True 291:True 292:True 293:True 294:True 295:True 296:True 297:True 298:True 299:True 300:True 301:True 302:True 303:True 304:True 305:True 306:True 307:True 308:True 309:True 310:True 311:True 312:True 313:True 314:True 315:True 316:True 317:True 318:True 319:True 320:True 321:True 322:True 323:True 324:True 325:True 326:True 327:True 328:True 329:True 330:True 331:True 332:True 333:True 334:True 335:True 336:True 337:True 338:True 339:True 340:True 341:True 342:True 343:True 344:True 345:True 346:True 347:True 348:True 349:True 350:True 351:True 352:True 353:True 354:True 355:True 356:True 357:True 358:True 359:True 360:True 361:True 362:True 363:True 364:True 365:True 366:True 367:True 368:True 369:True 370:True 371:True 372:True 373:True 374:True 375:True 376:True 377:True 378:True 379:True\n",
      "INFO:tensorflow:input_ids: 101 1327 1225 1103 2526 1328 1106 1525 1149 136 102 4515 14196 181 25509 1197 9455 14637 11970 113 26574 1708 118 157 2162 15499 114 117 164 130 166 1105 1679 12734 13064 1322 2155 22258 181 25509 1197 6187 10294 18778 1183 113 153 21678 2137 114 119 164 1275 117 1429 166 152 22074 1144 1151 4485 1112 1103 1211 3337 6315 13467 5146 1111 1231 21754 149 2137 3048 132 164 1367 117 1492 166 1649 117 1122 1108 2628 1114 1317 13522 117 1259 6484 3290 117 9071 1231 27539 117 1105 1103 8116 1104 3431 181 13499 118 1441 1204 117 164 1489 117 1405 166 1134 1169 1871 1107 20482 1105 14161 3384 1104 1103 174 25786 12602 2000 119 164 1479 117 1542 166 22157 2137 2745 170 17599 6696 2155 16260 1111 5173 23228 118 189 1988 117 1105 1103 18311 20080 4559 1361 6130 1132 8630 1118 6484 15601 1194 4267 13389 1116 132 164 1407 166 2456 117 1103 6484 1105 2991 7918 1132 10298 1193 4475 119 164 1627 166 26574 1708 118 157 2162 15499 1110 170 1218 118 3134 2805 3442 1111 1231 21754 149 2137 3048 119 1262 1122 1144 1103 13300 1104 1750 178 2980 26767 1596 2991 7918 3773 117 2211 3187 1104 2112 19807 5838 187 14230 10182 12888 1548 117 1105 10558 1231 27539 1104 3840 4412 21718 1665 119 164 1406 117 1626 166 153 21678 2137 1110 170 1167 10298 1193 19849 6059 1272 1103 16530 5551 4413 1132 3073 118 1462 119 164 1659 117 1695 166 1135 1144 3388 2199 1111 1157 3209 4316 1107 1103 3549 3187 1104 1339 1204 19365 3773 117 8307 2112 19807 5838 13522 117 170 7681 2704 2215 1105 2211 2616 119 164 1572 117 1512 166 24142 2527 1138 2103 1115 153 21678 2137 1110 1126 3903 1105 2914 3252 1111 149 2137 3048 119 164 1744 117 1765 166 1438 117 2480 153 21678 2137 1110 7298 1106 1168 13467 6665 2606 6241 119 4516 117 1195 3303 1142 27154 118 3622 1106 14133 1103 7300 117 2070 13791 1596 117 1105 13522 1104 153 21678 2137 1105 1168 12814 3377 1111 4420 1114 149 2137 3048 119 102 0 0 0\n",
      "I1208 12:27:36.972460 139883775852736 run_factoid.py:449] input_ids: 101 1327 1225 1103 2526 1328 1106 1525 1149 136 102 4515 14196 181 25509 1197 9455 14637 11970 113 26574 1708 118 157 2162 15499 114 117 164 130 166 1105 1679 12734 13064 1322 2155 22258 181 25509 1197 6187 10294 18778 1183 113 153 21678 2137 114 119 164 1275 117 1429 166 152 22074 1144 1151 4485 1112 1103 1211 3337 6315 13467 5146 1111 1231 21754 149 2137 3048 132 164 1367 117 1492 166 1649 117 1122 1108 2628 1114 1317 13522 117 1259 6484 3290 117 9071 1231 27539 117 1105 1103 8116 1104 3431 181 13499 118 1441 1204 117 164 1489 117 1405 166 1134 1169 1871 1107 20482 1105 14161 3384 1104 1103 174 25786 12602 2000 119 164 1479 117 1542 166 22157 2137 2745 170 17599 6696 2155 16260 1111 5173 23228 118 189 1988 117 1105 1103 18311 20080 4559 1361 6130 1132 8630 1118 6484 15601 1194 4267 13389 1116 132 164 1407 166 2456 117 1103 6484 1105 2991 7918 1132 10298 1193 4475 119 164 1627 166 26574 1708 118 157 2162 15499 1110 170 1218 118 3134 2805 3442 1111 1231 21754 149 2137 3048 119 1262 1122 1144 1103 13300 1104 1750 178 2980 26767 1596 2991 7918 3773 117 2211 3187 1104 2112 19807 5838 187 14230 10182 12888 1548 117 1105 10558 1231 27539 1104 3840 4412 21718 1665 119 164 1406 117 1626 166 153 21678 2137 1110 170 1167 10298 1193 19849 6059 1272 1103 16530 5551 4413 1132 3073 118 1462 119 164 1659 117 1695 166 1135 1144 3388 2199 1111 1157 3209 4316 1107 1103 3549 3187 1104 1339 1204 19365 3773 117 8307 2112 19807 5838 13522 117 170 7681 2704 2215 1105 2211 2616 119 164 1572 117 1512 166 24142 2527 1138 2103 1115 153 21678 2137 1110 1126 3903 1105 2914 3252 1111 149 2137 3048 119 164 1744 117 1765 166 1438 117 2480 153 21678 2137 1110 7298 1106 1168 13467 6665 2606 6241 119 4516 117 1195 3303 1142 27154 118 3622 1106 14133 1103 7300 117 2070 13791 1596 117 1105 13522 1104 153 21678 2137 1105 1168 12814 3377 1111 4420 1114 149 2137 3048 119 102 0 0 0\n",
      "INFO:tensorflow:input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0\n",
      "I1208 12:27:36.972550 139883775852736 run_factoid.py:451] input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0\n",
      "INFO:tensorflow:segment_ids: 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0\n",
      "I1208 12:27:36.972652 139883775852736 run_factoid.py:453] segment_ids: 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0\n",
      "INFO:tensorflow:*** Example ***\n",
      "I1208 12:27:36.978307 139883775852736 run_factoid.py:438] *** Example ***\n",
      "INFO:tensorflow:unique_id: 1000000002\n",
      "I1208 12:27:36.978406 139883775852736 run_factoid.py:439] unique_id: 1000000002\n",
      "INFO:tensorflow:example_index: 1\n",
      "I1208 12:27:36.978447 139883775852736 run_factoid.py:440] example_index: 1\n",
      "INFO:tensorflow:doc_span_index: 0\n",
      "I1208 12:27:36.978482 139883775852736 run_factoid.py:441] doc_span_index: 0\n",
      "INFO:tensorflow:tokens: [CLS] What condition does the paper study ? [SEP] Lu ##mba ##r disc her ##nia ##tion ( L ##D ##H ) is one of the most frequently diagnosed causes of low back pain and is a common cause of r ##adi ##cu ##lop ##athy . [ 1 – 3 ] Although most patients with L ##D ##H can achieve satisfying clinical and functional outcomes with conservative treatment , a few patients do not respond effectively to conservative treatment and eventually require surgical treatment . [ 4 , 5 ] There are several main surgical options : open l ##umba ##r micro - disc ##ec ##tom ##y ( O ##LM ) , [ 6 ] micro ##end ##os ##copic disc ##ec ##tom ##y ( ME ##D ) , [ 7 , 8 ] minimal ##ly invasive trans ##fo ##ram ##inal l ##umba ##r inter ##body fusion ( MI ##S - T ##L ##IF ) , [ 9 ] and per ##cut ##aneous end ##os ##copic l ##umba ##r disc ##ec ##tom ##y ( P ##EL ##D ) . [ 10 , 11 ] O ##LM has been regarded as the most commonly recommended surgical option for re ##current L ##D ##H ; [ 12 , 13 ] however , it was associated with several complications , including muscle damage , nerve re ##traction , and the removal of yellow l ##iga - men ##t , [ 14 , 15 ] which can result in instability and scar ##ring of the e ##pid ##ural space . [ 16 , 17 ] ME ##D uses a micro ##end ##os ##cope for visual ##iza - t ##ion , and the para ##sp ##ino ##us muscles are handled by muscle splitting through di ##lator ##s ; [ 18 ] thus , the muscle and soft tissue are minimal ##ly injured . [ 19 ] MI ##S - T ##L ##IF is a well - accepted operation method for re ##current L ##D ##H . And it has the advantages of less i ##at ##rogen ##ic soft tissue injury , lower risk of post ##oper ##ative r ##adi ##cu ##lit ##is , and decreased re ##traction of du ##ral sa ##c . [ 20 , 21 ] P ##EL ##D is a more minimal ##ly invasive surgery because the [SEP]\n",
      "I1208 12:27:36.978597 139883775852736 run_factoid.py:443] tokens: [CLS] What condition does the paper study ? [SEP] Lu ##mba ##r disc her ##nia ##tion ( L ##D ##H ) is one of the most frequently diagnosed causes of low back pain and is a common cause of r ##adi ##cu ##lop ##athy . [ 1 – 3 ] Although most patients with L ##D ##H can achieve satisfying clinical and functional outcomes with conservative treatment , a few patients do not respond effectively to conservative treatment and eventually require surgical treatment . [ 4 , 5 ] There are several main surgical options : open l ##umba ##r micro - disc ##ec ##tom ##y ( O ##LM ) , [ 6 ] micro ##end ##os ##copic disc ##ec ##tom ##y ( ME ##D ) , [ 7 , 8 ] minimal ##ly invasive trans ##fo ##ram ##inal l ##umba ##r inter ##body fusion ( MI ##S - T ##L ##IF ) , [ 9 ] and per ##cut ##aneous end ##os ##copic l ##umba ##r disc ##ec ##tom ##y ( P ##EL ##D ) . [ 10 , 11 ] O ##LM has been regarded as the most commonly recommended surgical option for re ##current L ##D ##H ; [ 12 , 13 ] however , it was associated with several complications , including muscle damage , nerve re ##traction , and the removal of yellow l ##iga - men ##t , [ 14 , 15 ] which can result in instability and scar ##ring of the e ##pid ##ural space . [ 16 , 17 ] ME ##D uses a micro ##end ##os ##cope for visual ##iza - t ##ion , and the para ##sp ##ino ##us muscles are handled by muscle splitting through di ##lator ##s ; [ 18 ] thus , the muscle and soft tissue are minimal ##ly injured . [ 19 ] MI ##S - T ##L ##IF is a well - accepted operation method for re ##current L ##D ##H . And it has the advantages of less i ##at ##rogen ##ic soft tissue injury , lower risk of post ##oper ##ative r ##adi ##cu ##lit ##is , and decreased re ##traction of du ##ral sa ##c . [ 20 , 21 ] P ##EL ##D is a more minimal ##ly invasive surgery because the [SEP]\n",
      "INFO:tensorflow:token_to_orig_map: 9:0 10:0 11:0 12:1 13:2 14:2 15:2 16:3 17:3 18:3 19:3 20:3 21:4 22:5 23:6 24:7 25:8 26:9 27:10 28:11 29:12 30:13 31:14 32:15 33:16 34:17 35:18 36:19 37:20 38:21 39:22 40:22 41:22 42:22 43:22 44:22 45:22 46:22 47:22 48:22 49:22 50:23 51:24 52:25 53:26 54:27 55:27 56:27 57:28 58:29 59:30 60:31 61:32 62:33 63:34 64:35 65:36 66:37 67:37 68:38 69:39 70:40 71:41 72:42 73:43 74:44 75:45 76:46 77:47 78:48 79:49 80:50 81:51 82:52 83:52 84:52 85:52 86:52 87:52 88:52 89:53 90:54 91:55 92:56 93:57 94:58 95:58 96:59 97:60 98:60 99:60 100:61 101:61 102:62 103:62 104:62 105:62 106:63 107:63 108:63 109:63 110:63 111:63 112:63 113:63 114:64 115:64 116:64 117:64 118:65 119:65 120:65 121:65 122:66 123:66 124:66 125:66 126:66 127:66 128:66 129:66 130:66 131:66 132:67 133:67 134:68 135:69 136:69 137:69 138:69 139:70 140:70 141:70 142:71 143:71 144:72 145:73 146:73 147:73 148:73 149:74 150:74 151:74 152:74 153:74 154:74 155:74 156:74 157:75 158:76 159:76 160:76 161:77 162:77 163:77 164:78 165:78 166:78 167:79 168:79 169:79 170:79 171:80 172:80 173:80 174:80 175:80 176:80 177:80 178:80 179:80 180:80 181:80 182:81 183:81 184:82 185:83 186:84 187:85 188:86 189:87 190:88 191:89 192:90 193:91 194:92 195:93 196:93 197:94 198:94 199:94 200:94 201:94 202:94 203:94 204:94 205:94 206:95 207:95 208:96 209:97 210:98 211:99 212:100 213:101 214:101 215:102 216:103 217:104 218:104 219:105 220:106 221:106 222:106 223:107 224:108 225:109 226:110 227:111 228:112 229:112 230:112 231:113 232:113 233:113 234:113 235:113 236:113 237:113 238:113 239:114 240:115 241:116 242:117 243:118 244:119 245:120 246:120 247:121 248:122 249:123 250:123 251:123 252:124 253:124 254:124 255:124 256:124 257:124 258:124 259:125 260:125 261:126 262:127 263:128 264:128 265:128 266:128 267:129 268:130 269:130 270:130 271:131 272:131 273:131 274:132 275:133 276:134 277:134 278:134 279:134 280:135 281:136 282:137 283:138 284:139 285:140 286:141 287:142 288:142 289:142 290:142 291:142 292:142 293:142 294:143 295:143 296:144 297:145 298:146 299:147 300:148 301:149 302:150 303:150 304:151 305:151 306:151 307:151 308:151 309:152 310:152 311:152 312:152 313:152 314:152 315:153 316:154 317:155 318:155 319:155 320:156 321:157 322:158 323:159 324:159 325:160 326:160 327:160 328:160 329:161 330:162 331:163 332:164 333:165 334:166 335:167 336:168 337:168 338:168 339:168 340:169 341:170 342:171 343:171 344:172 345:173 346:174 347:175 348:175 349:175 350:176 351:176 352:176 353:176 354:176 355:176 356:177 357:178 358:179 359:179 360:180 361:181 362:181 363:182 364:182 365:182 366:182 367:182 368:182 369:182 370:182 371:183 372:183 373:183 374:184 375:185 376:186 377:187 378:187 379:188 380:189 381:190 382:191\n",
      "I1208 12:27:36.978716 139883775852736 run_factoid.py:445] token_to_orig_map: 9:0 10:0 11:0 12:1 13:2 14:2 15:2 16:3 17:3 18:3 19:3 20:3 21:4 22:5 23:6 24:7 25:8 26:9 27:10 28:11 29:12 30:13 31:14 32:15 33:16 34:17 35:18 36:19 37:20 38:21 39:22 40:22 41:22 42:22 43:22 44:22 45:22 46:22 47:22 48:22 49:22 50:23 51:24 52:25 53:26 54:27 55:27 56:27 57:28 58:29 59:30 60:31 61:32 62:33 63:34 64:35 65:36 66:37 67:37 68:38 69:39 70:40 71:41 72:42 73:43 74:44 75:45 76:46 77:47 78:48 79:49 80:50 81:51 82:52 83:52 84:52 85:52 86:52 87:52 88:52 89:53 90:54 91:55 92:56 93:57 94:58 95:58 96:59 97:60 98:60 99:60 100:61 101:61 102:62 103:62 104:62 105:62 106:63 107:63 108:63 109:63 110:63 111:63 112:63 113:63 114:64 115:64 116:64 117:64 118:65 119:65 120:65 121:65 122:66 123:66 124:66 125:66 126:66 127:66 128:66 129:66 130:66 131:66 132:67 133:67 134:68 135:69 136:69 137:69 138:69 139:70 140:70 141:70 142:71 143:71 144:72 145:73 146:73 147:73 148:73 149:74 150:74 151:74 152:74 153:74 154:74 155:74 156:74 157:75 158:76 159:76 160:76 161:77 162:77 163:77 164:78 165:78 166:78 167:79 168:79 169:79 170:79 171:80 172:80 173:80 174:80 175:80 176:80 177:80 178:80 179:80 180:80 181:80 182:81 183:81 184:82 185:83 186:84 187:85 188:86 189:87 190:88 191:89 192:90 193:91 194:92 195:93 196:93 197:94 198:94 199:94 200:94 201:94 202:94 203:94 204:94 205:94 206:95 207:95 208:96 209:97 210:98 211:99 212:100 213:101 214:101 215:102 216:103 217:104 218:104 219:105 220:106 221:106 222:106 223:107 224:108 225:109 226:110 227:111 228:112 229:112 230:112 231:113 232:113 233:113 234:113 235:113 236:113 237:113 238:113 239:114 240:115 241:116 242:117 243:118 244:119 245:120 246:120 247:121 248:122 249:123 250:123 251:123 252:124 253:124 254:124 255:124 256:124 257:124 258:124 259:125 260:125 261:126 262:127 263:128 264:128 265:128 266:128 267:129 268:130 269:130 270:130 271:131 272:131 273:131 274:132 275:133 276:134 277:134 278:134 279:134 280:135 281:136 282:137 283:138 284:139 285:140 286:141 287:142 288:142 289:142 290:142 291:142 292:142 293:142 294:143 295:143 296:144 297:145 298:146 299:147 300:148 301:149 302:150 303:150 304:151 305:151 306:151 307:151 308:151 309:152 310:152 311:152 312:152 313:152 314:152 315:153 316:154 317:155 318:155 319:155 320:156 321:157 322:158 323:159 324:159 325:160 326:160 327:160 328:160 329:161 330:162 331:163 332:164 333:165 334:166 335:167 336:168 337:168 338:168 339:168 340:169 341:170 342:171 343:171 344:172 345:173 346:174 347:175 348:175 349:175 350:176 351:176 352:176 353:176 354:176 355:176 356:177 357:178 358:179 359:179 360:180 361:181 362:181 363:182 364:182 365:182 366:182 367:182 368:182 369:182 370:182 371:183 372:183 373:183 374:184 375:185 376:186 377:187 378:187 379:188 380:189 381:190 382:191\n",
      "INFO:tensorflow:token_is_max_context: 9:True 10:True 11:True 12:True 13:True 14:True 15:True 16:True 17:True 18:True 19:True 20:True 21:True 22:True 23:True 24:True 25:True 26:True 27:True 28:True 29:True 30:True 31:True 32:True 33:True 34:True 35:True 36:True 37:True 38:True 39:True 40:True 41:True 42:True 43:True 44:True 45:True 46:True 47:True 48:True 49:True 50:True 51:True 52:True 53:True 54:True 55:True 56:True 57:True 58:True 59:True 60:True 61:True 62:True 63:True 64:True 65:True 66:True 67:True 68:True 69:True 70:True 71:True 72:True 73:True 74:True 75:True 76:True 77:True 78:True 79:True 80:True 81:True 82:True 83:True 84:True 85:True 86:True 87:True 88:True 89:True 90:True 91:True 92:True 93:True 94:True 95:True 96:True 97:True 98:True 99:True 100:True 101:True 102:True 103:True 104:True 105:True 106:True 107:True 108:True 109:True 110:True 111:True 112:True 113:True 114:True 115:True 116:True 117:True 118:True 119:True 120:True 121:True 122:True 123:True 124:True 125:True 126:True 127:True 128:True 129:True 130:True 131:True 132:True 133:True 134:True 135:True 136:True 137:True 138:True 139:True 140:True 141:True 142:True 143:True 144:True 145:True 146:True 147:True 148:True 149:True 150:True 151:True 152:True 153:True 154:True 155:True 156:True 157:True 158:True 159:True 160:True 161:True 162:True 163:True 164:True 165:True 166:True 167:True 168:True 169:True 170:True 171:True 172:True 173:True 174:True 175:True 176:True 177:True 178:True 179:True 180:True 181:True 182:True 183:True 184:True 185:True 186:True 187:True 188:True 189:True 190:True 191:True 192:True 193:True 194:True 195:True 196:True 197:True 198:True 199:True 200:True 201:True 202:True 203:True 204:True 205:True 206:True 207:True 208:True 209:True 210:True 211:True 212:True 213:True 214:True 215:True 216:True 217:True 218:True 219:True 220:True 221:True 222:True 223:True 224:True 225:True 226:True 227:True 228:True 229:True 230:True 231:True 232:True 233:True 234:True 235:True 236:True 237:True 238:True 239:True 240:True 241:True 242:True 243:True 244:True 245:True 246:True 247:True 248:True 249:True 250:True 251:True 252:True 253:True 254:True 255:True 256:True 257:True 258:True 259:True 260:False 261:False 262:False 263:False 264:False 265:False 266:False 267:False 268:False 269:False 270:False 271:False 272:False 273:False 274:False 275:False 276:False 277:False 278:False 279:False 280:False 281:False 282:False 283:False 284:False 285:False 286:False 287:False 288:False 289:False 290:False 291:False 292:False 293:False 294:False 295:False 296:False 297:False 298:False 299:False 300:False 301:False 302:False 303:False 304:False 305:False 306:False 307:False 308:False 309:False 310:False 311:False 312:False 313:False 314:False 315:False 316:False 317:False 318:False 319:False 320:False 321:False 322:False 323:False 324:False 325:False 326:False 327:False 328:False 329:False 330:False 331:False 332:False 333:False 334:False 335:False 336:False 337:False 338:False 339:False 340:False 341:False 342:False 343:False 344:False 345:False 346:False 347:False 348:False 349:False 350:False 351:False 352:False 353:False 354:False 355:False 356:False 357:False 358:False 359:False 360:False 361:False 362:False 363:False 364:False 365:False 366:False 367:False 368:False 369:False 370:False 371:False 372:False 373:False 374:False 375:False 376:False 377:False 378:False 379:False 380:False 381:False 382:False\n",
      "I1208 12:27:36.978826 139883775852736 run_factoid.py:447] token_is_max_context: 9:True 10:True 11:True 12:True 13:True 14:True 15:True 16:True 17:True 18:True 19:True 20:True 21:True 22:True 23:True 24:True 25:True 26:True 27:True 28:True 29:True 30:True 31:True 32:True 33:True 34:True 35:True 36:True 37:True 38:True 39:True 40:True 41:True 42:True 43:True 44:True 45:True 46:True 47:True 48:True 49:True 50:True 51:True 52:True 53:True 54:True 55:True 56:True 57:True 58:True 59:True 60:True 61:True 62:True 63:True 64:True 65:True 66:True 67:True 68:True 69:True 70:True 71:True 72:True 73:True 74:True 75:True 76:True 77:True 78:True 79:True 80:True 81:True 82:True 83:True 84:True 85:True 86:True 87:True 88:True 89:True 90:True 91:True 92:True 93:True 94:True 95:True 96:True 97:True 98:True 99:True 100:True 101:True 102:True 103:True 104:True 105:True 106:True 107:True 108:True 109:True 110:True 111:True 112:True 113:True 114:True 115:True 116:True 117:True 118:True 119:True 120:True 121:True 122:True 123:True 124:True 125:True 126:True 127:True 128:True 129:True 130:True 131:True 132:True 133:True 134:True 135:True 136:True 137:True 138:True 139:True 140:True 141:True 142:True 143:True 144:True 145:True 146:True 147:True 148:True 149:True 150:True 151:True 152:True 153:True 154:True 155:True 156:True 157:True 158:True 159:True 160:True 161:True 162:True 163:True 164:True 165:True 166:True 167:True 168:True 169:True 170:True 171:True 172:True 173:True 174:True 175:True 176:True 177:True 178:True 179:True 180:True 181:True 182:True 183:True 184:True 185:True 186:True 187:True 188:True 189:True 190:True 191:True 192:True 193:True 194:True 195:True 196:True 197:True 198:True 199:True 200:True 201:True 202:True 203:True 204:True 205:True 206:True 207:True 208:True 209:True 210:True 211:True 212:True 213:True 214:True 215:True 216:True 217:True 218:True 219:True 220:True 221:True 222:True 223:True 224:True 225:True 226:True 227:True 228:True 229:True 230:True 231:True 232:True 233:True 234:True 235:True 236:True 237:True 238:True 239:True 240:True 241:True 242:True 243:True 244:True 245:True 246:True 247:True 248:True 249:True 250:True 251:True 252:True 253:True 254:True 255:True 256:True 257:True 258:True 259:True 260:False 261:False 262:False 263:False 264:False 265:False 266:False 267:False 268:False 269:False 270:False 271:False 272:False 273:False 274:False 275:False 276:False 277:False 278:False 279:False 280:False 281:False 282:False 283:False 284:False 285:False 286:False 287:False 288:False 289:False 290:False 291:False 292:False 293:False 294:False 295:False 296:False 297:False 298:False 299:False 300:False 301:False 302:False 303:False 304:False 305:False 306:False 307:False 308:False 309:False 310:False 311:False 312:False 313:False 314:False 315:False 316:False 317:False 318:False 319:False 320:False 321:False 322:False 323:False 324:False 325:False 326:False 327:False 328:False 329:False 330:False 331:False 332:False 333:False 334:False 335:False 336:False 337:False 338:False 339:False 340:False 341:False 342:False 343:False 344:False 345:False 346:False 347:False 348:False 349:False 350:False 351:False 352:False 353:False 354:False 355:False 356:False 357:False 358:False 359:False 360:False 361:False 362:False 363:False 364:False 365:False 366:False 367:False 368:False 369:False 370:False 371:False 372:False 373:False 374:False 375:False 376:False 377:False 378:False 379:False 380:False 381:False 382:False\n",
      "INFO:tensorflow:input_ids: 101 1327 3879 1674 1103 2526 2025 136 102 14557 10806 1197 6187 1123 5813 2116 113 149 2137 3048 114 1110 1141 1104 1103 1211 3933 11534 4680 1104 1822 1171 2489 1105 1110 170 1887 2612 1104 187 14230 10182 13200 23610 119 164 122 782 124 166 1966 1211 4420 1114 149 2137 3048 1169 5515 18330 7300 1105 8458 13950 1114 6588 3252 117 170 1374 4420 1202 1136 6297 5877 1106 6588 3252 1105 2028 4752 13467 3252 119 164 125 117 126 166 1247 1132 1317 1514 13467 6665 131 1501 181 25509 1197 17599 118 6187 10294 18778 1183 113 152 22074 114 117 164 127 166 17599 6696 2155 22258 6187 10294 18778 1183 113 22157 2137 114 117 164 128 117 129 166 10298 1193 19849 14715 14467 4515 14196 181 25509 1197 9455 14637 11970 113 26574 1708 118 157 2162 15499 114 117 164 130 166 1105 1679 12734 13064 1322 2155 22258 181 25509 1197 6187 10294 18778 1183 113 153 21678 2137 114 119 164 1275 117 1429 166 152 22074 1144 1151 4485 1112 1103 1211 3337 6315 13467 5146 1111 1231 21754 149 2137 3048 132 164 1367 117 1492 166 1649 117 1122 1108 2628 1114 1317 13522 117 1259 6484 3290 117 9071 1231 27539 117 1105 1103 8116 1104 3431 181 13499 118 1441 1204 117 164 1489 117 1405 166 1134 1169 1871 1107 20482 1105 14161 3384 1104 1103 174 25786 12602 2000 119 164 1479 117 1542 166 22157 2137 2745 170 17599 6696 2155 16260 1111 5173 23228 118 189 1988 117 1105 1103 18311 20080 4559 1361 6130 1132 8630 1118 6484 15601 1194 4267 13389 1116 132 164 1407 166 2456 117 1103 6484 1105 2991 7918 1132 10298 1193 4475 119 164 1627 166 26574 1708 118 157 2162 15499 1110 170 1218 118 3134 2805 3442 1111 1231 21754 149 2137 3048 119 1262 1122 1144 1103 13300 1104 1750 178 2980 26767 1596 2991 7918 3773 117 2211 3187 1104 2112 19807 5838 187 14230 10182 12888 1548 117 1105 10558 1231 27539 1104 3840 4412 21718 1665 119 164 1406 117 1626 166 153 21678 2137 1110 170 1167 10298 1193 19849 6059 1272 1103 102\n",
      "I1208 12:27:36.978929 139883775852736 run_factoid.py:449] input_ids: 101 1327 3879 1674 1103 2526 2025 136 102 14557 10806 1197 6187 1123 5813 2116 113 149 2137 3048 114 1110 1141 1104 1103 1211 3933 11534 4680 1104 1822 1171 2489 1105 1110 170 1887 2612 1104 187 14230 10182 13200 23610 119 164 122 782 124 166 1966 1211 4420 1114 149 2137 3048 1169 5515 18330 7300 1105 8458 13950 1114 6588 3252 117 170 1374 4420 1202 1136 6297 5877 1106 6588 3252 1105 2028 4752 13467 3252 119 164 125 117 126 166 1247 1132 1317 1514 13467 6665 131 1501 181 25509 1197 17599 118 6187 10294 18778 1183 113 152 22074 114 117 164 127 166 17599 6696 2155 22258 6187 10294 18778 1183 113 22157 2137 114 117 164 128 117 129 166 10298 1193 19849 14715 14467 4515 14196 181 25509 1197 9455 14637 11970 113 26574 1708 118 157 2162 15499 114 117 164 130 166 1105 1679 12734 13064 1322 2155 22258 181 25509 1197 6187 10294 18778 1183 113 153 21678 2137 114 119 164 1275 117 1429 166 152 22074 1144 1151 4485 1112 1103 1211 3337 6315 13467 5146 1111 1231 21754 149 2137 3048 132 164 1367 117 1492 166 1649 117 1122 1108 2628 1114 1317 13522 117 1259 6484 3290 117 9071 1231 27539 117 1105 1103 8116 1104 3431 181 13499 118 1441 1204 117 164 1489 117 1405 166 1134 1169 1871 1107 20482 1105 14161 3384 1104 1103 174 25786 12602 2000 119 164 1479 117 1542 166 22157 2137 2745 170 17599 6696 2155 16260 1111 5173 23228 118 189 1988 117 1105 1103 18311 20080 4559 1361 6130 1132 8630 1118 6484 15601 1194 4267 13389 1116 132 164 1407 166 2456 117 1103 6484 1105 2991 7918 1132 10298 1193 4475 119 164 1627 166 26574 1708 118 157 2162 15499 1110 170 1218 118 3134 2805 3442 1111 1231 21754 149 2137 3048 119 1262 1122 1144 1103 13300 1104 1750 178 2980 26767 1596 2991 7918 3773 117 2211 3187 1104 2112 19807 5838 187 14230 10182 12888 1548 117 1105 10558 1231 27539 1104 3840 4412 21718 1665 119 164 1406 117 1626 166 153 21678 2137 1110 170 1167 10298 1193 19849 6059 1272 1103 102\n",
      "INFO:tensorflow:input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      "I1208 12:27:36.979021 139883775852736 run_factoid.py:451] input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      "INFO:tensorflow:segment_ids: 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      "I1208 12:27:36.979110 139883775852736 run_factoid.py:453] segment_ids: 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      "INFO:tensorflow:*** Example ***\n",
      "I1208 12:27:36.979994 139883775852736 run_factoid.py:438] *** Example ***\n",
      "INFO:tensorflow:unique_id: 1000000003\n",
      "I1208 12:27:36.980054 139883775852736 run_factoid.py:439] unique_id: 1000000003\n",
      "INFO:tensorflow:example_index: 1\n",
      "I1208 12:27:36.980092 139883775852736 run_factoid.py:440] example_index: 1\n",
      "INFO:tensorflow:doc_span_index: 1\n",
      "I1208 12:27:36.980126 139883775852736 run_factoid.py:441] doc_span_index: 1\n",
      "INFO:tensorflow:tokens: [CLS] What condition does the paper study ? [SEP] ##ram ##inal l ##umba ##r inter ##body fusion ( MI ##S - T ##L ##IF ) , [ 9 ] and per ##cut ##aneous end ##os ##copic l ##umba ##r disc ##ec ##tom ##y ( P ##EL ##D ) . [ 10 , 11 ] O ##LM has been regarded as the most commonly recommended surgical option for re ##current L ##D ##H ; [ 12 , 13 ] however , it was associated with several complications , including muscle damage , nerve re ##traction , and the removal of yellow l ##iga - men ##t , [ 14 , 15 ] which can result in instability and scar ##ring of the e ##pid ##ural space . [ 16 , 17 ] ME ##D uses a micro ##end ##os ##cope for visual ##iza - t ##ion , and the para ##sp ##ino ##us muscles are handled by muscle splitting through di ##lator ##s ; [ 18 ] thus , the muscle and soft tissue are minimal ##ly injured . [ 19 ] MI ##S - T ##L ##IF is a well - accepted operation method for re ##current L ##D ##H . And it has the advantages of less i ##at ##rogen ##ic soft tissue injury , lower risk of post ##oper ##ative r ##adi ##cu ##lit ##is , and decreased re ##traction of du ##ral sa ##c . [ 20 , 21 ] P ##EL ##D is a more minimal ##ly invasive surgery because the posterior column structures are pre - served . [ 22 , 23 ] It has gained interest for its potential advantage in the reduced risk of face ##t joints injury , fewer post ##oper ##ative complications , a shorter hospital stay and lower cost . [ 24 , 25 ] Previous studies have reported that P ##EL ##D is an effective and safe treatment for L ##D ##H . [ 26 , 27 ] However , whether P ##EL ##D is superior to other surgical options remains controversial . Thus , we conducted this meta - analysis to compare the clinical , radio ##log ##ic , and complications of P ##EL ##D and other surge ##ries for patients with L ##D ##H . [SEP]\n",
      "I1208 12:27:36.980235 139883775852736 run_factoid.py:443] tokens: [CLS] What condition does the paper study ? [SEP] ##ram ##inal l ##umba ##r inter ##body fusion ( MI ##S - T ##L ##IF ) , [ 9 ] and per ##cut ##aneous end ##os ##copic l ##umba ##r disc ##ec ##tom ##y ( P ##EL ##D ) . [ 10 , 11 ] O ##LM has been regarded as the most commonly recommended surgical option for re ##current L ##D ##H ; [ 12 , 13 ] however , it was associated with several complications , including muscle damage , nerve re ##traction , and the removal of yellow l ##iga - men ##t , [ 14 , 15 ] which can result in instability and scar ##ring of the e ##pid ##ural space . [ 16 , 17 ] ME ##D uses a micro ##end ##os ##cope for visual ##iza - t ##ion , and the para ##sp ##ino ##us muscles are handled by muscle splitting through di ##lator ##s ; [ 18 ] thus , the muscle and soft tissue are minimal ##ly injured . [ 19 ] MI ##S - T ##L ##IF is a well - accepted operation method for re ##current L ##D ##H . And it has the advantages of less i ##at ##rogen ##ic soft tissue injury , lower risk of post ##oper ##ative r ##adi ##cu ##lit ##is , and decreased re ##traction of du ##ral sa ##c . [ 20 , 21 ] P ##EL ##D is a more minimal ##ly invasive surgery because the posterior column structures are pre - served . [ 22 , 23 ] It has gained interest for its potential advantage in the reduced risk of face ##t joints injury , fewer post ##oper ##ative complications , a shorter hospital stay and lower cost . [ 24 , 25 ] Previous studies have reported that P ##EL ##D is an effective and safe treatment for L ##D ##H . [ 26 , 27 ] However , whether P ##EL ##D is superior to other surgical options remains controversial . Thus , we conducted this meta - analysis to compare the clinical , radio ##log ##ic , and complications of P ##EL ##D and other surge ##ries for patients with L ##D ##H . [SEP]\n",
      "INFO:tensorflow:token_to_orig_map: 9:69 10:69 11:70 12:70 13:70 14:71 15:71 16:72 17:73 18:73 19:73 20:73 21:74 22:74 23:74 24:74 25:74 26:74 27:74 28:74 29:75 30:76 31:76 32:76 33:77 34:77 35:77 36:78 37:78 38:78 39:79 40:79 41:79 42:79 43:80 44:80 45:80 46:80 47:80 48:80 49:80 50:80 51:80 52:80 53:80 54:81 55:81 56:82 57:83 58:84 59:85 60:86 61:87 62:88 63:89 64:90 65:91 66:92 67:93 68:93 69:94 70:94 71:94 72:94 73:94 74:94 75:94 76:94 77:94 78:95 79:95 80:96 81:97 82:98 83:99 84:100 85:101 86:101 87:102 88:103 89:104 90:104 91:105 92:106 93:106 94:106 95:107 96:108 97:109 98:110 99:111 100:112 101:112 102:112 103:113 104:113 105:113 106:113 107:113 108:113 109:113 110:113 111:114 112:115 113:116 114:117 115:118 116:119 117:120 118:120 119:121 120:122 121:123 122:123 123:123 124:124 125:124 126:124 127:124 128:124 129:124 130:124 131:125 132:125 133:126 134:127 135:128 136:128 137:128 138:128 139:129 140:130 141:130 142:130 143:131 144:131 145:131 146:132 147:133 148:134 149:134 150:134 151:134 152:135 153:136 154:137 155:138 156:139 157:140 158:141 159:142 160:142 161:142 162:142 163:142 164:142 165:142 166:143 167:143 168:144 169:145 170:146 171:147 172:148 173:149 174:150 175:150 176:151 177:151 178:151 179:151 180:151 181:152 182:152 183:152 184:152 185:152 186:152 187:153 188:154 189:155 190:155 191:155 192:156 193:157 194:158 195:159 196:159 197:160 198:160 199:160 200:160 201:161 202:162 203:163 204:164 205:165 206:166 207:167 208:168 209:168 210:168 211:168 212:169 213:170 214:171 215:171 216:172 217:173 218:174 219:175 220:175 221:175 222:176 223:176 224:176 225:176 226:176 227:176 228:177 229:178 230:179 231:179 232:180 233:181 234:181 235:182 236:182 237:182 238:182 239:182 240:182 241:182 242:182 243:183 244:183 245:183 246:184 247:185 248:186 249:187 250:187 251:188 252:189 253:190 254:191 255:192 256:193 257:194 258:195 259:196 260:196 261:197 262:197 263:197 264:197 265:197 266:197 267:197 268:198 269:199 270:200 271:201 272:202 273:203 274:204 275:205 276:206 277:207 278:208 279:209 280:210 281:211 282:211 283:212 284:213 285:213 286:214 287:215 288:215 289:215 290:216 291:216 292:217 293:218 294:219 295:220 296:221 297:222 298:223 299:223 300:223 301:223 302:223 303:223 304:223 305:224 306:225 307:226 308:227 309:228 310:229 311:229 312:229 313:230 314:231 315:232 316:233 317:234 318:235 319:236 320:237 321:237 322:237 323:237 324:237 325:237 326:237 327:237 328:237 329:238 330:238 331:239 332:240 333:240 334:240 335:241 336:242 337:243 338:244 339:245 340:246 341:247 342:248 343:248 344:249 345:249 346:250 347:251 348:252 349:253 350:253 351:253 352:254 353:255 354:256 355:257 356:257 357:258 358:258 359:258 360:258 361:259 362:260 363:261 364:262 365:262 366:262 367:263 368:264 369:265 370:265 371:266 372:267 373:268 374:269 375:269 376:269 377:269\n",
      "I1208 12:27:36.980347 139883775852736 run_factoid.py:445] token_to_orig_map: 9:69 10:69 11:70 12:70 13:70 14:71 15:71 16:72 17:73 18:73 19:73 20:73 21:74 22:74 23:74 24:74 25:74 26:74 27:74 28:74 29:75 30:76 31:76 32:76 33:77 34:77 35:77 36:78 37:78 38:78 39:79 40:79 41:79 42:79 43:80 44:80 45:80 46:80 47:80 48:80 49:80 50:80 51:80 52:80 53:80 54:81 55:81 56:82 57:83 58:84 59:85 60:86 61:87 62:88 63:89 64:90 65:91 66:92 67:93 68:93 69:94 70:94 71:94 72:94 73:94 74:94 75:94 76:94 77:94 78:95 79:95 80:96 81:97 82:98 83:99 84:100 85:101 86:101 87:102 88:103 89:104 90:104 91:105 92:106 93:106 94:106 95:107 96:108 97:109 98:110 99:111 100:112 101:112 102:112 103:113 104:113 105:113 106:113 107:113 108:113 109:113 110:113 111:114 112:115 113:116 114:117 115:118 116:119 117:120 118:120 119:121 120:122 121:123 122:123 123:123 124:124 125:124 126:124 127:124 128:124 129:124 130:124 131:125 132:125 133:126 134:127 135:128 136:128 137:128 138:128 139:129 140:130 141:130 142:130 143:131 144:131 145:131 146:132 147:133 148:134 149:134 150:134 151:134 152:135 153:136 154:137 155:138 156:139 157:140 158:141 159:142 160:142 161:142 162:142 163:142 164:142 165:142 166:143 167:143 168:144 169:145 170:146 171:147 172:148 173:149 174:150 175:150 176:151 177:151 178:151 179:151 180:151 181:152 182:152 183:152 184:152 185:152 186:152 187:153 188:154 189:155 190:155 191:155 192:156 193:157 194:158 195:159 196:159 197:160 198:160 199:160 200:160 201:161 202:162 203:163 204:164 205:165 206:166 207:167 208:168 209:168 210:168 211:168 212:169 213:170 214:171 215:171 216:172 217:173 218:174 219:175 220:175 221:175 222:176 223:176 224:176 225:176 226:176 227:176 228:177 229:178 230:179 231:179 232:180 233:181 234:181 235:182 236:182 237:182 238:182 239:182 240:182 241:182 242:182 243:183 244:183 245:183 246:184 247:185 248:186 249:187 250:187 251:188 252:189 253:190 254:191 255:192 256:193 257:194 258:195 259:196 260:196 261:197 262:197 263:197 264:197 265:197 266:197 267:197 268:198 269:199 270:200 271:201 272:202 273:203 274:204 275:205 276:206 277:207 278:208 279:209 280:210 281:211 282:211 283:212 284:213 285:213 286:214 287:215 288:215 289:215 290:216 291:216 292:217 293:218 294:219 295:220 296:221 297:222 298:223 299:223 300:223 301:223 302:223 303:223 304:223 305:224 306:225 307:226 308:227 309:228 310:229 311:229 312:229 313:230 314:231 315:232 316:233 317:234 318:235 319:236 320:237 321:237 322:237 323:237 324:237 325:237 326:237 327:237 328:237 329:238 330:238 331:239 332:240 333:240 334:240 335:241 336:242 337:243 338:244 339:245 340:246 341:247 342:248 343:248 344:249 345:249 346:250 347:251 348:252 349:253 350:253 351:253 352:254 353:255 354:256 355:257 356:257 357:258 358:258 359:258 360:258 361:259 362:260 363:261 364:262 365:262 366:262 367:263 368:264 369:265 370:265 371:266 372:267 373:268 374:269 375:269 376:269 377:269\n",
      "INFO:tensorflow:token_is_max_context: 9:False 10:False 11:False 12:False 13:False 14:False 15:False 16:False 17:False 18:False 19:False 20:False 21:False 22:False 23:False 24:False 25:False 26:False 27:False 28:False 29:False 30:False 31:False 32:False 33:False 34:False 35:False 36:False 37:False 38:False 39:False 40:False 41:False 42:False 43:False 44:False 45:False 46:False 47:False 48:False 49:False 50:False 51:False 52:False 53:False 54:False 55:False 56:False 57:False 58:False 59:False 60:False 61:False 62:False 63:False 64:False 65:False 66:False 67:False 68:False 69:False 70:False 71:False 72:False 73:False 74:False 75:False 76:False 77:False 78:False 79:False 80:False 81:False 82:False 83:False 84:False 85:False 86:False 87:False 88:False 89:False 90:False 91:False 92:False 93:False 94:False 95:False 96:False 97:False 98:False 99:False 100:False 101:False 102:False 103:False 104:False 105:False 106:False 107:False 108:False 109:False 110:False 111:False 112:False 113:False 114:False 115:False 116:False 117:False 118:False 119:False 120:False 121:False 122:False 123:False 124:False 125:False 126:False 127:False 128:False 129:False 130:False 131:False 132:True 133:True 134:True 135:True 136:True 137:True 138:True 139:True 140:True 141:True 142:True 143:True 144:True 145:True 146:True 147:True 148:True 149:True 150:True 151:True 152:True 153:True 154:True 155:True 156:True 157:True 158:True 159:True 160:True 161:True 162:True 163:True 164:True 165:True 166:True 167:True 168:True 169:True 170:True 171:True 172:True 173:True 174:True 175:True 176:True 177:True 178:True 179:True 180:True 181:True 182:True 183:True 184:True 185:True 186:True 187:True 188:True 189:True 190:True 191:True 192:True 193:True 194:True 195:True 196:True 197:True 198:True 199:True 200:True 201:True 202:True 203:True 204:True 205:True 206:True 207:True 208:True 209:True 210:True 211:True 212:True 213:True 214:True 215:True 216:True 217:True 218:True 219:True 220:True 221:True 222:True 223:True 224:True 225:True 226:True 227:True 228:True 229:True 230:True 231:True 232:True 233:True 234:True 235:True 236:True 237:True 238:True 239:True 240:True 241:True 242:True 243:True 244:True 245:True 246:True 247:True 248:True 249:True 250:True 251:True 252:True 253:True 254:True 255:True 256:True 257:True 258:True 259:True 260:True 261:True 262:True 263:True 264:True 265:True 266:True 267:True 268:True 269:True 270:True 271:True 272:True 273:True 274:True 275:True 276:True 277:True 278:True 279:True 280:True 281:True 282:True 283:True 284:True 285:True 286:True 287:True 288:True 289:True 290:True 291:True 292:True 293:True 294:True 295:True 296:True 297:True 298:True 299:True 300:True 301:True 302:True 303:True 304:True 305:True 306:True 307:True 308:True 309:True 310:True 311:True 312:True 313:True 314:True 315:True 316:True 317:True 318:True 319:True 320:True 321:True 322:True 323:True 324:True 325:True 326:True 327:True 328:True 329:True 330:True 331:True 332:True 333:True 334:True 335:True 336:True 337:True 338:True 339:True 340:True 341:True 342:True 343:True 344:True 345:True 346:True 347:True 348:True 349:True 350:True 351:True 352:True 353:True 354:True 355:True 356:True 357:True 358:True 359:True 360:True 361:True 362:True 363:True 364:True 365:True 366:True 367:True 368:True 369:True 370:True 371:True 372:True 373:True 374:True 375:True 376:True 377:True\n",
      "I1208 12:27:36.980454 139883775852736 run_factoid.py:447] token_is_max_context: 9:False 10:False 11:False 12:False 13:False 14:False 15:False 16:False 17:False 18:False 19:False 20:False 21:False 22:False 23:False 24:False 25:False 26:False 27:False 28:False 29:False 30:False 31:False 32:False 33:False 34:False 35:False 36:False 37:False 38:False 39:False 40:False 41:False 42:False 43:False 44:False 45:False 46:False 47:False 48:False 49:False 50:False 51:False 52:False 53:False 54:False 55:False 56:False 57:False 58:False 59:False 60:False 61:False 62:False 63:False 64:False 65:False 66:False 67:False 68:False 69:False 70:False 71:False 72:False 73:False 74:False 75:False 76:False 77:False 78:False 79:False 80:False 81:False 82:False 83:False 84:False 85:False 86:False 87:False 88:False 89:False 90:False 91:False 92:False 93:False 94:False 95:False 96:False 97:False 98:False 99:False 100:False 101:False 102:False 103:False 104:False 105:False 106:False 107:False 108:False 109:False 110:False 111:False 112:False 113:False 114:False 115:False 116:False 117:False 118:False 119:False 120:False 121:False 122:False 123:False 124:False 125:False 126:False 127:False 128:False 129:False 130:False 131:False 132:True 133:True 134:True 135:True 136:True 137:True 138:True 139:True 140:True 141:True 142:True 143:True 144:True 145:True 146:True 147:True 148:True 149:True 150:True 151:True 152:True 153:True 154:True 155:True 156:True 157:True 158:True 159:True 160:True 161:True 162:True 163:True 164:True 165:True 166:True 167:True 168:True 169:True 170:True 171:True 172:True 173:True 174:True 175:True 176:True 177:True 178:True 179:True 180:True 181:True 182:True 183:True 184:True 185:True 186:True 187:True 188:True 189:True 190:True 191:True 192:True 193:True 194:True 195:True 196:True 197:True 198:True 199:True 200:True 201:True 202:True 203:True 204:True 205:True 206:True 207:True 208:True 209:True 210:True 211:True 212:True 213:True 214:True 215:True 216:True 217:True 218:True 219:True 220:True 221:True 222:True 223:True 224:True 225:True 226:True 227:True 228:True 229:True 230:True 231:True 232:True 233:True 234:True 235:True 236:True 237:True 238:True 239:True 240:True 241:True 242:True 243:True 244:True 245:True 246:True 247:True 248:True 249:True 250:True 251:True 252:True 253:True 254:True 255:True 256:True 257:True 258:True 259:True 260:True 261:True 262:True 263:True 264:True 265:True 266:True 267:True 268:True 269:True 270:True 271:True 272:True 273:True 274:True 275:True 276:True 277:True 278:True 279:True 280:True 281:True 282:True 283:True 284:True 285:True 286:True 287:True 288:True 289:True 290:True 291:True 292:True 293:True 294:True 295:True 296:True 297:True 298:True 299:True 300:True 301:True 302:True 303:True 304:True 305:True 306:True 307:True 308:True 309:True 310:True 311:True 312:True 313:True 314:True 315:True 316:True 317:True 318:True 319:True 320:True 321:True 322:True 323:True 324:True 325:True 326:True 327:True 328:True 329:True 330:True 331:True 332:True 333:True 334:True 335:True 336:True 337:True 338:True 339:True 340:True 341:True 342:True 343:True 344:True 345:True 346:True 347:True 348:True 349:True 350:True 351:True 352:True 353:True 354:True 355:True 356:True 357:True 358:True 359:True 360:True 361:True 362:True 363:True 364:True 365:True 366:True 367:True 368:True 369:True 370:True 371:True 372:True 373:True 374:True 375:True 376:True 377:True\n",
      "INFO:tensorflow:input_ids: 101 1327 3879 1674 1103 2526 2025 136 102 4515 14196 181 25509 1197 9455 14637 11970 113 26574 1708 118 157 2162 15499 114 117 164 130 166 1105 1679 12734 13064 1322 2155 22258 181 25509 1197 6187 10294 18778 1183 113 153 21678 2137 114 119 164 1275 117 1429 166 152 22074 1144 1151 4485 1112 1103 1211 3337 6315 13467 5146 1111 1231 21754 149 2137 3048 132 164 1367 117 1492 166 1649 117 1122 1108 2628 1114 1317 13522 117 1259 6484 3290 117 9071 1231 27539 117 1105 1103 8116 1104 3431 181 13499 118 1441 1204 117 164 1489 117 1405 166 1134 1169 1871 1107 20482 1105 14161 3384 1104 1103 174 25786 12602 2000 119 164 1479 117 1542 166 22157 2137 2745 170 17599 6696 2155 16260 1111 5173 23228 118 189 1988 117 1105 1103 18311 20080 4559 1361 6130 1132 8630 1118 6484 15601 1194 4267 13389 1116 132 164 1407 166 2456 117 1103 6484 1105 2991 7918 1132 10298 1193 4475 119 164 1627 166 26574 1708 118 157 2162 15499 1110 170 1218 118 3134 2805 3442 1111 1231 21754 149 2137 3048 119 1262 1122 1144 1103 13300 1104 1750 178 2980 26767 1596 2991 7918 3773 117 2211 3187 1104 2112 19807 5838 187 14230 10182 12888 1548 117 1105 10558 1231 27539 1104 3840 4412 21718 1665 119 164 1406 117 1626 166 153 21678 2137 1110 170 1167 10298 1193 19849 6059 1272 1103 16530 5551 4413 1132 3073 118 1462 119 164 1659 117 1695 166 1135 1144 3388 2199 1111 1157 3209 4316 1107 1103 3549 3187 1104 1339 1204 19365 3773 117 8307 2112 19807 5838 13522 117 170 7681 2704 2215 1105 2211 2616 119 164 1572 117 1512 166 24142 2527 1138 2103 1115 153 21678 2137 1110 1126 3903 1105 2914 3252 1111 149 2137 3048 119 164 1744 117 1765 166 1438 117 2480 153 21678 2137 1110 7298 1106 1168 13467 6665 2606 6241 119 4516 117 1195 3303 1142 27154 118 3622 1106 14133 1103 7300 117 2070 13791 1596 117 1105 13522 1104 153 21678 2137 1105 1168 12814 3377 1111 4420 1114 149 2137 3048 119 102 0 0 0 0 0\n",
      "I1208 12:27:36.980553 139883775852736 run_factoid.py:449] input_ids: 101 1327 3879 1674 1103 2526 2025 136 102 4515 14196 181 25509 1197 9455 14637 11970 113 26574 1708 118 157 2162 15499 114 117 164 130 166 1105 1679 12734 13064 1322 2155 22258 181 25509 1197 6187 10294 18778 1183 113 153 21678 2137 114 119 164 1275 117 1429 166 152 22074 1144 1151 4485 1112 1103 1211 3337 6315 13467 5146 1111 1231 21754 149 2137 3048 132 164 1367 117 1492 166 1649 117 1122 1108 2628 1114 1317 13522 117 1259 6484 3290 117 9071 1231 27539 117 1105 1103 8116 1104 3431 181 13499 118 1441 1204 117 164 1489 117 1405 166 1134 1169 1871 1107 20482 1105 14161 3384 1104 1103 174 25786 12602 2000 119 164 1479 117 1542 166 22157 2137 2745 170 17599 6696 2155 16260 1111 5173 23228 118 189 1988 117 1105 1103 18311 20080 4559 1361 6130 1132 8630 1118 6484 15601 1194 4267 13389 1116 132 164 1407 166 2456 117 1103 6484 1105 2991 7918 1132 10298 1193 4475 119 164 1627 166 26574 1708 118 157 2162 15499 1110 170 1218 118 3134 2805 3442 1111 1231 21754 149 2137 3048 119 1262 1122 1144 1103 13300 1104 1750 178 2980 26767 1596 2991 7918 3773 117 2211 3187 1104 2112 19807 5838 187 14230 10182 12888 1548 117 1105 10558 1231 27539 1104 3840 4412 21718 1665 119 164 1406 117 1626 166 153 21678 2137 1110 170 1167 10298 1193 19849 6059 1272 1103 16530 5551 4413 1132 3073 118 1462 119 164 1659 117 1695 166 1135 1144 3388 2199 1111 1157 3209 4316 1107 1103 3549 3187 1104 1339 1204 19365 3773 117 8307 2112 19807 5838 13522 117 170 7681 2704 2215 1105 2211 2616 119 164 1572 117 1512 166 24142 2527 1138 2103 1115 153 21678 2137 1110 1126 3903 1105 2914 3252 1111 149 2137 3048 119 164 1744 117 1765 166 1438 117 2480 153 21678 2137 1110 7298 1106 1168 13467 6665 2606 6241 119 4516 117 1195 3303 1142 27154 118 3622 1106 14133 1103 7300 117 2070 13791 1596 117 1105 13522 1104 153 21678 2137 1105 1168 12814 3377 1111 4420 1114 149 2137 3048 119 102 0 0 0 0 0\n",
      "INFO:tensorflow:input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0\n",
      "I1208 12:27:36.980648 139883775852736 run_factoid.py:451] input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0\n",
      "INFO:tensorflow:segment_ids: 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0\n",
      "I1208 12:27:36.980738 139883775852736 run_factoid.py:453] segment_ids: 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0\n",
      "INFO:tensorflow:*** Example ***\n",
      "I1208 12:27:36.986342 139883775852736 run_factoid.py:438] *** Example ***\n",
      "INFO:tensorflow:unique_id: 1000000004\n",
      "I1208 12:27:36.986415 139883775852736 run_factoid.py:439] unique_id: 1000000004\n",
      "INFO:tensorflow:example_index: 2\n",
      "I1208 12:27:36.986454 139883775852736 run_factoid.py:440] example_index: 2\n",
      "INFO:tensorflow:doc_span_index: 0\n",
      "I1208 12:27:36.986489 139883775852736 run_factoid.py:441] doc_span_index: 0\n",
      "INFO:tensorflow:tokens: [CLS] How is the condition usually treated ? [SEP] Lu ##mba ##r disc her ##nia ##tion ( L ##D ##H ) is one of the most frequently diagnosed causes of low back pain and is a common cause of r ##adi ##cu ##lop ##athy . [ 1 – 3 ] Although most patients with L ##D ##H can achieve satisfying clinical and functional outcomes with conservative treatment , a few patients do not respond effectively to conservative treatment and eventually require surgical treatment . [ 4 , 5 ] There are several main surgical options : open l ##umba ##r micro - disc ##ec ##tom ##y ( O ##LM ) , [ 6 ] micro ##end ##os ##copic disc ##ec ##tom ##y ( ME ##D ) , [ 7 , 8 ] minimal ##ly invasive trans ##fo ##ram ##inal l ##umba ##r inter ##body fusion ( MI ##S - T ##L ##IF ) , [ 9 ] and per ##cut ##aneous end ##os ##copic l ##umba ##r disc ##ec ##tom ##y ( P ##EL ##D ) . [ 10 , 11 ] O ##LM has been regarded as the most commonly recommended surgical option for re ##current L ##D ##H ; [ 12 , 13 ] however , it was associated with several complications , including muscle damage , nerve re ##traction , and the removal of yellow l ##iga - men ##t , [ 14 , 15 ] which can result in instability and scar ##ring of the e ##pid ##ural space . [ 16 , 17 ] ME ##D uses a micro ##end ##os ##cope for visual ##iza - t ##ion , and the para ##sp ##ino ##us muscles are handled by muscle splitting through di ##lator ##s ; [ 18 ] thus , the muscle and soft tissue are minimal ##ly injured . [ 19 ] MI ##S - T ##L ##IF is a well - accepted operation method for re ##current L ##D ##H . And it has the advantages of less i ##at ##rogen ##ic soft tissue injury , lower risk of post ##oper ##ative r ##adi ##cu ##lit ##is , and decreased re ##traction of du ##ral sa ##c . [ 20 , 21 ] P ##EL ##D is a more minimal ##ly invasive surgery because the [SEP]\n",
      "I1208 12:27:36.986610 139883775852736 run_factoid.py:443] tokens: [CLS] How is the condition usually treated ? [SEP] Lu ##mba ##r disc her ##nia ##tion ( L ##D ##H ) is one of the most frequently diagnosed causes of low back pain and is a common cause of r ##adi ##cu ##lop ##athy . [ 1 – 3 ] Although most patients with L ##D ##H can achieve satisfying clinical and functional outcomes with conservative treatment , a few patients do not respond effectively to conservative treatment and eventually require surgical treatment . [ 4 , 5 ] There are several main surgical options : open l ##umba ##r micro - disc ##ec ##tom ##y ( O ##LM ) , [ 6 ] micro ##end ##os ##copic disc ##ec ##tom ##y ( ME ##D ) , [ 7 , 8 ] minimal ##ly invasive trans ##fo ##ram ##inal l ##umba ##r inter ##body fusion ( MI ##S - T ##L ##IF ) , [ 9 ] and per ##cut ##aneous end ##os ##copic l ##umba ##r disc ##ec ##tom ##y ( P ##EL ##D ) . [ 10 , 11 ] O ##LM has been regarded as the most commonly recommended surgical option for re ##current L ##D ##H ; [ 12 , 13 ] however , it was associated with several complications , including muscle damage , nerve re ##traction , and the removal of yellow l ##iga - men ##t , [ 14 , 15 ] which can result in instability and scar ##ring of the e ##pid ##ural space . [ 16 , 17 ] ME ##D uses a micro ##end ##os ##cope for visual ##iza - t ##ion , and the para ##sp ##ino ##us muscles are handled by muscle splitting through di ##lator ##s ; [ 18 ] thus , the muscle and soft tissue are minimal ##ly injured . [ 19 ] MI ##S - T ##L ##IF is a well - accepted operation method for re ##current L ##D ##H . And it has the advantages of less i ##at ##rogen ##ic soft tissue injury , lower risk of post ##oper ##ative r ##adi ##cu ##lit ##is , and decreased re ##traction of du ##ral sa ##c . [ 20 , 21 ] P ##EL ##D is a more minimal ##ly invasive surgery because the [SEP]\n",
      "INFO:tensorflow:token_to_orig_map: 9:0 10:0 11:0 12:1 13:2 14:2 15:2 16:3 17:3 18:3 19:3 20:3 21:4 22:5 23:6 24:7 25:8 26:9 27:10 28:11 29:12 30:13 31:14 32:15 33:16 34:17 35:18 36:19 37:20 38:21 39:22 40:22 41:22 42:22 43:22 44:22 45:22 46:22 47:22 48:22 49:22 50:23 51:24 52:25 53:26 54:27 55:27 56:27 57:28 58:29 59:30 60:31 61:32 62:33 63:34 64:35 65:36 66:37 67:37 68:38 69:39 70:40 71:41 72:42 73:43 74:44 75:45 76:46 77:47 78:48 79:49 80:50 81:51 82:52 83:52 84:52 85:52 86:52 87:52 88:52 89:53 90:54 91:55 92:56 93:57 94:58 95:58 96:59 97:60 98:60 99:60 100:61 101:61 102:62 103:62 104:62 105:62 106:63 107:63 108:63 109:63 110:63 111:63 112:63 113:63 114:64 115:64 116:64 117:64 118:65 119:65 120:65 121:65 122:66 123:66 124:66 125:66 126:66 127:66 128:66 129:66 130:66 131:66 132:67 133:67 134:68 135:69 136:69 137:69 138:69 139:70 140:70 141:70 142:71 143:71 144:72 145:73 146:73 147:73 148:73 149:74 150:74 151:74 152:74 153:74 154:74 155:74 156:74 157:75 158:76 159:76 160:76 161:77 162:77 163:77 164:78 165:78 166:78 167:79 168:79 169:79 170:79 171:80 172:80 173:80 174:80 175:80 176:80 177:80 178:80 179:80 180:80 181:80 182:81 183:81 184:82 185:83 186:84 187:85 188:86 189:87 190:88 191:89 192:90 193:91 194:92 195:93 196:93 197:94 198:94 199:94 200:94 201:94 202:94 203:94 204:94 205:94 206:95 207:95 208:96 209:97 210:98 211:99 212:100 213:101 214:101 215:102 216:103 217:104 218:104 219:105 220:106 221:106 222:106 223:107 224:108 225:109 226:110 227:111 228:112 229:112 230:112 231:113 232:113 233:113 234:113 235:113 236:113 237:113 238:113 239:114 240:115 241:116 242:117 243:118 244:119 245:120 246:120 247:121 248:122 249:123 250:123 251:123 252:124 253:124 254:124 255:124 256:124 257:124 258:124 259:125 260:125 261:126 262:127 263:128 264:128 265:128 266:128 267:129 268:130 269:130 270:130 271:131 272:131 273:131 274:132 275:133 276:134 277:134 278:134 279:134 280:135 281:136 282:137 283:138 284:139 285:140 286:141 287:142 288:142 289:142 290:142 291:142 292:142 293:142 294:143 295:143 296:144 297:145 298:146 299:147 300:148 301:149 302:150 303:150 304:151 305:151 306:151 307:151 308:151 309:152 310:152 311:152 312:152 313:152 314:152 315:153 316:154 317:155 318:155 319:155 320:156 321:157 322:158 323:159 324:159 325:160 326:160 327:160 328:160 329:161 330:162 331:163 332:164 333:165 334:166 335:167 336:168 337:168 338:168 339:168 340:169 341:170 342:171 343:171 344:172 345:173 346:174 347:175 348:175 349:175 350:176 351:176 352:176 353:176 354:176 355:176 356:177 357:178 358:179 359:179 360:180 361:181 362:181 363:182 364:182 365:182 366:182 367:182 368:182 369:182 370:182 371:183 372:183 373:183 374:184 375:185 376:186 377:187 378:187 379:188 380:189 381:190 382:191\n",
      "I1208 12:27:36.986729 139883775852736 run_factoid.py:445] token_to_orig_map: 9:0 10:0 11:0 12:1 13:2 14:2 15:2 16:3 17:3 18:3 19:3 20:3 21:4 22:5 23:6 24:7 25:8 26:9 27:10 28:11 29:12 30:13 31:14 32:15 33:16 34:17 35:18 36:19 37:20 38:21 39:22 40:22 41:22 42:22 43:22 44:22 45:22 46:22 47:22 48:22 49:22 50:23 51:24 52:25 53:26 54:27 55:27 56:27 57:28 58:29 59:30 60:31 61:32 62:33 63:34 64:35 65:36 66:37 67:37 68:38 69:39 70:40 71:41 72:42 73:43 74:44 75:45 76:46 77:47 78:48 79:49 80:50 81:51 82:52 83:52 84:52 85:52 86:52 87:52 88:52 89:53 90:54 91:55 92:56 93:57 94:58 95:58 96:59 97:60 98:60 99:60 100:61 101:61 102:62 103:62 104:62 105:62 106:63 107:63 108:63 109:63 110:63 111:63 112:63 113:63 114:64 115:64 116:64 117:64 118:65 119:65 120:65 121:65 122:66 123:66 124:66 125:66 126:66 127:66 128:66 129:66 130:66 131:66 132:67 133:67 134:68 135:69 136:69 137:69 138:69 139:70 140:70 141:70 142:71 143:71 144:72 145:73 146:73 147:73 148:73 149:74 150:74 151:74 152:74 153:74 154:74 155:74 156:74 157:75 158:76 159:76 160:76 161:77 162:77 163:77 164:78 165:78 166:78 167:79 168:79 169:79 170:79 171:80 172:80 173:80 174:80 175:80 176:80 177:80 178:80 179:80 180:80 181:80 182:81 183:81 184:82 185:83 186:84 187:85 188:86 189:87 190:88 191:89 192:90 193:91 194:92 195:93 196:93 197:94 198:94 199:94 200:94 201:94 202:94 203:94 204:94 205:94 206:95 207:95 208:96 209:97 210:98 211:99 212:100 213:101 214:101 215:102 216:103 217:104 218:104 219:105 220:106 221:106 222:106 223:107 224:108 225:109 226:110 227:111 228:112 229:112 230:112 231:113 232:113 233:113 234:113 235:113 236:113 237:113 238:113 239:114 240:115 241:116 242:117 243:118 244:119 245:120 246:120 247:121 248:122 249:123 250:123 251:123 252:124 253:124 254:124 255:124 256:124 257:124 258:124 259:125 260:125 261:126 262:127 263:128 264:128 265:128 266:128 267:129 268:130 269:130 270:130 271:131 272:131 273:131 274:132 275:133 276:134 277:134 278:134 279:134 280:135 281:136 282:137 283:138 284:139 285:140 286:141 287:142 288:142 289:142 290:142 291:142 292:142 293:142 294:143 295:143 296:144 297:145 298:146 299:147 300:148 301:149 302:150 303:150 304:151 305:151 306:151 307:151 308:151 309:152 310:152 311:152 312:152 313:152 314:152 315:153 316:154 317:155 318:155 319:155 320:156 321:157 322:158 323:159 324:159 325:160 326:160 327:160 328:160 329:161 330:162 331:163 332:164 333:165 334:166 335:167 336:168 337:168 338:168 339:168 340:169 341:170 342:171 343:171 344:172 345:173 346:174 347:175 348:175 349:175 350:176 351:176 352:176 353:176 354:176 355:176 356:177 357:178 358:179 359:179 360:180 361:181 362:181 363:182 364:182 365:182 366:182 367:182 368:182 369:182 370:182 371:183 372:183 373:183 374:184 375:185 376:186 377:187 378:187 379:188 380:189 381:190 382:191\n",
      "INFO:tensorflow:token_is_max_context: 9:True 10:True 11:True 12:True 13:True 14:True 15:True 16:True 17:True 18:True 19:True 20:True 21:True 22:True 23:True 24:True 25:True 26:True 27:True 28:True 29:True 30:True 31:True 32:True 33:True 34:True 35:True 36:True 37:True 38:True 39:True 40:True 41:True 42:True 43:True 44:True 45:True 46:True 47:True 48:True 49:True 50:True 51:True 52:True 53:True 54:True 55:True 56:True 57:True 58:True 59:True 60:True 61:True 62:True 63:True 64:True 65:True 66:True 67:True 68:True 69:True 70:True 71:True 72:True 73:True 74:True 75:True 76:True 77:True 78:True 79:True 80:True 81:True 82:True 83:True 84:True 85:True 86:True 87:True 88:True 89:True 90:True 91:True 92:True 93:True 94:True 95:True 96:True 97:True 98:True 99:True 100:True 101:True 102:True 103:True 104:True 105:True 106:True 107:True 108:True 109:True 110:True 111:True 112:True 113:True 114:True 115:True 116:True 117:True 118:True 119:True 120:True 121:True 122:True 123:True 124:True 125:True 126:True 127:True 128:True 129:True 130:True 131:True 132:True 133:True 134:True 135:True 136:True 137:True 138:True 139:True 140:True 141:True 142:True 143:True 144:True 145:True 146:True 147:True 148:True 149:True 150:True 151:True 152:True 153:True 154:True 155:True 156:True 157:True 158:True 159:True 160:True 161:True 162:True 163:True 164:True 165:True 166:True 167:True 168:True 169:True 170:True 171:True 172:True 173:True 174:True 175:True 176:True 177:True 178:True 179:True 180:True 181:True 182:True 183:True 184:True 185:True 186:True 187:True 188:True 189:True 190:True 191:True 192:True 193:True 194:True 195:True 196:True 197:True 198:True 199:True 200:True 201:True 202:True 203:True 204:True 205:True 206:True 207:True 208:True 209:True 210:True 211:True 212:True 213:True 214:True 215:True 216:True 217:True 218:True 219:True 220:True 221:True 222:True 223:True 224:True 225:True 226:True 227:True 228:True 229:True 230:True 231:True 232:True 233:True 234:True 235:True 236:True 237:True 238:True 239:True 240:True 241:True 242:True 243:True 244:True 245:True 246:True 247:True 248:True 249:True 250:True 251:True 252:True 253:True 254:True 255:True 256:True 257:True 258:True 259:True 260:False 261:False 262:False 263:False 264:False 265:False 266:False 267:False 268:False 269:False 270:False 271:False 272:False 273:False 274:False 275:False 276:False 277:False 278:False 279:False 280:False 281:False 282:False 283:False 284:False 285:False 286:False 287:False 288:False 289:False 290:False 291:False 292:False 293:False 294:False 295:False 296:False 297:False 298:False 299:False 300:False 301:False 302:False 303:False 304:False 305:False 306:False 307:False 308:False 309:False 310:False 311:False 312:False 313:False 314:False 315:False 316:False 317:False 318:False 319:False 320:False 321:False 322:False 323:False 324:False 325:False 326:False 327:False 328:False 329:False 330:False 331:False 332:False 333:False 334:False 335:False 336:False 337:False 338:False 339:False 340:False 341:False 342:False 343:False 344:False 345:False 346:False 347:False 348:False 349:False 350:False 351:False 352:False 353:False 354:False 355:False 356:False 357:False 358:False 359:False 360:False 361:False 362:False 363:False 364:False 365:False 366:False 367:False 368:False 369:False 370:False 371:False 372:False 373:False 374:False 375:False 376:False 377:False 378:False 379:False 380:False 381:False 382:False\n",
      "I1208 12:27:36.986837 139883775852736 run_factoid.py:447] token_is_max_context: 9:True 10:True 11:True 12:True 13:True 14:True 15:True 16:True 17:True 18:True 19:True 20:True 21:True 22:True 23:True 24:True 25:True 26:True 27:True 28:True 29:True 30:True 31:True 32:True 33:True 34:True 35:True 36:True 37:True 38:True 39:True 40:True 41:True 42:True 43:True 44:True 45:True 46:True 47:True 48:True 49:True 50:True 51:True 52:True 53:True 54:True 55:True 56:True 57:True 58:True 59:True 60:True 61:True 62:True 63:True 64:True 65:True 66:True 67:True 68:True 69:True 70:True 71:True 72:True 73:True 74:True 75:True 76:True 77:True 78:True 79:True 80:True 81:True 82:True 83:True 84:True 85:True 86:True 87:True 88:True 89:True 90:True 91:True 92:True 93:True 94:True 95:True 96:True 97:True 98:True 99:True 100:True 101:True 102:True 103:True 104:True 105:True 106:True 107:True 108:True 109:True 110:True 111:True 112:True 113:True 114:True 115:True 116:True 117:True 118:True 119:True 120:True 121:True 122:True 123:True 124:True 125:True 126:True 127:True 128:True 129:True 130:True 131:True 132:True 133:True 134:True 135:True 136:True 137:True 138:True 139:True 140:True 141:True 142:True 143:True 144:True 145:True 146:True 147:True 148:True 149:True 150:True 151:True 152:True 153:True 154:True 155:True 156:True 157:True 158:True 159:True 160:True 161:True 162:True 163:True 164:True 165:True 166:True 167:True 168:True 169:True 170:True 171:True 172:True 173:True 174:True 175:True 176:True 177:True 178:True 179:True 180:True 181:True 182:True 183:True 184:True 185:True 186:True 187:True 188:True 189:True 190:True 191:True 192:True 193:True 194:True 195:True 196:True 197:True 198:True 199:True 200:True 201:True 202:True 203:True 204:True 205:True 206:True 207:True 208:True 209:True 210:True 211:True 212:True 213:True 214:True 215:True 216:True 217:True 218:True 219:True 220:True 221:True 222:True 223:True 224:True 225:True 226:True 227:True 228:True 229:True 230:True 231:True 232:True 233:True 234:True 235:True 236:True 237:True 238:True 239:True 240:True 241:True 242:True 243:True 244:True 245:True 246:True 247:True 248:True 249:True 250:True 251:True 252:True 253:True 254:True 255:True 256:True 257:True 258:True 259:True 260:False 261:False 262:False 263:False 264:False 265:False 266:False 267:False 268:False 269:False 270:False 271:False 272:False 273:False 274:False 275:False 276:False 277:False 278:False 279:False 280:False 281:False 282:False 283:False 284:False 285:False 286:False 287:False 288:False 289:False 290:False 291:False 292:False 293:False 294:False 295:False 296:False 297:False 298:False 299:False 300:False 301:False 302:False 303:False 304:False 305:False 306:False 307:False 308:False 309:False 310:False 311:False 312:False 313:False 314:False 315:False 316:False 317:False 318:False 319:False 320:False 321:False 322:False 323:False 324:False 325:False 326:False 327:False 328:False 329:False 330:False 331:False 332:False 333:False 334:False 335:False 336:False 337:False 338:False 339:False 340:False 341:False 342:False 343:False 344:False 345:False 346:False 347:False 348:False 349:False 350:False 351:False 352:False 353:False 354:False 355:False 356:False 357:False 358:False 359:False 360:False 361:False 362:False 363:False 364:False 365:False 366:False 367:False 368:False 369:False 370:False 371:False 372:False 373:False 374:False 375:False 376:False 377:False 378:False 379:False 380:False 381:False 382:False\n",
      "INFO:tensorflow:input_ids: 101 1731 1110 1103 3879 1932 5165 136 102 14557 10806 1197 6187 1123 5813 2116 113 149 2137 3048 114 1110 1141 1104 1103 1211 3933 11534 4680 1104 1822 1171 2489 1105 1110 170 1887 2612 1104 187 14230 10182 13200 23610 119 164 122 782 124 166 1966 1211 4420 1114 149 2137 3048 1169 5515 18330 7300 1105 8458 13950 1114 6588 3252 117 170 1374 4420 1202 1136 6297 5877 1106 6588 3252 1105 2028 4752 13467 3252 119 164 125 117 126 166 1247 1132 1317 1514 13467 6665 131 1501 181 25509 1197 17599 118 6187 10294 18778 1183 113 152 22074 114 117 164 127 166 17599 6696 2155 22258 6187 10294 18778 1183 113 22157 2137 114 117 164 128 117 129 166 10298 1193 19849 14715 14467 4515 14196 181 25509 1197 9455 14637 11970 113 26574 1708 118 157 2162 15499 114 117 164 130 166 1105 1679 12734 13064 1322 2155 22258 181 25509 1197 6187 10294 18778 1183 113 153 21678 2137 114 119 164 1275 117 1429 166 152 22074 1144 1151 4485 1112 1103 1211 3337 6315 13467 5146 1111 1231 21754 149 2137 3048 132 164 1367 117 1492 166 1649 117 1122 1108 2628 1114 1317 13522 117 1259 6484 3290 117 9071 1231 27539 117 1105 1103 8116 1104 3431 181 13499 118 1441 1204 117 164 1489 117 1405 166 1134 1169 1871 1107 20482 1105 14161 3384 1104 1103 174 25786 12602 2000 119 164 1479 117 1542 166 22157 2137 2745 170 17599 6696 2155 16260 1111 5173 23228 118 189 1988 117 1105 1103 18311 20080 4559 1361 6130 1132 8630 1118 6484 15601 1194 4267 13389 1116 132 164 1407 166 2456 117 1103 6484 1105 2991 7918 1132 10298 1193 4475 119 164 1627 166 26574 1708 118 157 2162 15499 1110 170 1218 118 3134 2805 3442 1111 1231 21754 149 2137 3048 119 1262 1122 1144 1103 13300 1104 1750 178 2980 26767 1596 2991 7918 3773 117 2211 3187 1104 2112 19807 5838 187 14230 10182 12888 1548 117 1105 10558 1231 27539 1104 3840 4412 21718 1665 119 164 1406 117 1626 166 153 21678 2137 1110 170 1167 10298 1193 19849 6059 1272 1103 102\n",
      "I1208 12:27:36.986938 139883775852736 run_factoid.py:449] input_ids: 101 1731 1110 1103 3879 1932 5165 136 102 14557 10806 1197 6187 1123 5813 2116 113 149 2137 3048 114 1110 1141 1104 1103 1211 3933 11534 4680 1104 1822 1171 2489 1105 1110 170 1887 2612 1104 187 14230 10182 13200 23610 119 164 122 782 124 166 1966 1211 4420 1114 149 2137 3048 1169 5515 18330 7300 1105 8458 13950 1114 6588 3252 117 170 1374 4420 1202 1136 6297 5877 1106 6588 3252 1105 2028 4752 13467 3252 119 164 125 117 126 166 1247 1132 1317 1514 13467 6665 131 1501 181 25509 1197 17599 118 6187 10294 18778 1183 113 152 22074 114 117 164 127 166 17599 6696 2155 22258 6187 10294 18778 1183 113 22157 2137 114 117 164 128 117 129 166 10298 1193 19849 14715 14467 4515 14196 181 25509 1197 9455 14637 11970 113 26574 1708 118 157 2162 15499 114 117 164 130 166 1105 1679 12734 13064 1322 2155 22258 181 25509 1197 6187 10294 18778 1183 113 153 21678 2137 114 119 164 1275 117 1429 166 152 22074 1144 1151 4485 1112 1103 1211 3337 6315 13467 5146 1111 1231 21754 149 2137 3048 132 164 1367 117 1492 166 1649 117 1122 1108 2628 1114 1317 13522 117 1259 6484 3290 117 9071 1231 27539 117 1105 1103 8116 1104 3431 181 13499 118 1441 1204 117 164 1489 117 1405 166 1134 1169 1871 1107 20482 1105 14161 3384 1104 1103 174 25786 12602 2000 119 164 1479 117 1542 166 22157 2137 2745 170 17599 6696 2155 16260 1111 5173 23228 118 189 1988 117 1105 1103 18311 20080 4559 1361 6130 1132 8630 1118 6484 15601 1194 4267 13389 1116 132 164 1407 166 2456 117 1103 6484 1105 2991 7918 1132 10298 1193 4475 119 164 1627 166 26574 1708 118 157 2162 15499 1110 170 1218 118 3134 2805 3442 1111 1231 21754 149 2137 3048 119 1262 1122 1144 1103 13300 1104 1750 178 2980 26767 1596 2991 7918 3773 117 2211 3187 1104 2112 19807 5838 187 14230 10182 12888 1548 117 1105 10558 1231 27539 1104 3840 4412 21718 1665 119 164 1406 117 1626 166 153 21678 2137 1110 170 1167 10298 1193 19849 6059 1272 1103 102\n",
      "INFO:tensorflow:input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      "I1208 12:27:36.987030 139883775852736 run_factoid.py:451] input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      "INFO:tensorflow:segment_ids: 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      "I1208 12:27:36.987120 139883775852736 run_factoid.py:453] segment_ids: 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      "INFO:tensorflow:*** Example ***\n",
      "I1208 12:27:36.988011 139883775852736 run_factoid.py:438] *** Example ***\n",
      "INFO:tensorflow:unique_id: 1000000005\n",
      "I1208 12:27:36.988067 139883775852736 run_factoid.py:439] unique_id: 1000000005\n",
      "INFO:tensorflow:example_index: 2\n",
      "I1208 12:27:36.988105 139883775852736 run_factoid.py:440] example_index: 2\n",
      "INFO:tensorflow:doc_span_index: 1\n",
      "I1208 12:27:36.988139 139883775852736 run_factoid.py:441] doc_span_index: 1\n",
      "INFO:tensorflow:tokens: [CLS] How is the condition usually treated ? [SEP] ##ram ##inal l ##umba ##r inter ##body fusion ( MI ##S - T ##L ##IF ) , [ 9 ] and per ##cut ##aneous end ##os ##copic l ##umba ##r disc ##ec ##tom ##y ( P ##EL ##D ) . [ 10 , 11 ] O ##LM has been regarded as the most commonly recommended surgical option for re ##current L ##D ##H ; [ 12 , 13 ] however , it was associated with several complications , including muscle damage , nerve re ##traction , and the removal of yellow l ##iga - men ##t , [ 14 , 15 ] which can result in instability and scar ##ring of the e ##pid ##ural space . [ 16 , 17 ] ME ##D uses a micro ##end ##os ##cope for visual ##iza - t ##ion , and the para ##sp ##ino ##us muscles are handled by muscle splitting through di ##lator ##s ; [ 18 ] thus , the muscle and soft tissue are minimal ##ly injured . [ 19 ] MI ##S - T ##L ##IF is a well - accepted operation method for re ##current L ##D ##H . And it has the advantages of less i ##at ##rogen ##ic soft tissue injury , lower risk of post ##oper ##ative r ##adi ##cu ##lit ##is , and decreased re ##traction of du ##ral sa ##c . [ 20 , 21 ] P ##EL ##D is a more minimal ##ly invasive surgery because the posterior column structures are pre - served . [ 22 , 23 ] It has gained interest for its potential advantage in the reduced risk of face ##t joints injury , fewer post ##oper ##ative complications , a shorter hospital stay and lower cost . [ 24 , 25 ] Previous studies have reported that P ##EL ##D is an effective and safe treatment for L ##D ##H . [ 26 , 27 ] However , whether P ##EL ##D is superior to other surgical options remains controversial . Thus , we conducted this meta - analysis to compare the clinical , radio ##log ##ic , and complications of P ##EL ##D and other surge ##ries for patients with L ##D ##H . [SEP]\n",
      "I1208 12:27:36.988248 139883775852736 run_factoid.py:443] tokens: [CLS] How is the condition usually treated ? [SEP] ##ram ##inal l ##umba ##r inter ##body fusion ( MI ##S - T ##L ##IF ) , [ 9 ] and per ##cut ##aneous end ##os ##copic l ##umba ##r disc ##ec ##tom ##y ( P ##EL ##D ) . [ 10 , 11 ] O ##LM has been regarded as the most commonly recommended surgical option for re ##current L ##D ##H ; [ 12 , 13 ] however , it was associated with several complications , including muscle damage , nerve re ##traction , and the removal of yellow l ##iga - men ##t , [ 14 , 15 ] which can result in instability and scar ##ring of the e ##pid ##ural space . [ 16 , 17 ] ME ##D uses a micro ##end ##os ##cope for visual ##iza - t ##ion , and the para ##sp ##ino ##us muscles are handled by muscle splitting through di ##lator ##s ; [ 18 ] thus , the muscle and soft tissue are minimal ##ly injured . [ 19 ] MI ##S - T ##L ##IF is a well - accepted operation method for re ##current L ##D ##H . And it has the advantages of less i ##at ##rogen ##ic soft tissue injury , lower risk of post ##oper ##ative r ##adi ##cu ##lit ##is , and decreased re ##traction of du ##ral sa ##c . [ 20 , 21 ] P ##EL ##D is a more minimal ##ly invasive surgery because the posterior column structures are pre - served . [ 22 , 23 ] It has gained interest for its potential advantage in the reduced risk of face ##t joints injury , fewer post ##oper ##ative complications , a shorter hospital stay and lower cost . [ 24 , 25 ] Previous studies have reported that P ##EL ##D is an effective and safe treatment for L ##D ##H . [ 26 , 27 ] However , whether P ##EL ##D is superior to other surgical options remains controversial . Thus , we conducted this meta - analysis to compare the clinical , radio ##log ##ic , and complications of P ##EL ##D and other surge ##ries for patients with L ##D ##H . [SEP]\n",
      "INFO:tensorflow:token_to_orig_map: 9:69 10:69 11:70 12:70 13:70 14:71 15:71 16:72 17:73 18:73 19:73 20:73 21:74 22:74 23:74 24:74 25:74 26:74 27:74 28:74 29:75 30:76 31:76 32:76 33:77 34:77 35:77 36:78 37:78 38:78 39:79 40:79 41:79 42:79 43:80 44:80 45:80 46:80 47:80 48:80 49:80 50:80 51:80 52:80 53:80 54:81 55:81 56:82 57:83 58:84 59:85 60:86 61:87 62:88 63:89 64:90 65:91 66:92 67:93 68:93 69:94 70:94 71:94 72:94 73:94 74:94 75:94 76:94 77:94 78:95 79:95 80:96 81:97 82:98 83:99 84:100 85:101 86:101 87:102 88:103 89:104 90:104 91:105 92:106 93:106 94:106 95:107 96:108 97:109 98:110 99:111 100:112 101:112 102:112 103:113 104:113 105:113 106:113 107:113 108:113 109:113 110:113 111:114 112:115 113:116 114:117 115:118 116:119 117:120 118:120 119:121 120:122 121:123 122:123 123:123 124:124 125:124 126:124 127:124 128:124 129:124 130:124 131:125 132:125 133:126 134:127 135:128 136:128 137:128 138:128 139:129 140:130 141:130 142:130 143:131 144:131 145:131 146:132 147:133 148:134 149:134 150:134 151:134 152:135 153:136 154:137 155:138 156:139 157:140 158:141 159:142 160:142 161:142 162:142 163:142 164:142 165:142 166:143 167:143 168:144 169:145 170:146 171:147 172:148 173:149 174:150 175:150 176:151 177:151 178:151 179:151 180:151 181:152 182:152 183:152 184:152 185:152 186:152 187:153 188:154 189:155 190:155 191:155 192:156 193:157 194:158 195:159 196:159 197:160 198:160 199:160 200:160 201:161 202:162 203:163 204:164 205:165 206:166 207:167 208:168 209:168 210:168 211:168 212:169 213:170 214:171 215:171 216:172 217:173 218:174 219:175 220:175 221:175 222:176 223:176 224:176 225:176 226:176 227:176 228:177 229:178 230:179 231:179 232:180 233:181 234:181 235:182 236:182 237:182 238:182 239:182 240:182 241:182 242:182 243:183 244:183 245:183 246:184 247:185 248:186 249:187 250:187 251:188 252:189 253:190 254:191 255:192 256:193 257:194 258:195 259:196 260:196 261:197 262:197 263:197 264:197 265:197 266:197 267:197 268:198 269:199 270:200 271:201 272:202 273:203 274:204 275:205 276:206 277:207 278:208 279:209 280:210 281:211 282:211 283:212 284:213 285:213 286:214 287:215 288:215 289:215 290:216 291:216 292:217 293:218 294:219 295:220 296:221 297:222 298:223 299:223 300:223 301:223 302:223 303:223 304:223 305:224 306:225 307:226 308:227 309:228 310:229 311:229 312:229 313:230 314:231 315:232 316:233 317:234 318:235 319:236 320:237 321:237 322:237 323:237 324:237 325:237 326:237 327:237 328:237 329:238 330:238 331:239 332:240 333:240 334:240 335:241 336:242 337:243 338:244 339:245 340:246 341:247 342:248 343:248 344:249 345:249 346:250 347:251 348:252 349:253 350:253 351:253 352:254 353:255 354:256 355:257 356:257 357:258 358:258 359:258 360:258 361:259 362:260 363:261 364:262 365:262 366:262 367:263 368:264 369:265 370:265 371:266 372:267 373:268 374:269 375:269 376:269 377:269\n",
      "I1208 12:27:36.988361 139883775852736 run_factoid.py:445] token_to_orig_map: 9:69 10:69 11:70 12:70 13:70 14:71 15:71 16:72 17:73 18:73 19:73 20:73 21:74 22:74 23:74 24:74 25:74 26:74 27:74 28:74 29:75 30:76 31:76 32:76 33:77 34:77 35:77 36:78 37:78 38:78 39:79 40:79 41:79 42:79 43:80 44:80 45:80 46:80 47:80 48:80 49:80 50:80 51:80 52:80 53:80 54:81 55:81 56:82 57:83 58:84 59:85 60:86 61:87 62:88 63:89 64:90 65:91 66:92 67:93 68:93 69:94 70:94 71:94 72:94 73:94 74:94 75:94 76:94 77:94 78:95 79:95 80:96 81:97 82:98 83:99 84:100 85:101 86:101 87:102 88:103 89:104 90:104 91:105 92:106 93:106 94:106 95:107 96:108 97:109 98:110 99:111 100:112 101:112 102:112 103:113 104:113 105:113 106:113 107:113 108:113 109:113 110:113 111:114 112:115 113:116 114:117 115:118 116:119 117:120 118:120 119:121 120:122 121:123 122:123 123:123 124:124 125:124 126:124 127:124 128:124 129:124 130:124 131:125 132:125 133:126 134:127 135:128 136:128 137:128 138:128 139:129 140:130 141:130 142:130 143:131 144:131 145:131 146:132 147:133 148:134 149:134 150:134 151:134 152:135 153:136 154:137 155:138 156:139 157:140 158:141 159:142 160:142 161:142 162:142 163:142 164:142 165:142 166:143 167:143 168:144 169:145 170:146 171:147 172:148 173:149 174:150 175:150 176:151 177:151 178:151 179:151 180:151 181:152 182:152 183:152 184:152 185:152 186:152 187:153 188:154 189:155 190:155 191:155 192:156 193:157 194:158 195:159 196:159 197:160 198:160 199:160 200:160 201:161 202:162 203:163 204:164 205:165 206:166 207:167 208:168 209:168 210:168 211:168 212:169 213:170 214:171 215:171 216:172 217:173 218:174 219:175 220:175 221:175 222:176 223:176 224:176 225:176 226:176 227:176 228:177 229:178 230:179 231:179 232:180 233:181 234:181 235:182 236:182 237:182 238:182 239:182 240:182 241:182 242:182 243:183 244:183 245:183 246:184 247:185 248:186 249:187 250:187 251:188 252:189 253:190 254:191 255:192 256:193 257:194 258:195 259:196 260:196 261:197 262:197 263:197 264:197 265:197 266:197 267:197 268:198 269:199 270:200 271:201 272:202 273:203 274:204 275:205 276:206 277:207 278:208 279:209 280:210 281:211 282:211 283:212 284:213 285:213 286:214 287:215 288:215 289:215 290:216 291:216 292:217 293:218 294:219 295:220 296:221 297:222 298:223 299:223 300:223 301:223 302:223 303:223 304:223 305:224 306:225 307:226 308:227 309:228 310:229 311:229 312:229 313:230 314:231 315:232 316:233 317:234 318:235 319:236 320:237 321:237 322:237 323:237 324:237 325:237 326:237 327:237 328:237 329:238 330:238 331:239 332:240 333:240 334:240 335:241 336:242 337:243 338:244 339:245 340:246 341:247 342:248 343:248 344:249 345:249 346:250 347:251 348:252 349:253 350:253 351:253 352:254 353:255 354:256 355:257 356:257 357:258 358:258 359:258 360:258 361:259 362:260 363:261 364:262 365:262 366:262 367:263 368:264 369:265 370:265 371:266 372:267 373:268 374:269 375:269 376:269 377:269\n",
      "INFO:tensorflow:token_is_max_context: 9:False 10:False 11:False 12:False 13:False 14:False 15:False 16:False 17:False 18:False 19:False 20:False 21:False 22:False 23:False 24:False 25:False 26:False 27:False 28:False 29:False 30:False 31:False 32:False 33:False 34:False 35:False 36:False 37:False 38:False 39:False 40:False 41:False 42:False 43:False 44:False 45:False 46:False 47:False 48:False 49:False 50:False 51:False 52:False 53:False 54:False 55:False 56:False 57:False 58:False 59:False 60:False 61:False 62:False 63:False 64:False 65:False 66:False 67:False 68:False 69:False 70:False 71:False 72:False 73:False 74:False 75:False 76:False 77:False 78:False 79:False 80:False 81:False 82:False 83:False 84:False 85:False 86:False 87:False 88:False 89:False 90:False 91:False 92:False 93:False 94:False 95:False 96:False 97:False 98:False 99:False 100:False 101:False 102:False 103:False 104:False 105:False 106:False 107:False 108:False 109:False 110:False 111:False 112:False 113:False 114:False 115:False 116:False 117:False 118:False 119:False 120:False 121:False 122:False 123:False 124:False 125:False 126:False 127:False 128:False 129:False 130:False 131:False 132:True 133:True 134:True 135:True 136:True 137:True 138:True 139:True 140:True 141:True 142:True 143:True 144:True 145:True 146:True 147:True 148:True 149:True 150:True 151:True 152:True 153:True 154:True 155:True 156:True 157:True 158:True 159:True 160:True 161:True 162:True 163:True 164:True 165:True 166:True 167:True 168:True 169:True 170:True 171:True 172:True 173:True 174:True 175:True 176:True 177:True 178:True 179:True 180:True 181:True 182:True 183:True 184:True 185:True 186:True 187:True 188:True 189:True 190:True 191:True 192:True 193:True 194:True 195:True 196:True 197:True 198:True 199:True 200:True 201:True 202:True 203:True 204:True 205:True 206:True 207:True 208:True 209:True 210:True 211:True 212:True 213:True 214:True 215:True 216:True 217:True 218:True 219:True 220:True 221:True 222:True 223:True 224:True 225:True 226:True 227:True 228:True 229:True 230:True 231:True 232:True 233:True 234:True 235:True 236:True 237:True 238:True 239:True 240:True 241:True 242:True 243:True 244:True 245:True 246:True 247:True 248:True 249:True 250:True 251:True 252:True 253:True 254:True 255:True 256:True 257:True 258:True 259:True 260:True 261:True 262:True 263:True 264:True 265:True 266:True 267:True 268:True 269:True 270:True 271:True 272:True 273:True 274:True 275:True 276:True 277:True 278:True 279:True 280:True 281:True 282:True 283:True 284:True 285:True 286:True 287:True 288:True 289:True 290:True 291:True 292:True 293:True 294:True 295:True 296:True 297:True 298:True 299:True 300:True 301:True 302:True 303:True 304:True 305:True 306:True 307:True 308:True 309:True 310:True 311:True 312:True 313:True 314:True 315:True 316:True 317:True 318:True 319:True 320:True 321:True 322:True 323:True 324:True 325:True 326:True 327:True 328:True 329:True 330:True 331:True 332:True 333:True 334:True 335:True 336:True 337:True 338:True 339:True 340:True 341:True 342:True 343:True 344:True 345:True 346:True 347:True 348:True 349:True 350:True 351:True 352:True 353:True 354:True 355:True 356:True 357:True 358:True 359:True 360:True 361:True 362:True 363:True 364:True 365:True 366:True 367:True 368:True 369:True 370:True 371:True 372:True 373:True 374:True 375:True 376:True 377:True\n",
      "I1208 12:27:36.988467 139883775852736 run_factoid.py:447] token_is_max_context: 9:False 10:False 11:False 12:False 13:False 14:False 15:False 16:False 17:False 18:False 19:False 20:False 21:False 22:False 23:False 24:False 25:False 26:False 27:False 28:False 29:False 30:False 31:False 32:False 33:False 34:False 35:False 36:False 37:False 38:False 39:False 40:False 41:False 42:False 43:False 44:False 45:False 46:False 47:False 48:False 49:False 50:False 51:False 52:False 53:False 54:False 55:False 56:False 57:False 58:False 59:False 60:False 61:False 62:False 63:False 64:False 65:False 66:False 67:False 68:False 69:False 70:False 71:False 72:False 73:False 74:False 75:False 76:False 77:False 78:False 79:False 80:False 81:False 82:False 83:False 84:False 85:False 86:False 87:False 88:False 89:False 90:False 91:False 92:False 93:False 94:False 95:False 96:False 97:False 98:False 99:False 100:False 101:False 102:False 103:False 104:False 105:False 106:False 107:False 108:False 109:False 110:False 111:False 112:False 113:False 114:False 115:False 116:False 117:False 118:False 119:False 120:False 121:False 122:False 123:False 124:False 125:False 126:False 127:False 128:False 129:False 130:False 131:False 132:True 133:True 134:True 135:True 136:True 137:True 138:True 139:True 140:True 141:True 142:True 143:True 144:True 145:True 146:True 147:True 148:True 149:True 150:True 151:True 152:True 153:True 154:True 155:True 156:True 157:True 158:True 159:True 160:True 161:True 162:True 163:True 164:True 165:True 166:True 167:True 168:True 169:True 170:True 171:True 172:True 173:True 174:True 175:True 176:True 177:True 178:True 179:True 180:True 181:True 182:True 183:True 184:True 185:True 186:True 187:True 188:True 189:True 190:True 191:True 192:True 193:True 194:True 195:True 196:True 197:True 198:True 199:True 200:True 201:True 202:True 203:True 204:True 205:True 206:True 207:True 208:True 209:True 210:True 211:True 212:True 213:True 214:True 215:True 216:True 217:True 218:True 219:True 220:True 221:True 222:True 223:True 224:True 225:True 226:True 227:True 228:True 229:True 230:True 231:True 232:True 233:True 234:True 235:True 236:True 237:True 238:True 239:True 240:True 241:True 242:True 243:True 244:True 245:True 246:True 247:True 248:True 249:True 250:True 251:True 252:True 253:True 254:True 255:True 256:True 257:True 258:True 259:True 260:True 261:True 262:True 263:True 264:True 265:True 266:True 267:True 268:True 269:True 270:True 271:True 272:True 273:True 274:True 275:True 276:True 277:True 278:True 279:True 280:True 281:True 282:True 283:True 284:True 285:True 286:True 287:True 288:True 289:True 290:True 291:True 292:True 293:True 294:True 295:True 296:True 297:True 298:True 299:True 300:True 301:True 302:True 303:True 304:True 305:True 306:True 307:True 308:True 309:True 310:True 311:True 312:True 313:True 314:True 315:True 316:True 317:True 318:True 319:True 320:True 321:True 322:True 323:True 324:True 325:True 326:True 327:True 328:True 329:True 330:True 331:True 332:True 333:True 334:True 335:True 336:True 337:True 338:True 339:True 340:True 341:True 342:True 343:True 344:True 345:True 346:True 347:True 348:True 349:True 350:True 351:True 352:True 353:True 354:True 355:True 356:True 357:True 358:True 359:True 360:True 361:True 362:True 363:True 364:True 365:True 366:True 367:True 368:True 369:True 370:True 371:True 372:True 373:True 374:True 375:True 376:True 377:True\n",
      "INFO:tensorflow:input_ids: 101 1731 1110 1103 3879 1932 5165 136 102 4515 14196 181 25509 1197 9455 14637 11970 113 26574 1708 118 157 2162 15499 114 117 164 130 166 1105 1679 12734 13064 1322 2155 22258 181 25509 1197 6187 10294 18778 1183 113 153 21678 2137 114 119 164 1275 117 1429 166 152 22074 1144 1151 4485 1112 1103 1211 3337 6315 13467 5146 1111 1231 21754 149 2137 3048 132 164 1367 117 1492 166 1649 117 1122 1108 2628 1114 1317 13522 117 1259 6484 3290 117 9071 1231 27539 117 1105 1103 8116 1104 3431 181 13499 118 1441 1204 117 164 1489 117 1405 166 1134 1169 1871 1107 20482 1105 14161 3384 1104 1103 174 25786 12602 2000 119 164 1479 117 1542 166 22157 2137 2745 170 17599 6696 2155 16260 1111 5173 23228 118 189 1988 117 1105 1103 18311 20080 4559 1361 6130 1132 8630 1118 6484 15601 1194 4267 13389 1116 132 164 1407 166 2456 117 1103 6484 1105 2991 7918 1132 10298 1193 4475 119 164 1627 166 26574 1708 118 157 2162 15499 1110 170 1218 118 3134 2805 3442 1111 1231 21754 149 2137 3048 119 1262 1122 1144 1103 13300 1104 1750 178 2980 26767 1596 2991 7918 3773 117 2211 3187 1104 2112 19807 5838 187 14230 10182 12888 1548 117 1105 10558 1231 27539 1104 3840 4412 21718 1665 119 164 1406 117 1626 166 153 21678 2137 1110 170 1167 10298 1193 19849 6059 1272 1103 16530 5551 4413 1132 3073 118 1462 119 164 1659 117 1695 166 1135 1144 3388 2199 1111 1157 3209 4316 1107 1103 3549 3187 1104 1339 1204 19365 3773 117 8307 2112 19807 5838 13522 117 170 7681 2704 2215 1105 2211 2616 119 164 1572 117 1512 166 24142 2527 1138 2103 1115 153 21678 2137 1110 1126 3903 1105 2914 3252 1111 149 2137 3048 119 164 1744 117 1765 166 1438 117 2480 153 21678 2137 1110 7298 1106 1168 13467 6665 2606 6241 119 4516 117 1195 3303 1142 27154 118 3622 1106 14133 1103 7300 117 2070 13791 1596 117 1105 13522 1104 153 21678 2137 1105 1168 12814 3377 1111 4420 1114 149 2137 3048 119 102 0 0 0 0 0\n",
      "I1208 12:27:36.988566 139883775852736 run_factoid.py:449] input_ids: 101 1731 1110 1103 3879 1932 5165 136 102 4515 14196 181 25509 1197 9455 14637 11970 113 26574 1708 118 157 2162 15499 114 117 164 130 166 1105 1679 12734 13064 1322 2155 22258 181 25509 1197 6187 10294 18778 1183 113 153 21678 2137 114 119 164 1275 117 1429 166 152 22074 1144 1151 4485 1112 1103 1211 3337 6315 13467 5146 1111 1231 21754 149 2137 3048 132 164 1367 117 1492 166 1649 117 1122 1108 2628 1114 1317 13522 117 1259 6484 3290 117 9071 1231 27539 117 1105 1103 8116 1104 3431 181 13499 118 1441 1204 117 164 1489 117 1405 166 1134 1169 1871 1107 20482 1105 14161 3384 1104 1103 174 25786 12602 2000 119 164 1479 117 1542 166 22157 2137 2745 170 17599 6696 2155 16260 1111 5173 23228 118 189 1988 117 1105 1103 18311 20080 4559 1361 6130 1132 8630 1118 6484 15601 1194 4267 13389 1116 132 164 1407 166 2456 117 1103 6484 1105 2991 7918 1132 10298 1193 4475 119 164 1627 166 26574 1708 118 157 2162 15499 1110 170 1218 118 3134 2805 3442 1111 1231 21754 149 2137 3048 119 1262 1122 1144 1103 13300 1104 1750 178 2980 26767 1596 2991 7918 3773 117 2211 3187 1104 2112 19807 5838 187 14230 10182 12888 1548 117 1105 10558 1231 27539 1104 3840 4412 21718 1665 119 164 1406 117 1626 166 153 21678 2137 1110 170 1167 10298 1193 19849 6059 1272 1103 16530 5551 4413 1132 3073 118 1462 119 164 1659 117 1695 166 1135 1144 3388 2199 1111 1157 3209 4316 1107 1103 3549 3187 1104 1339 1204 19365 3773 117 8307 2112 19807 5838 13522 117 170 7681 2704 2215 1105 2211 2616 119 164 1572 117 1512 166 24142 2527 1138 2103 1115 153 21678 2137 1110 1126 3903 1105 2914 3252 1111 149 2137 3048 119 164 1744 117 1765 166 1438 117 2480 153 21678 2137 1110 7298 1106 1168 13467 6665 2606 6241 119 4516 117 1195 3303 1142 27154 118 3622 1106 14133 1103 7300 117 2070 13791 1596 117 1105 13522 1104 153 21678 2137 1105 1168 12814 3377 1111 4420 1114 149 2137 3048 119 102 0 0 0 0 0\n",
      "INFO:tensorflow:input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0\n",
      "I1208 12:27:36.988662 139883775852736 run_factoid.py:451] input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0\n",
      "INFO:tensorflow:segment_ids: 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0\n",
      "I1208 12:27:36.988752 139883775852736 run_factoid.py:453] segment_ids: 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0\n",
      "INFO:tensorflow:*** Example ***\n",
      "I1208 12:27:36.994373 139883775852736 run_factoid.py:438] *** Example ***\n",
      "INFO:tensorflow:unique_id: 1000000006\n",
      "I1208 12:27:36.994477 139883775852736 run_factoid.py:439] unique_id: 1000000006\n",
      "INFO:tensorflow:example_index: 3\n",
      "I1208 12:27:36.994527 139883775852736 run_factoid.py:440] example_index: 3\n",
      "INFO:tensorflow:doc_span_index: 0\n",
      "I1208 12:27:36.994563 139883775852736 run_factoid.py:441] doc_span_index: 0\n",
      "INFO:tensorflow:tokens: [CLS] What are ways to manage this condition ? [SEP] Lu ##mba ##r disc her ##nia ##tion ( L ##D ##H ) is one of the most frequently diagnosed causes of low back pain and is a common cause of r ##adi ##cu ##lop ##athy . [ 1 – 3 ] Although most patients with L ##D ##H can achieve satisfying clinical and functional outcomes with conservative treatment , a few patients do not respond effectively to conservative treatment and eventually require surgical treatment . [ 4 , 5 ] There are several main surgical options : open l ##umba ##r micro - disc ##ec ##tom ##y ( O ##LM ) , [ 6 ] micro ##end ##os ##copic disc ##ec ##tom ##y ( ME ##D ) , [ 7 , 8 ] minimal ##ly invasive trans ##fo ##ram ##inal l ##umba ##r inter ##body fusion ( MI ##S - T ##L ##IF ) , [ 9 ] and per ##cut ##aneous end ##os ##copic l ##umba ##r disc ##ec ##tom ##y ( P ##EL ##D ) . [ 10 , 11 ] O ##LM has been regarded as the most commonly recommended surgical option for re ##current L ##D ##H ; [ 12 , 13 ] however , it was associated with several complications , including muscle damage , nerve re ##traction , and the removal of yellow l ##iga - men ##t , [ 14 , 15 ] which can result in instability and scar ##ring of the e ##pid ##ural space . [ 16 , 17 ] ME ##D uses a micro ##end ##os ##cope for visual ##iza - t ##ion , and the para ##sp ##ino ##us muscles are handled by muscle splitting through di ##lator ##s ; [ 18 ] thus , the muscle and soft tissue are minimal ##ly injured . [ 19 ] MI ##S - T ##L ##IF is a well - accepted operation method for re ##current L ##D ##H . And it has the advantages of less i ##at ##rogen ##ic soft tissue injury , lower risk of post ##oper ##ative r ##adi ##cu ##lit ##is , and decreased re ##traction of du ##ral sa ##c . [ 20 , 21 ] P ##EL ##D is a more minimal ##ly invasive surgery because [SEP]\n",
      "I1208 12:27:36.994688 139883775852736 run_factoid.py:443] tokens: [CLS] What are ways to manage this condition ? [SEP] Lu ##mba ##r disc her ##nia ##tion ( L ##D ##H ) is one of the most frequently diagnosed causes of low back pain and is a common cause of r ##adi ##cu ##lop ##athy . [ 1 – 3 ] Although most patients with L ##D ##H can achieve satisfying clinical and functional outcomes with conservative treatment , a few patients do not respond effectively to conservative treatment and eventually require surgical treatment . [ 4 , 5 ] There are several main surgical options : open l ##umba ##r micro - disc ##ec ##tom ##y ( O ##LM ) , [ 6 ] micro ##end ##os ##copic disc ##ec ##tom ##y ( ME ##D ) , [ 7 , 8 ] minimal ##ly invasive trans ##fo ##ram ##inal l ##umba ##r inter ##body fusion ( MI ##S - T ##L ##IF ) , [ 9 ] and per ##cut ##aneous end ##os ##copic l ##umba ##r disc ##ec ##tom ##y ( P ##EL ##D ) . [ 10 , 11 ] O ##LM has been regarded as the most commonly recommended surgical option for re ##current L ##D ##H ; [ 12 , 13 ] however , it was associated with several complications , including muscle damage , nerve re ##traction , and the removal of yellow l ##iga - men ##t , [ 14 , 15 ] which can result in instability and scar ##ring of the e ##pid ##ural space . [ 16 , 17 ] ME ##D uses a micro ##end ##os ##cope for visual ##iza - t ##ion , and the para ##sp ##ino ##us muscles are handled by muscle splitting through di ##lator ##s ; [ 18 ] thus , the muscle and soft tissue are minimal ##ly injured . [ 19 ] MI ##S - T ##L ##IF is a well - accepted operation method for re ##current L ##D ##H . And it has the advantages of less i ##at ##rogen ##ic soft tissue injury , lower risk of post ##oper ##ative r ##adi ##cu ##lit ##is , and decreased re ##traction of du ##ral sa ##c . [ 20 , 21 ] P ##EL ##D is a more minimal ##ly invasive surgery because [SEP]\n",
      "INFO:tensorflow:token_to_orig_map: 10:0 11:0 12:0 13:1 14:2 15:2 16:2 17:3 18:3 19:3 20:3 21:3 22:4 23:5 24:6 25:7 26:8 27:9 28:10 29:11 30:12 31:13 32:14 33:15 34:16 35:17 36:18 37:19 38:20 39:21 40:22 41:22 42:22 43:22 44:22 45:22 46:22 47:22 48:22 49:22 50:22 51:23 52:24 53:25 54:26 55:27 56:27 57:27 58:28 59:29 60:30 61:31 62:32 63:33 64:34 65:35 66:36 67:37 68:37 69:38 70:39 71:40 72:41 73:42 74:43 75:44 76:45 77:46 78:47 79:48 80:49 81:50 82:51 83:52 84:52 85:52 86:52 87:52 88:52 89:52 90:53 91:54 92:55 93:56 94:57 95:58 96:58 97:59 98:60 99:60 100:60 101:61 102:61 103:62 104:62 105:62 106:62 107:63 108:63 109:63 110:63 111:63 112:63 113:63 114:63 115:64 116:64 117:64 118:64 119:65 120:65 121:65 122:65 123:66 124:66 125:66 126:66 127:66 128:66 129:66 130:66 131:66 132:66 133:67 134:67 135:68 136:69 137:69 138:69 139:69 140:70 141:70 142:70 143:71 144:71 145:72 146:73 147:73 148:73 149:73 150:74 151:74 152:74 153:74 154:74 155:74 156:74 157:74 158:75 159:76 160:76 161:76 162:77 163:77 164:77 165:78 166:78 167:78 168:79 169:79 170:79 171:79 172:80 173:80 174:80 175:80 176:80 177:80 178:80 179:80 180:80 181:80 182:80 183:81 184:81 185:82 186:83 187:84 188:85 189:86 190:87 191:88 192:89 193:90 194:91 195:92 196:93 197:93 198:94 199:94 200:94 201:94 202:94 203:94 204:94 205:94 206:94 207:95 208:95 209:96 210:97 211:98 212:99 213:100 214:101 215:101 216:102 217:103 218:104 219:104 220:105 221:106 222:106 223:106 224:107 225:108 226:109 227:110 228:111 229:112 230:112 231:112 232:113 233:113 234:113 235:113 236:113 237:113 238:113 239:113 240:114 241:115 242:116 243:117 244:118 245:119 246:120 247:120 248:121 249:122 250:123 251:123 252:123 253:124 254:124 255:124 256:124 257:124 258:124 259:124 260:125 261:125 262:126 263:127 264:128 265:128 266:128 267:128 268:129 269:130 270:130 271:130 272:131 273:131 274:131 275:132 276:133 277:134 278:134 279:134 280:134 281:135 282:136 283:137 284:138 285:139 286:140 287:141 288:142 289:142 290:142 291:142 292:142 293:142 294:142 295:143 296:143 297:144 298:145 299:146 300:147 301:148 302:149 303:150 304:150 305:151 306:151 307:151 308:151 309:151 310:152 311:152 312:152 313:152 314:152 315:152 316:153 317:154 318:155 319:155 320:155 321:156 322:157 323:158 324:159 325:159 326:160 327:160 328:160 329:160 330:161 331:162 332:163 333:164 334:165 335:166 336:167 337:168 338:168 339:168 340:168 341:169 342:170 343:171 344:171 345:172 346:173 347:174 348:175 349:175 350:175 351:176 352:176 353:176 354:176 355:176 356:176 357:177 358:178 359:179 360:179 361:180 362:181 363:181 364:182 365:182 366:182 367:182 368:182 369:182 370:182 371:182 372:183 373:183 374:183 375:184 376:185 377:186 378:187 379:187 380:188 381:189 382:190\n",
      "I1208 12:27:36.994806 139883775852736 run_factoid.py:445] token_to_orig_map: 10:0 11:0 12:0 13:1 14:2 15:2 16:2 17:3 18:3 19:3 20:3 21:3 22:4 23:5 24:6 25:7 26:8 27:9 28:10 29:11 30:12 31:13 32:14 33:15 34:16 35:17 36:18 37:19 38:20 39:21 40:22 41:22 42:22 43:22 44:22 45:22 46:22 47:22 48:22 49:22 50:22 51:23 52:24 53:25 54:26 55:27 56:27 57:27 58:28 59:29 60:30 61:31 62:32 63:33 64:34 65:35 66:36 67:37 68:37 69:38 70:39 71:40 72:41 73:42 74:43 75:44 76:45 77:46 78:47 79:48 80:49 81:50 82:51 83:52 84:52 85:52 86:52 87:52 88:52 89:52 90:53 91:54 92:55 93:56 94:57 95:58 96:58 97:59 98:60 99:60 100:60 101:61 102:61 103:62 104:62 105:62 106:62 107:63 108:63 109:63 110:63 111:63 112:63 113:63 114:63 115:64 116:64 117:64 118:64 119:65 120:65 121:65 122:65 123:66 124:66 125:66 126:66 127:66 128:66 129:66 130:66 131:66 132:66 133:67 134:67 135:68 136:69 137:69 138:69 139:69 140:70 141:70 142:70 143:71 144:71 145:72 146:73 147:73 148:73 149:73 150:74 151:74 152:74 153:74 154:74 155:74 156:74 157:74 158:75 159:76 160:76 161:76 162:77 163:77 164:77 165:78 166:78 167:78 168:79 169:79 170:79 171:79 172:80 173:80 174:80 175:80 176:80 177:80 178:80 179:80 180:80 181:80 182:80 183:81 184:81 185:82 186:83 187:84 188:85 189:86 190:87 191:88 192:89 193:90 194:91 195:92 196:93 197:93 198:94 199:94 200:94 201:94 202:94 203:94 204:94 205:94 206:94 207:95 208:95 209:96 210:97 211:98 212:99 213:100 214:101 215:101 216:102 217:103 218:104 219:104 220:105 221:106 222:106 223:106 224:107 225:108 226:109 227:110 228:111 229:112 230:112 231:112 232:113 233:113 234:113 235:113 236:113 237:113 238:113 239:113 240:114 241:115 242:116 243:117 244:118 245:119 246:120 247:120 248:121 249:122 250:123 251:123 252:123 253:124 254:124 255:124 256:124 257:124 258:124 259:124 260:125 261:125 262:126 263:127 264:128 265:128 266:128 267:128 268:129 269:130 270:130 271:130 272:131 273:131 274:131 275:132 276:133 277:134 278:134 279:134 280:134 281:135 282:136 283:137 284:138 285:139 286:140 287:141 288:142 289:142 290:142 291:142 292:142 293:142 294:142 295:143 296:143 297:144 298:145 299:146 300:147 301:148 302:149 303:150 304:150 305:151 306:151 307:151 308:151 309:151 310:152 311:152 312:152 313:152 314:152 315:152 316:153 317:154 318:155 319:155 320:155 321:156 322:157 323:158 324:159 325:159 326:160 327:160 328:160 329:160 330:161 331:162 332:163 333:164 334:165 335:166 336:167 337:168 338:168 339:168 340:168 341:169 342:170 343:171 344:171 345:172 346:173 347:174 348:175 349:175 350:175 351:176 352:176 353:176 354:176 355:176 356:176 357:177 358:178 359:179 360:179 361:180 362:181 363:181 364:182 365:182 366:182 367:182 368:182 369:182 370:182 371:182 372:183 373:183 374:183 375:184 376:185 377:186 378:187 379:187 380:188 381:189 382:190\n",
      "INFO:tensorflow:token_is_max_context: 10:True 11:True 12:True 13:True 14:True 15:True 16:True 17:True 18:True 19:True 20:True 21:True 22:True 23:True 24:True 25:True 26:True 27:True 28:True 29:True 30:True 31:True 32:True 33:True 34:True 35:True 36:True 37:True 38:True 39:True 40:True 41:True 42:True 43:True 44:True 45:True 46:True 47:True 48:True 49:True 50:True 51:True 52:True 53:True 54:True 55:True 56:True 57:True 58:True 59:True 60:True 61:True 62:True 63:True 64:True 65:True 66:True 67:True 68:True 69:True 70:True 71:True 72:True 73:True 74:True 75:True 76:True 77:True 78:True 79:True 80:True 81:True 82:True 83:True 84:True 85:True 86:True 87:True 88:True 89:True 90:True 91:True 92:True 93:True 94:True 95:True 96:True 97:True 98:True 99:True 100:True 101:True 102:True 103:True 104:True 105:True 106:True 107:True 108:True 109:True 110:True 111:True 112:True 113:True 114:True 115:True 116:True 117:True 118:True 119:True 120:True 121:True 122:True 123:True 124:True 125:True 126:True 127:True 128:True 129:True 130:True 131:True 132:True 133:True 134:True 135:True 136:True 137:True 138:True 139:True 140:True 141:True 142:True 143:True 144:True 145:True 146:True 147:True 148:True 149:True 150:True 151:True 152:True 153:True 154:True 155:True 156:True 157:True 158:True 159:True 160:True 161:True 162:True 163:True 164:True 165:True 166:True 167:True 168:True 169:True 170:True 171:True 172:True 173:True 174:True 175:True 176:True 177:True 178:True 179:True 180:True 181:True 182:True 183:True 184:True 185:True 186:True 187:True 188:True 189:True 190:True 191:True 192:True 193:True 194:True 195:True 196:True 197:True 198:True 199:True 200:True 201:True 202:True 203:True 204:True 205:True 206:True 207:True 208:True 209:True 210:True 211:True 212:True 213:True 214:True 215:True 216:True 217:True 218:True 219:True 220:True 221:True 222:True 223:True 224:True 225:True 226:True 227:True 228:True 229:True 230:True 231:True 232:True 233:True 234:True 235:True 236:True 237:True 238:True 239:True 240:True 241:True 242:True 243:True 244:True 245:True 246:True 247:True 248:True 249:True 250:True 251:True 252:True 253:True 254:True 255:True 256:True 257:True 258:True 259:True 260:True 261:False 262:False 263:False 264:False 265:False 266:False 267:False 268:False 269:False 270:False 271:False 272:False 273:False 274:False 275:False 276:False 277:False 278:False 279:False 280:False 281:False 282:False 283:False 284:False 285:False 286:False 287:False 288:False 289:False 290:False 291:False 292:False 293:False 294:False 295:False 296:False 297:False 298:False 299:False 300:False 301:False 302:False 303:False 304:False 305:False 306:False 307:False 308:False 309:False 310:False 311:False 312:False 313:False 314:False 315:False 316:False 317:False 318:False 319:False 320:False 321:False 322:False 323:False 324:False 325:False 326:False 327:False 328:False 329:False 330:False 331:False 332:False 333:False 334:False 335:False 336:False 337:False 338:False 339:False 340:False 341:False 342:False 343:False 344:False 345:False 346:False 347:False 348:False 349:False 350:False 351:False 352:False 353:False 354:False 355:False 356:False 357:False 358:False 359:False 360:False 361:False 362:False 363:False 364:False 365:False 366:False 367:False 368:False 369:False 370:False 371:False 372:False 373:False 374:False 375:False 376:False 377:False 378:False 379:False 380:False 381:False 382:False\n",
      "I1208 12:27:36.994915 139883775852736 run_factoid.py:447] token_is_max_context: 10:True 11:True 12:True 13:True 14:True 15:True 16:True 17:True 18:True 19:True 20:True 21:True 22:True 23:True 24:True 25:True 26:True 27:True 28:True 29:True 30:True 31:True 32:True 33:True 34:True 35:True 36:True 37:True 38:True 39:True 40:True 41:True 42:True 43:True 44:True 45:True 46:True 47:True 48:True 49:True 50:True 51:True 52:True 53:True 54:True 55:True 56:True 57:True 58:True 59:True 60:True 61:True 62:True 63:True 64:True 65:True 66:True 67:True 68:True 69:True 70:True 71:True 72:True 73:True 74:True 75:True 76:True 77:True 78:True 79:True 80:True 81:True 82:True 83:True 84:True 85:True 86:True 87:True 88:True 89:True 90:True 91:True 92:True 93:True 94:True 95:True 96:True 97:True 98:True 99:True 100:True 101:True 102:True 103:True 104:True 105:True 106:True 107:True 108:True 109:True 110:True 111:True 112:True 113:True 114:True 115:True 116:True 117:True 118:True 119:True 120:True 121:True 122:True 123:True 124:True 125:True 126:True 127:True 128:True 129:True 130:True 131:True 132:True 133:True 134:True 135:True 136:True 137:True 138:True 139:True 140:True 141:True 142:True 143:True 144:True 145:True 146:True 147:True 148:True 149:True 150:True 151:True 152:True 153:True 154:True 155:True 156:True 157:True 158:True 159:True 160:True 161:True 162:True 163:True 164:True 165:True 166:True 167:True 168:True 169:True 170:True 171:True 172:True 173:True 174:True 175:True 176:True 177:True 178:True 179:True 180:True 181:True 182:True 183:True 184:True 185:True 186:True 187:True 188:True 189:True 190:True 191:True 192:True 193:True 194:True 195:True 196:True 197:True 198:True 199:True 200:True 201:True 202:True 203:True 204:True 205:True 206:True 207:True 208:True 209:True 210:True 211:True 212:True 213:True 214:True 215:True 216:True 217:True 218:True 219:True 220:True 221:True 222:True 223:True 224:True 225:True 226:True 227:True 228:True 229:True 230:True 231:True 232:True 233:True 234:True 235:True 236:True 237:True 238:True 239:True 240:True 241:True 242:True 243:True 244:True 245:True 246:True 247:True 248:True 249:True 250:True 251:True 252:True 253:True 254:True 255:True 256:True 257:True 258:True 259:True 260:True 261:False 262:False 263:False 264:False 265:False 266:False 267:False 268:False 269:False 270:False 271:False 272:False 273:False 274:False 275:False 276:False 277:False 278:False 279:False 280:False 281:False 282:False 283:False 284:False 285:False 286:False 287:False 288:False 289:False 290:False 291:False 292:False 293:False 294:False 295:False 296:False 297:False 298:False 299:False 300:False 301:False 302:False 303:False 304:False 305:False 306:False 307:False 308:False 309:False 310:False 311:False 312:False 313:False 314:False 315:False 316:False 317:False 318:False 319:False 320:False 321:False 322:False 323:False 324:False 325:False 326:False 327:False 328:False 329:False 330:False 331:False 332:False 333:False 334:False 335:False 336:False 337:False 338:False 339:False 340:False 341:False 342:False 343:False 344:False 345:False 346:False 347:False 348:False 349:False 350:False 351:False 352:False 353:False 354:False 355:False 356:False 357:False 358:False 359:False 360:False 361:False 362:False 363:False 364:False 365:False 366:False 367:False 368:False 369:False 370:False 371:False 372:False 373:False 374:False 375:False 376:False 377:False 378:False 379:False 380:False 381:False 382:False\n",
      "INFO:tensorflow:input_ids: 101 1327 1132 3242 1106 5494 1142 3879 136 102 14557 10806 1197 6187 1123 5813 2116 113 149 2137 3048 114 1110 1141 1104 1103 1211 3933 11534 4680 1104 1822 1171 2489 1105 1110 170 1887 2612 1104 187 14230 10182 13200 23610 119 164 122 782 124 166 1966 1211 4420 1114 149 2137 3048 1169 5515 18330 7300 1105 8458 13950 1114 6588 3252 117 170 1374 4420 1202 1136 6297 5877 1106 6588 3252 1105 2028 4752 13467 3252 119 164 125 117 126 166 1247 1132 1317 1514 13467 6665 131 1501 181 25509 1197 17599 118 6187 10294 18778 1183 113 152 22074 114 117 164 127 166 17599 6696 2155 22258 6187 10294 18778 1183 113 22157 2137 114 117 164 128 117 129 166 10298 1193 19849 14715 14467 4515 14196 181 25509 1197 9455 14637 11970 113 26574 1708 118 157 2162 15499 114 117 164 130 166 1105 1679 12734 13064 1322 2155 22258 181 25509 1197 6187 10294 18778 1183 113 153 21678 2137 114 119 164 1275 117 1429 166 152 22074 1144 1151 4485 1112 1103 1211 3337 6315 13467 5146 1111 1231 21754 149 2137 3048 132 164 1367 117 1492 166 1649 117 1122 1108 2628 1114 1317 13522 117 1259 6484 3290 117 9071 1231 27539 117 1105 1103 8116 1104 3431 181 13499 118 1441 1204 117 164 1489 117 1405 166 1134 1169 1871 1107 20482 1105 14161 3384 1104 1103 174 25786 12602 2000 119 164 1479 117 1542 166 22157 2137 2745 170 17599 6696 2155 16260 1111 5173 23228 118 189 1988 117 1105 1103 18311 20080 4559 1361 6130 1132 8630 1118 6484 15601 1194 4267 13389 1116 132 164 1407 166 2456 117 1103 6484 1105 2991 7918 1132 10298 1193 4475 119 164 1627 166 26574 1708 118 157 2162 15499 1110 170 1218 118 3134 2805 3442 1111 1231 21754 149 2137 3048 119 1262 1122 1144 1103 13300 1104 1750 178 2980 26767 1596 2991 7918 3773 117 2211 3187 1104 2112 19807 5838 187 14230 10182 12888 1548 117 1105 10558 1231 27539 1104 3840 4412 21718 1665 119 164 1406 117 1626 166 153 21678 2137 1110 170 1167 10298 1193 19849 6059 1272 102\n",
      "I1208 12:27:36.995016 139883775852736 run_factoid.py:449] input_ids: 101 1327 1132 3242 1106 5494 1142 3879 136 102 14557 10806 1197 6187 1123 5813 2116 113 149 2137 3048 114 1110 1141 1104 1103 1211 3933 11534 4680 1104 1822 1171 2489 1105 1110 170 1887 2612 1104 187 14230 10182 13200 23610 119 164 122 782 124 166 1966 1211 4420 1114 149 2137 3048 1169 5515 18330 7300 1105 8458 13950 1114 6588 3252 117 170 1374 4420 1202 1136 6297 5877 1106 6588 3252 1105 2028 4752 13467 3252 119 164 125 117 126 166 1247 1132 1317 1514 13467 6665 131 1501 181 25509 1197 17599 118 6187 10294 18778 1183 113 152 22074 114 117 164 127 166 17599 6696 2155 22258 6187 10294 18778 1183 113 22157 2137 114 117 164 128 117 129 166 10298 1193 19849 14715 14467 4515 14196 181 25509 1197 9455 14637 11970 113 26574 1708 118 157 2162 15499 114 117 164 130 166 1105 1679 12734 13064 1322 2155 22258 181 25509 1197 6187 10294 18778 1183 113 153 21678 2137 114 119 164 1275 117 1429 166 152 22074 1144 1151 4485 1112 1103 1211 3337 6315 13467 5146 1111 1231 21754 149 2137 3048 132 164 1367 117 1492 166 1649 117 1122 1108 2628 1114 1317 13522 117 1259 6484 3290 117 9071 1231 27539 117 1105 1103 8116 1104 3431 181 13499 118 1441 1204 117 164 1489 117 1405 166 1134 1169 1871 1107 20482 1105 14161 3384 1104 1103 174 25786 12602 2000 119 164 1479 117 1542 166 22157 2137 2745 170 17599 6696 2155 16260 1111 5173 23228 118 189 1988 117 1105 1103 18311 20080 4559 1361 6130 1132 8630 1118 6484 15601 1194 4267 13389 1116 132 164 1407 166 2456 117 1103 6484 1105 2991 7918 1132 10298 1193 4475 119 164 1627 166 26574 1708 118 157 2162 15499 1110 170 1218 118 3134 2805 3442 1111 1231 21754 149 2137 3048 119 1262 1122 1144 1103 13300 1104 1750 178 2980 26767 1596 2991 7918 3773 117 2211 3187 1104 2112 19807 5838 187 14230 10182 12888 1548 117 1105 10558 1231 27539 1104 3840 4412 21718 1665 119 164 1406 117 1626 166 153 21678 2137 1110 170 1167 10298 1193 19849 6059 1272 102\n",
      "INFO:tensorflow:input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      "I1208 12:27:36.995107 139883775852736 run_factoid.py:451] input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      "INFO:tensorflow:segment_ids: 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      "I1208 12:27:36.995195 139883775852736 run_factoid.py:453] segment_ids: 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      "INFO:tensorflow:*** Example ***\n",
      "I1208 12:27:36.996059 139883775852736 run_factoid.py:438] *** Example ***\n",
      "INFO:tensorflow:unique_id: 1000000007\n",
      "I1208 12:27:36.996117 139883775852736 run_factoid.py:439] unique_id: 1000000007\n",
      "INFO:tensorflow:example_index: 3\n",
      "I1208 12:27:36.996154 139883775852736 run_factoid.py:440] example_index: 3\n",
      "INFO:tensorflow:doc_span_index: 1\n",
      "I1208 12:27:36.996188 139883775852736 run_factoid.py:441] doc_span_index: 1\n",
      "INFO:tensorflow:tokens: [CLS] What are ways to manage this condition ? [SEP] ##ram ##inal l ##umba ##r inter ##body fusion ( MI ##S - T ##L ##IF ) , [ 9 ] and per ##cut ##aneous end ##os ##copic l ##umba ##r disc ##ec ##tom ##y ( P ##EL ##D ) . [ 10 , 11 ] O ##LM has been regarded as the most commonly recommended surgical option for re ##current L ##D ##H ; [ 12 , 13 ] however , it was associated with several complications , including muscle damage , nerve re ##traction , and the removal of yellow l ##iga - men ##t , [ 14 , 15 ] which can result in instability and scar ##ring of the e ##pid ##ural space . [ 16 , 17 ] ME ##D uses a micro ##end ##os ##cope for visual ##iza - t ##ion , and the para ##sp ##ino ##us muscles are handled by muscle splitting through di ##lator ##s ; [ 18 ] thus , the muscle and soft tissue are minimal ##ly injured . [ 19 ] MI ##S - T ##L ##IF is a well - accepted operation method for re ##current L ##D ##H . And it has the advantages of less i ##at ##rogen ##ic soft tissue injury , lower risk of post ##oper ##ative r ##adi ##cu ##lit ##is , and decreased re ##traction of du ##ral sa ##c . [ 20 , 21 ] P ##EL ##D is a more minimal ##ly invasive surgery because the posterior column structures are pre - served . [ 22 , 23 ] It has gained interest for its potential advantage in the reduced risk of face ##t joints injury , fewer post ##oper ##ative complications , a shorter hospital stay and lower cost . [ 24 , 25 ] Previous studies have reported that P ##EL ##D is an effective and safe treatment for L ##D ##H . [ 26 , 27 ] However , whether P ##EL ##D is superior to other surgical options remains controversial . Thus , we conducted this meta - analysis to compare the clinical , radio ##log ##ic , and complications of P ##EL ##D and other surge ##ries for patients with L ##D ##H . [SEP]\n",
      "I1208 12:27:36.996297 139883775852736 run_factoid.py:443] tokens: [CLS] What are ways to manage this condition ? [SEP] ##ram ##inal l ##umba ##r inter ##body fusion ( MI ##S - T ##L ##IF ) , [ 9 ] and per ##cut ##aneous end ##os ##copic l ##umba ##r disc ##ec ##tom ##y ( P ##EL ##D ) . [ 10 , 11 ] O ##LM has been regarded as the most commonly recommended surgical option for re ##current L ##D ##H ; [ 12 , 13 ] however , it was associated with several complications , including muscle damage , nerve re ##traction , and the removal of yellow l ##iga - men ##t , [ 14 , 15 ] which can result in instability and scar ##ring of the e ##pid ##ural space . [ 16 , 17 ] ME ##D uses a micro ##end ##os ##cope for visual ##iza - t ##ion , and the para ##sp ##ino ##us muscles are handled by muscle splitting through di ##lator ##s ; [ 18 ] thus , the muscle and soft tissue are minimal ##ly injured . [ 19 ] MI ##S - T ##L ##IF is a well - accepted operation method for re ##current L ##D ##H . And it has the advantages of less i ##at ##rogen ##ic soft tissue injury , lower risk of post ##oper ##ative r ##adi ##cu ##lit ##is , and decreased re ##traction of du ##ral sa ##c . [ 20 , 21 ] P ##EL ##D is a more minimal ##ly invasive surgery because the posterior column structures are pre - served . [ 22 , 23 ] It has gained interest for its potential advantage in the reduced risk of face ##t joints injury , fewer post ##oper ##ative complications , a shorter hospital stay and lower cost . [ 24 , 25 ] Previous studies have reported that P ##EL ##D is an effective and safe treatment for L ##D ##H . [ 26 , 27 ] However , whether P ##EL ##D is superior to other surgical options remains controversial . Thus , we conducted this meta - analysis to compare the clinical , radio ##log ##ic , and complications of P ##EL ##D and other surge ##ries for patients with L ##D ##H . [SEP]\n",
      "INFO:tensorflow:token_to_orig_map: 10:69 11:69 12:70 13:70 14:70 15:71 16:71 17:72 18:73 19:73 20:73 21:73 22:74 23:74 24:74 25:74 26:74 27:74 28:74 29:74 30:75 31:76 32:76 33:76 34:77 35:77 36:77 37:78 38:78 39:78 40:79 41:79 42:79 43:79 44:80 45:80 46:80 47:80 48:80 49:80 50:80 51:80 52:80 53:80 54:80 55:81 56:81 57:82 58:83 59:84 60:85 61:86 62:87 63:88 64:89 65:90 66:91 67:92 68:93 69:93 70:94 71:94 72:94 73:94 74:94 75:94 76:94 77:94 78:94 79:95 80:95 81:96 82:97 83:98 84:99 85:100 86:101 87:101 88:102 89:103 90:104 91:104 92:105 93:106 94:106 95:106 96:107 97:108 98:109 99:110 100:111 101:112 102:112 103:112 104:113 105:113 106:113 107:113 108:113 109:113 110:113 111:113 112:114 113:115 114:116 115:117 116:118 117:119 118:120 119:120 120:121 121:122 122:123 123:123 124:123 125:124 126:124 127:124 128:124 129:124 130:124 131:124 132:125 133:125 134:126 135:127 136:128 137:128 138:128 139:128 140:129 141:130 142:130 143:130 144:131 145:131 146:131 147:132 148:133 149:134 150:134 151:134 152:134 153:135 154:136 155:137 156:138 157:139 158:140 159:141 160:142 161:142 162:142 163:142 164:142 165:142 166:142 167:143 168:143 169:144 170:145 171:146 172:147 173:148 174:149 175:150 176:150 177:151 178:151 179:151 180:151 181:151 182:152 183:152 184:152 185:152 186:152 187:152 188:153 189:154 190:155 191:155 192:155 193:156 194:157 195:158 196:159 197:159 198:160 199:160 200:160 201:160 202:161 203:162 204:163 205:164 206:165 207:166 208:167 209:168 210:168 211:168 212:168 213:169 214:170 215:171 216:171 217:172 218:173 219:174 220:175 221:175 222:175 223:176 224:176 225:176 226:176 227:176 228:176 229:177 230:178 231:179 232:179 233:180 234:181 235:181 236:182 237:182 238:182 239:182 240:182 241:182 242:182 243:182 244:183 245:183 246:183 247:184 248:185 249:186 250:187 251:187 252:188 253:189 254:190 255:191 256:192 257:193 258:194 259:195 260:196 261:196 262:197 263:197 264:197 265:197 266:197 267:197 268:197 269:198 270:199 271:200 272:201 273:202 274:203 275:204 276:205 277:206 278:207 279:208 280:209 281:210 282:211 283:211 284:212 285:213 286:213 287:214 288:215 289:215 290:215 291:216 292:216 293:217 294:218 295:219 296:220 297:221 298:222 299:223 300:223 301:223 302:223 303:223 304:223 305:223 306:224 307:225 308:226 309:227 310:228 311:229 312:229 313:229 314:230 315:231 316:232 317:233 318:234 319:235 320:236 321:237 322:237 323:237 324:237 325:237 326:237 327:237 328:237 329:237 330:238 331:238 332:239 333:240 334:240 335:240 336:241 337:242 338:243 339:244 340:245 341:246 342:247 343:248 344:248 345:249 346:249 347:250 348:251 349:252 350:253 351:253 352:253 353:254 354:255 355:256 356:257 357:257 358:258 359:258 360:258 361:258 362:259 363:260 364:261 365:262 366:262 367:262 368:263 369:264 370:265 371:265 372:266 373:267 374:268 375:269 376:269 377:269 378:269\n",
      "I1208 12:27:36.996409 139883775852736 run_factoid.py:445] token_to_orig_map: 10:69 11:69 12:70 13:70 14:70 15:71 16:71 17:72 18:73 19:73 20:73 21:73 22:74 23:74 24:74 25:74 26:74 27:74 28:74 29:74 30:75 31:76 32:76 33:76 34:77 35:77 36:77 37:78 38:78 39:78 40:79 41:79 42:79 43:79 44:80 45:80 46:80 47:80 48:80 49:80 50:80 51:80 52:80 53:80 54:80 55:81 56:81 57:82 58:83 59:84 60:85 61:86 62:87 63:88 64:89 65:90 66:91 67:92 68:93 69:93 70:94 71:94 72:94 73:94 74:94 75:94 76:94 77:94 78:94 79:95 80:95 81:96 82:97 83:98 84:99 85:100 86:101 87:101 88:102 89:103 90:104 91:104 92:105 93:106 94:106 95:106 96:107 97:108 98:109 99:110 100:111 101:112 102:112 103:112 104:113 105:113 106:113 107:113 108:113 109:113 110:113 111:113 112:114 113:115 114:116 115:117 116:118 117:119 118:120 119:120 120:121 121:122 122:123 123:123 124:123 125:124 126:124 127:124 128:124 129:124 130:124 131:124 132:125 133:125 134:126 135:127 136:128 137:128 138:128 139:128 140:129 141:130 142:130 143:130 144:131 145:131 146:131 147:132 148:133 149:134 150:134 151:134 152:134 153:135 154:136 155:137 156:138 157:139 158:140 159:141 160:142 161:142 162:142 163:142 164:142 165:142 166:142 167:143 168:143 169:144 170:145 171:146 172:147 173:148 174:149 175:150 176:150 177:151 178:151 179:151 180:151 181:151 182:152 183:152 184:152 185:152 186:152 187:152 188:153 189:154 190:155 191:155 192:155 193:156 194:157 195:158 196:159 197:159 198:160 199:160 200:160 201:160 202:161 203:162 204:163 205:164 206:165 207:166 208:167 209:168 210:168 211:168 212:168 213:169 214:170 215:171 216:171 217:172 218:173 219:174 220:175 221:175 222:175 223:176 224:176 225:176 226:176 227:176 228:176 229:177 230:178 231:179 232:179 233:180 234:181 235:181 236:182 237:182 238:182 239:182 240:182 241:182 242:182 243:182 244:183 245:183 246:183 247:184 248:185 249:186 250:187 251:187 252:188 253:189 254:190 255:191 256:192 257:193 258:194 259:195 260:196 261:196 262:197 263:197 264:197 265:197 266:197 267:197 268:197 269:198 270:199 271:200 272:201 273:202 274:203 275:204 276:205 277:206 278:207 279:208 280:209 281:210 282:211 283:211 284:212 285:213 286:213 287:214 288:215 289:215 290:215 291:216 292:216 293:217 294:218 295:219 296:220 297:221 298:222 299:223 300:223 301:223 302:223 303:223 304:223 305:223 306:224 307:225 308:226 309:227 310:228 311:229 312:229 313:229 314:230 315:231 316:232 317:233 318:234 319:235 320:236 321:237 322:237 323:237 324:237 325:237 326:237 327:237 328:237 329:237 330:238 331:238 332:239 333:240 334:240 335:240 336:241 337:242 338:243 339:244 340:245 341:246 342:247 343:248 344:248 345:249 346:249 347:250 348:251 349:252 350:253 351:253 352:253 353:254 354:255 355:256 356:257 357:257 358:258 359:258 360:258 361:258 362:259 363:260 364:261 365:262 366:262 367:262 368:263 369:264 370:265 371:265 372:266 373:267 374:268 375:269 376:269 377:269 378:269\n",
      "INFO:tensorflow:token_is_max_context: 10:False 11:False 12:False 13:False 14:False 15:False 16:False 17:False 18:False 19:False 20:False 21:False 22:False 23:False 24:False 25:False 26:False 27:False 28:False 29:False 30:False 31:False 32:False 33:False 34:False 35:False 36:False 37:False 38:False 39:False 40:False 41:False 42:False 43:False 44:False 45:False 46:False 47:False 48:False 49:False 50:False 51:False 52:False 53:False 54:False 55:False 56:False 57:False 58:False 59:False 60:False 61:False 62:False 63:False 64:False 65:False 66:False 67:False 68:False 69:False 70:False 71:False 72:False 73:False 74:False 75:False 76:False 77:False 78:False 79:False 80:False 81:False 82:False 83:False 84:False 85:False 86:False 87:False 88:False 89:False 90:False 91:False 92:False 93:False 94:False 95:False 96:False 97:False 98:False 99:False 100:False 101:False 102:False 103:False 104:False 105:False 106:False 107:False 108:False 109:False 110:False 111:False 112:False 113:False 114:False 115:False 116:False 117:False 118:False 119:False 120:False 121:False 122:False 123:False 124:False 125:False 126:False 127:False 128:False 129:False 130:False 131:False 132:False 133:True 134:True 135:True 136:True 137:True 138:True 139:True 140:True 141:True 142:True 143:True 144:True 145:True 146:True 147:True 148:True 149:True 150:True 151:True 152:True 153:True 154:True 155:True 156:True 157:True 158:True 159:True 160:True 161:True 162:True 163:True 164:True 165:True 166:True 167:True 168:True 169:True 170:True 171:True 172:True 173:True 174:True 175:True 176:True 177:True 178:True 179:True 180:True 181:True 182:True 183:True 184:True 185:True 186:True 187:True 188:True 189:True 190:True 191:True 192:True 193:True 194:True 195:True 196:True 197:True 198:True 199:True 200:True 201:True 202:True 203:True 204:True 205:True 206:True 207:True 208:True 209:True 210:True 211:True 212:True 213:True 214:True 215:True 216:True 217:True 218:True 219:True 220:True 221:True 222:True 223:True 224:True 225:True 226:True 227:True 228:True 229:True 230:True 231:True 232:True 233:True 234:True 235:True 236:True 237:True 238:True 239:True 240:True 241:True 242:True 243:True 244:True 245:True 246:True 247:True 248:True 249:True 250:True 251:True 252:True 253:True 254:True 255:True 256:True 257:True 258:True 259:True 260:True 261:True 262:True 263:True 264:True 265:True 266:True 267:True 268:True 269:True 270:True 271:True 272:True 273:True 274:True 275:True 276:True 277:True 278:True 279:True 280:True 281:True 282:True 283:True 284:True 285:True 286:True 287:True 288:True 289:True 290:True 291:True 292:True 293:True 294:True 295:True 296:True 297:True 298:True 299:True 300:True 301:True 302:True 303:True 304:True 305:True 306:True 307:True 308:True 309:True 310:True 311:True 312:True 313:True 314:True 315:True 316:True 317:True 318:True 319:True 320:True 321:True 322:True 323:True 324:True 325:True 326:True 327:True 328:True 329:True 330:True 331:True 332:True 333:True 334:True 335:True 336:True 337:True 338:True 339:True 340:True 341:True 342:True 343:True 344:True 345:True 346:True 347:True 348:True 349:True 350:True 351:True 352:True 353:True 354:True 355:True 356:True 357:True 358:True 359:True 360:True 361:True 362:True 363:True 364:True 365:True 366:True 367:True 368:True 369:True 370:True 371:True 372:True 373:True 374:True 375:True 376:True 377:True 378:True\n",
      "I1208 12:27:36.996515 139883775852736 run_factoid.py:447] token_is_max_context: 10:False 11:False 12:False 13:False 14:False 15:False 16:False 17:False 18:False 19:False 20:False 21:False 22:False 23:False 24:False 25:False 26:False 27:False 28:False 29:False 30:False 31:False 32:False 33:False 34:False 35:False 36:False 37:False 38:False 39:False 40:False 41:False 42:False 43:False 44:False 45:False 46:False 47:False 48:False 49:False 50:False 51:False 52:False 53:False 54:False 55:False 56:False 57:False 58:False 59:False 60:False 61:False 62:False 63:False 64:False 65:False 66:False 67:False 68:False 69:False 70:False 71:False 72:False 73:False 74:False 75:False 76:False 77:False 78:False 79:False 80:False 81:False 82:False 83:False 84:False 85:False 86:False 87:False 88:False 89:False 90:False 91:False 92:False 93:False 94:False 95:False 96:False 97:False 98:False 99:False 100:False 101:False 102:False 103:False 104:False 105:False 106:False 107:False 108:False 109:False 110:False 111:False 112:False 113:False 114:False 115:False 116:False 117:False 118:False 119:False 120:False 121:False 122:False 123:False 124:False 125:False 126:False 127:False 128:False 129:False 130:False 131:False 132:False 133:True 134:True 135:True 136:True 137:True 138:True 139:True 140:True 141:True 142:True 143:True 144:True 145:True 146:True 147:True 148:True 149:True 150:True 151:True 152:True 153:True 154:True 155:True 156:True 157:True 158:True 159:True 160:True 161:True 162:True 163:True 164:True 165:True 166:True 167:True 168:True 169:True 170:True 171:True 172:True 173:True 174:True 175:True 176:True 177:True 178:True 179:True 180:True 181:True 182:True 183:True 184:True 185:True 186:True 187:True 188:True 189:True 190:True 191:True 192:True 193:True 194:True 195:True 196:True 197:True 198:True 199:True 200:True 201:True 202:True 203:True 204:True 205:True 206:True 207:True 208:True 209:True 210:True 211:True 212:True 213:True 214:True 215:True 216:True 217:True 218:True 219:True 220:True 221:True 222:True 223:True 224:True 225:True 226:True 227:True 228:True 229:True 230:True 231:True 232:True 233:True 234:True 235:True 236:True 237:True 238:True 239:True 240:True 241:True 242:True 243:True 244:True 245:True 246:True 247:True 248:True 249:True 250:True 251:True 252:True 253:True 254:True 255:True 256:True 257:True 258:True 259:True 260:True 261:True 262:True 263:True 264:True 265:True 266:True 267:True 268:True 269:True 270:True 271:True 272:True 273:True 274:True 275:True 276:True 277:True 278:True 279:True 280:True 281:True 282:True 283:True 284:True 285:True 286:True 287:True 288:True 289:True 290:True 291:True 292:True 293:True 294:True 295:True 296:True 297:True 298:True 299:True 300:True 301:True 302:True 303:True 304:True 305:True 306:True 307:True 308:True 309:True 310:True 311:True 312:True 313:True 314:True 315:True 316:True 317:True 318:True 319:True 320:True 321:True 322:True 323:True 324:True 325:True 326:True 327:True 328:True 329:True 330:True 331:True 332:True 333:True 334:True 335:True 336:True 337:True 338:True 339:True 340:True 341:True 342:True 343:True 344:True 345:True 346:True 347:True 348:True 349:True 350:True 351:True 352:True 353:True 354:True 355:True 356:True 357:True 358:True 359:True 360:True 361:True 362:True 363:True 364:True 365:True 366:True 367:True 368:True 369:True 370:True 371:True 372:True 373:True 374:True 375:True 376:True 377:True 378:True\n",
      "INFO:tensorflow:input_ids: 101 1327 1132 3242 1106 5494 1142 3879 136 102 4515 14196 181 25509 1197 9455 14637 11970 113 26574 1708 118 157 2162 15499 114 117 164 130 166 1105 1679 12734 13064 1322 2155 22258 181 25509 1197 6187 10294 18778 1183 113 153 21678 2137 114 119 164 1275 117 1429 166 152 22074 1144 1151 4485 1112 1103 1211 3337 6315 13467 5146 1111 1231 21754 149 2137 3048 132 164 1367 117 1492 166 1649 117 1122 1108 2628 1114 1317 13522 117 1259 6484 3290 117 9071 1231 27539 117 1105 1103 8116 1104 3431 181 13499 118 1441 1204 117 164 1489 117 1405 166 1134 1169 1871 1107 20482 1105 14161 3384 1104 1103 174 25786 12602 2000 119 164 1479 117 1542 166 22157 2137 2745 170 17599 6696 2155 16260 1111 5173 23228 118 189 1988 117 1105 1103 18311 20080 4559 1361 6130 1132 8630 1118 6484 15601 1194 4267 13389 1116 132 164 1407 166 2456 117 1103 6484 1105 2991 7918 1132 10298 1193 4475 119 164 1627 166 26574 1708 118 157 2162 15499 1110 170 1218 118 3134 2805 3442 1111 1231 21754 149 2137 3048 119 1262 1122 1144 1103 13300 1104 1750 178 2980 26767 1596 2991 7918 3773 117 2211 3187 1104 2112 19807 5838 187 14230 10182 12888 1548 117 1105 10558 1231 27539 1104 3840 4412 21718 1665 119 164 1406 117 1626 166 153 21678 2137 1110 170 1167 10298 1193 19849 6059 1272 1103 16530 5551 4413 1132 3073 118 1462 119 164 1659 117 1695 166 1135 1144 3388 2199 1111 1157 3209 4316 1107 1103 3549 3187 1104 1339 1204 19365 3773 117 8307 2112 19807 5838 13522 117 170 7681 2704 2215 1105 2211 2616 119 164 1572 117 1512 166 24142 2527 1138 2103 1115 153 21678 2137 1110 1126 3903 1105 2914 3252 1111 149 2137 3048 119 164 1744 117 1765 166 1438 117 2480 153 21678 2137 1110 7298 1106 1168 13467 6665 2606 6241 119 4516 117 1195 3303 1142 27154 118 3622 1106 14133 1103 7300 117 2070 13791 1596 117 1105 13522 1104 153 21678 2137 1105 1168 12814 3377 1111 4420 1114 149 2137 3048 119 102 0 0 0 0\n",
      "I1208 12:27:36.996615 139883775852736 run_factoid.py:449] input_ids: 101 1327 1132 3242 1106 5494 1142 3879 136 102 4515 14196 181 25509 1197 9455 14637 11970 113 26574 1708 118 157 2162 15499 114 117 164 130 166 1105 1679 12734 13064 1322 2155 22258 181 25509 1197 6187 10294 18778 1183 113 153 21678 2137 114 119 164 1275 117 1429 166 152 22074 1144 1151 4485 1112 1103 1211 3337 6315 13467 5146 1111 1231 21754 149 2137 3048 132 164 1367 117 1492 166 1649 117 1122 1108 2628 1114 1317 13522 117 1259 6484 3290 117 9071 1231 27539 117 1105 1103 8116 1104 3431 181 13499 118 1441 1204 117 164 1489 117 1405 166 1134 1169 1871 1107 20482 1105 14161 3384 1104 1103 174 25786 12602 2000 119 164 1479 117 1542 166 22157 2137 2745 170 17599 6696 2155 16260 1111 5173 23228 118 189 1988 117 1105 1103 18311 20080 4559 1361 6130 1132 8630 1118 6484 15601 1194 4267 13389 1116 132 164 1407 166 2456 117 1103 6484 1105 2991 7918 1132 10298 1193 4475 119 164 1627 166 26574 1708 118 157 2162 15499 1110 170 1218 118 3134 2805 3442 1111 1231 21754 149 2137 3048 119 1262 1122 1144 1103 13300 1104 1750 178 2980 26767 1596 2991 7918 3773 117 2211 3187 1104 2112 19807 5838 187 14230 10182 12888 1548 117 1105 10558 1231 27539 1104 3840 4412 21718 1665 119 164 1406 117 1626 166 153 21678 2137 1110 170 1167 10298 1193 19849 6059 1272 1103 16530 5551 4413 1132 3073 118 1462 119 164 1659 117 1695 166 1135 1144 3388 2199 1111 1157 3209 4316 1107 1103 3549 3187 1104 1339 1204 19365 3773 117 8307 2112 19807 5838 13522 117 170 7681 2704 2215 1105 2211 2616 119 164 1572 117 1512 166 24142 2527 1138 2103 1115 153 21678 2137 1110 1126 3903 1105 2914 3252 1111 149 2137 3048 119 164 1744 117 1765 166 1438 117 2480 153 21678 2137 1110 7298 1106 1168 13467 6665 2606 6241 119 4516 117 1195 3303 1142 27154 118 3622 1106 14133 1103 7300 117 2070 13791 1596 117 1105 13522 1104 153 21678 2137 1105 1168 12814 3377 1111 4420 1114 149 2137 3048 119 102 0 0 0 0\n",
      "INFO:tensorflow:input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0\n",
      "I1208 12:27:36.996718 139883775852736 run_factoid.py:451] input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0\n",
      "INFO:tensorflow:segment_ids: 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0\n",
      "I1208 12:27:36.996808 139883775852736 run_factoid.py:453] segment_ids: 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0\n",
      "INFO:tensorflow:*** Example ***\n",
      "I1208 12:27:37.002524 139883775852736 run_factoid.py:438] *** Example ***\n",
      "INFO:tensorflow:unique_id: 1000000008\n",
      "I1208 12:27:37.002599 139883775852736 run_factoid.py:439] unique_id: 1000000008\n",
      "INFO:tensorflow:example_index: 4\n",
      "I1208 12:27:37.002640 139883775852736 run_factoid.py:440] example_index: 4\n",
      "INFO:tensorflow:doc_span_index: 0\n",
      "I1208 12:27:37.002676 139883775852736 run_factoid.py:441] doc_span_index: 0\n",
      "INFO:tensorflow:tokens: [CLS] What were the new treatment ( s ) this paper looked into ? [SEP] Lu ##mba ##r disc her ##nia ##tion ( L ##D ##H ) is one of the most frequently diagnosed causes of low back pain and is a common cause of r ##adi ##cu ##lop ##athy . [ 1 – 3 ] Although most patients with L ##D ##H can achieve satisfying clinical and functional outcomes with conservative treatment , a few patients do not respond effectively to conservative treatment and eventually require surgical treatment . [ 4 , 5 ] There are several main surgical options : open l ##umba ##r micro - disc ##ec ##tom ##y ( O ##LM ) , [ 6 ] micro ##end ##os ##copic disc ##ec ##tom ##y ( ME ##D ) , [ 7 , 8 ] minimal ##ly invasive trans ##fo ##ram ##inal l ##umba ##r inter ##body fusion ( MI ##S - T ##L ##IF ) , [ 9 ] and per ##cut ##aneous end ##os ##copic l ##umba ##r disc ##ec ##tom ##y ( P ##EL ##D ) . [ 10 , 11 ] O ##LM has been regarded as the most commonly recommended surgical option for re ##current L ##D ##H ; [ 12 , 13 ] however , it was associated with several complications , including muscle damage , nerve re ##traction , and the removal of yellow l ##iga - men ##t , [ 14 , 15 ] which can result in instability and scar ##ring of the e ##pid ##ural space . [ 16 , 17 ] ME ##D uses a micro ##end ##os ##cope for visual ##iza - t ##ion , and the para ##sp ##ino ##us muscles are handled by muscle splitting through di ##lator ##s ; [ 18 ] thus , the muscle and soft tissue are minimal ##ly injured . [ 19 ] MI ##S - T ##L ##IF is a well - accepted operation method for re ##current L ##D ##H . And it has the advantages of less i ##at ##rogen ##ic soft tissue injury , lower risk of post ##oper ##ative r ##adi ##cu ##lit ##is , and decreased re ##traction of du ##ral sa ##c . [ 20 , 21 ] P ##EL ##D is a more [SEP]\n",
      "I1208 12:27:37.002792 139883775852736 run_factoid.py:443] tokens: [CLS] What were the new treatment ( s ) this paper looked into ? [SEP] Lu ##mba ##r disc her ##nia ##tion ( L ##D ##H ) is one of the most frequently diagnosed causes of low back pain and is a common cause of r ##adi ##cu ##lop ##athy . [ 1 – 3 ] Although most patients with L ##D ##H can achieve satisfying clinical and functional outcomes with conservative treatment , a few patients do not respond effectively to conservative treatment and eventually require surgical treatment . [ 4 , 5 ] There are several main surgical options : open l ##umba ##r micro - disc ##ec ##tom ##y ( O ##LM ) , [ 6 ] micro ##end ##os ##copic disc ##ec ##tom ##y ( ME ##D ) , [ 7 , 8 ] minimal ##ly invasive trans ##fo ##ram ##inal l ##umba ##r inter ##body fusion ( MI ##S - T ##L ##IF ) , [ 9 ] and per ##cut ##aneous end ##os ##copic l ##umba ##r disc ##ec ##tom ##y ( P ##EL ##D ) . [ 10 , 11 ] O ##LM has been regarded as the most commonly recommended surgical option for re ##current L ##D ##H ; [ 12 , 13 ] however , it was associated with several complications , including muscle damage , nerve re ##traction , and the removal of yellow l ##iga - men ##t , [ 14 , 15 ] which can result in instability and scar ##ring of the e ##pid ##ural space . [ 16 , 17 ] ME ##D uses a micro ##end ##os ##cope for visual ##iza - t ##ion , and the para ##sp ##ino ##us muscles are handled by muscle splitting through di ##lator ##s ; [ 18 ] thus , the muscle and soft tissue are minimal ##ly injured . [ 19 ] MI ##S - T ##L ##IF is a well - accepted operation method for re ##current L ##D ##H . And it has the advantages of less i ##at ##rogen ##ic soft tissue injury , lower risk of post ##oper ##ative r ##adi ##cu ##lit ##is , and decreased re ##traction of du ##ral sa ##c . [ 20 , 21 ] P ##EL ##D is a more [SEP]\n",
      "INFO:tensorflow:token_to_orig_map: 15:0 16:0 17:0 18:1 19:2 20:2 21:2 22:3 23:3 24:3 25:3 26:3 27:4 28:5 29:6 30:7 31:8 32:9 33:10 34:11 35:12 36:13 37:14 38:15 39:16 40:17 41:18 42:19 43:20 44:21 45:22 46:22 47:22 48:22 49:22 50:22 51:22 52:22 53:22 54:22 55:22 56:23 57:24 58:25 59:26 60:27 61:27 62:27 63:28 64:29 65:30 66:31 67:32 68:33 69:34 70:35 71:36 72:37 73:37 74:38 75:39 76:40 77:41 78:42 79:43 80:44 81:45 82:46 83:47 84:48 85:49 86:50 87:51 88:52 89:52 90:52 91:52 92:52 93:52 94:52 95:53 96:54 97:55 98:56 99:57 100:58 101:58 102:59 103:60 104:60 105:60 106:61 107:61 108:62 109:62 110:62 111:62 112:63 113:63 114:63 115:63 116:63 117:63 118:63 119:63 120:64 121:64 122:64 123:64 124:65 125:65 126:65 127:65 128:66 129:66 130:66 131:66 132:66 133:66 134:66 135:66 136:66 137:66 138:67 139:67 140:68 141:69 142:69 143:69 144:69 145:70 146:70 147:70 148:71 149:71 150:72 151:73 152:73 153:73 154:73 155:74 156:74 157:74 158:74 159:74 160:74 161:74 162:74 163:75 164:76 165:76 166:76 167:77 168:77 169:77 170:78 171:78 172:78 173:79 174:79 175:79 176:79 177:80 178:80 179:80 180:80 181:80 182:80 183:80 184:80 185:80 186:80 187:80 188:81 189:81 190:82 191:83 192:84 193:85 194:86 195:87 196:88 197:89 198:90 199:91 200:92 201:93 202:93 203:94 204:94 205:94 206:94 207:94 208:94 209:94 210:94 211:94 212:95 213:95 214:96 215:97 216:98 217:99 218:100 219:101 220:101 221:102 222:103 223:104 224:104 225:105 226:106 227:106 228:106 229:107 230:108 231:109 232:110 233:111 234:112 235:112 236:112 237:113 238:113 239:113 240:113 241:113 242:113 243:113 244:113 245:114 246:115 247:116 248:117 249:118 250:119 251:120 252:120 253:121 254:122 255:123 256:123 257:123 258:124 259:124 260:124 261:124 262:124 263:124 264:124 265:125 266:125 267:126 268:127 269:128 270:128 271:128 272:128 273:129 274:130 275:130 276:130 277:131 278:131 279:131 280:132 281:133 282:134 283:134 284:134 285:134 286:135 287:136 288:137 289:138 290:139 291:140 292:141 293:142 294:142 295:142 296:142 297:142 298:142 299:142 300:143 301:143 302:144 303:145 304:146 305:147 306:148 307:149 308:150 309:150 310:151 311:151 312:151 313:151 314:151 315:152 316:152 317:152 318:152 319:152 320:152 321:153 322:154 323:155 324:155 325:155 326:156 327:157 328:158 329:159 330:159 331:160 332:160 333:160 334:160 335:161 336:162 337:163 338:164 339:165 340:166 341:167 342:168 343:168 344:168 345:168 346:169 347:170 348:171 349:171 350:172 351:173 352:174 353:175 354:175 355:175 356:176 357:176 358:176 359:176 360:176 361:176 362:177 363:178 364:179 365:179 366:180 367:181 368:181 369:182 370:182 371:182 372:182 373:182 374:182 375:182 376:182 377:183 378:183 379:183 380:184 381:185 382:186\n",
      "I1208 12:27:37.002909 139883775852736 run_factoid.py:445] token_to_orig_map: 15:0 16:0 17:0 18:1 19:2 20:2 21:2 22:3 23:3 24:3 25:3 26:3 27:4 28:5 29:6 30:7 31:8 32:9 33:10 34:11 35:12 36:13 37:14 38:15 39:16 40:17 41:18 42:19 43:20 44:21 45:22 46:22 47:22 48:22 49:22 50:22 51:22 52:22 53:22 54:22 55:22 56:23 57:24 58:25 59:26 60:27 61:27 62:27 63:28 64:29 65:30 66:31 67:32 68:33 69:34 70:35 71:36 72:37 73:37 74:38 75:39 76:40 77:41 78:42 79:43 80:44 81:45 82:46 83:47 84:48 85:49 86:50 87:51 88:52 89:52 90:52 91:52 92:52 93:52 94:52 95:53 96:54 97:55 98:56 99:57 100:58 101:58 102:59 103:60 104:60 105:60 106:61 107:61 108:62 109:62 110:62 111:62 112:63 113:63 114:63 115:63 116:63 117:63 118:63 119:63 120:64 121:64 122:64 123:64 124:65 125:65 126:65 127:65 128:66 129:66 130:66 131:66 132:66 133:66 134:66 135:66 136:66 137:66 138:67 139:67 140:68 141:69 142:69 143:69 144:69 145:70 146:70 147:70 148:71 149:71 150:72 151:73 152:73 153:73 154:73 155:74 156:74 157:74 158:74 159:74 160:74 161:74 162:74 163:75 164:76 165:76 166:76 167:77 168:77 169:77 170:78 171:78 172:78 173:79 174:79 175:79 176:79 177:80 178:80 179:80 180:80 181:80 182:80 183:80 184:80 185:80 186:80 187:80 188:81 189:81 190:82 191:83 192:84 193:85 194:86 195:87 196:88 197:89 198:90 199:91 200:92 201:93 202:93 203:94 204:94 205:94 206:94 207:94 208:94 209:94 210:94 211:94 212:95 213:95 214:96 215:97 216:98 217:99 218:100 219:101 220:101 221:102 222:103 223:104 224:104 225:105 226:106 227:106 228:106 229:107 230:108 231:109 232:110 233:111 234:112 235:112 236:112 237:113 238:113 239:113 240:113 241:113 242:113 243:113 244:113 245:114 246:115 247:116 248:117 249:118 250:119 251:120 252:120 253:121 254:122 255:123 256:123 257:123 258:124 259:124 260:124 261:124 262:124 263:124 264:124 265:125 266:125 267:126 268:127 269:128 270:128 271:128 272:128 273:129 274:130 275:130 276:130 277:131 278:131 279:131 280:132 281:133 282:134 283:134 284:134 285:134 286:135 287:136 288:137 289:138 290:139 291:140 292:141 293:142 294:142 295:142 296:142 297:142 298:142 299:142 300:143 301:143 302:144 303:145 304:146 305:147 306:148 307:149 308:150 309:150 310:151 311:151 312:151 313:151 314:151 315:152 316:152 317:152 318:152 319:152 320:152 321:153 322:154 323:155 324:155 325:155 326:156 327:157 328:158 329:159 330:159 331:160 332:160 333:160 334:160 335:161 336:162 337:163 338:164 339:165 340:166 341:167 342:168 343:168 344:168 345:168 346:169 347:170 348:171 349:171 350:172 351:173 352:174 353:175 354:175 355:175 356:176 357:176 358:176 359:176 360:176 361:176 362:177 363:178 364:179 365:179 366:180 367:181 368:181 369:182 370:182 371:182 372:182 373:182 374:182 375:182 376:182 377:183 378:183 379:183 380:184 381:185 382:186\n",
      "INFO:tensorflow:token_is_max_context: 15:True 16:True 17:True 18:True 19:True 20:True 21:True 22:True 23:True 24:True 25:True 26:True 27:True 28:True 29:True 30:True 31:True 32:True 33:True 34:True 35:True 36:True 37:True 38:True 39:True 40:True 41:True 42:True 43:True 44:True 45:True 46:True 47:True 48:True 49:True 50:True 51:True 52:True 53:True 54:True 55:True 56:True 57:True 58:True 59:True 60:True 61:True 62:True 63:True 64:True 65:True 66:True 67:True 68:True 69:True 70:True 71:True 72:True 73:True 74:True 75:True 76:True 77:True 78:True 79:True 80:True 81:True 82:True 83:True 84:True 85:True 86:True 87:True 88:True 89:True 90:True 91:True 92:True 93:True 94:True 95:True 96:True 97:True 98:True 99:True 100:True 101:True 102:True 103:True 104:True 105:True 106:True 107:True 108:True 109:True 110:True 111:True 112:True 113:True 114:True 115:True 116:True 117:True 118:True 119:True 120:True 121:True 122:True 123:True 124:True 125:True 126:True 127:True 128:True 129:True 130:True 131:True 132:True 133:True 134:True 135:True 136:True 137:True 138:True 139:True 140:True 141:True 142:True 143:True 144:True 145:True 146:True 147:True 148:True 149:True 150:True 151:True 152:True 153:True 154:True 155:True 156:True 157:True 158:True 159:True 160:True 161:True 162:True 163:True 164:True 165:True 166:True 167:True 168:True 169:True 170:True 171:True 172:True 173:True 174:True 175:True 176:True 177:True 178:True 179:True 180:True 181:True 182:True 183:True 184:True 185:True 186:True 187:True 188:True 189:True 190:True 191:True 192:True 193:True 194:True 195:True 196:True 197:True 198:True 199:True 200:True 201:True 202:True 203:True 204:True 205:True 206:True 207:True 208:True 209:True 210:True 211:True 212:True 213:True 214:True 215:True 216:True 217:True 218:True 219:True 220:True 221:True 222:True 223:True 224:True 225:True 226:True 227:True 228:True 229:True 230:True 231:True 232:True 233:True 234:True 235:True 236:True 237:True 238:True 239:True 240:True 241:True 242:True 243:True 244:True 245:True 246:True 247:True 248:True 249:True 250:True 251:True 252:True 253:True 254:True 255:True 256:True 257:True 258:True 259:True 260:True 261:True 262:True 263:False 264:False 265:False 266:False 267:False 268:False 269:False 270:False 271:False 272:False 273:False 274:False 275:False 276:False 277:False 278:False 279:False 280:False 281:False 282:False 283:False 284:False 285:False 286:False 287:False 288:False 289:False 290:False 291:False 292:False 293:False 294:False 295:False 296:False 297:False 298:False 299:False 300:False 301:False 302:False 303:False 304:False 305:False 306:False 307:False 308:False 309:False 310:False 311:False 312:False 313:False 314:False 315:False 316:False 317:False 318:False 319:False 320:False 321:False 322:False 323:False 324:False 325:False 326:False 327:False 328:False 329:False 330:False 331:False 332:False 333:False 334:False 335:False 336:False 337:False 338:False 339:False 340:False 341:False 342:False 343:False 344:False 345:False 346:False 347:False 348:False 349:False 350:False 351:False 352:False 353:False 354:False 355:False 356:False 357:False 358:False 359:False 360:False 361:False 362:False 363:False 364:False 365:False 366:False 367:False 368:False 369:False 370:False 371:False 372:False 373:False 374:False 375:False 376:False 377:False 378:False 379:False 380:False 381:False 382:False\n",
      "I1208 12:27:37.003017 139883775852736 run_factoid.py:447] token_is_max_context: 15:True 16:True 17:True 18:True 19:True 20:True 21:True 22:True 23:True 24:True 25:True 26:True 27:True 28:True 29:True 30:True 31:True 32:True 33:True 34:True 35:True 36:True 37:True 38:True 39:True 40:True 41:True 42:True 43:True 44:True 45:True 46:True 47:True 48:True 49:True 50:True 51:True 52:True 53:True 54:True 55:True 56:True 57:True 58:True 59:True 60:True 61:True 62:True 63:True 64:True 65:True 66:True 67:True 68:True 69:True 70:True 71:True 72:True 73:True 74:True 75:True 76:True 77:True 78:True 79:True 80:True 81:True 82:True 83:True 84:True 85:True 86:True 87:True 88:True 89:True 90:True 91:True 92:True 93:True 94:True 95:True 96:True 97:True 98:True 99:True 100:True 101:True 102:True 103:True 104:True 105:True 106:True 107:True 108:True 109:True 110:True 111:True 112:True 113:True 114:True 115:True 116:True 117:True 118:True 119:True 120:True 121:True 122:True 123:True 124:True 125:True 126:True 127:True 128:True 129:True 130:True 131:True 132:True 133:True 134:True 135:True 136:True 137:True 138:True 139:True 140:True 141:True 142:True 143:True 144:True 145:True 146:True 147:True 148:True 149:True 150:True 151:True 152:True 153:True 154:True 155:True 156:True 157:True 158:True 159:True 160:True 161:True 162:True 163:True 164:True 165:True 166:True 167:True 168:True 169:True 170:True 171:True 172:True 173:True 174:True 175:True 176:True 177:True 178:True 179:True 180:True 181:True 182:True 183:True 184:True 185:True 186:True 187:True 188:True 189:True 190:True 191:True 192:True 193:True 194:True 195:True 196:True 197:True 198:True 199:True 200:True 201:True 202:True 203:True 204:True 205:True 206:True 207:True 208:True 209:True 210:True 211:True 212:True 213:True 214:True 215:True 216:True 217:True 218:True 219:True 220:True 221:True 222:True 223:True 224:True 225:True 226:True 227:True 228:True 229:True 230:True 231:True 232:True 233:True 234:True 235:True 236:True 237:True 238:True 239:True 240:True 241:True 242:True 243:True 244:True 245:True 246:True 247:True 248:True 249:True 250:True 251:True 252:True 253:True 254:True 255:True 256:True 257:True 258:True 259:True 260:True 261:True 262:True 263:False 264:False 265:False 266:False 267:False 268:False 269:False 270:False 271:False 272:False 273:False 274:False 275:False 276:False 277:False 278:False 279:False 280:False 281:False 282:False 283:False 284:False 285:False 286:False 287:False 288:False 289:False 290:False 291:False 292:False 293:False 294:False 295:False 296:False 297:False 298:False 299:False 300:False 301:False 302:False 303:False 304:False 305:False 306:False 307:False 308:False 309:False 310:False 311:False 312:False 313:False 314:False 315:False 316:False 317:False 318:False 319:False 320:False 321:False 322:False 323:False 324:False 325:False 326:False 327:False 328:False 329:False 330:False 331:False 332:False 333:False 334:False 335:False 336:False 337:False 338:False 339:False 340:False 341:False 342:False 343:False 344:False 345:False 346:False 347:False 348:False 349:False 350:False 351:False 352:False 353:False 354:False 355:False 356:False 357:False 358:False 359:False 360:False 361:False 362:False 363:False 364:False 365:False 366:False 367:False 368:False 369:False 370:False 371:False 372:False 373:False 374:False 375:False 376:False 377:False 378:False 379:False 380:False 381:False 382:False\n",
      "INFO:tensorflow:input_ids: 101 1327 1127 1103 1207 3252 113 188 114 1142 2526 1350 1154 136 102 14557 10806 1197 6187 1123 5813 2116 113 149 2137 3048 114 1110 1141 1104 1103 1211 3933 11534 4680 1104 1822 1171 2489 1105 1110 170 1887 2612 1104 187 14230 10182 13200 23610 119 164 122 782 124 166 1966 1211 4420 1114 149 2137 3048 1169 5515 18330 7300 1105 8458 13950 1114 6588 3252 117 170 1374 4420 1202 1136 6297 5877 1106 6588 3252 1105 2028 4752 13467 3252 119 164 125 117 126 166 1247 1132 1317 1514 13467 6665 131 1501 181 25509 1197 17599 118 6187 10294 18778 1183 113 152 22074 114 117 164 127 166 17599 6696 2155 22258 6187 10294 18778 1183 113 22157 2137 114 117 164 128 117 129 166 10298 1193 19849 14715 14467 4515 14196 181 25509 1197 9455 14637 11970 113 26574 1708 118 157 2162 15499 114 117 164 130 166 1105 1679 12734 13064 1322 2155 22258 181 25509 1197 6187 10294 18778 1183 113 153 21678 2137 114 119 164 1275 117 1429 166 152 22074 1144 1151 4485 1112 1103 1211 3337 6315 13467 5146 1111 1231 21754 149 2137 3048 132 164 1367 117 1492 166 1649 117 1122 1108 2628 1114 1317 13522 117 1259 6484 3290 117 9071 1231 27539 117 1105 1103 8116 1104 3431 181 13499 118 1441 1204 117 164 1489 117 1405 166 1134 1169 1871 1107 20482 1105 14161 3384 1104 1103 174 25786 12602 2000 119 164 1479 117 1542 166 22157 2137 2745 170 17599 6696 2155 16260 1111 5173 23228 118 189 1988 117 1105 1103 18311 20080 4559 1361 6130 1132 8630 1118 6484 15601 1194 4267 13389 1116 132 164 1407 166 2456 117 1103 6484 1105 2991 7918 1132 10298 1193 4475 119 164 1627 166 26574 1708 118 157 2162 15499 1110 170 1218 118 3134 2805 3442 1111 1231 21754 149 2137 3048 119 1262 1122 1144 1103 13300 1104 1750 178 2980 26767 1596 2991 7918 3773 117 2211 3187 1104 2112 19807 5838 187 14230 10182 12888 1548 117 1105 10558 1231 27539 1104 3840 4412 21718 1665 119 164 1406 117 1626 166 153 21678 2137 1110 170 1167 102\n",
      "I1208 12:27:37.003118 139883775852736 run_factoid.py:449] input_ids: 101 1327 1127 1103 1207 3252 113 188 114 1142 2526 1350 1154 136 102 14557 10806 1197 6187 1123 5813 2116 113 149 2137 3048 114 1110 1141 1104 1103 1211 3933 11534 4680 1104 1822 1171 2489 1105 1110 170 1887 2612 1104 187 14230 10182 13200 23610 119 164 122 782 124 166 1966 1211 4420 1114 149 2137 3048 1169 5515 18330 7300 1105 8458 13950 1114 6588 3252 117 170 1374 4420 1202 1136 6297 5877 1106 6588 3252 1105 2028 4752 13467 3252 119 164 125 117 126 166 1247 1132 1317 1514 13467 6665 131 1501 181 25509 1197 17599 118 6187 10294 18778 1183 113 152 22074 114 117 164 127 166 17599 6696 2155 22258 6187 10294 18778 1183 113 22157 2137 114 117 164 128 117 129 166 10298 1193 19849 14715 14467 4515 14196 181 25509 1197 9455 14637 11970 113 26574 1708 118 157 2162 15499 114 117 164 130 166 1105 1679 12734 13064 1322 2155 22258 181 25509 1197 6187 10294 18778 1183 113 153 21678 2137 114 119 164 1275 117 1429 166 152 22074 1144 1151 4485 1112 1103 1211 3337 6315 13467 5146 1111 1231 21754 149 2137 3048 132 164 1367 117 1492 166 1649 117 1122 1108 2628 1114 1317 13522 117 1259 6484 3290 117 9071 1231 27539 117 1105 1103 8116 1104 3431 181 13499 118 1441 1204 117 164 1489 117 1405 166 1134 1169 1871 1107 20482 1105 14161 3384 1104 1103 174 25786 12602 2000 119 164 1479 117 1542 166 22157 2137 2745 170 17599 6696 2155 16260 1111 5173 23228 118 189 1988 117 1105 1103 18311 20080 4559 1361 6130 1132 8630 1118 6484 15601 1194 4267 13389 1116 132 164 1407 166 2456 117 1103 6484 1105 2991 7918 1132 10298 1193 4475 119 164 1627 166 26574 1708 118 157 2162 15499 1110 170 1218 118 3134 2805 3442 1111 1231 21754 149 2137 3048 119 1262 1122 1144 1103 13300 1104 1750 178 2980 26767 1596 2991 7918 3773 117 2211 3187 1104 2112 19807 5838 187 14230 10182 12888 1548 117 1105 10558 1231 27539 1104 3840 4412 21718 1665 119 164 1406 117 1626 166 153 21678 2137 1110 170 1167 102\n",
      "INFO:tensorflow:input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      "I1208 12:27:37.003210 139883775852736 run_factoid.py:451] input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      "INFO:tensorflow:segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      "I1208 12:27:37.003300 139883775852736 run_factoid.py:453] segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      "INFO:tensorflow:*** Example ***\n",
      "I1208 12:27:37.004298 139883775852736 run_factoid.py:438] *** Example ***\n",
      "INFO:tensorflow:unique_id: 1000000009\n",
      "I1208 12:27:37.004356 139883775852736 run_factoid.py:439] unique_id: 1000000009\n",
      "INFO:tensorflow:example_index: 4\n",
      "I1208 12:27:37.004394 139883775852736 run_factoid.py:440] example_index: 4\n",
      "INFO:tensorflow:doc_span_index: 1\n",
      "I1208 12:27:37.004429 139883775852736 run_factoid.py:441] doc_span_index: 1\n",
      "INFO:tensorflow:tokens: [CLS] What were the new treatment ( s ) this paper looked into ? [SEP] ##ram ##inal l ##umba ##r inter ##body fusion ( MI ##S - T ##L ##IF ) , [ 9 ] and per ##cut ##aneous end ##os ##copic l ##umba ##r disc ##ec ##tom ##y ( P ##EL ##D ) . [ 10 , 11 ] O ##LM has been regarded as the most commonly recommended surgical option for re ##current L ##D ##H ; [ 12 , 13 ] however , it was associated with several complications , including muscle damage , nerve re ##traction , and the removal of yellow l ##iga - men ##t , [ 14 , 15 ] which can result in instability and scar ##ring of the e ##pid ##ural space . [ 16 , 17 ] ME ##D uses a micro ##end ##os ##cope for visual ##iza - t ##ion , and the para ##sp ##ino ##us muscles are handled by muscle splitting through di ##lator ##s ; [ 18 ] thus , the muscle and soft tissue are minimal ##ly injured . [ 19 ] MI ##S - T ##L ##IF is a well - accepted operation method for re ##current L ##D ##H . And it has the advantages of less i ##at ##rogen ##ic soft tissue injury , lower risk of post ##oper ##ative r ##adi ##cu ##lit ##is , and decreased re ##traction of du ##ral sa ##c . [ 20 , 21 ] P ##EL ##D is a more minimal ##ly invasive surgery because the posterior column structures are pre - served . [ 22 , 23 ] It has gained interest for its potential advantage in the reduced risk of face ##t joints injury , fewer post ##oper ##ative complications , a shorter hospital stay and lower cost . [ 24 , 25 ] Previous studies have reported that P ##EL ##D is an effective and safe treatment for L ##D ##H . [ 26 , 27 ] However , whether P ##EL ##D is superior to other surgical options remains controversial . Thus , we conducted this meta - analysis to compare the clinical , radio ##log ##ic , and complications of P ##EL ##D and other surge ##ries for patients with L ##D ##H [SEP]\n",
      "I1208 12:27:37.004539 139883775852736 run_factoid.py:443] tokens: [CLS] What were the new treatment ( s ) this paper looked into ? [SEP] ##ram ##inal l ##umba ##r inter ##body fusion ( MI ##S - T ##L ##IF ) , [ 9 ] and per ##cut ##aneous end ##os ##copic l ##umba ##r disc ##ec ##tom ##y ( P ##EL ##D ) . [ 10 , 11 ] O ##LM has been regarded as the most commonly recommended surgical option for re ##current L ##D ##H ; [ 12 , 13 ] however , it was associated with several complications , including muscle damage , nerve re ##traction , and the removal of yellow l ##iga - men ##t , [ 14 , 15 ] which can result in instability and scar ##ring of the e ##pid ##ural space . [ 16 , 17 ] ME ##D uses a micro ##end ##os ##cope for visual ##iza - t ##ion , and the para ##sp ##ino ##us muscles are handled by muscle splitting through di ##lator ##s ; [ 18 ] thus , the muscle and soft tissue are minimal ##ly injured . [ 19 ] MI ##S - T ##L ##IF is a well - accepted operation method for re ##current L ##D ##H . And it has the advantages of less i ##at ##rogen ##ic soft tissue injury , lower risk of post ##oper ##ative r ##adi ##cu ##lit ##is , and decreased re ##traction of du ##ral sa ##c . [ 20 , 21 ] P ##EL ##D is a more minimal ##ly invasive surgery because the posterior column structures are pre - served . [ 22 , 23 ] It has gained interest for its potential advantage in the reduced risk of face ##t joints injury , fewer post ##oper ##ative complications , a shorter hospital stay and lower cost . [ 24 , 25 ] Previous studies have reported that P ##EL ##D is an effective and safe treatment for L ##D ##H . [ 26 , 27 ] However , whether P ##EL ##D is superior to other surgical options remains controversial . Thus , we conducted this meta - analysis to compare the clinical , radio ##log ##ic , and complications of P ##EL ##D and other surge ##ries for patients with L ##D ##H [SEP]\n",
      "INFO:tensorflow:token_to_orig_map: 15:69 16:69 17:70 18:70 19:70 20:71 21:71 22:72 23:73 24:73 25:73 26:73 27:74 28:74 29:74 30:74 31:74 32:74 33:74 34:74 35:75 36:76 37:76 38:76 39:77 40:77 41:77 42:78 43:78 44:78 45:79 46:79 47:79 48:79 49:80 50:80 51:80 52:80 53:80 54:80 55:80 56:80 57:80 58:80 59:80 60:81 61:81 62:82 63:83 64:84 65:85 66:86 67:87 68:88 69:89 70:90 71:91 72:92 73:93 74:93 75:94 76:94 77:94 78:94 79:94 80:94 81:94 82:94 83:94 84:95 85:95 86:96 87:97 88:98 89:99 90:100 91:101 92:101 93:102 94:103 95:104 96:104 97:105 98:106 99:106 100:106 101:107 102:108 103:109 104:110 105:111 106:112 107:112 108:112 109:113 110:113 111:113 112:113 113:113 114:113 115:113 116:113 117:114 118:115 119:116 120:117 121:118 122:119 123:120 124:120 125:121 126:122 127:123 128:123 129:123 130:124 131:124 132:124 133:124 134:124 135:124 136:124 137:125 138:125 139:126 140:127 141:128 142:128 143:128 144:128 145:129 146:130 147:130 148:130 149:131 150:131 151:131 152:132 153:133 154:134 155:134 156:134 157:134 158:135 159:136 160:137 161:138 162:139 163:140 164:141 165:142 166:142 167:142 168:142 169:142 170:142 171:142 172:143 173:143 174:144 175:145 176:146 177:147 178:148 179:149 180:150 181:150 182:151 183:151 184:151 185:151 186:151 187:152 188:152 189:152 190:152 191:152 192:152 193:153 194:154 195:155 196:155 197:155 198:156 199:157 200:158 201:159 202:159 203:160 204:160 205:160 206:160 207:161 208:162 209:163 210:164 211:165 212:166 213:167 214:168 215:168 216:168 217:168 218:169 219:170 220:171 221:171 222:172 223:173 224:174 225:175 226:175 227:175 228:176 229:176 230:176 231:176 232:176 233:176 234:177 235:178 236:179 237:179 238:180 239:181 240:181 241:182 242:182 243:182 244:182 245:182 246:182 247:182 248:182 249:183 250:183 251:183 252:184 253:185 254:186 255:187 256:187 257:188 258:189 259:190 260:191 261:192 262:193 263:194 264:195 265:196 266:196 267:197 268:197 269:197 270:197 271:197 272:197 273:197 274:198 275:199 276:200 277:201 278:202 279:203 280:204 281:205 282:206 283:207 284:208 285:209 286:210 287:211 288:211 289:212 290:213 291:213 292:214 293:215 294:215 295:215 296:216 297:216 298:217 299:218 300:219 301:220 302:221 303:222 304:223 305:223 306:223 307:223 308:223 309:223 310:223 311:224 312:225 313:226 314:227 315:228 316:229 317:229 318:229 319:230 320:231 321:232 322:233 323:234 324:235 325:236 326:237 327:237 328:237 329:237 330:237 331:237 332:237 333:237 334:237 335:238 336:238 337:239 338:240 339:240 340:240 341:241 342:242 343:243 344:244 345:245 346:246 347:247 348:248 349:248 350:249 351:249 352:250 353:251 354:252 355:253 356:253 357:253 358:254 359:255 360:256 361:257 362:257 363:258 364:258 365:258 366:258 367:259 368:260 369:261 370:262 371:262 372:262 373:263 374:264 375:265 376:265 377:266 378:267 379:268 380:269 381:269 382:269\n",
      "I1208 12:27:37.004657 139883775852736 run_factoid.py:445] token_to_orig_map: 15:69 16:69 17:70 18:70 19:70 20:71 21:71 22:72 23:73 24:73 25:73 26:73 27:74 28:74 29:74 30:74 31:74 32:74 33:74 34:74 35:75 36:76 37:76 38:76 39:77 40:77 41:77 42:78 43:78 44:78 45:79 46:79 47:79 48:79 49:80 50:80 51:80 52:80 53:80 54:80 55:80 56:80 57:80 58:80 59:80 60:81 61:81 62:82 63:83 64:84 65:85 66:86 67:87 68:88 69:89 70:90 71:91 72:92 73:93 74:93 75:94 76:94 77:94 78:94 79:94 80:94 81:94 82:94 83:94 84:95 85:95 86:96 87:97 88:98 89:99 90:100 91:101 92:101 93:102 94:103 95:104 96:104 97:105 98:106 99:106 100:106 101:107 102:108 103:109 104:110 105:111 106:112 107:112 108:112 109:113 110:113 111:113 112:113 113:113 114:113 115:113 116:113 117:114 118:115 119:116 120:117 121:118 122:119 123:120 124:120 125:121 126:122 127:123 128:123 129:123 130:124 131:124 132:124 133:124 134:124 135:124 136:124 137:125 138:125 139:126 140:127 141:128 142:128 143:128 144:128 145:129 146:130 147:130 148:130 149:131 150:131 151:131 152:132 153:133 154:134 155:134 156:134 157:134 158:135 159:136 160:137 161:138 162:139 163:140 164:141 165:142 166:142 167:142 168:142 169:142 170:142 171:142 172:143 173:143 174:144 175:145 176:146 177:147 178:148 179:149 180:150 181:150 182:151 183:151 184:151 185:151 186:151 187:152 188:152 189:152 190:152 191:152 192:152 193:153 194:154 195:155 196:155 197:155 198:156 199:157 200:158 201:159 202:159 203:160 204:160 205:160 206:160 207:161 208:162 209:163 210:164 211:165 212:166 213:167 214:168 215:168 216:168 217:168 218:169 219:170 220:171 221:171 222:172 223:173 224:174 225:175 226:175 227:175 228:176 229:176 230:176 231:176 232:176 233:176 234:177 235:178 236:179 237:179 238:180 239:181 240:181 241:182 242:182 243:182 244:182 245:182 246:182 247:182 248:182 249:183 250:183 251:183 252:184 253:185 254:186 255:187 256:187 257:188 258:189 259:190 260:191 261:192 262:193 263:194 264:195 265:196 266:196 267:197 268:197 269:197 270:197 271:197 272:197 273:197 274:198 275:199 276:200 277:201 278:202 279:203 280:204 281:205 282:206 283:207 284:208 285:209 286:210 287:211 288:211 289:212 290:213 291:213 292:214 293:215 294:215 295:215 296:216 297:216 298:217 299:218 300:219 301:220 302:221 303:222 304:223 305:223 306:223 307:223 308:223 309:223 310:223 311:224 312:225 313:226 314:227 315:228 316:229 317:229 318:229 319:230 320:231 321:232 322:233 323:234 324:235 325:236 326:237 327:237 328:237 329:237 330:237 331:237 332:237 333:237 334:237 335:238 336:238 337:239 338:240 339:240 340:240 341:241 342:242 343:243 344:244 345:245 346:246 347:247 348:248 349:248 350:249 351:249 352:250 353:251 354:252 355:253 356:253 357:253 358:254 359:255 360:256 361:257 362:257 363:258 364:258 365:258 366:258 367:259 368:260 369:261 370:262 371:262 372:262 373:263 374:264 375:265 376:265 377:266 378:267 379:268 380:269 381:269 382:269\n",
      "INFO:tensorflow:token_is_max_context: 15:False 16:False 17:False 18:False 19:False 20:False 21:False 22:False 23:False 24:False 25:False 26:False 27:False 28:False 29:False 30:False 31:False 32:False 33:False 34:False 35:False 36:False 37:False 38:False 39:False 40:False 41:False 42:False 43:False 44:False 45:False 46:False 47:False 48:False 49:False 50:False 51:False 52:False 53:False 54:False 55:False 56:False 57:False 58:False 59:False 60:False 61:False 62:False 63:False 64:False 65:False 66:False 67:False 68:False 69:False 70:False 71:False 72:False 73:False 74:False 75:False 76:False 77:False 78:False 79:False 80:False 81:False 82:False 83:False 84:False 85:False 86:False 87:False 88:False 89:False 90:False 91:False 92:False 93:False 94:False 95:False 96:False 97:False 98:False 99:False 100:False 101:False 102:False 103:False 104:False 105:False 106:False 107:False 108:False 109:False 110:False 111:False 112:False 113:False 114:False 115:False 116:False 117:False 118:False 119:False 120:False 121:False 122:False 123:False 124:False 125:False 126:False 127:False 128:False 129:False 130:False 131:False 132:False 133:False 134:False 135:True 136:True 137:True 138:True 139:True 140:True 141:True 142:True 143:True 144:True 145:True 146:True 147:True 148:True 149:True 150:True 151:True 152:True 153:True 154:True 155:True 156:True 157:True 158:True 159:True 160:True 161:True 162:True 163:True 164:True 165:True 166:True 167:True 168:True 169:True 170:True 171:True 172:True 173:True 174:True 175:True 176:True 177:True 178:True 179:True 180:True 181:True 182:True 183:True 184:True 185:True 186:True 187:True 188:True 189:True 190:True 191:True 192:True 193:True 194:True 195:True 196:True 197:True 198:True 199:True 200:True 201:True 202:True 203:True 204:True 205:True 206:True 207:True 208:True 209:True 210:True 211:True 212:True 213:True 214:True 215:True 216:True 217:True 218:True 219:True 220:True 221:True 222:True 223:True 224:True 225:True 226:True 227:True 228:True 229:True 230:True 231:True 232:True 233:True 234:True 235:True 236:True 237:True 238:True 239:True 240:True 241:True 242:True 243:True 244:True 245:True 246:True 247:True 248:True 249:True 250:True 251:True 252:True 253:True 254:True 255:True 256:True 257:True 258:True 259:True 260:True 261:True 262:True 263:True 264:True 265:True 266:True 267:True 268:True 269:True 270:True 271:True 272:True 273:True 274:True 275:True 276:True 277:True 278:True 279:True 280:True 281:True 282:True 283:True 284:True 285:True 286:True 287:True 288:True 289:True 290:True 291:True 292:True 293:True 294:True 295:True 296:True 297:True 298:True 299:True 300:True 301:True 302:True 303:True 304:True 305:True 306:True 307:True 308:True 309:True 310:True 311:True 312:True 313:True 314:True 315:True 316:True 317:True 318:True 319:True 320:True 321:True 322:True 323:True 324:True 325:True 326:True 327:True 328:True 329:True 330:True 331:True 332:True 333:True 334:True 335:True 336:True 337:True 338:True 339:True 340:True 341:True 342:True 343:True 344:True 345:True 346:True 347:True 348:True 349:True 350:True 351:True 352:True 353:True 354:True 355:True 356:True 357:True 358:True 359:True 360:True 361:True 362:True 363:True 364:True 365:True 366:True 367:True 368:True 369:True 370:True 371:True 372:True 373:True 374:True 375:True 376:True 377:True 378:True 379:True 380:True 381:True 382:True\n",
      "I1208 12:27:37.004766 139883775852736 run_factoid.py:447] token_is_max_context: 15:False 16:False 17:False 18:False 19:False 20:False 21:False 22:False 23:False 24:False 25:False 26:False 27:False 28:False 29:False 30:False 31:False 32:False 33:False 34:False 35:False 36:False 37:False 38:False 39:False 40:False 41:False 42:False 43:False 44:False 45:False 46:False 47:False 48:False 49:False 50:False 51:False 52:False 53:False 54:False 55:False 56:False 57:False 58:False 59:False 60:False 61:False 62:False 63:False 64:False 65:False 66:False 67:False 68:False 69:False 70:False 71:False 72:False 73:False 74:False 75:False 76:False 77:False 78:False 79:False 80:False 81:False 82:False 83:False 84:False 85:False 86:False 87:False 88:False 89:False 90:False 91:False 92:False 93:False 94:False 95:False 96:False 97:False 98:False 99:False 100:False 101:False 102:False 103:False 104:False 105:False 106:False 107:False 108:False 109:False 110:False 111:False 112:False 113:False 114:False 115:False 116:False 117:False 118:False 119:False 120:False 121:False 122:False 123:False 124:False 125:False 126:False 127:False 128:False 129:False 130:False 131:False 132:False 133:False 134:False 135:True 136:True 137:True 138:True 139:True 140:True 141:True 142:True 143:True 144:True 145:True 146:True 147:True 148:True 149:True 150:True 151:True 152:True 153:True 154:True 155:True 156:True 157:True 158:True 159:True 160:True 161:True 162:True 163:True 164:True 165:True 166:True 167:True 168:True 169:True 170:True 171:True 172:True 173:True 174:True 175:True 176:True 177:True 178:True 179:True 180:True 181:True 182:True 183:True 184:True 185:True 186:True 187:True 188:True 189:True 190:True 191:True 192:True 193:True 194:True 195:True 196:True 197:True 198:True 199:True 200:True 201:True 202:True 203:True 204:True 205:True 206:True 207:True 208:True 209:True 210:True 211:True 212:True 213:True 214:True 215:True 216:True 217:True 218:True 219:True 220:True 221:True 222:True 223:True 224:True 225:True 226:True 227:True 228:True 229:True 230:True 231:True 232:True 233:True 234:True 235:True 236:True 237:True 238:True 239:True 240:True 241:True 242:True 243:True 244:True 245:True 246:True 247:True 248:True 249:True 250:True 251:True 252:True 253:True 254:True 255:True 256:True 257:True 258:True 259:True 260:True 261:True 262:True 263:True 264:True 265:True 266:True 267:True 268:True 269:True 270:True 271:True 272:True 273:True 274:True 275:True 276:True 277:True 278:True 279:True 280:True 281:True 282:True 283:True 284:True 285:True 286:True 287:True 288:True 289:True 290:True 291:True 292:True 293:True 294:True 295:True 296:True 297:True 298:True 299:True 300:True 301:True 302:True 303:True 304:True 305:True 306:True 307:True 308:True 309:True 310:True 311:True 312:True 313:True 314:True 315:True 316:True 317:True 318:True 319:True 320:True 321:True 322:True 323:True 324:True 325:True 326:True 327:True 328:True 329:True 330:True 331:True 332:True 333:True 334:True 335:True 336:True 337:True 338:True 339:True 340:True 341:True 342:True 343:True 344:True 345:True 346:True 347:True 348:True 349:True 350:True 351:True 352:True 353:True 354:True 355:True 356:True 357:True 358:True 359:True 360:True 361:True 362:True 363:True 364:True 365:True 366:True 367:True 368:True 369:True 370:True 371:True 372:True 373:True 374:True 375:True 376:True 377:True 378:True 379:True 380:True 381:True 382:True\n",
      "INFO:tensorflow:input_ids: 101 1327 1127 1103 1207 3252 113 188 114 1142 2526 1350 1154 136 102 4515 14196 181 25509 1197 9455 14637 11970 113 26574 1708 118 157 2162 15499 114 117 164 130 166 1105 1679 12734 13064 1322 2155 22258 181 25509 1197 6187 10294 18778 1183 113 153 21678 2137 114 119 164 1275 117 1429 166 152 22074 1144 1151 4485 1112 1103 1211 3337 6315 13467 5146 1111 1231 21754 149 2137 3048 132 164 1367 117 1492 166 1649 117 1122 1108 2628 1114 1317 13522 117 1259 6484 3290 117 9071 1231 27539 117 1105 1103 8116 1104 3431 181 13499 118 1441 1204 117 164 1489 117 1405 166 1134 1169 1871 1107 20482 1105 14161 3384 1104 1103 174 25786 12602 2000 119 164 1479 117 1542 166 22157 2137 2745 170 17599 6696 2155 16260 1111 5173 23228 118 189 1988 117 1105 1103 18311 20080 4559 1361 6130 1132 8630 1118 6484 15601 1194 4267 13389 1116 132 164 1407 166 2456 117 1103 6484 1105 2991 7918 1132 10298 1193 4475 119 164 1627 166 26574 1708 118 157 2162 15499 1110 170 1218 118 3134 2805 3442 1111 1231 21754 149 2137 3048 119 1262 1122 1144 1103 13300 1104 1750 178 2980 26767 1596 2991 7918 3773 117 2211 3187 1104 2112 19807 5838 187 14230 10182 12888 1548 117 1105 10558 1231 27539 1104 3840 4412 21718 1665 119 164 1406 117 1626 166 153 21678 2137 1110 170 1167 10298 1193 19849 6059 1272 1103 16530 5551 4413 1132 3073 118 1462 119 164 1659 117 1695 166 1135 1144 3388 2199 1111 1157 3209 4316 1107 1103 3549 3187 1104 1339 1204 19365 3773 117 8307 2112 19807 5838 13522 117 170 7681 2704 2215 1105 2211 2616 119 164 1572 117 1512 166 24142 2527 1138 2103 1115 153 21678 2137 1110 1126 3903 1105 2914 3252 1111 149 2137 3048 119 164 1744 117 1765 166 1438 117 2480 153 21678 2137 1110 7298 1106 1168 13467 6665 2606 6241 119 4516 117 1195 3303 1142 27154 118 3622 1106 14133 1103 7300 117 2070 13791 1596 117 1105 13522 1104 153 21678 2137 1105 1168 12814 3377 1111 4420 1114 149 2137 3048 102\n",
      "I1208 12:27:37.004866 139883775852736 run_factoid.py:449] input_ids: 101 1327 1127 1103 1207 3252 113 188 114 1142 2526 1350 1154 136 102 4515 14196 181 25509 1197 9455 14637 11970 113 26574 1708 118 157 2162 15499 114 117 164 130 166 1105 1679 12734 13064 1322 2155 22258 181 25509 1197 6187 10294 18778 1183 113 153 21678 2137 114 119 164 1275 117 1429 166 152 22074 1144 1151 4485 1112 1103 1211 3337 6315 13467 5146 1111 1231 21754 149 2137 3048 132 164 1367 117 1492 166 1649 117 1122 1108 2628 1114 1317 13522 117 1259 6484 3290 117 9071 1231 27539 117 1105 1103 8116 1104 3431 181 13499 118 1441 1204 117 164 1489 117 1405 166 1134 1169 1871 1107 20482 1105 14161 3384 1104 1103 174 25786 12602 2000 119 164 1479 117 1542 166 22157 2137 2745 170 17599 6696 2155 16260 1111 5173 23228 118 189 1988 117 1105 1103 18311 20080 4559 1361 6130 1132 8630 1118 6484 15601 1194 4267 13389 1116 132 164 1407 166 2456 117 1103 6484 1105 2991 7918 1132 10298 1193 4475 119 164 1627 166 26574 1708 118 157 2162 15499 1110 170 1218 118 3134 2805 3442 1111 1231 21754 149 2137 3048 119 1262 1122 1144 1103 13300 1104 1750 178 2980 26767 1596 2991 7918 3773 117 2211 3187 1104 2112 19807 5838 187 14230 10182 12888 1548 117 1105 10558 1231 27539 1104 3840 4412 21718 1665 119 164 1406 117 1626 166 153 21678 2137 1110 170 1167 10298 1193 19849 6059 1272 1103 16530 5551 4413 1132 3073 118 1462 119 164 1659 117 1695 166 1135 1144 3388 2199 1111 1157 3209 4316 1107 1103 3549 3187 1104 1339 1204 19365 3773 117 8307 2112 19807 5838 13522 117 170 7681 2704 2215 1105 2211 2616 119 164 1572 117 1512 166 24142 2527 1138 2103 1115 153 21678 2137 1110 1126 3903 1105 2914 3252 1111 149 2137 3048 119 164 1744 117 1765 166 1438 117 2480 153 21678 2137 1110 7298 1106 1168 13467 6665 2606 6241 119 4516 117 1195 3303 1142 27154 118 3622 1106 14133 1103 7300 117 2070 13791 1596 117 1105 13522 1104 153 21678 2137 1105 1168 12814 3377 1111 4420 1114 149 2137 3048 102\n",
      "INFO:tensorflow:input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      "I1208 12:27:37.004957 139883775852736 run_factoid.py:451] input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      "INFO:tensorflow:segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      "I1208 12:27:37.005047 139883775852736 run_factoid.py:453] segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      "INFO:tensorflow:*** Example ***\n",
      "I1208 12:27:37.005853 139883775852736 run_factoid.py:438] *** Example ***\n",
      "INFO:tensorflow:unique_id: 1000000010\n",
      "I1208 12:27:37.005909 139883775852736 run_factoid.py:439] unique_id: 1000000010\n",
      "INFO:tensorflow:example_index: 4\n",
      "I1208 12:27:37.005946 139883775852736 run_factoid.py:440] example_index: 4\n",
      "INFO:tensorflow:doc_span_index: 2\n",
      "I1208 12:27:37.005980 139883775852736 run_factoid.py:441] doc_span_index: 2\n",
      "INFO:tensorflow:tokens: [CLS] What were the new treatment ( s ) this paper looked into ? [SEP] ##os ##cope for visual ##iza - t ##ion , and the para ##sp ##ino ##us muscles are handled by muscle splitting through di ##lator ##s ; [ 18 ] thus , the muscle and soft tissue are minimal ##ly injured . [ 19 ] MI ##S - T ##L ##IF is a well - accepted operation method for re ##current L ##D ##H . And it has the advantages of less i ##at ##rogen ##ic soft tissue injury , lower risk of post ##oper ##ative r ##adi ##cu ##lit ##is , and decreased re ##traction of du ##ral sa ##c . [ 20 , 21 ] P ##EL ##D is a more minimal ##ly invasive surgery because the posterior column structures are pre - served . [ 22 , 23 ] It has gained interest for its potential advantage in the reduced risk of face ##t joints injury , fewer post ##oper ##ative complications , a shorter hospital stay and lower cost . [ 24 , 25 ] Previous studies have reported that P ##EL ##D is an effective and safe treatment for L ##D ##H . [ 26 , 27 ] However , whether P ##EL ##D is superior to other surgical options remains controversial . Thus , we conducted this meta - analysis to compare the clinical , radio ##log ##ic , and complications of P ##EL ##D and other surge ##ries for patients with L ##D ##H . [SEP]\n",
      "I1208 12:27:37.006065 139883775852736 run_factoid.py:443] tokens: [CLS] What were the new treatment ( s ) this paper looked into ? [SEP] ##os ##cope for visual ##iza - t ##ion , and the para ##sp ##ino ##us muscles are handled by muscle splitting through di ##lator ##s ; [ 18 ] thus , the muscle and soft tissue are minimal ##ly injured . [ 19 ] MI ##S - T ##L ##IF is a well - accepted operation method for re ##current L ##D ##H . And it has the advantages of less i ##at ##rogen ##ic soft tissue injury , lower risk of post ##oper ##ative r ##adi ##cu ##lit ##is , and decreased re ##traction of du ##ral sa ##c . [ 20 , 21 ] P ##EL ##D is a more minimal ##ly invasive surgery because the posterior column structures are pre - served . [ 22 , 23 ] It has gained interest for its potential advantage in the reduced risk of face ##t joints injury , fewer post ##oper ##ative complications , a shorter hospital stay and lower cost . [ 24 , 25 ] Previous studies have reported that P ##EL ##D is an effective and safe treatment for L ##D ##H . [ 26 , 27 ] However , whether P ##EL ##D is superior to other surgical options remains controversial . Thus , we conducted this meta - analysis to compare the clinical , radio ##log ##ic , and complications of P ##EL ##D and other surge ##ries for patients with L ##D ##H . [SEP]\n",
      "INFO:tensorflow:token_to_orig_map: 15:128 16:128 17:129 18:130 19:130 20:130 21:131 22:131 23:131 24:132 25:133 26:134 27:134 28:134 29:134 30:135 31:136 32:137 33:138 34:139 35:140 36:141 37:142 38:142 39:142 40:142 41:142 42:142 43:142 44:143 45:143 46:144 47:145 48:146 49:147 50:148 51:149 52:150 53:150 54:151 55:151 56:151 57:151 58:151 59:152 60:152 61:152 62:152 63:152 64:152 65:153 66:154 67:155 68:155 69:155 70:156 71:157 72:158 73:159 74:159 75:160 76:160 77:160 78:160 79:161 80:162 81:163 82:164 83:165 84:166 85:167 86:168 87:168 88:168 89:168 90:169 91:170 92:171 93:171 94:172 95:173 96:174 97:175 98:175 99:175 100:176 101:176 102:176 103:176 104:176 105:176 106:177 107:178 108:179 109:179 110:180 111:181 112:181 113:182 114:182 115:182 116:182 117:182 118:182 119:182 120:182 121:183 122:183 123:183 124:184 125:185 126:186 127:187 128:187 129:188 130:189 131:190 132:191 133:192 134:193 135:194 136:195 137:196 138:196 139:197 140:197 141:197 142:197 143:197 144:197 145:197 146:198 147:199 148:200 149:201 150:202 151:203 152:204 153:205 154:206 155:207 156:208 157:209 158:210 159:211 160:211 161:212 162:213 163:213 164:214 165:215 166:215 167:215 168:216 169:216 170:217 171:218 172:219 173:220 174:221 175:222 176:223 177:223 178:223 179:223 180:223 181:223 182:223 183:224 184:225 185:226 186:227 187:228 188:229 189:229 190:229 191:230 192:231 193:232 194:233 195:234 196:235 197:236 198:237 199:237 200:237 201:237 202:237 203:237 204:237 205:237 206:237 207:238 208:238 209:239 210:240 211:240 212:240 213:241 214:242 215:243 216:244 217:245 218:246 219:247 220:248 221:248 222:249 223:249 224:250 225:251 226:252 227:253 228:253 229:253 230:254 231:255 232:256 233:257 234:257 235:258 236:258 237:258 238:258 239:259 240:260 241:261 242:262 243:262 244:262 245:263 246:264 247:265 248:265 249:266 250:267 251:268 252:269 253:269 254:269 255:269\n",
      "I1208 12:27:37.006151 139883775852736 run_factoid.py:445] token_to_orig_map: 15:128 16:128 17:129 18:130 19:130 20:130 21:131 22:131 23:131 24:132 25:133 26:134 27:134 28:134 29:134 30:135 31:136 32:137 33:138 34:139 35:140 36:141 37:142 38:142 39:142 40:142 41:142 42:142 43:142 44:143 45:143 46:144 47:145 48:146 49:147 50:148 51:149 52:150 53:150 54:151 55:151 56:151 57:151 58:151 59:152 60:152 61:152 62:152 63:152 64:152 65:153 66:154 67:155 68:155 69:155 70:156 71:157 72:158 73:159 74:159 75:160 76:160 77:160 78:160 79:161 80:162 81:163 82:164 83:165 84:166 85:167 86:168 87:168 88:168 89:168 90:169 91:170 92:171 93:171 94:172 95:173 96:174 97:175 98:175 99:175 100:176 101:176 102:176 103:176 104:176 105:176 106:177 107:178 108:179 109:179 110:180 111:181 112:181 113:182 114:182 115:182 116:182 117:182 118:182 119:182 120:182 121:183 122:183 123:183 124:184 125:185 126:186 127:187 128:187 129:188 130:189 131:190 132:191 133:192 134:193 135:194 136:195 137:196 138:196 139:197 140:197 141:197 142:197 143:197 144:197 145:197 146:198 147:199 148:200 149:201 150:202 151:203 152:204 153:205 154:206 155:207 156:208 157:209 158:210 159:211 160:211 161:212 162:213 163:213 164:214 165:215 166:215 167:215 168:216 169:216 170:217 171:218 172:219 173:220 174:221 175:222 176:223 177:223 178:223 179:223 180:223 181:223 182:223 183:224 184:225 185:226 186:227 187:228 188:229 189:229 190:229 191:230 192:231 193:232 194:233 195:234 196:235 197:236 198:237 199:237 200:237 201:237 202:237 203:237 204:237 205:237 206:237 207:238 208:238 209:239 210:240 211:240 212:240 213:241 214:242 215:243 216:244 217:245 218:246 219:247 220:248 221:248 222:249 223:249 224:250 225:251 226:252 227:253 228:253 229:253 230:254 231:255 232:256 233:257 234:257 235:258 236:258 237:258 238:258 239:259 240:260 241:261 242:262 243:262 244:262 245:263 246:264 247:265 248:265 249:266 250:267 251:268 252:269 253:269 254:269 255:269\n",
      "INFO:tensorflow:token_is_max_context: 15:False 16:False 17:False 18:False 19:False 20:False 21:False 22:False 23:False 24:False 25:False 26:False 27:False 28:False 29:False 30:False 31:False 32:False 33:False 34:False 35:False 36:False 37:False 38:False 39:False 40:False 41:False 42:False 43:False 44:False 45:False 46:False 47:False 48:False 49:False 50:False 51:False 52:False 53:False 54:False 55:False 56:False 57:False 58:False 59:False 60:False 61:False 62:False 63:False 64:False 65:False 66:False 67:False 68:False 69:False 70:False 71:False 72:False 73:False 74:False 75:False 76:False 77:False 78:False 79:False 80:False 81:False 82:False 83:False 84:False 85:False 86:False 87:False 88:False 89:False 90:False 91:False 92:False 93:False 94:False 95:False 96:False 97:False 98:False 99:False 100:False 101:False 102:False 103:False 104:False 105:False 106:False 107:False 108:False 109:False 110:False 111:False 112:False 113:False 114:False 115:False 116:False 117:False 118:False 119:False 120:False 121:False 122:False 123:False 124:False 125:False 126:False 127:False 128:False 129:False 130:False 131:False 132:False 133:False 134:False 135:False 136:False 137:False 138:False 139:False 140:False 141:False 142:False 143:False 144:False 145:False 146:False 147:False 148:False 149:False 150:False 151:False 152:False 153:False 154:False 155:False 156:False 157:False 158:False 159:False 160:False 161:False 162:False 163:False 164:False 165:False 166:False 167:False 168:False 169:False 170:False 171:False 172:False 173:False 174:False 175:False 176:False 177:False 178:False 179:False 180:False 181:False 182:False 183:False 184:False 185:False 186:False 187:False 188:False 189:False 190:False 191:False 192:False 193:False 194:False 195:False 196:False 197:False 198:False 199:False 200:False 201:False 202:False 203:False 204:False 205:False 206:False 207:False 208:False 209:False 210:False 211:False 212:False 213:False 214:False 215:False 216:False 217:False 218:False 219:False 220:False 221:False 222:False 223:False 224:False 225:False 226:False 227:False 228:False 229:False 230:False 231:False 232:False 233:False 234:False 235:False 236:False 237:False 238:False 239:False 240:False 241:False 242:False 243:False 244:False 245:False 246:False 247:False 248:False 249:False 250:False 251:False 252:False 253:False 254:False 255:True\n",
      "I1208 12:27:37.006233 139883775852736 run_factoid.py:447] token_is_max_context: 15:False 16:False 17:False 18:False 19:False 20:False 21:False 22:False 23:False 24:False 25:False 26:False 27:False 28:False 29:False 30:False 31:False 32:False 33:False 34:False 35:False 36:False 37:False 38:False 39:False 40:False 41:False 42:False 43:False 44:False 45:False 46:False 47:False 48:False 49:False 50:False 51:False 52:False 53:False 54:False 55:False 56:False 57:False 58:False 59:False 60:False 61:False 62:False 63:False 64:False 65:False 66:False 67:False 68:False 69:False 70:False 71:False 72:False 73:False 74:False 75:False 76:False 77:False 78:False 79:False 80:False 81:False 82:False 83:False 84:False 85:False 86:False 87:False 88:False 89:False 90:False 91:False 92:False 93:False 94:False 95:False 96:False 97:False 98:False 99:False 100:False 101:False 102:False 103:False 104:False 105:False 106:False 107:False 108:False 109:False 110:False 111:False 112:False 113:False 114:False 115:False 116:False 117:False 118:False 119:False 120:False 121:False 122:False 123:False 124:False 125:False 126:False 127:False 128:False 129:False 130:False 131:False 132:False 133:False 134:False 135:False 136:False 137:False 138:False 139:False 140:False 141:False 142:False 143:False 144:False 145:False 146:False 147:False 148:False 149:False 150:False 151:False 152:False 153:False 154:False 155:False 156:False 157:False 158:False 159:False 160:False 161:False 162:False 163:False 164:False 165:False 166:False 167:False 168:False 169:False 170:False 171:False 172:False 173:False 174:False 175:False 176:False 177:False 178:False 179:False 180:False 181:False 182:False 183:False 184:False 185:False 186:False 187:False 188:False 189:False 190:False 191:False 192:False 193:False 194:False 195:False 196:False 197:False 198:False 199:False 200:False 201:False 202:False 203:False 204:False 205:False 206:False 207:False 208:False 209:False 210:False 211:False 212:False 213:False 214:False 215:False 216:False 217:False 218:False 219:False 220:False 221:False 222:False 223:False 224:False 225:False 226:False 227:False 228:False 229:False 230:False 231:False 232:False 233:False 234:False 235:False 236:False 237:False 238:False 239:False 240:False 241:False 242:False 243:False 244:False 245:False 246:False 247:False 248:False 249:False 250:False 251:False 252:False 253:False 254:False 255:True\n",
      "INFO:tensorflow:input_ids: 101 1327 1127 1103 1207 3252 113 188 114 1142 2526 1350 1154 136 102 2155 16260 1111 5173 23228 118 189 1988 117 1105 1103 18311 20080 4559 1361 6130 1132 8630 1118 6484 15601 1194 4267 13389 1116 132 164 1407 166 2456 117 1103 6484 1105 2991 7918 1132 10298 1193 4475 119 164 1627 166 26574 1708 118 157 2162 15499 1110 170 1218 118 3134 2805 3442 1111 1231 21754 149 2137 3048 119 1262 1122 1144 1103 13300 1104 1750 178 2980 26767 1596 2991 7918 3773 117 2211 3187 1104 2112 19807 5838 187 14230 10182 12888 1548 117 1105 10558 1231 27539 1104 3840 4412 21718 1665 119 164 1406 117 1626 166 153 21678 2137 1110 170 1167 10298 1193 19849 6059 1272 1103 16530 5551 4413 1132 3073 118 1462 119 164 1659 117 1695 166 1135 1144 3388 2199 1111 1157 3209 4316 1107 1103 3549 3187 1104 1339 1204 19365 3773 117 8307 2112 19807 5838 13522 117 170 7681 2704 2215 1105 2211 2616 119 164 1572 117 1512 166 24142 2527 1138 2103 1115 153 21678 2137 1110 1126 3903 1105 2914 3252 1111 149 2137 3048 119 164 1744 117 1765 166 1438 117 2480 153 21678 2137 1110 7298 1106 1168 13467 6665 2606 6241 119 4516 117 1195 3303 1142 27154 118 3622 1106 14133 1103 7300 117 2070 13791 1596 117 1105 13522 1104 153 21678 2137 1105 1168 12814 3377 1111 4420 1114 149 2137 3048 119 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "I1208 12:27:37.006328 139883775852736 run_factoid.py:449] input_ids: 101 1327 1127 1103 1207 3252 113 188 114 1142 2526 1350 1154 136 102 2155 16260 1111 5173 23228 118 189 1988 117 1105 1103 18311 20080 4559 1361 6130 1132 8630 1118 6484 15601 1194 4267 13389 1116 132 164 1407 166 2456 117 1103 6484 1105 2991 7918 1132 10298 1193 4475 119 164 1627 166 26574 1708 118 157 2162 15499 1110 170 1218 118 3134 2805 3442 1111 1231 21754 149 2137 3048 119 1262 1122 1144 1103 13300 1104 1750 178 2980 26767 1596 2991 7918 3773 117 2211 3187 1104 2112 19807 5838 187 14230 10182 12888 1548 117 1105 10558 1231 27539 1104 3840 4412 21718 1665 119 164 1406 117 1626 166 153 21678 2137 1110 170 1167 10298 1193 19849 6059 1272 1103 16530 5551 4413 1132 3073 118 1462 119 164 1659 117 1695 166 1135 1144 3388 2199 1111 1157 3209 4316 1107 1103 3549 3187 1104 1339 1204 19365 3773 117 8307 2112 19807 5838 13522 117 170 7681 2704 2215 1105 2211 2616 119 164 1572 117 1512 166 24142 2527 1138 2103 1115 153 21678 2137 1110 1126 3903 1105 2914 3252 1111 149 2137 3048 119 164 1744 117 1765 166 1438 117 2480 153 21678 2137 1110 7298 1106 1168 13467 6665 2606 6241 119 4516 117 1195 3303 1142 27154 118 3622 1106 14133 1103 7300 117 2070 13791 1596 117 1105 13522 1104 153 21678 2137 1105 1168 12814 3377 1111 4420 1114 149 2137 3048 119 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "INFO:tensorflow:input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "I1208 12:27:37.006418 139883775852736 run_factoid.py:451] input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "INFO:tensorflow:segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "I1208 12:27:37.006506 139883775852736 run_factoid.py:453] segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "INFO:tensorflow:*** Example ***\n",
      "I1208 12:27:37.019092 139883775852736 run_factoid.py:438] *** Example ***\n",
      "INFO:tensorflow:unique_id: 1000000011\n",
      "I1208 12:27:37.019167 139883775852736 run_factoid.py:439] unique_id: 1000000011\n",
      "INFO:tensorflow:example_index: 5\n",
      "I1208 12:27:37.019209 139883775852736 run_factoid.py:440] example_index: 5\n",
      "INFO:tensorflow:doc_span_index: 0\n",
      "I1208 12:27:37.019245 139883775852736 run_factoid.py:441] doc_span_index: 0\n",
      "INFO:tensorflow:tokens: [CLS] What did the paper do ? [SEP] We conducted this meta - analysis in compliance with the Pre ##ferred Report ##ing It ##ems for System ##atic Reviews and Met ##a - analysis ( PR ##IS ##MA ) statement guidelines . [ 28 ] Multiple databases , including Pub ##M ##ed , Em ##base , and Web of Science were system ##ati - call ##y searched before February 2018 . The structured search strategies were listed as following ##s : ( ( “ l ##um ##bos ##ac ##ral region ” [ - Me ##S ##H Te ##rms ] OR ( “ l ##um ##bos ##ac ##ral ” [ All Fields ] AND “ region ” [ All Fields ] ) OR “ l ##um ##bos ##ac ##ral region ” [ All Fields ] OR “ l ##umba ##r ” [ All Fields ] ) AND disc [ All Fields ] AND ( “ her ##nia ” [ Me ##S ##H Te ##rms ] OR “ her ##nia ” [ All Fields ] OR “ her ##nia ##tion ” [ All Fields ] ) ) AND ( per ##cu - tan ##eous [ All Fields ] AND ( “ end ##os ##copy ” [ Me ##S ##H Te ##rms ] OR “ end ##os ##copy ” [ All Fields ] OR “ end ##os ##copic ” [ All Fields ] ) AND ( “ l ##um ##bos ##ac ##ral region ” [ Me ##S ##H Te ##rms ] OR ( “ l ##um ##bos ##ac ##ral ” [ All Fields ] AND “ region ” [ All Fields ] ) OR “ l ##um ##bos ##ac ##ral region ” [ All Fields ] OR “ l ##umba ##r ” [ All Fields ] ) AND ( “ disk ##ec ##tom ##y ” [ Me ##S ##H Te ##rms ] OR “ disk ##ec ##tom ##y ” [ All Fields ] OR “ disc ##ec ##tom ##y ” [ All Fields ] ) ) . This search was limited to human subjects , and no language or publication status was imposed . In addition , we also manually searched the reference lists of the included studies and previous review , systematic review and meta - analysis to identify potential studies until no additional articles could [SEP]\n",
      "I1208 12:27:37.019361 139883775852736 run_factoid.py:443] tokens: [CLS] What did the paper do ? [SEP] We conducted this meta - analysis in compliance with the Pre ##ferred Report ##ing It ##ems for System ##atic Reviews and Met ##a - analysis ( PR ##IS ##MA ) statement guidelines . [ 28 ] Multiple databases , including Pub ##M ##ed , Em ##base , and Web of Science were system ##ati - call ##y searched before February 2018 . The structured search strategies were listed as following ##s : ( ( “ l ##um ##bos ##ac ##ral region ” [ - Me ##S ##H Te ##rms ] OR ( “ l ##um ##bos ##ac ##ral ” [ All Fields ] AND “ region ” [ All Fields ] ) OR “ l ##um ##bos ##ac ##ral region ” [ All Fields ] OR “ l ##umba ##r ” [ All Fields ] ) AND disc [ All Fields ] AND ( “ her ##nia ” [ Me ##S ##H Te ##rms ] OR “ her ##nia ” [ All Fields ] OR “ her ##nia ##tion ” [ All Fields ] ) ) AND ( per ##cu - tan ##eous [ All Fields ] AND ( “ end ##os ##copy ” [ Me ##S ##H Te ##rms ] OR “ end ##os ##copy ” [ All Fields ] OR “ end ##os ##copic ” [ All Fields ] ) AND ( “ l ##um ##bos ##ac ##ral region ” [ Me ##S ##H Te ##rms ] OR ( “ l ##um ##bos ##ac ##ral ” [ All Fields ] AND “ region ” [ All Fields ] ) OR “ l ##um ##bos ##ac ##ral region ” [ All Fields ] OR “ l ##umba ##r ” [ All Fields ] ) AND ( “ disk ##ec ##tom ##y ” [ Me ##S ##H Te ##rms ] OR “ disk ##ec ##tom ##y ” [ All Fields ] OR “ disc ##ec ##tom ##y ” [ All Fields ] ) ) . This search was limited to human subjects , and no language or publication status was imposed . In addition , we also manually searched the reference lists of the included studies and previous review , systematic review and meta - analysis to identify potential studies until no additional articles could [SEP]\n",
      "INFO:tensorflow:token_to_orig_map: 8:0 9:1 10:2 11:3 12:3 13:3 14:4 15:5 16:6 17:7 18:8 19:8 20:9 21:9 22:10 23:10 24:11 25:12 26:12 27:13 28:14 29:15 30:15 31:15 32:16 33:17 34:17 35:17 36:17 37:17 38:18 39:19 40:19 41:19 42:19 43:19 44:20 45:21 46:21 47:22 48:23 49:23 50:23 51:23 52:24 53:24 54:24 55:25 56:26 57:27 58:28 59:29 60:30 61:30 62:30 63:31 64:31 65:32 66:33 67:34 68:35 69:35 70:36 71:37 72:38 73:39 74:40 75:41 76:42 77:43 78:43 79:43 80:44 81:44 82:44 83:44 84:44 85:44 86:44 87:44 88:45 89:45 90:45 91:45 92:46 93:46 94:46 95:47 96:47 97:47 98:48 99:49 100:49 101:49 102:49 103:49 104:49 105:49 106:49 107:49 108:49 109:50 110:50 111:51 112:52 113:52 114:52 115:52 116:52 117:53 118:53 119:53 120:54 121:55 122:55 123:55 124:55 125:55 126:55 127:56 128:56 129:56 130:56 131:57 132:57 133:58 134:59 135:59 136:59 137:59 138:59 139:59 140:59 141:60 142:60 143:60 144:61 145:62 146:62 147:62 148:63 149:63 150:64 151:65 152:65 153:65 154:65 155:65 156:65 157:65 158:65 159:65 160:66 161:66 162:66 163:67 164:68 165:68 166:68 167:68 168:68 169:68 170:69 171:69 172:70 173:71 174:71 175:71 176:71 177:71 178:71 179:71 180:72 181:72 182:72 183:72 184:73 185:74 186:74 187:74 188:74 189:75 190:75 191:75 192:75 193:76 194:76 195:77 196:78 197:78 198:78 199:78 200:78 201:78 202:78 203:78 204:78 205:78 206:79 207:79 208:79 209:80 210:81 211:81 212:81 213:81 214:81 215:81 216:81 217:82 218:82 219:83 220:84 221:84 222:84 223:84 224:84 225:84 226:84 227:85 228:85 229:85 230:86 231:87 232:87 233:87 234:87 235:87 236:87 237:87 238:88 239:88 240:88 241:88 242:88 243:88 244:89 245:89 246:89 247:90 248:91 249:91 250:91 251:91 252:91 253:91 254:91 255:91 256:91 257:91 258:92 259:92 260:93 261:94 262:94 263:94 264:94 265:94 266:95 267:95 268:95 269:96 270:97 271:97 272:97 273:97 274:97 275:97 276:98 277:98 278:98 279:98 280:99 281:99 282:100 283:101 284:101 285:101 286:101 287:101 288:101 289:101 290:102 291:102 292:102 293:103 294:104 295:104 296:104 297:104 298:104 299:104 300:104 301:104 302:104 303:104 304:104 305:105 306:105 307:105 308:106 309:107 310:107 311:107 312:107 313:107 314:107 315:107 316:107 317:108 318:108 319:109 320:110 321:110 322:110 323:110 324:110 325:110 326:110 327:110 328:111 329:111 330:111 331:111 332:111 333:112 334:113 335:114 336:115 337:116 338:117 339:118 340:118 341:119 342:120 343:121 344:122 345:123 346:124 347:125 348:126 349:126 350:127 351:128 352:128 353:129 354:130 355:131 356:132 357:133 358:134 359:135 360:136 361:137 362:138 363:139 364:140 365:141 366:142 367:142 368:143 369:144 370:145 371:146 372:146 373:146 374:147 375:148 376:149 377:150 378:151 379:152 380:153 381:154 382:155\n",
      "I1208 12:27:37.019479 139883775852736 run_factoid.py:445] token_to_orig_map: 8:0 9:1 10:2 11:3 12:3 13:3 14:4 15:5 16:6 17:7 18:8 19:8 20:9 21:9 22:10 23:10 24:11 25:12 26:12 27:13 28:14 29:15 30:15 31:15 32:16 33:17 34:17 35:17 36:17 37:17 38:18 39:19 40:19 41:19 42:19 43:19 44:20 45:21 46:21 47:22 48:23 49:23 50:23 51:23 52:24 53:24 54:24 55:25 56:26 57:27 58:28 59:29 60:30 61:30 62:30 63:31 64:31 65:32 66:33 67:34 68:35 69:35 70:36 71:37 72:38 73:39 74:40 75:41 76:42 77:43 78:43 79:43 80:44 81:44 82:44 83:44 84:44 85:44 86:44 87:44 88:45 89:45 90:45 91:45 92:46 93:46 94:46 95:47 96:47 97:47 98:48 99:49 100:49 101:49 102:49 103:49 104:49 105:49 106:49 107:49 108:49 109:50 110:50 111:51 112:52 113:52 114:52 115:52 116:52 117:53 118:53 119:53 120:54 121:55 122:55 123:55 124:55 125:55 126:55 127:56 128:56 129:56 130:56 131:57 132:57 133:58 134:59 135:59 136:59 137:59 138:59 139:59 140:59 141:60 142:60 143:60 144:61 145:62 146:62 147:62 148:63 149:63 150:64 151:65 152:65 153:65 154:65 155:65 156:65 157:65 158:65 159:65 160:66 161:66 162:66 163:67 164:68 165:68 166:68 167:68 168:68 169:68 170:69 171:69 172:70 173:71 174:71 175:71 176:71 177:71 178:71 179:71 180:72 181:72 182:72 183:72 184:73 185:74 186:74 187:74 188:74 189:75 190:75 191:75 192:75 193:76 194:76 195:77 196:78 197:78 198:78 199:78 200:78 201:78 202:78 203:78 204:78 205:78 206:79 207:79 208:79 209:80 210:81 211:81 212:81 213:81 214:81 215:81 216:81 217:82 218:82 219:83 220:84 221:84 222:84 223:84 224:84 225:84 226:84 227:85 228:85 229:85 230:86 231:87 232:87 233:87 234:87 235:87 236:87 237:87 238:88 239:88 240:88 241:88 242:88 243:88 244:89 245:89 246:89 247:90 248:91 249:91 250:91 251:91 252:91 253:91 254:91 255:91 256:91 257:91 258:92 259:92 260:93 261:94 262:94 263:94 264:94 265:94 266:95 267:95 268:95 269:96 270:97 271:97 272:97 273:97 274:97 275:97 276:98 277:98 278:98 279:98 280:99 281:99 282:100 283:101 284:101 285:101 286:101 287:101 288:101 289:101 290:102 291:102 292:102 293:103 294:104 295:104 296:104 297:104 298:104 299:104 300:104 301:104 302:104 303:104 304:104 305:105 306:105 307:105 308:106 309:107 310:107 311:107 312:107 313:107 314:107 315:107 316:107 317:108 318:108 319:109 320:110 321:110 322:110 323:110 324:110 325:110 326:110 327:110 328:111 329:111 330:111 331:111 332:111 333:112 334:113 335:114 336:115 337:116 338:117 339:118 340:118 341:119 342:120 343:121 344:122 345:123 346:124 347:125 348:126 349:126 350:127 351:128 352:128 353:129 354:130 355:131 356:132 357:133 358:134 359:135 360:136 361:137 362:138 363:139 364:140 365:141 366:142 367:142 368:143 369:144 370:145 371:146 372:146 373:146 374:147 375:148 376:149 377:150 378:151 379:152 380:153 381:154 382:155\n",
      "INFO:tensorflow:token_is_max_context: 8:True 9:True 10:True 11:True 12:True 13:True 14:True 15:True 16:True 17:True 18:True 19:True 20:True 21:True 22:True 23:True 24:True 25:True 26:True 27:True 28:True 29:True 30:True 31:True 32:True 33:True 34:True 35:True 36:True 37:True 38:True 39:True 40:True 41:True 42:True 43:True 44:True 45:True 46:True 47:True 48:True 49:True 50:True 51:True 52:True 53:True 54:True 55:True 56:True 57:True 58:True 59:True 60:True 61:True 62:True 63:True 64:True 65:True 66:True 67:True 68:True 69:True 70:True 71:True 72:True 73:True 74:True 75:True 76:True 77:True 78:True 79:True 80:True 81:True 82:True 83:True 84:True 85:True 86:True 87:True 88:True 89:True 90:True 91:True 92:True 93:True 94:True 95:True 96:True 97:True 98:True 99:True 100:True 101:True 102:True 103:True 104:True 105:True 106:True 107:True 108:True 109:True 110:True 111:True 112:True 113:True 114:True 115:True 116:True 117:True 118:True 119:True 120:True 121:True 122:True 123:True 124:True 125:True 126:True 127:True 128:True 129:True 130:True 131:True 132:True 133:True 134:True 135:True 136:True 137:True 138:True 139:True 140:True 141:True 142:True 143:True 144:True 145:True 146:True 147:True 148:True 149:True 150:True 151:True 152:True 153:True 154:True 155:True 156:True 157:True 158:True 159:True 160:True 161:True 162:True 163:True 164:True 165:True 166:True 167:True 168:True 169:True 170:True 171:True 172:True 173:True 174:True 175:True 176:True 177:True 178:True 179:True 180:True 181:True 182:True 183:True 184:True 185:True 186:True 187:True 188:True 189:True 190:True 191:True 192:True 193:True 194:True 195:True 196:True 197:True 198:True 199:True 200:True 201:True 202:True 203:True 204:True 205:True 206:True 207:True 208:True 209:True 210:True 211:True 212:True 213:True 214:True 215:True 216:True 217:True 218:True 219:True 220:True 221:True 222:True 223:True 224:True 225:True 226:True 227:True 228:True 229:True 230:True 231:True 232:True 233:True 234:True 235:True 236:True 237:True 238:True 239:True 240:True 241:True 242:True 243:True 244:True 245:True 246:True 247:True 248:True 249:True 250:True 251:True 252:True 253:True 254:True 255:True 256:True 257:True 258:True 259:True 260:False 261:False 262:False 263:False 264:False 265:False 266:False 267:False 268:False 269:False 270:False 271:False 272:False 273:False 274:False 275:False 276:False 277:False 278:False 279:False 280:False 281:False 282:False 283:False 284:False 285:False 286:False 287:False 288:False 289:False 290:False 291:False 292:False 293:False 294:False 295:False 296:False 297:False 298:False 299:False 300:False 301:False 302:False 303:False 304:False 305:False 306:False 307:False 308:False 309:False 310:False 311:False 312:False 313:False 314:False 315:False 316:False 317:False 318:False 319:False 320:False 321:False 322:False 323:False 324:False 325:False 326:False 327:False 328:False 329:False 330:False 331:False 332:False 333:False 334:False 335:False 336:False 337:False 338:False 339:False 340:False 341:False 342:False 343:False 344:False 345:False 346:False 347:False 348:False 349:False 350:False 351:False 352:False 353:False 354:False 355:False 356:False 357:False 358:False 359:False 360:False 361:False 362:False 363:False 364:False 365:False 366:False 367:False 368:False 369:False 370:False 371:False 372:False 373:False 374:False 375:False 376:False 377:False 378:False 379:False 380:False 381:False 382:False\n",
      "I1208 12:27:37.019589 139883775852736 run_factoid.py:447] token_is_max_context: 8:True 9:True 10:True 11:True 12:True 13:True 14:True 15:True 16:True 17:True 18:True 19:True 20:True 21:True 22:True 23:True 24:True 25:True 26:True 27:True 28:True 29:True 30:True 31:True 32:True 33:True 34:True 35:True 36:True 37:True 38:True 39:True 40:True 41:True 42:True 43:True 44:True 45:True 46:True 47:True 48:True 49:True 50:True 51:True 52:True 53:True 54:True 55:True 56:True 57:True 58:True 59:True 60:True 61:True 62:True 63:True 64:True 65:True 66:True 67:True 68:True 69:True 70:True 71:True 72:True 73:True 74:True 75:True 76:True 77:True 78:True 79:True 80:True 81:True 82:True 83:True 84:True 85:True 86:True 87:True 88:True 89:True 90:True 91:True 92:True 93:True 94:True 95:True 96:True 97:True 98:True 99:True 100:True 101:True 102:True 103:True 104:True 105:True 106:True 107:True 108:True 109:True 110:True 111:True 112:True 113:True 114:True 115:True 116:True 117:True 118:True 119:True 120:True 121:True 122:True 123:True 124:True 125:True 126:True 127:True 128:True 129:True 130:True 131:True 132:True 133:True 134:True 135:True 136:True 137:True 138:True 139:True 140:True 141:True 142:True 143:True 144:True 145:True 146:True 147:True 148:True 149:True 150:True 151:True 152:True 153:True 154:True 155:True 156:True 157:True 158:True 159:True 160:True 161:True 162:True 163:True 164:True 165:True 166:True 167:True 168:True 169:True 170:True 171:True 172:True 173:True 174:True 175:True 176:True 177:True 178:True 179:True 180:True 181:True 182:True 183:True 184:True 185:True 186:True 187:True 188:True 189:True 190:True 191:True 192:True 193:True 194:True 195:True 196:True 197:True 198:True 199:True 200:True 201:True 202:True 203:True 204:True 205:True 206:True 207:True 208:True 209:True 210:True 211:True 212:True 213:True 214:True 215:True 216:True 217:True 218:True 219:True 220:True 221:True 222:True 223:True 224:True 225:True 226:True 227:True 228:True 229:True 230:True 231:True 232:True 233:True 234:True 235:True 236:True 237:True 238:True 239:True 240:True 241:True 242:True 243:True 244:True 245:True 246:True 247:True 248:True 249:True 250:True 251:True 252:True 253:True 254:True 255:True 256:True 257:True 258:True 259:True 260:False 261:False 262:False 263:False 264:False 265:False 266:False 267:False 268:False 269:False 270:False 271:False 272:False 273:False 274:False 275:False 276:False 277:False 278:False 279:False 280:False 281:False 282:False 283:False 284:False 285:False 286:False 287:False 288:False 289:False 290:False 291:False 292:False 293:False 294:False 295:False 296:False 297:False 298:False 299:False 300:False 301:False 302:False 303:False 304:False 305:False 306:False 307:False 308:False 309:False 310:False 311:False 312:False 313:False 314:False 315:False 316:False 317:False 318:False 319:False 320:False 321:False 322:False 323:False 324:False 325:False 326:False 327:False 328:False 329:False 330:False 331:False 332:False 333:False 334:False 335:False 336:False 337:False 338:False 339:False 340:False 341:False 342:False 343:False 344:False 345:False 346:False 347:False 348:False 349:False 350:False 351:False 352:False 353:False 354:False 355:False 356:False 357:False 358:False 359:False 360:False 361:False 362:False 363:False 364:False 365:False 366:False 367:False 368:False 369:False 370:False 371:False 372:False 373:False 374:False 375:False 376:False 377:False 378:False 379:False 380:False 381:False 382:False\n",
      "INFO:tensorflow:input_ids: 101 1327 1225 1103 2526 1202 136 102 1284 3303 1142 27154 118 3622 1107 14037 1114 1103 11689 26025 7178 1158 1135 14587 1111 3910 7698 20321 1105 19415 1161 118 3622 113 11629 6258 8271 114 4195 13112 119 164 1743 166 17476 19908 117 1259 21385 2107 1174 117 18653 14017 117 1105 9059 1104 2444 1127 1449 11745 118 1840 1183 8703 1196 1428 1857 119 1109 15695 3403 10700 1127 2345 1112 1378 1116 131 113 113 789 181 1818 18071 7409 4412 1805 790 164 118 2508 1708 3048 12008 19995 166 23066 113 789 181 1818 18071 7409 4412 790 164 1398 11628 166 16716 789 1805 790 164 1398 11628 166 114 23066 789 181 1818 18071 7409 4412 1805 790 164 1398 11628 166 23066 789 181 25509 1197 790 164 1398 11628 166 114 16716 6187 164 1398 11628 166 16716 113 789 1123 5813 790 164 2508 1708 3048 12008 19995 166 23066 789 1123 5813 790 164 1398 11628 166 23066 789 1123 5813 2116 790 164 1398 11628 166 114 114 16716 113 1679 10182 118 15925 13169 164 1398 11628 166 16716 113 789 1322 2155 20739 790 164 2508 1708 3048 12008 19995 166 23066 789 1322 2155 20739 790 164 1398 11628 166 23066 789 1322 2155 22258 790 164 1398 11628 166 114 16716 113 789 181 1818 18071 7409 4412 1805 790 164 2508 1708 3048 12008 19995 166 23066 113 789 181 1818 18071 7409 4412 790 164 1398 11628 166 16716 789 1805 790 164 1398 11628 166 114 23066 789 181 1818 18071 7409 4412 1805 790 164 1398 11628 166 23066 789 181 25509 1197 790 164 1398 11628 166 114 16716 113 789 10437 10294 18778 1183 790 164 2508 1708 3048 12008 19995 166 23066 789 10437 10294 18778 1183 790 164 1398 11628 166 23066 789 6187 10294 18778 1183 790 164 1398 11628 166 114 114 119 1188 3403 1108 2609 1106 1769 5174 117 1105 1185 1846 1137 4128 2781 1108 9520 119 1130 1901 117 1195 1145 23465 8703 1103 3835 6802 1104 1103 1529 2527 1105 2166 3189 117 12818 3189 1105 27154 118 3622 1106 6183 3209 2527 1235 1185 2509 4237 1180 102\n",
      "I1208 12:27:37.019696 139883775852736 run_factoid.py:449] input_ids: 101 1327 1225 1103 2526 1202 136 102 1284 3303 1142 27154 118 3622 1107 14037 1114 1103 11689 26025 7178 1158 1135 14587 1111 3910 7698 20321 1105 19415 1161 118 3622 113 11629 6258 8271 114 4195 13112 119 164 1743 166 17476 19908 117 1259 21385 2107 1174 117 18653 14017 117 1105 9059 1104 2444 1127 1449 11745 118 1840 1183 8703 1196 1428 1857 119 1109 15695 3403 10700 1127 2345 1112 1378 1116 131 113 113 789 181 1818 18071 7409 4412 1805 790 164 118 2508 1708 3048 12008 19995 166 23066 113 789 181 1818 18071 7409 4412 790 164 1398 11628 166 16716 789 1805 790 164 1398 11628 166 114 23066 789 181 1818 18071 7409 4412 1805 790 164 1398 11628 166 23066 789 181 25509 1197 790 164 1398 11628 166 114 16716 6187 164 1398 11628 166 16716 113 789 1123 5813 790 164 2508 1708 3048 12008 19995 166 23066 789 1123 5813 790 164 1398 11628 166 23066 789 1123 5813 2116 790 164 1398 11628 166 114 114 16716 113 1679 10182 118 15925 13169 164 1398 11628 166 16716 113 789 1322 2155 20739 790 164 2508 1708 3048 12008 19995 166 23066 789 1322 2155 20739 790 164 1398 11628 166 23066 789 1322 2155 22258 790 164 1398 11628 166 114 16716 113 789 181 1818 18071 7409 4412 1805 790 164 2508 1708 3048 12008 19995 166 23066 113 789 181 1818 18071 7409 4412 790 164 1398 11628 166 16716 789 1805 790 164 1398 11628 166 114 23066 789 181 1818 18071 7409 4412 1805 790 164 1398 11628 166 23066 789 181 25509 1197 790 164 1398 11628 166 114 16716 113 789 10437 10294 18778 1183 790 164 2508 1708 3048 12008 19995 166 23066 789 10437 10294 18778 1183 790 164 1398 11628 166 23066 789 6187 10294 18778 1183 790 164 1398 11628 166 114 114 119 1188 3403 1108 2609 1106 1769 5174 117 1105 1185 1846 1137 4128 2781 1108 9520 119 1130 1901 117 1195 1145 23465 8703 1103 3835 6802 1104 1103 1529 2527 1105 2166 3189 117 12818 3189 1105 27154 118 3622 1106 6183 3209 2527 1235 1185 2509 4237 1180 102\n",
      "INFO:tensorflow:input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      "I1208 12:27:37.019788 139883775852736 run_factoid.py:451] input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      "INFO:tensorflow:segment_ids: 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      "I1208 12:27:37.019878 139883775852736 run_factoid.py:453] segment_ids: 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      "INFO:tensorflow:*** Example ***\n",
      "I1208 12:27:37.021319 139883775852736 run_factoid.py:438] *** Example ***\n",
      "INFO:tensorflow:unique_id: 1000000012\n",
      "I1208 12:27:37.021380 139883775852736 run_factoid.py:439] unique_id: 1000000012\n",
      "INFO:tensorflow:example_index: 5\n",
      "I1208 12:27:37.021418 139883775852736 run_factoid.py:440] example_index: 5\n",
      "INFO:tensorflow:doc_span_index: 1\n",
      "I1208 12:27:37.021452 139883775852736 run_factoid.py:441] doc_span_index: 1\n",
      "INFO:tensorflow:tokens: [CLS] What did the paper do ? [SEP] ##umba ##r ” [ All Fields ] ) AND disc [ All Fields ] AND ( “ her ##nia ” [ Me ##S ##H Te ##rms ] OR “ her ##nia ” [ All Fields ] OR “ her ##nia ##tion ” [ All Fields ] ) ) AND ( per ##cu - tan ##eous [ All Fields ] AND ( “ end ##os ##copy ” [ Me ##S ##H Te ##rms ] OR “ end ##os ##copy ” [ All Fields ] OR “ end ##os ##copic ” [ All Fields ] ) AND ( “ l ##um ##bos ##ac ##ral region ” [ Me ##S ##H Te ##rms ] OR ( “ l ##um ##bos ##ac ##ral ” [ All Fields ] AND “ region ” [ All Fields ] ) OR “ l ##um ##bos ##ac ##ral region ” [ All Fields ] OR “ l ##umba ##r ” [ All Fields ] ) AND ( “ disk ##ec ##tom ##y ” [ Me ##S ##H Te ##rms ] OR “ disk ##ec ##tom ##y ” [ All Fields ] OR “ disc ##ec ##tom ##y ” [ All Fields ] ) ) . This search was limited to human subjects , and no language or publication status was imposed . In addition , we also manually searched the reference lists of the included studies and previous review , systematic review and meta - analysis to identify potential studies until no additional articles could be found . The inclusion criteria were as follows : . ( 1 ) study design : random ##ized control trial ( RC ##T ) , co ##hor ##t study , or case - control study ; ( 2 ) population : patients who were diagnosed with L ##D ##H ( 3 ) intervention : P ##EL ##D ; ( 4 ) comparison : other surgical approaches ; ( 5 ) outcome measures : one of the following ##s : success rate , re ##cu ##rrence rate , com ##plication rate , operation time , hospital stay , blood loss , visual analog scale ( VA ##S ) score for back pain and leg pain , 12 - item Short Form Health Survey ( SF ##12 ) physical [SEP]\n",
      "I1208 12:27:37.021567 139883775852736 run_factoid.py:443] tokens: [CLS] What did the paper do ? [SEP] ##umba ##r ” [ All Fields ] ) AND disc [ All Fields ] AND ( “ her ##nia ” [ Me ##S ##H Te ##rms ] OR “ her ##nia ” [ All Fields ] OR “ her ##nia ##tion ” [ All Fields ] ) ) AND ( per ##cu - tan ##eous [ All Fields ] AND ( “ end ##os ##copy ” [ Me ##S ##H Te ##rms ] OR “ end ##os ##copy ” [ All Fields ] OR “ end ##os ##copic ” [ All Fields ] ) AND ( “ l ##um ##bos ##ac ##ral region ” [ Me ##S ##H Te ##rms ] OR ( “ l ##um ##bos ##ac ##ral ” [ All Fields ] AND “ region ” [ All Fields ] ) OR “ l ##um ##bos ##ac ##ral region ” [ All Fields ] OR “ l ##umba ##r ” [ All Fields ] ) AND ( “ disk ##ec ##tom ##y ” [ Me ##S ##H Te ##rms ] OR “ disk ##ec ##tom ##y ” [ All Fields ] OR “ disc ##ec ##tom ##y ” [ All Fields ] ) ) . This search was limited to human subjects , and no language or publication status was imposed . In addition , we also manually searched the reference lists of the included studies and previous review , systematic review and meta - analysis to identify potential studies until no additional articles could be found . The inclusion criteria were as follows : . ( 1 ) study design : random ##ized control trial ( RC ##T ) , co ##hor ##t study , or case - control study ; ( 2 ) population : patients who were diagnosed with L ##D ##H ( 3 ) intervention : P ##EL ##D ; ( 4 ) comparison : other surgical approaches ; ( 5 ) outcome measures : one of the following ##s : success rate , re ##cu ##rrence rate , com ##plication rate , operation time , hospital stay , blood loss , visual analog scale ( VA ##S ) score for back pain and leg pain , 12 - item Short Form Health Survey ( SF ##12 ) physical [SEP]\n",
      "INFO:tensorflow:token_to_orig_map: 8:59 9:59 10:59 11:59 12:59 13:60 14:60 15:60 16:61 17:62 18:62 19:62 20:63 21:63 22:64 23:65 24:65 25:65 26:65 27:65 28:65 29:65 30:65 31:65 32:66 33:66 34:66 35:67 36:68 37:68 38:68 39:68 40:68 41:68 42:69 43:69 44:70 45:71 46:71 47:71 48:71 49:71 50:71 51:71 52:72 53:72 54:72 55:72 56:73 57:74 58:74 59:74 60:74 61:75 62:75 63:75 64:75 65:76 66:76 67:77 68:78 69:78 70:78 71:78 72:78 73:78 74:78 75:78 76:78 77:78 78:79 79:79 80:79 81:80 82:81 83:81 84:81 85:81 86:81 87:81 88:81 89:82 90:82 91:83 92:84 93:84 94:84 95:84 96:84 97:84 98:84 99:85 100:85 101:85 102:86 103:87 104:87 105:87 106:87 107:87 108:87 109:87 110:88 111:88 112:88 113:88 114:88 115:88 116:89 117:89 118:89 119:90 120:91 121:91 122:91 123:91 124:91 125:91 126:91 127:91 128:91 129:91 130:92 131:92 132:93 133:94 134:94 135:94 136:94 137:94 138:95 139:95 140:95 141:96 142:97 143:97 144:97 145:97 146:97 147:97 148:98 149:98 150:98 151:98 152:99 153:99 154:100 155:101 156:101 157:101 158:101 159:101 160:101 161:101 162:102 163:102 164:102 165:103 166:104 167:104 168:104 169:104 170:104 171:104 172:104 173:104 174:104 175:104 176:104 177:105 178:105 179:105 180:106 181:107 182:107 183:107 184:107 185:107 186:107 187:107 188:107 189:108 190:108 191:109 192:110 193:110 194:110 195:110 196:110 197:110 198:110 199:110 200:111 201:111 202:111 203:111 204:111 205:112 206:113 207:114 208:115 209:116 210:117 211:118 212:118 213:119 214:120 215:121 216:122 217:123 218:124 219:125 220:126 221:126 222:127 223:128 224:128 225:129 226:130 227:131 228:132 229:133 230:134 231:135 232:136 233:137 234:138 235:139 236:140 237:141 238:142 239:142 240:143 241:144 242:145 243:146 244:146 245:146 246:147 247:148 248:149 249:150 250:151 251:152 252:153 253:154 254:155 255:156 256:157 257:157 258:158 259:159 260:160 261:161 262:162 263:163 264:163 265:164 266:165 267:165 268:165 269:166 270:167 271:167 272:168 273:168 274:169 275:170 276:171 277:171 278:171 279:171 280:171 281:172 282:172 283:172 284:173 285:173 286:174 287:175 288:175 289:175 290:176 291:176 292:177 293:177 294:177 295:178 296:178 297:179 298:180 299:181 300:182 301:183 302:184 303:184 304:184 305:185 306:185 307:185 308:186 309:186 310:187 311:187 312:187 313:187 314:188 315:188 316:188 317:189 318:189 319:190 320:191 321:192 322:192 323:193 324:193 325:193 326:194 327:195 328:195 329:196 330:197 331:198 332:199 333:199 334:199 335:200 336:201 337:201 338:202 339:202 340:202 341:203 342:203 343:204 344:204 345:205 346:205 347:206 348:207 349:207 350:208 351:209 352:209 353:210 354:211 355:211 356:212 357:213 358:214 359:215 360:215 361:215 362:215 363:216 364:217 365:218 366:219 367:220 368:221 369:222 370:222 371:223 372:223 373:223 374:224 375:225 376:226 377:227 378:228 379:228 380:228 381:228 382:229\n",
      "I1208 12:27:37.021686 139883775852736 run_factoid.py:445] token_to_orig_map: 8:59 9:59 10:59 11:59 12:59 13:60 14:60 15:60 16:61 17:62 18:62 19:62 20:63 21:63 22:64 23:65 24:65 25:65 26:65 27:65 28:65 29:65 30:65 31:65 32:66 33:66 34:66 35:67 36:68 37:68 38:68 39:68 40:68 41:68 42:69 43:69 44:70 45:71 46:71 47:71 48:71 49:71 50:71 51:71 52:72 53:72 54:72 55:72 56:73 57:74 58:74 59:74 60:74 61:75 62:75 63:75 64:75 65:76 66:76 67:77 68:78 69:78 70:78 71:78 72:78 73:78 74:78 75:78 76:78 77:78 78:79 79:79 80:79 81:80 82:81 83:81 84:81 85:81 86:81 87:81 88:81 89:82 90:82 91:83 92:84 93:84 94:84 95:84 96:84 97:84 98:84 99:85 100:85 101:85 102:86 103:87 104:87 105:87 106:87 107:87 108:87 109:87 110:88 111:88 112:88 113:88 114:88 115:88 116:89 117:89 118:89 119:90 120:91 121:91 122:91 123:91 124:91 125:91 126:91 127:91 128:91 129:91 130:92 131:92 132:93 133:94 134:94 135:94 136:94 137:94 138:95 139:95 140:95 141:96 142:97 143:97 144:97 145:97 146:97 147:97 148:98 149:98 150:98 151:98 152:99 153:99 154:100 155:101 156:101 157:101 158:101 159:101 160:101 161:101 162:102 163:102 164:102 165:103 166:104 167:104 168:104 169:104 170:104 171:104 172:104 173:104 174:104 175:104 176:104 177:105 178:105 179:105 180:106 181:107 182:107 183:107 184:107 185:107 186:107 187:107 188:107 189:108 190:108 191:109 192:110 193:110 194:110 195:110 196:110 197:110 198:110 199:110 200:111 201:111 202:111 203:111 204:111 205:112 206:113 207:114 208:115 209:116 210:117 211:118 212:118 213:119 214:120 215:121 216:122 217:123 218:124 219:125 220:126 221:126 222:127 223:128 224:128 225:129 226:130 227:131 228:132 229:133 230:134 231:135 232:136 233:137 234:138 235:139 236:140 237:141 238:142 239:142 240:143 241:144 242:145 243:146 244:146 245:146 246:147 247:148 248:149 249:150 250:151 251:152 252:153 253:154 254:155 255:156 256:157 257:157 258:158 259:159 260:160 261:161 262:162 263:163 264:163 265:164 266:165 267:165 268:165 269:166 270:167 271:167 272:168 273:168 274:169 275:170 276:171 277:171 278:171 279:171 280:171 281:172 282:172 283:172 284:173 285:173 286:174 287:175 288:175 289:175 290:176 291:176 292:177 293:177 294:177 295:178 296:178 297:179 298:180 299:181 300:182 301:183 302:184 303:184 304:184 305:185 306:185 307:185 308:186 309:186 310:187 311:187 312:187 313:187 314:188 315:188 316:188 317:189 318:189 319:190 320:191 321:192 322:192 323:193 324:193 325:193 326:194 327:195 328:195 329:196 330:197 331:198 332:199 333:199 334:199 335:200 336:201 337:201 338:202 339:202 340:202 341:203 342:203 343:204 344:204 345:205 346:205 347:206 348:207 349:207 350:208 351:209 352:209 353:210 354:211 355:211 356:212 357:213 358:214 359:215 360:215 361:215 362:215 363:216 364:217 365:218 366:219 367:220 368:221 369:222 370:222 371:223 372:223 373:223 374:224 375:225 376:226 377:227 378:228 379:228 380:228 381:228 382:229\n",
      "INFO:tensorflow:token_is_max_context: 8:False 9:False 10:False 11:False 12:False 13:False 14:False 15:False 16:False 17:False 18:False 19:False 20:False 21:False 22:False 23:False 24:False 25:False 26:False 27:False 28:False 29:False 30:False 31:False 32:False 33:False 34:False 35:False 36:False 37:False 38:False 39:False 40:False 41:False 42:False 43:False 44:False 45:False 46:False 47:False 48:False 49:False 50:False 51:False 52:False 53:False 54:False 55:False 56:False 57:False 58:False 59:False 60:False 61:False 62:False 63:False 64:False 65:False 66:False 67:False 68:False 69:False 70:False 71:False 72:False 73:False 74:False 75:False 76:False 77:False 78:False 79:False 80:False 81:False 82:False 83:False 84:False 85:False 86:False 87:False 88:False 89:False 90:False 91:False 92:False 93:False 94:False 95:False 96:False 97:False 98:False 99:False 100:False 101:False 102:False 103:False 104:False 105:False 106:False 107:False 108:False 109:False 110:False 111:False 112:False 113:False 114:False 115:False 116:False 117:False 118:False 119:False 120:False 121:False 122:False 123:False 124:False 125:False 126:False 127:False 128:False 129:False 130:False 131:False 132:True 133:True 134:True 135:True 136:True 137:True 138:True 139:True 140:True 141:True 142:True 143:True 144:True 145:True 146:True 147:True 148:True 149:True 150:True 151:True 152:True 153:True 154:True 155:True 156:True 157:True 158:True 159:True 160:True 161:True 162:True 163:True 164:True 165:True 166:True 167:True 168:True 169:True 170:True 171:True 172:True 173:True 174:True 175:True 176:True 177:True 178:True 179:True 180:True 181:True 182:True 183:True 184:True 185:True 186:True 187:True 188:True 189:True 190:True 191:True 192:True 193:True 194:True 195:True 196:True 197:True 198:True 199:True 200:True 201:True 202:True 203:True 204:True 205:True 206:True 207:True 208:True 209:True 210:True 211:True 212:True 213:True 214:True 215:True 216:True 217:True 218:True 219:True 220:True 221:True 222:True 223:True 224:True 225:True 226:True 227:True 228:True 229:True 230:True 231:True 232:True 233:True 234:True 235:True 236:True 237:True 238:True 239:True 240:True 241:True 242:True 243:True 244:True 245:True 246:True 247:True 248:True 249:True 250:True 251:True 252:True 253:True 254:True 255:True 256:True 257:True 258:True 259:True 260:False 261:False 262:False 263:False 264:False 265:False 266:False 267:False 268:False 269:False 270:False 271:False 272:False 273:False 274:False 275:False 276:False 277:False 278:False 279:False 280:False 281:False 282:False 283:False 284:False 285:False 286:False 287:False 288:False 289:False 290:False 291:False 292:False 293:False 294:False 295:False 296:False 297:False 298:False 299:False 300:False 301:False 302:False 303:False 304:False 305:False 306:False 307:False 308:False 309:False 310:False 311:False 312:False 313:False 314:False 315:False 316:False 317:False 318:False 319:False 320:False 321:False 322:False 323:False 324:False 325:False 326:False 327:False 328:False 329:False 330:False 331:False 332:False 333:False 334:False 335:False 336:False 337:False 338:False 339:False 340:False 341:False 342:False 343:False 344:False 345:False 346:False 347:False 348:False 349:False 350:False 351:False 352:False 353:False 354:False 355:False 356:False 357:False 358:False 359:False 360:False 361:False 362:False 363:False 364:False 365:False 366:False 367:False 368:False 369:False 370:False 371:False 372:False 373:False 374:False 375:False 376:False 377:False 378:False 379:False 380:False 381:False 382:False\n",
      "I1208 12:27:37.021794 139883775852736 run_factoid.py:447] token_is_max_context: 8:False 9:False 10:False 11:False 12:False 13:False 14:False 15:False 16:False 17:False 18:False 19:False 20:False 21:False 22:False 23:False 24:False 25:False 26:False 27:False 28:False 29:False 30:False 31:False 32:False 33:False 34:False 35:False 36:False 37:False 38:False 39:False 40:False 41:False 42:False 43:False 44:False 45:False 46:False 47:False 48:False 49:False 50:False 51:False 52:False 53:False 54:False 55:False 56:False 57:False 58:False 59:False 60:False 61:False 62:False 63:False 64:False 65:False 66:False 67:False 68:False 69:False 70:False 71:False 72:False 73:False 74:False 75:False 76:False 77:False 78:False 79:False 80:False 81:False 82:False 83:False 84:False 85:False 86:False 87:False 88:False 89:False 90:False 91:False 92:False 93:False 94:False 95:False 96:False 97:False 98:False 99:False 100:False 101:False 102:False 103:False 104:False 105:False 106:False 107:False 108:False 109:False 110:False 111:False 112:False 113:False 114:False 115:False 116:False 117:False 118:False 119:False 120:False 121:False 122:False 123:False 124:False 125:False 126:False 127:False 128:False 129:False 130:False 131:False 132:True 133:True 134:True 135:True 136:True 137:True 138:True 139:True 140:True 141:True 142:True 143:True 144:True 145:True 146:True 147:True 148:True 149:True 150:True 151:True 152:True 153:True 154:True 155:True 156:True 157:True 158:True 159:True 160:True 161:True 162:True 163:True 164:True 165:True 166:True 167:True 168:True 169:True 170:True 171:True 172:True 173:True 174:True 175:True 176:True 177:True 178:True 179:True 180:True 181:True 182:True 183:True 184:True 185:True 186:True 187:True 188:True 189:True 190:True 191:True 192:True 193:True 194:True 195:True 196:True 197:True 198:True 199:True 200:True 201:True 202:True 203:True 204:True 205:True 206:True 207:True 208:True 209:True 210:True 211:True 212:True 213:True 214:True 215:True 216:True 217:True 218:True 219:True 220:True 221:True 222:True 223:True 224:True 225:True 226:True 227:True 228:True 229:True 230:True 231:True 232:True 233:True 234:True 235:True 236:True 237:True 238:True 239:True 240:True 241:True 242:True 243:True 244:True 245:True 246:True 247:True 248:True 249:True 250:True 251:True 252:True 253:True 254:True 255:True 256:True 257:True 258:True 259:True 260:False 261:False 262:False 263:False 264:False 265:False 266:False 267:False 268:False 269:False 270:False 271:False 272:False 273:False 274:False 275:False 276:False 277:False 278:False 279:False 280:False 281:False 282:False 283:False 284:False 285:False 286:False 287:False 288:False 289:False 290:False 291:False 292:False 293:False 294:False 295:False 296:False 297:False 298:False 299:False 300:False 301:False 302:False 303:False 304:False 305:False 306:False 307:False 308:False 309:False 310:False 311:False 312:False 313:False 314:False 315:False 316:False 317:False 318:False 319:False 320:False 321:False 322:False 323:False 324:False 325:False 326:False 327:False 328:False 329:False 330:False 331:False 332:False 333:False 334:False 335:False 336:False 337:False 338:False 339:False 340:False 341:False 342:False 343:False 344:False 345:False 346:False 347:False 348:False 349:False 350:False 351:False 352:False 353:False 354:False 355:False 356:False 357:False 358:False 359:False 360:False 361:False 362:False 363:False 364:False 365:False 366:False 367:False 368:False 369:False 370:False 371:False 372:False 373:False 374:False 375:False 376:False 377:False 378:False 379:False 380:False 381:False 382:False\n",
      "INFO:tensorflow:input_ids: 101 1327 1225 1103 2526 1202 136 102 25509 1197 790 164 1398 11628 166 114 16716 6187 164 1398 11628 166 16716 113 789 1123 5813 790 164 2508 1708 3048 12008 19995 166 23066 789 1123 5813 790 164 1398 11628 166 23066 789 1123 5813 2116 790 164 1398 11628 166 114 114 16716 113 1679 10182 118 15925 13169 164 1398 11628 166 16716 113 789 1322 2155 20739 790 164 2508 1708 3048 12008 19995 166 23066 789 1322 2155 20739 790 164 1398 11628 166 23066 789 1322 2155 22258 790 164 1398 11628 166 114 16716 113 789 181 1818 18071 7409 4412 1805 790 164 2508 1708 3048 12008 19995 166 23066 113 789 181 1818 18071 7409 4412 790 164 1398 11628 166 16716 789 1805 790 164 1398 11628 166 114 23066 789 181 1818 18071 7409 4412 1805 790 164 1398 11628 166 23066 789 181 25509 1197 790 164 1398 11628 166 114 16716 113 789 10437 10294 18778 1183 790 164 2508 1708 3048 12008 19995 166 23066 789 10437 10294 18778 1183 790 164 1398 11628 166 23066 789 6187 10294 18778 1183 790 164 1398 11628 166 114 114 119 1188 3403 1108 2609 1106 1769 5174 117 1105 1185 1846 1137 4128 2781 1108 9520 119 1130 1901 117 1195 1145 23465 8703 1103 3835 6802 1104 1103 1529 2527 1105 2166 3189 117 12818 3189 1105 27154 118 3622 1106 6183 3209 2527 1235 1185 2509 4237 1180 1129 1276 119 1109 10838 9173 1127 1112 3226 131 119 113 122 114 2025 1902 131 7091 2200 1654 3443 113 25157 1942 114 117 1884 13252 1204 2025 117 1137 1692 118 1654 2025 132 113 123 114 1416 131 4420 1150 1127 11534 1114 149 2137 3048 113 124 114 9108 131 153 21678 2137 132 113 125 114 7577 131 1168 13467 8015 132 113 126 114 9386 5252 131 1141 1104 1103 1378 1116 131 2244 2603 117 1231 10182 21629 2603 117 3254 15534 2603 117 2805 1159 117 2704 2215 117 1892 2445 117 5173 13022 3418 113 19497 1708 114 2794 1111 1171 2489 1105 3420 2489 117 1367 118 8926 6373 15075 3225 8157 113 18659 11964 114 2952 102\n",
      "I1208 12:27:37.021898 139883775852736 run_factoid.py:449] input_ids: 101 1327 1225 1103 2526 1202 136 102 25509 1197 790 164 1398 11628 166 114 16716 6187 164 1398 11628 166 16716 113 789 1123 5813 790 164 2508 1708 3048 12008 19995 166 23066 789 1123 5813 790 164 1398 11628 166 23066 789 1123 5813 2116 790 164 1398 11628 166 114 114 16716 113 1679 10182 118 15925 13169 164 1398 11628 166 16716 113 789 1322 2155 20739 790 164 2508 1708 3048 12008 19995 166 23066 789 1322 2155 20739 790 164 1398 11628 166 23066 789 1322 2155 22258 790 164 1398 11628 166 114 16716 113 789 181 1818 18071 7409 4412 1805 790 164 2508 1708 3048 12008 19995 166 23066 113 789 181 1818 18071 7409 4412 790 164 1398 11628 166 16716 789 1805 790 164 1398 11628 166 114 23066 789 181 1818 18071 7409 4412 1805 790 164 1398 11628 166 23066 789 181 25509 1197 790 164 1398 11628 166 114 16716 113 789 10437 10294 18778 1183 790 164 2508 1708 3048 12008 19995 166 23066 789 10437 10294 18778 1183 790 164 1398 11628 166 23066 789 6187 10294 18778 1183 790 164 1398 11628 166 114 114 119 1188 3403 1108 2609 1106 1769 5174 117 1105 1185 1846 1137 4128 2781 1108 9520 119 1130 1901 117 1195 1145 23465 8703 1103 3835 6802 1104 1103 1529 2527 1105 2166 3189 117 12818 3189 1105 27154 118 3622 1106 6183 3209 2527 1235 1185 2509 4237 1180 1129 1276 119 1109 10838 9173 1127 1112 3226 131 119 113 122 114 2025 1902 131 7091 2200 1654 3443 113 25157 1942 114 117 1884 13252 1204 2025 117 1137 1692 118 1654 2025 132 113 123 114 1416 131 4420 1150 1127 11534 1114 149 2137 3048 113 124 114 9108 131 153 21678 2137 132 113 125 114 7577 131 1168 13467 8015 132 113 126 114 9386 5252 131 1141 1104 1103 1378 1116 131 2244 2603 117 1231 10182 21629 2603 117 3254 15534 2603 117 2805 1159 117 2704 2215 117 1892 2445 117 5173 13022 3418 113 19497 1708 114 2794 1111 1171 2489 1105 3420 2489 117 1367 118 8926 6373 15075 3225 8157 113 18659 11964 114 2952 102\n",
      "INFO:tensorflow:input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      "I1208 12:27:37.021989 139883775852736 run_factoid.py:451] input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      "INFO:tensorflow:segment_ids: 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      "I1208 12:27:37.022078 139883775852736 run_factoid.py:453] segment_ids: 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      "INFO:tensorflow:*** Example ***\n",
      "I1208 12:27:37.023595 139883775852736 run_factoid.py:438] *** Example ***\n",
      "INFO:tensorflow:unique_id: 1000000013\n",
      "I1208 12:27:37.023655 139883775852736 run_factoid.py:439] unique_id: 1000000013\n",
      "INFO:tensorflow:example_index: 5\n",
      "I1208 12:27:37.023692 139883775852736 run_factoid.py:440] example_index: 5\n",
      "INFO:tensorflow:doc_span_index: 2\n",
      "I1208 12:27:37.023727 139883775852736 run_factoid.py:441] doc_span_index: 2\n",
      "INFO:tensorflow:tokens: [CLS] What did the paper do ? [SEP] [ All Fields ] ) OR “ l ##um ##bos ##ac ##ral region ” [ All Fields ] OR “ l ##umba ##r ” [ All Fields ] ) AND ( “ disk ##ec ##tom ##y ” [ Me ##S ##H Te ##rms ] OR “ disk ##ec ##tom ##y ” [ All Fields ] OR “ disc ##ec ##tom ##y ” [ All Fields ] ) ) . This search was limited to human subjects , and no language or publication status was imposed . In addition , we also manually searched the reference lists of the included studies and previous review , systematic review and meta - analysis to identify potential studies until no additional articles could be found . The inclusion criteria were as follows : . ( 1 ) study design : random ##ized control trial ( RC ##T ) , co ##hor ##t study , or case - control study ; ( 2 ) population : patients who were diagnosed with L ##D ##H ( 3 ) intervention : P ##EL ##D ; ( 4 ) comparison : other surgical approaches ; ( 5 ) outcome measures : one of the following ##s : success rate , re ##cu ##rrence rate , com ##plication rate , operation time , hospital stay , blood loss , visual analog scale ( VA ##S ) score for back pain and leg pain , 12 - item Short Form Health Survey ( SF ##12 ) physical component score ( PC ##S ) , mental component score ( MC ##S ) , Japanese Or ##th ##op ##ae ##dic Association Score ( J ##OA ) , O ##s ##wes ##try Di ##sa ##bility Index ( ODI ) . Two independent investigators extracted the following data from the included studies : first author ’ name , publication year , study design , country , number of patients in each group , patients ’ characteristics , and outcome data ( success rate , re ##cu ##rrence rate , com ##plication rate , operation time , hospital stay , blood loss , VA ##S scores for back pain and leg pain , J ##OA , SF ##12 - MC ##S / PC ##S , and ODI ) . If [SEP]\n",
      "I1208 12:27:37.023841 139883775852736 run_factoid.py:443] tokens: [CLS] What did the paper do ? [SEP] [ All Fields ] ) OR “ l ##um ##bos ##ac ##ral region ” [ All Fields ] OR “ l ##umba ##r ” [ All Fields ] ) AND ( “ disk ##ec ##tom ##y ” [ Me ##S ##H Te ##rms ] OR “ disk ##ec ##tom ##y ” [ All Fields ] OR “ disc ##ec ##tom ##y ” [ All Fields ] ) ) . This search was limited to human subjects , and no language or publication status was imposed . In addition , we also manually searched the reference lists of the included studies and previous review , systematic review and meta - analysis to identify potential studies until no additional articles could be found . The inclusion criteria were as follows : . ( 1 ) study design : random ##ized control trial ( RC ##T ) , co ##hor ##t study , or case - control study ; ( 2 ) population : patients who were diagnosed with L ##D ##H ( 3 ) intervention : P ##EL ##D ; ( 4 ) comparison : other surgical approaches ; ( 5 ) outcome measures : one of the following ##s : success rate , re ##cu ##rrence rate , com ##plication rate , operation time , hospital stay , blood loss , visual analog scale ( VA ##S ) score for back pain and leg pain , 12 - item Short Form Health Survey ( SF ##12 ) physical component score ( PC ##S ) , mental component score ( MC ##S ) , Japanese Or ##th ##op ##ae ##dic Association Score ( J ##OA ) , O ##s ##wes ##try Di ##sa ##bility Index ( ODI ) . Two independent investigators extracted the following data from the included studies : first author ’ name , publication year , study design , country , number of patients in each group , patients ’ characteristics , and outcome data ( success rate , re ##cu ##rrence rate , com ##plication rate , operation time , hospital stay , blood loss , VA ##S scores for back pain and leg pain , J ##OA , SF ##12 - MC ##S / PC ##S , and ODI ) . If [SEP]\n",
      "INFO:tensorflow:token_to_orig_map: 8:94 9:94 10:95 11:95 12:95 13:96 14:97 15:97 16:97 17:97 18:97 19:97 20:98 21:98 22:98 23:98 24:99 25:99 26:100 27:101 28:101 29:101 30:101 31:101 32:101 33:101 34:102 35:102 36:102 37:103 38:104 39:104 40:104 41:104 42:104 43:104 44:104 45:104 46:104 47:104 48:104 49:105 50:105 51:105 52:106 53:107 54:107 55:107 56:107 57:107 58:107 59:107 60:107 61:108 62:108 63:109 64:110 65:110 66:110 67:110 68:110 69:110 70:110 71:110 72:111 73:111 74:111 75:111 76:111 77:112 78:113 79:114 80:115 81:116 82:117 83:118 84:118 85:119 86:120 87:121 88:122 89:123 90:124 91:125 92:126 93:126 94:127 95:128 96:128 97:129 98:130 99:131 100:132 101:133 102:134 103:135 104:136 105:137 106:138 107:139 108:140 109:141 110:142 111:142 112:143 113:144 114:145 115:146 116:146 117:146 118:147 119:148 120:149 121:150 122:151 123:152 124:153 125:154 126:155 127:156 128:157 129:157 130:158 131:159 132:160 133:161 134:162 135:163 136:163 137:164 138:165 139:165 140:165 141:166 142:167 143:167 144:168 145:168 146:169 147:170 148:171 149:171 150:171 151:171 152:171 153:172 154:172 155:172 156:173 157:173 158:174 159:175 160:175 161:175 162:176 163:176 164:177 165:177 166:177 167:178 168:178 169:179 170:180 171:181 172:182 173:183 174:184 175:184 176:184 177:185 178:185 179:185 180:186 181:186 182:187 183:187 184:187 185:187 186:188 187:188 188:188 189:189 190:189 191:190 192:191 193:192 194:192 195:193 196:193 197:193 198:194 199:195 200:195 201:196 202:197 203:198 204:199 205:199 206:199 207:200 208:201 209:201 210:202 211:202 212:202 213:203 214:203 215:204 216:204 217:205 218:205 219:206 220:207 221:207 222:208 223:209 224:209 225:210 226:211 227:211 228:212 229:213 230:214 231:215 232:215 233:215 234:215 235:216 236:217 237:218 238:219 239:220 240:221 241:222 242:222 243:223 244:223 245:223 246:224 247:225 248:226 249:227 250:228 251:228 252:228 253:228 254:229 255:230 256:231 257:232 258:232 259:232 260:232 261:232 262:233 263:234 264:235 265:236 266:236 267:236 268:236 269:236 270:237 271:238 272:238 273:238 274:238 275:238 276:239 277:240 278:241 279:241 280:241 281:241 282:241 283:242 284:242 285:242 286:242 287:243 288:243 289:243 290:244 291:245 292:245 293:245 294:245 295:246 296:247 297:248 298:249 299:250 300:251 301:252 302:253 303:254 304:255 305:256 306:256 307:257 308:258 309:258 310:259 311:259 312:260 313:261 314:261 315:262 316:263 317:263 318:264 319:264 320:265 321:266 322:267 323:268 324:269 325:270 326:270 327:271 328:271 329:272 330:272 331:273 332:274 333:275 334:276 335:276 336:277 337:277 338:278 339:278 340:278 341:279 342:279 343:280 344:280 345:281 346:281 347:282 348:283 349:283 350:284 351:285 352:285 353:286 354:287 355:287 356:288 357:288 358:289 359:290 360:291 361:292 362:293 363:294 364:295 365:295 366:296 367:296 368:296 369:297 370:297 371:297 372:297 373:297 374:297 375:297 376:297 377:297 378:298 379:299 380:299 381:299 382:300\n",
      "I1208 12:27:37.023960 139883775852736 run_factoid.py:445] token_to_orig_map: 8:94 9:94 10:95 11:95 12:95 13:96 14:97 15:97 16:97 17:97 18:97 19:97 20:98 21:98 22:98 23:98 24:99 25:99 26:100 27:101 28:101 29:101 30:101 31:101 32:101 33:101 34:102 35:102 36:102 37:103 38:104 39:104 40:104 41:104 42:104 43:104 44:104 45:104 46:104 47:104 48:104 49:105 50:105 51:105 52:106 53:107 54:107 55:107 56:107 57:107 58:107 59:107 60:107 61:108 62:108 63:109 64:110 65:110 66:110 67:110 68:110 69:110 70:110 71:110 72:111 73:111 74:111 75:111 76:111 77:112 78:113 79:114 80:115 81:116 82:117 83:118 84:118 85:119 86:120 87:121 88:122 89:123 90:124 91:125 92:126 93:126 94:127 95:128 96:128 97:129 98:130 99:131 100:132 101:133 102:134 103:135 104:136 105:137 106:138 107:139 108:140 109:141 110:142 111:142 112:143 113:144 114:145 115:146 116:146 117:146 118:147 119:148 120:149 121:150 122:151 123:152 124:153 125:154 126:155 127:156 128:157 129:157 130:158 131:159 132:160 133:161 134:162 135:163 136:163 137:164 138:165 139:165 140:165 141:166 142:167 143:167 144:168 145:168 146:169 147:170 148:171 149:171 150:171 151:171 152:171 153:172 154:172 155:172 156:173 157:173 158:174 159:175 160:175 161:175 162:176 163:176 164:177 165:177 166:177 167:178 168:178 169:179 170:180 171:181 172:182 173:183 174:184 175:184 176:184 177:185 178:185 179:185 180:186 181:186 182:187 183:187 184:187 185:187 186:188 187:188 188:188 189:189 190:189 191:190 192:191 193:192 194:192 195:193 196:193 197:193 198:194 199:195 200:195 201:196 202:197 203:198 204:199 205:199 206:199 207:200 208:201 209:201 210:202 211:202 212:202 213:203 214:203 215:204 216:204 217:205 218:205 219:206 220:207 221:207 222:208 223:209 224:209 225:210 226:211 227:211 228:212 229:213 230:214 231:215 232:215 233:215 234:215 235:216 236:217 237:218 238:219 239:220 240:221 241:222 242:222 243:223 244:223 245:223 246:224 247:225 248:226 249:227 250:228 251:228 252:228 253:228 254:229 255:230 256:231 257:232 258:232 259:232 260:232 261:232 262:233 263:234 264:235 265:236 266:236 267:236 268:236 269:236 270:237 271:238 272:238 273:238 274:238 275:238 276:239 277:240 278:241 279:241 280:241 281:241 282:241 283:242 284:242 285:242 286:242 287:243 288:243 289:243 290:244 291:245 292:245 293:245 294:245 295:246 296:247 297:248 298:249 299:250 300:251 301:252 302:253 303:254 304:255 305:256 306:256 307:257 308:258 309:258 310:259 311:259 312:260 313:261 314:261 315:262 316:263 317:263 318:264 319:264 320:265 321:266 322:267 323:268 324:269 325:270 326:270 327:271 328:271 329:272 330:272 331:273 332:274 333:275 334:276 335:276 336:277 337:277 338:278 339:278 340:278 341:279 342:279 343:280 344:280 345:281 346:281 347:282 348:283 349:283 350:284 351:285 352:285 353:286 354:287 355:287 356:288 357:288 358:289 359:290 360:291 361:292 362:293 363:294 364:295 365:295 366:296 367:296 368:296 369:297 370:297 371:297 372:297 373:297 374:297 375:297 376:297 377:297 378:298 379:299 380:299 381:299 382:300\n",
      "INFO:tensorflow:token_is_max_context: 8:False 9:False 10:False 11:False 12:False 13:False 14:False 15:False 16:False 17:False 18:False 19:False 20:False 21:False 22:False 23:False 24:False 25:False 26:False 27:False 28:False 29:False 30:False 31:False 32:False 33:False 34:False 35:False 36:False 37:False 38:False 39:False 40:False 41:False 42:False 43:False 44:False 45:False 46:False 47:False 48:False 49:False 50:False 51:False 52:False 53:False 54:False 55:False 56:False 57:False 58:False 59:False 60:False 61:False 62:False 63:False 64:False 65:False 66:False 67:False 68:False 69:False 70:False 71:False 72:False 73:False 74:False 75:False 76:False 77:False 78:False 79:False 80:False 81:False 82:False 83:False 84:False 85:False 86:False 87:False 88:False 89:False 90:False 91:False 92:False 93:False 94:False 95:False 96:False 97:False 98:False 99:False 100:False 101:False 102:False 103:False 104:False 105:False 106:False 107:False 108:False 109:False 110:False 111:False 112:False 113:False 114:False 115:False 116:False 117:False 118:False 119:False 120:False 121:False 122:False 123:False 124:False 125:False 126:False 127:False 128:False 129:False 130:False 131:False 132:True 133:True 134:True 135:True 136:True 137:True 138:True 139:True 140:True 141:True 142:True 143:True 144:True 145:True 146:True 147:True 148:True 149:True 150:True 151:True 152:True 153:True 154:True 155:True 156:True 157:True 158:True 159:True 160:True 161:True 162:True 163:True 164:True 165:True 166:True 167:True 168:True 169:True 170:True 171:True 172:True 173:True 174:True 175:True 176:True 177:True 178:True 179:True 180:True 181:True 182:True 183:True 184:True 185:True 186:True 187:True 188:True 189:True 190:True 191:True 192:True 193:True 194:True 195:True 196:True 197:True 198:True 199:True 200:True 201:True 202:True 203:True 204:True 205:True 206:True 207:True 208:True 209:True 210:True 211:True 212:True 213:True 214:True 215:True 216:True 217:True 218:True 219:True 220:True 221:True 222:True 223:True 224:True 225:True 226:True 227:True 228:True 229:True 230:True 231:True 232:True 233:True 234:True 235:True 236:True 237:True 238:True 239:True 240:True 241:True 242:True 243:True 244:True 245:True 246:True 247:True 248:True 249:True 250:True 251:True 252:True 253:True 254:True 255:True 256:True 257:True 258:True 259:True 260:False 261:False 262:False 263:False 264:False 265:False 266:False 267:False 268:False 269:False 270:False 271:False 272:False 273:False 274:False 275:False 276:False 277:False 278:False 279:False 280:False 281:False 282:False 283:False 284:False 285:False 286:False 287:False 288:False 289:False 290:False 291:False 292:False 293:False 294:False 295:False 296:False 297:False 298:False 299:False 300:False 301:False 302:False 303:False 304:False 305:False 306:False 307:False 308:False 309:False 310:False 311:False 312:False 313:False 314:False 315:False 316:False 317:False 318:False 319:False 320:False 321:False 322:False 323:False 324:False 325:False 326:False 327:False 328:False 329:False 330:False 331:False 332:False 333:False 334:False 335:False 336:False 337:False 338:False 339:False 340:False 341:False 342:False 343:False 344:False 345:False 346:False 347:False 348:False 349:False 350:False 351:False 352:False 353:False 354:False 355:False 356:False 357:False 358:False 359:False 360:False 361:False 362:False 363:False 364:False 365:False 366:False 367:False 368:False 369:False 370:False 371:False 372:False 373:False 374:False 375:False 376:False 377:False 378:False 379:False 380:False 381:False 382:False\n",
      "I1208 12:27:37.024068 139883775852736 run_factoid.py:447] token_is_max_context: 8:False 9:False 10:False 11:False 12:False 13:False 14:False 15:False 16:False 17:False 18:False 19:False 20:False 21:False 22:False 23:False 24:False 25:False 26:False 27:False 28:False 29:False 30:False 31:False 32:False 33:False 34:False 35:False 36:False 37:False 38:False 39:False 40:False 41:False 42:False 43:False 44:False 45:False 46:False 47:False 48:False 49:False 50:False 51:False 52:False 53:False 54:False 55:False 56:False 57:False 58:False 59:False 60:False 61:False 62:False 63:False 64:False 65:False 66:False 67:False 68:False 69:False 70:False 71:False 72:False 73:False 74:False 75:False 76:False 77:False 78:False 79:False 80:False 81:False 82:False 83:False 84:False 85:False 86:False 87:False 88:False 89:False 90:False 91:False 92:False 93:False 94:False 95:False 96:False 97:False 98:False 99:False 100:False 101:False 102:False 103:False 104:False 105:False 106:False 107:False 108:False 109:False 110:False 111:False 112:False 113:False 114:False 115:False 116:False 117:False 118:False 119:False 120:False 121:False 122:False 123:False 124:False 125:False 126:False 127:False 128:False 129:False 130:False 131:False 132:True 133:True 134:True 135:True 136:True 137:True 138:True 139:True 140:True 141:True 142:True 143:True 144:True 145:True 146:True 147:True 148:True 149:True 150:True 151:True 152:True 153:True 154:True 155:True 156:True 157:True 158:True 159:True 160:True 161:True 162:True 163:True 164:True 165:True 166:True 167:True 168:True 169:True 170:True 171:True 172:True 173:True 174:True 175:True 176:True 177:True 178:True 179:True 180:True 181:True 182:True 183:True 184:True 185:True 186:True 187:True 188:True 189:True 190:True 191:True 192:True 193:True 194:True 195:True 196:True 197:True 198:True 199:True 200:True 201:True 202:True 203:True 204:True 205:True 206:True 207:True 208:True 209:True 210:True 211:True 212:True 213:True 214:True 215:True 216:True 217:True 218:True 219:True 220:True 221:True 222:True 223:True 224:True 225:True 226:True 227:True 228:True 229:True 230:True 231:True 232:True 233:True 234:True 235:True 236:True 237:True 238:True 239:True 240:True 241:True 242:True 243:True 244:True 245:True 246:True 247:True 248:True 249:True 250:True 251:True 252:True 253:True 254:True 255:True 256:True 257:True 258:True 259:True 260:False 261:False 262:False 263:False 264:False 265:False 266:False 267:False 268:False 269:False 270:False 271:False 272:False 273:False 274:False 275:False 276:False 277:False 278:False 279:False 280:False 281:False 282:False 283:False 284:False 285:False 286:False 287:False 288:False 289:False 290:False 291:False 292:False 293:False 294:False 295:False 296:False 297:False 298:False 299:False 300:False 301:False 302:False 303:False 304:False 305:False 306:False 307:False 308:False 309:False 310:False 311:False 312:False 313:False 314:False 315:False 316:False 317:False 318:False 319:False 320:False 321:False 322:False 323:False 324:False 325:False 326:False 327:False 328:False 329:False 330:False 331:False 332:False 333:False 334:False 335:False 336:False 337:False 338:False 339:False 340:False 341:False 342:False 343:False 344:False 345:False 346:False 347:False 348:False 349:False 350:False 351:False 352:False 353:False 354:False 355:False 356:False 357:False 358:False 359:False 360:False 361:False 362:False 363:False 364:False 365:False 366:False 367:False 368:False 369:False 370:False 371:False 372:False 373:False 374:False 375:False 376:False 377:False 378:False 379:False 380:False 381:False 382:False\n",
      "INFO:tensorflow:input_ids: 101 1327 1225 1103 2526 1202 136 102 164 1398 11628 166 114 23066 789 181 1818 18071 7409 4412 1805 790 164 1398 11628 166 23066 789 181 25509 1197 790 164 1398 11628 166 114 16716 113 789 10437 10294 18778 1183 790 164 2508 1708 3048 12008 19995 166 23066 789 10437 10294 18778 1183 790 164 1398 11628 166 23066 789 6187 10294 18778 1183 790 164 1398 11628 166 114 114 119 1188 3403 1108 2609 1106 1769 5174 117 1105 1185 1846 1137 4128 2781 1108 9520 119 1130 1901 117 1195 1145 23465 8703 1103 3835 6802 1104 1103 1529 2527 1105 2166 3189 117 12818 3189 1105 27154 118 3622 1106 6183 3209 2527 1235 1185 2509 4237 1180 1129 1276 119 1109 10838 9173 1127 1112 3226 131 119 113 122 114 2025 1902 131 7091 2200 1654 3443 113 25157 1942 114 117 1884 13252 1204 2025 117 1137 1692 118 1654 2025 132 113 123 114 1416 131 4420 1150 1127 11534 1114 149 2137 3048 113 124 114 9108 131 153 21678 2137 132 113 125 114 7577 131 1168 13467 8015 132 113 126 114 9386 5252 131 1141 1104 1103 1378 1116 131 2244 2603 117 1231 10182 21629 2603 117 3254 15534 2603 117 2805 1159 117 2704 2215 117 1892 2445 117 5173 13022 3418 113 19497 1708 114 2794 1111 1171 2489 1105 3420 2489 117 1367 118 8926 6373 15075 3225 8157 113 18659 11964 114 2952 6552 2794 113 7054 1708 114 117 4910 6552 2794 113 12029 1708 114 117 1983 2926 1582 4184 5024 13328 1791 18417 113 147 23579 114 117 152 1116 14291 6013 12120 3202 5474 10146 113 23882 114 119 1960 2457 17718 16939 1103 1378 2233 1121 1103 1529 2527 131 1148 2351 787 1271 117 4128 1214 117 2025 1902 117 1583 117 1295 1104 4420 1107 1296 1372 117 4420 787 5924 117 1105 9386 2233 113 2244 2603 117 1231 10182 21629 2603 117 3254 15534 2603 117 2805 1159 117 2704 2215 117 1892 2445 117 19497 1708 7432 1111 1171 2489 1105 3420 2489 117 147 23579 117 18659 11964 118 12029 1708 120 7054 1708 117 1105 23882 114 119 1409 102\n",
      "I1208 12:27:37.024173 139883775852736 run_factoid.py:449] input_ids: 101 1327 1225 1103 2526 1202 136 102 164 1398 11628 166 114 23066 789 181 1818 18071 7409 4412 1805 790 164 1398 11628 166 23066 789 181 25509 1197 790 164 1398 11628 166 114 16716 113 789 10437 10294 18778 1183 790 164 2508 1708 3048 12008 19995 166 23066 789 10437 10294 18778 1183 790 164 1398 11628 166 23066 789 6187 10294 18778 1183 790 164 1398 11628 166 114 114 119 1188 3403 1108 2609 1106 1769 5174 117 1105 1185 1846 1137 4128 2781 1108 9520 119 1130 1901 117 1195 1145 23465 8703 1103 3835 6802 1104 1103 1529 2527 1105 2166 3189 117 12818 3189 1105 27154 118 3622 1106 6183 3209 2527 1235 1185 2509 4237 1180 1129 1276 119 1109 10838 9173 1127 1112 3226 131 119 113 122 114 2025 1902 131 7091 2200 1654 3443 113 25157 1942 114 117 1884 13252 1204 2025 117 1137 1692 118 1654 2025 132 113 123 114 1416 131 4420 1150 1127 11534 1114 149 2137 3048 113 124 114 9108 131 153 21678 2137 132 113 125 114 7577 131 1168 13467 8015 132 113 126 114 9386 5252 131 1141 1104 1103 1378 1116 131 2244 2603 117 1231 10182 21629 2603 117 3254 15534 2603 117 2805 1159 117 2704 2215 117 1892 2445 117 5173 13022 3418 113 19497 1708 114 2794 1111 1171 2489 1105 3420 2489 117 1367 118 8926 6373 15075 3225 8157 113 18659 11964 114 2952 6552 2794 113 7054 1708 114 117 4910 6552 2794 113 12029 1708 114 117 1983 2926 1582 4184 5024 13328 1791 18417 113 147 23579 114 117 152 1116 14291 6013 12120 3202 5474 10146 113 23882 114 119 1960 2457 17718 16939 1103 1378 2233 1121 1103 1529 2527 131 1148 2351 787 1271 117 4128 1214 117 2025 1902 117 1583 117 1295 1104 4420 1107 1296 1372 117 4420 787 5924 117 1105 9386 2233 113 2244 2603 117 1231 10182 21629 2603 117 3254 15534 2603 117 2805 1159 117 2704 2215 117 1892 2445 117 19497 1708 7432 1111 1171 2489 1105 3420 2489 117 147 23579 117 18659 11964 118 12029 1708 120 7054 1708 117 1105 23882 114 119 1409 102\n",
      "INFO:tensorflow:input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      "I1208 12:27:37.024265 139883775852736 run_factoid.py:451] input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      "INFO:tensorflow:segment_ids: 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      "I1208 12:27:37.024353 139883775852736 run_factoid.py:453] segment_ids: 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      "INFO:tensorflow:*** Example ***\n",
      "I1208 12:27:37.025829 139883775852736 run_factoid.py:438] *** Example ***\n",
      "INFO:tensorflow:unique_id: 1000000014\n",
      "I1208 12:27:37.025889 139883775852736 run_factoid.py:439] unique_id: 1000000014\n",
      "INFO:tensorflow:example_index: 5\n",
      "I1208 12:27:37.025926 139883775852736 run_factoid.py:440] example_index: 5\n",
      "INFO:tensorflow:doc_span_index: 3\n",
      "I1208 12:27:37.025960 139883775852736 run_factoid.py:441] doc_span_index: 3\n",
      "INFO:tensorflow:tokens: [CLS] What did the paper do ? [SEP] : . ( 1 ) study design : random ##ized control trial ( RC ##T ) , co ##hor ##t study , or case - control study ; ( 2 ) population : patients who were diagnosed with L ##D ##H ( 3 ) intervention : P ##EL ##D ; ( 4 ) comparison : other surgical approaches ; ( 5 ) outcome measures : one of the following ##s : success rate , re ##cu ##rrence rate , com ##plication rate , operation time , hospital stay , blood loss , visual analog scale ( VA ##S ) score for back pain and leg pain , 12 - item Short Form Health Survey ( SF ##12 ) physical component score ( PC ##S ) , mental component score ( MC ##S ) , Japanese Or ##th ##op ##ae ##dic Association Score ( J ##OA ) , O ##s ##wes ##try Di ##sa ##bility Index ( ODI ) . Two independent investigators extracted the following data from the included studies : first author ’ name , publication year , study design , country , number of patients in each group , patients ’ characteristics , and outcome data ( success rate , re ##cu ##rrence rate , com ##plication rate , operation time , hospital stay , blood loss , VA ##S scores for back pain and leg pain , J ##OA , SF ##12 - MC ##S / PC ##S , and ODI ) . If the study did not provide the important data , we would contact the corresponding authors for the missing information . We evaluated the risk of bias in RC ##T ##s with the method recommended by Cochrane Col ##la ##bor ##ation . [ 29 ] Five items , including blinding , method of random ##ization , allocation con - c ##eal ##ment , follow - up , and intention - to - treat analysis were used to assess the quality of study . [ 29 ] And each study was classified as high , low , or unclear risk of bias . We evaluated the method ##ological quality of non - random ##ized studies ( co ##hor ##t study , or case - control study ) using the modified [SEP]\n",
      "I1208 12:27:37.026075 139883775852736 run_factoid.py:443] tokens: [CLS] What did the paper do ? [SEP] : . ( 1 ) study design : random ##ized control trial ( RC ##T ) , co ##hor ##t study , or case - control study ; ( 2 ) population : patients who were diagnosed with L ##D ##H ( 3 ) intervention : P ##EL ##D ; ( 4 ) comparison : other surgical approaches ; ( 5 ) outcome measures : one of the following ##s : success rate , re ##cu ##rrence rate , com ##plication rate , operation time , hospital stay , blood loss , visual analog scale ( VA ##S ) score for back pain and leg pain , 12 - item Short Form Health Survey ( SF ##12 ) physical component score ( PC ##S ) , mental component score ( MC ##S ) , Japanese Or ##th ##op ##ae ##dic Association Score ( J ##OA ) , O ##s ##wes ##try Di ##sa ##bility Index ( ODI ) . Two independent investigators extracted the following data from the included studies : first author ’ name , publication year , study design , country , number of patients in each group , patients ’ characteristics , and outcome data ( success rate , re ##cu ##rrence rate , com ##plication rate , operation time , hospital stay , blood loss , VA ##S scores for back pain and leg pain , J ##OA , SF ##12 - MC ##S / PC ##S , and ODI ) . If the study did not provide the important data , we would contact the corresponding authors for the missing information . We evaluated the risk of bias in RC ##T ##s with the method recommended by Cochrane Col ##la ##bor ##ation . [ 29 ] Five items , including blinding , method of random ##ization , allocation con - c ##eal ##ment , follow - up , and intention - to - treat analysis were used to assess the quality of study . [ 29 ] And each study was classified as high , low , or unclear risk of bias . We evaluated the method ##ological quality of non - random ##ized studies ( co ##hor ##t study , or case - control study ) using the modified [SEP]\n",
      "INFO:tensorflow:token_to_orig_map: 8:163 9:164 10:165 11:165 12:165 13:166 14:167 15:167 16:168 17:168 18:169 19:170 20:171 21:171 22:171 23:171 24:171 25:172 26:172 27:172 28:173 29:173 30:174 31:175 32:175 33:175 34:176 35:176 36:177 37:177 38:177 39:178 40:178 41:179 42:180 43:181 44:182 45:183 46:184 47:184 48:184 49:185 50:185 51:185 52:186 53:186 54:187 55:187 56:187 57:187 58:188 59:188 60:188 61:189 62:189 63:190 64:191 65:192 66:192 67:193 68:193 69:193 70:194 71:195 72:195 73:196 74:197 75:198 76:199 77:199 78:199 79:200 80:201 81:201 82:202 83:202 84:202 85:203 86:203 87:204 88:204 89:205 90:205 91:206 92:207 93:207 94:208 95:209 96:209 97:210 98:211 99:211 100:212 101:213 102:214 103:215 104:215 105:215 106:215 107:216 108:217 109:218 110:219 111:220 112:221 113:222 114:222 115:223 116:223 117:223 118:224 119:225 120:226 121:227 122:228 123:228 124:228 125:228 126:229 127:230 128:231 129:232 130:232 131:232 132:232 133:232 134:233 135:234 136:235 137:236 138:236 139:236 140:236 141:236 142:237 143:238 144:238 145:238 146:238 147:238 148:239 149:240 150:241 151:241 152:241 153:241 154:241 155:242 156:242 157:242 158:242 159:243 160:243 161:243 162:244 163:245 164:245 165:245 166:245 167:246 168:247 169:248 170:249 171:250 172:251 173:252 174:253 175:254 176:255 177:256 178:256 179:257 180:258 181:258 182:259 183:259 184:260 185:261 186:261 187:262 188:263 189:263 190:264 191:264 192:265 193:266 194:267 195:268 196:269 197:270 198:270 199:271 200:271 201:272 202:272 203:273 204:274 205:275 206:276 207:276 208:277 209:277 210:278 211:278 212:278 213:279 214:279 215:280 216:280 217:281 218:281 219:282 220:283 221:283 222:284 223:285 224:285 225:286 226:287 227:287 228:288 229:288 230:289 231:290 232:291 233:292 234:293 235:294 236:295 237:295 238:296 239:296 240:296 241:297 242:297 243:297 244:297 245:297 246:297 247:297 248:297 249:297 250:298 251:299 252:299 253:299 254:300 255:301 256:302 257:303 258:304 259:305 260:306 261:307 262:308 263:308 264:309 265:310 266:311 267:312 268:313 269:314 270:315 271:316 272:317 273:318 274:318 275:319 276:320 277:321 278:322 279:323 280:324 281:325 282:326 283:326 284:326 285:327 286:328 287:329 288:330 289:331 290:332 291:333 292:333 293:333 294:333 295:333 296:333 297:333 298:333 299:334 300:335 301:335 302:336 303:337 304:337 305:338 306:339 307:340 308:340 309:340 310:341 311:342 312:342 313:343 314:343 315:343 316:343 317:344 318:344 319:344 320:344 321:345 322:346 323:346 324:346 325:346 326:346 327:347 328:348 329:349 330:350 331:351 332:352 333:353 334:354 335:355 336:355 337:355 338:355 339:355 340:356 341:357 342:358 343:359 344:360 345:361 346:362 347:362 348:363 349:363 350:364 351:365 352:366 353:367 354:368 355:368 356:369 357:370 358:371 359:372 360:372 361:373 362:374 363:375 364:375 365:375 366:375 367:376 368:377 369:377 370:377 371:377 372:378 373:378 374:379 375:380 376:380 377:380 378:381 379:381 380:382 381:383 382:384\n",
      "I1208 12:27:37.026192 139883775852736 run_factoid.py:445] token_to_orig_map: 8:163 9:164 10:165 11:165 12:165 13:166 14:167 15:167 16:168 17:168 18:169 19:170 20:171 21:171 22:171 23:171 24:171 25:172 26:172 27:172 28:173 29:173 30:174 31:175 32:175 33:175 34:176 35:176 36:177 37:177 38:177 39:178 40:178 41:179 42:180 43:181 44:182 45:183 46:184 47:184 48:184 49:185 50:185 51:185 52:186 53:186 54:187 55:187 56:187 57:187 58:188 59:188 60:188 61:189 62:189 63:190 64:191 65:192 66:192 67:193 68:193 69:193 70:194 71:195 72:195 73:196 74:197 75:198 76:199 77:199 78:199 79:200 80:201 81:201 82:202 83:202 84:202 85:203 86:203 87:204 88:204 89:205 90:205 91:206 92:207 93:207 94:208 95:209 96:209 97:210 98:211 99:211 100:212 101:213 102:214 103:215 104:215 105:215 106:215 107:216 108:217 109:218 110:219 111:220 112:221 113:222 114:222 115:223 116:223 117:223 118:224 119:225 120:226 121:227 122:228 123:228 124:228 125:228 126:229 127:230 128:231 129:232 130:232 131:232 132:232 133:232 134:233 135:234 136:235 137:236 138:236 139:236 140:236 141:236 142:237 143:238 144:238 145:238 146:238 147:238 148:239 149:240 150:241 151:241 152:241 153:241 154:241 155:242 156:242 157:242 158:242 159:243 160:243 161:243 162:244 163:245 164:245 165:245 166:245 167:246 168:247 169:248 170:249 171:250 172:251 173:252 174:253 175:254 176:255 177:256 178:256 179:257 180:258 181:258 182:259 183:259 184:260 185:261 186:261 187:262 188:263 189:263 190:264 191:264 192:265 193:266 194:267 195:268 196:269 197:270 198:270 199:271 200:271 201:272 202:272 203:273 204:274 205:275 206:276 207:276 208:277 209:277 210:278 211:278 212:278 213:279 214:279 215:280 216:280 217:281 218:281 219:282 220:283 221:283 222:284 223:285 224:285 225:286 226:287 227:287 228:288 229:288 230:289 231:290 232:291 233:292 234:293 235:294 236:295 237:295 238:296 239:296 240:296 241:297 242:297 243:297 244:297 245:297 246:297 247:297 248:297 249:297 250:298 251:299 252:299 253:299 254:300 255:301 256:302 257:303 258:304 259:305 260:306 261:307 262:308 263:308 264:309 265:310 266:311 267:312 268:313 269:314 270:315 271:316 272:317 273:318 274:318 275:319 276:320 277:321 278:322 279:323 280:324 281:325 282:326 283:326 284:326 285:327 286:328 287:329 288:330 289:331 290:332 291:333 292:333 293:333 294:333 295:333 296:333 297:333 298:333 299:334 300:335 301:335 302:336 303:337 304:337 305:338 306:339 307:340 308:340 309:340 310:341 311:342 312:342 313:343 314:343 315:343 316:343 317:344 318:344 319:344 320:344 321:345 322:346 323:346 324:346 325:346 326:346 327:347 328:348 329:349 330:350 331:351 332:352 333:353 334:354 335:355 336:355 337:355 338:355 339:355 340:356 341:357 342:358 343:359 344:360 345:361 346:362 347:362 348:363 349:363 350:364 351:365 352:366 353:367 354:368 355:368 356:369 357:370 358:371 359:372 360:372 361:373 362:374 363:375 364:375 365:375 366:375 367:376 368:377 369:377 370:377 371:377 372:378 373:378 374:379 375:380 376:380 377:380 378:381 379:381 380:382 381:383 382:384\n",
      "INFO:tensorflow:token_is_max_context: 8:False 9:False 10:False 11:False 12:False 13:False 14:False 15:False 16:False 17:False 18:False 19:False 20:False 21:False 22:False 23:False 24:False 25:False 26:False 27:False 28:False 29:False 30:False 31:False 32:False 33:False 34:False 35:False 36:False 37:False 38:False 39:False 40:False 41:False 42:False 43:False 44:False 45:False 46:False 47:False 48:False 49:False 50:False 51:False 52:False 53:False 54:False 55:False 56:False 57:False 58:False 59:False 60:False 61:False 62:False 63:False 64:False 65:False 66:False 67:False 68:False 69:False 70:False 71:False 72:False 73:False 74:False 75:False 76:False 77:False 78:False 79:False 80:False 81:False 82:False 83:False 84:False 85:False 86:False 87:False 88:False 89:False 90:False 91:False 92:False 93:False 94:False 95:False 96:False 97:False 98:False 99:False 100:False 101:False 102:False 103:False 104:False 105:False 106:False 107:False 108:False 109:False 110:False 111:False 112:False 113:False 114:False 115:False 116:False 117:False 118:False 119:False 120:False 121:False 122:False 123:False 124:False 125:False 126:False 127:False 128:False 129:False 130:False 131:False 132:True 133:True 134:True 135:True 136:True 137:True 138:True 139:True 140:True 141:True 142:True 143:True 144:True 145:True 146:True 147:True 148:True 149:True 150:True 151:True 152:True 153:True 154:True 155:True 156:True 157:True 158:True 159:True 160:True 161:True 162:True 163:True 164:True 165:True 166:True 167:True 168:True 169:True 170:True 171:True 172:True 173:True 174:True 175:True 176:True 177:True 178:True 179:True 180:True 181:True 182:True 183:True 184:True 185:True 186:True 187:True 188:True 189:True 190:True 191:True 192:True 193:True 194:True 195:True 196:True 197:True 198:True 199:True 200:True 201:True 202:True 203:True 204:True 205:True 206:True 207:True 208:True 209:True 210:True 211:True 212:True 213:True 214:True 215:True 216:True 217:True 218:True 219:True 220:True 221:True 222:True 223:True 224:True 225:True 226:True 227:True 228:True 229:True 230:True 231:True 232:True 233:True 234:True 235:True 236:True 237:True 238:True 239:True 240:True 241:True 242:True 243:True 244:True 245:True 246:True 247:True 248:True 249:True 250:True 251:True 252:True 253:True 254:True 255:True 256:True 257:True 258:True 259:True 260:False 261:False 262:False 263:False 264:False 265:False 266:False 267:False 268:False 269:False 270:False 271:False 272:False 273:False 274:False 275:False 276:False 277:False 278:False 279:False 280:False 281:False 282:False 283:False 284:False 285:False 286:False 287:False 288:False 289:False 290:False 291:False 292:False 293:False 294:False 295:False 296:False 297:False 298:False 299:False 300:False 301:False 302:False 303:False 304:False 305:False 306:False 307:False 308:False 309:False 310:False 311:False 312:False 313:False 314:False 315:False 316:False 317:False 318:False 319:False 320:False 321:False 322:False 323:False 324:False 325:False 326:False 327:False 328:False 329:False 330:False 331:False 332:False 333:False 334:False 335:False 336:False 337:False 338:False 339:False 340:False 341:False 342:False 343:False 344:False 345:False 346:False 347:False 348:False 349:False 350:False 351:False 352:False 353:False 354:False 355:False 356:False 357:False 358:False 359:False 360:False 361:False 362:False 363:False 364:False 365:False 366:False 367:False 368:False 369:False 370:False 371:False 372:False 373:False 374:False 375:False 376:False 377:False 378:False 379:False 380:False 381:False 382:False\n",
      "I1208 12:27:37.026300 139883775852736 run_factoid.py:447] token_is_max_context: 8:False 9:False 10:False 11:False 12:False 13:False 14:False 15:False 16:False 17:False 18:False 19:False 20:False 21:False 22:False 23:False 24:False 25:False 26:False 27:False 28:False 29:False 30:False 31:False 32:False 33:False 34:False 35:False 36:False 37:False 38:False 39:False 40:False 41:False 42:False 43:False 44:False 45:False 46:False 47:False 48:False 49:False 50:False 51:False 52:False 53:False 54:False 55:False 56:False 57:False 58:False 59:False 60:False 61:False 62:False 63:False 64:False 65:False 66:False 67:False 68:False 69:False 70:False 71:False 72:False 73:False 74:False 75:False 76:False 77:False 78:False 79:False 80:False 81:False 82:False 83:False 84:False 85:False 86:False 87:False 88:False 89:False 90:False 91:False 92:False 93:False 94:False 95:False 96:False 97:False 98:False 99:False 100:False 101:False 102:False 103:False 104:False 105:False 106:False 107:False 108:False 109:False 110:False 111:False 112:False 113:False 114:False 115:False 116:False 117:False 118:False 119:False 120:False 121:False 122:False 123:False 124:False 125:False 126:False 127:False 128:False 129:False 130:False 131:False 132:True 133:True 134:True 135:True 136:True 137:True 138:True 139:True 140:True 141:True 142:True 143:True 144:True 145:True 146:True 147:True 148:True 149:True 150:True 151:True 152:True 153:True 154:True 155:True 156:True 157:True 158:True 159:True 160:True 161:True 162:True 163:True 164:True 165:True 166:True 167:True 168:True 169:True 170:True 171:True 172:True 173:True 174:True 175:True 176:True 177:True 178:True 179:True 180:True 181:True 182:True 183:True 184:True 185:True 186:True 187:True 188:True 189:True 190:True 191:True 192:True 193:True 194:True 195:True 196:True 197:True 198:True 199:True 200:True 201:True 202:True 203:True 204:True 205:True 206:True 207:True 208:True 209:True 210:True 211:True 212:True 213:True 214:True 215:True 216:True 217:True 218:True 219:True 220:True 221:True 222:True 223:True 224:True 225:True 226:True 227:True 228:True 229:True 230:True 231:True 232:True 233:True 234:True 235:True 236:True 237:True 238:True 239:True 240:True 241:True 242:True 243:True 244:True 245:True 246:True 247:True 248:True 249:True 250:True 251:True 252:True 253:True 254:True 255:True 256:True 257:True 258:True 259:True 260:False 261:False 262:False 263:False 264:False 265:False 266:False 267:False 268:False 269:False 270:False 271:False 272:False 273:False 274:False 275:False 276:False 277:False 278:False 279:False 280:False 281:False 282:False 283:False 284:False 285:False 286:False 287:False 288:False 289:False 290:False 291:False 292:False 293:False 294:False 295:False 296:False 297:False 298:False 299:False 300:False 301:False 302:False 303:False 304:False 305:False 306:False 307:False 308:False 309:False 310:False 311:False 312:False 313:False 314:False 315:False 316:False 317:False 318:False 319:False 320:False 321:False 322:False 323:False 324:False 325:False 326:False 327:False 328:False 329:False 330:False 331:False 332:False 333:False 334:False 335:False 336:False 337:False 338:False 339:False 340:False 341:False 342:False 343:False 344:False 345:False 346:False 347:False 348:False 349:False 350:False 351:False 352:False 353:False 354:False 355:False 356:False 357:False 358:False 359:False 360:False 361:False 362:False 363:False 364:False 365:False 366:False 367:False 368:False 369:False 370:False 371:False 372:False 373:False 374:False 375:False 376:False 377:False 378:False 379:False 380:False 381:False 382:False\n",
      "INFO:tensorflow:input_ids: 101 1327 1225 1103 2526 1202 136 102 131 119 113 122 114 2025 1902 131 7091 2200 1654 3443 113 25157 1942 114 117 1884 13252 1204 2025 117 1137 1692 118 1654 2025 132 113 123 114 1416 131 4420 1150 1127 11534 1114 149 2137 3048 113 124 114 9108 131 153 21678 2137 132 113 125 114 7577 131 1168 13467 8015 132 113 126 114 9386 5252 131 1141 1104 1103 1378 1116 131 2244 2603 117 1231 10182 21629 2603 117 3254 15534 2603 117 2805 1159 117 2704 2215 117 1892 2445 117 5173 13022 3418 113 19497 1708 114 2794 1111 1171 2489 1105 3420 2489 117 1367 118 8926 6373 15075 3225 8157 113 18659 11964 114 2952 6552 2794 113 7054 1708 114 117 4910 6552 2794 113 12029 1708 114 117 1983 2926 1582 4184 5024 13328 1791 18417 113 147 23579 114 117 152 1116 14291 6013 12120 3202 5474 10146 113 23882 114 119 1960 2457 17718 16939 1103 1378 2233 1121 1103 1529 2527 131 1148 2351 787 1271 117 4128 1214 117 2025 1902 117 1583 117 1295 1104 4420 1107 1296 1372 117 4420 787 5924 117 1105 9386 2233 113 2244 2603 117 1231 10182 21629 2603 117 3254 15534 2603 117 2805 1159 117 2704 2215 117 1892 2445 117 19497 1708 7432 1111 1171 2489 1105 3420 2489 117 147 23579 117 18659 11964 118 12029 1708 120 7054 1708 117 1105 23882 114 119 1409 1103 2025 1225 1136 2194 1103 1696 2233 117 1195 1156 3232 1103 7671 5752 1111 1103 3764 1869 119 1284 17428 1103 3187 1104 15069 1107 25157 1942 1116 1114 1103 3442 6315 1118 24763 9518 1742 12207 1891 119 164 1853 166 4222 4454 117 1259 22350 117 3442 1104 7091 2734 117 18205 14255 118 172 13003 1880 117 2812 118 1146 117 1105 6247 118 1106 118 7299 3622 1127 1215 1106 15187 1103 3068 1104 2025 119 164 1853 166 1262 1296 2025 1108 5667 1112 1344 117 1822 117 1137 10527 3187 1104 15069 119 1284 17428 1103 3442 7542 3068 1104 1664 118 7091 2200 2527 113 1884 13252 1204 2025 117 1137 1692 118 1654 2025 114 1606 1103 5847 102\n",
      "I1208 12:27:37.026405 139883775852736 run_factoid.py:449] input_ids: 101 1327 1225 1103 2526 1202 136 102 131 119 113 122 114 2025 1902 131 7091 2200 1654 3443 113 25157 1942 114 117 1884 13252 1204 2025 117 1137 1692 118 1654 2025 132 113 123 114 1416 131 4420 1150 1127 11534 1114 149 2137 3048 113 124 114 9108 131 153 21678 2137 132 113 125 114 7577 131 1168 13467 8015 132 113 126 114 9386 5252 131 1141 1104 1103 1378 1116 131 2244 2603 117 1231 10182 21629 2603 117 3254 15534 2603 117 2805 1159 117 2704 2215 117 1892 2445 117 5173 13022 3418 113 19497 1708 114 2794 1111 1171 2489 1105 3420 2489 117 1367 118 8926 6373 15075 3225 8157 113 18659 11964 114 2952 6552 2794 113 7054 1708 114 117 4910 6552 2794 113 12029 1708 114 117 1983 2926 1582 4184 5024 13328 1791 18417 113 147 23579 114 117 152 1116 14291 6013 12120 3202 5474 10146 113 23882 114 119 1960 2457 17718 16939 1103 1378 2233 1121 1103 1529 2527 131 1148 2351 787 1271 117 4128 1214 117 2025 1902 117 1583 117 1295 1104 4420 1107 1296 1372 117 4420 787 5924 117 1105 9386 2233 113 2244 2603 117 1231 10182 21629 2603 117 3254 15534 2603 117 2805 1159 117 2704 2215 117 1892 2445 117 19497 1708 7432 1111 1171 2489 1105 3420 2489 117 147 23579 117 18659 11964 118 12029 1708 120 7054 1708 117 1105 23882 114 119 1409 1103 2025 1225 1136 2194 1103 1696 2233 117 1195 1156 3232 1103 7671 5752 1111 1103 3764 1869 119 1284 17428 1103 3187 1104 15069 1107 25157 1942 1116 1114 1103 3442 6315 1118 24763 9518 1742 12207 1891 119 164 1853 166 4222 4454 117 1259 22350 117 3442 1104 7091 2734 117 18205 14255 118 172 13003 1880 117 2812 118 1146 117 1105 6247 118 1106 118 7299 3622 1127 1215 1106 15187 1103 3068 1104 2025 119 164 1853 166 1262 1296 2025 1108 5667 1112 1344 117 1822 117 1137 10527 3187 1104 15069 119 1284 17428 1103 3442 7542 3068 1104 1664 118 7091 2200 2527 113 1884 13252 1204 2025 117 1137 1692 118 1654 2025 114 1606 1103 5847 102\n",
      "INFO:tensorflow:input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      "I1208 12:27:37.026495 139883775852736 run_factoid.py:451] input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      "INFO:tensorflow:segment_ids: 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      "I1208 12:27:37.026584 139883775852736 run_factoid.py:453] segment_ids: 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      "INFO:tensorflow:*** Example ***\n",
      "I1208 12:27:37.028059 139883775852736 run_factoid.py:438] *** Example ***\n",
      "INFO:tensorflow:unique_id: 1000000015\n",
      "I1208 12:27:37.028117 139883775852736 run_factoid.py:439] unique_id: 1000000015\n",
      "INFO:tensorflow:example_index: 5\n",
      "I1208 12:27:37.028154 139883775852736 run_factoid.py:440] example_index: 5\n",
      "INFO:tensorflow:doc_span_index: 4\n",
      "I1208 12:27:37.028187 139883775852736 run_factoid.py:441] doc_span_index: 4\n",
      "INFO:tensorflow:tokens: [CLS] What did the paper do ? [SEP] score ( MC ##S ) , Japanese Or ##th ##op ##ae ##dic Association Score ( J ##OA ) , O ##s ##wes ##try Di ##sa ##bility Index ( ODI ) . Two independent investigators extracted the following data from the included studies : first author ’ name , publication year , study design , country , number of patients in each group , patients ’ characteristics , and outcome data ( success rate , re ##cu ##rrence rate , com ##plication rate , operation time , hospital stay , blood loss , VA ##S scores for back pain and leg pain , J ##OA , SF ##12 - MC ##S / PC ##S , and ODI ) . If the study did not provide the important data , we would contact the corresponding authors for the missing information . We evaluated the risk of bias in RC ##T ##s with the method recommended by Cochrane Col ##la ##bor ##ation . [ 29 ] Five items , including blinding , method of random ##ization , allocation con - c ##eal ##ment , follow - up , and intention - to - treat analysis were used to assess the quality of study . [ 29 ] And each study was classified as high , low , or unclear risk of bias . We evaluated the method ##ological quality of non - random ##ized studies ( co ##hor ##t study , or case - control study ) using the modified Newcastle - Ottawa scale . [ 30 ] The total scale of this method was 9 points , and higher point indicated better quality . [ 30 ] Any study was considered to be high quality if the score was more than 5 points . Two independent investigators used the ST ##AT ##A version 12 . 0 ( St ##ata Corporation , College Station , TX , USA ) to perform the statistical analysis . Success rate , re ##cu ##rrence rate , and com ##p ##lica - t ##ion rate , were treated as di ##cho ##tom ##ous variables and were expressed as relative risk ( R ##R ) with 95 % confidence intervals . Operation time , hospital stay , blood loss , back - pain [SEP]\n",
      "I1208 12:27:37.028303 139883775852736 run_factoid.py:443] tokens: [CLS] What did the paper do ? [SEP] score ( MC ##S ) , Japanese Or ##th ##op ##ae ##dic Association Score ( J ##OA ) , O ##s ##wes ##try Di ##sa ##bility Index ( ODI ) . Two independent investigators extracted the following data from the included studies : first author ’ name , publication year , study design , country , number of patients in each group , patients ’ characteristics , and outcome data ( success rate , re ##cu ##rrence rate , com ##plication rate , operation time , hospital stay , blood loss , VA ##S scores for back pain and leg pain , J ##OA , SF ##12 - MC ##S / PC ##S , and ODI ) . If the study did not provide the important data , we would contact the corresponding authors for the missing information . We evaluated the risk of bias in RC ##T ##s with the method recommended by Cochrane Col ##la ##bor ##ation . [ 29 ] Five items , including blinding , method of random ##ization , allocation con - c ##eal ##ment , follow - up , and intention - to - treat analysis were used to assess the quality of study . [ 29 ] And each study was classified as high , low , or unclear risk of bias . We evaluated the method ##ological quality of non - random ##ized studies ( co ##hor ##t study , or case - control study ) using the modified Newcastle - Ottawa scale . [ 30 ] The total scale of this method was 9 points , and higher point indicated better quality . [ 30 ] Any study was considered to be high quality if the score was more than 5 points . Two independent investigators used the ST ##AT ##A version 12 . 0 ( St ##ata Corporation , College Station , TX , USA ) to perform the statistical analysis . Success rate , re ##cu ##rrence rate , and com ##p ##lica - t ##ion rate , were treated as di ##cho ##tom ##ous variables and were expressed as relative risk ( R ##R ) with 95 % confidence intervals . Operation time , hospital stay , blood loss , back - pain [SEP]\n",
      "INFO:tensorflow:token_to_orig_map: 8:235 9:236 10:236 11:236 12:236 13:236 14:237 15:238 16:238 17:238 18:238 19:238 20:239 21:240 22:241 23:241 24:241 25:241 26:241 27:242 28:242 29:242 30:242 31:243 32:243 33:243 34:244 35:245 36:245 37:245 38:245 39:246 40:247 41:248 42:249 43:250 44:251 45:252 46:253 47:254 48:255 49:256 50:256 51:257 52:258 53:258 54:259 55:259 56:260 57:261 58:261 59:262 60:263 61:263 62:264 63:264 64:265 65:266 66:267 67:268 68:269 69:270 70:270 71:271 72:271 73:272 74:272 75:273 76:274 77:275 78:276 79:276 80:277 81:277 82:278 83:278 84:278 85:279 86:279 87:280 88:280 89:281 90:281 91:282 92:283 93:283 94:284 95:285 96:285 97:286 98:287 99:287 100:288 101:288 102:289 103:290 104:291 105:292 106:293 107:294 108:295 109:295 110:296 111:296 112:296 113:297 114:297 115:297 116:297 117:297 118:297 119:297 120:297 121:297 122:298 123:299 124:299 125:299 126:300 127:301 128:302 129:303 130:304 131:305 132:306 133:307 134:308 135:308 136:309 137:310 138:311 139:312 140:313 141:314 142:315 143:316 144:317 145:318 146:318 147:319 148:320 149:321 150:322 151:323 152:324 153:325 154:326 155:326 156:326 157:327 158:328 159:329 160:330 161:331 162:332 163:333 164:333 165:333 166:333 167:333 168:333 169:333 170:333 171:334 172:335 173:335 174:336 175:337 176:337 177:338 178:339 179:340 180:340 181:340 182:341 183:342 184:342 185:343 186:343 187:343 188:343 189:344 190:344 191:344 192:344 193:345 194:346 195:346 196:346 197:346 198:346 199:347 200:348 201:349 202:350 203:351 204:352 205:353 206:354 207:355 208:355 209:355 210:355 211:355 212:356 213:357 214:358 215:359 216:360 217:361 218:362 219:362 220:363 221:363 222:364 223:365 224:366 225:367 226:368 227:368 228:369 229:370 230:371 231:372 232:372 233:373 234:374 235:375 236:375 237:375 238:375 239:376 240:377 241:377 242:377 243:377 244:378 245:378 246:379 247:380 248:380 249:380 250:381 251:381 252:382 253:383 254:384 255:385 256:385 257:385 258:386 259:386 260:386 261:386 262:386 263:387 264:388 265:389 266:390 267:391 268:392 269:393 270:394 271:395 272:395 273:396 274:397 275:398 276:399 277:400 278:401 279:401 280:401 281:401 282:401 283:402 284:403 285:404 286:405 287:406 288:407 289:408 290:409 291:410 292:411 293:412 294:413 295:414 296:415 297:416 298:417 299:417 300:418 301:419 302:420 303:421 304:422 305:423 306:423 307:423 308:424 309:425 310:425 311:425 312:426 313:426 314:426 315:427 316:427 317:428 318:429 319:429 320:430 321:430 322:431 323:431 324:432 325:433 326:434 327:435 328:436 329:436 330:437 331:438 332:438 333:439 334:439 335:439 336:440 337:440 338:441 339:442 340:442 341:442 342:442 343:443 344:443 345:444 346:444 347:445 348:446 349:447 350:448 351:448 352:448 353:448 354:449 355:450 356:451 357:452 358:453 359:454 360:455 361:456 362:456 363:456 364:456 365:457 366:458 367:458 368:459 369:460 370:460 371:461 372:462 373:462 374:463 375:464 376:464 377:465 378:466 379:466 380:467 381:467 382:467\n",
      "I1208 12:27:37.028419 139883775852736 run_factoid.py:445] token_to_orig_map: 8:235 9:236 10:236 11:236 12:236 13:236 14:237 15:238 16:238 17:238 18:238 19:238 20:239 21:240 22:241 23:241 24:241 25:241 26:241 27:242 28:242 29:242 30:242 31:243 32:243 33:243 34:244 35:245 36:245 37:245 38:245 39:246 40:247 41:248 42:249 43:250 44:251 45:252 46:253 47:254 48:255 49:256 50:256 51:257 52:258 53:258 54:259 55:259 56:260 57:261 58:261 59:262 60:263 61:263 62:264 63:264 64:265 65:266 66:267 67:268 68:269 69:270 70:270 71:271 72:271 73:272 74:272 75:273 76:274 77:275 78:276 79:276 80:277 81:277 82:278 83:278 84:278 85:279 86:279 87:280 88:280 89:281 90:281 91:282 92:283 93:283 94:284 95:285 96:285 97:286 98:287 99:287 100:288 101:288 102:289 103:290 104:291 105:292 106:293 107:294 108:295 109:295 110:296 111:296 112:296 113:297 114:297 115:297 116:297 117:297 118:297 119:297 120:297 121:297 122:298 123:299 124:299 125:299 126:300 127:301 128:302 129:303 130:304 131:305 132:306 133:307 134:308 135:308 136:309 137:310 138:311 139:312 140:313 141:314 142:315 143:316 144:317 145:318 146:318 147:319 148:320 149:321 150:322 151:323 152:324 153:325 154:326 155:326 156:326 157:327 158:328 159:329 160:330 161:331 162:332 163:333 164:333 165:333 166:333 167:333 168:333 169:333 170:333 171:334 172:335 173:335 174:336 175:337 176:337 177:338 178:339 179:340 180:340 181:340 182:341 183:342 184:342 185:343 186:343 187:343 188:343 189:344 190:344 191:344 192:344 193:345 194:346 195:346 196:346 197:346 198:346 199:347 200:348 201:349 202:350 203:351 204:352 205:353 206:354 207:355 208:355 209:355 210:355 211:355 212:356 213:357 214:358 215:359 216:360 217:361 218:362 219:362 220:363 221:363 222:364 223:365 224:366 225:367 226:368 227:368 228:369 229:370 230:371 231:372 232:372 233:373 234:374 235:375 236:375 237:375 238:375 239:376 240:377 241:377 242:377 243:377 244:378 245:378 246:379 247:380 248:380 249:380 250:381 251:381 252:382 253:383 254:384 255:385 256:385 257:385 258:386 259:386 260:386 261:386 262:386 263:387 264:388 265:389 266:390 267:391 268:392 269:393 270:394 271:395 272:395 273:396 274:397 275:398 276:399 277:400 278:401 279:401 280:401 281:401 282:401 283:402 284:403 285:404 286:405 287:406 288:407 289:408 290:409 291:410 292:411 293:412 294:413 295:414 296:415 297:416 298:417 299:417 300:418 301:419 302:420 303:421 304:422 305:423 306:423 307:423 308:424 309:425 310:425 311:425 312:426 313:426 314:426 315:427 316:427 317:428 318:429 319:429 320:430 321:430 322:431 323:431 324:432 325:433 326:434 327:435 328:436 329:436 330:437 331:438 332:438 333:439 334:439 335:439 336:440 337:440 338:441 339:442 340:442 341:442 342:442 343:443 344:443 345:444 346:444 347:445 348:446 349:447 350:448 351:448 352:448 353:448 354:449 355:450 356:451 357:452 358:453 359:454 360:455 361:456 362:456 363:456 364:456 365:457 366:458 367:458 368:459 369:460 370:460 371:461 372:462 373:462 374:463 375:464 376:464 377:465 378:466 379:466 380:467 381:467 382:467\n",
      "INFO:tensorflow:token_is_max_context: 8:False 9:False 10:False 11:False 12:False 13:False 14:False 15:False 16:False 17:False 18:False 19:False 20:False 21:False 22:False 23:False 24:False 25:False 26:False 27:False 28:False 29:False 30:False 31:False 32:False 33:False 34:False 35:False 36:False 37:False 38:False 39:False 40:False 41:False 42:False 43:False 44:False 45:False 46:False 47:False 48:False 49:False 50:False 51:False 52:False 53:False 54:False 55:False 56:False 57:False 58:False 59:False 60:False 61:False 62:False 63:False 64:False 65:False 66:False 67:False 68:False 69:False 70:False 71:False 72:False 73:False 74:False 75:False 76:False 77:False 78:False 79:False 80:False 81:False 82:False 83:False 84:False 85:False 86:False 87:False 88:False 89:False 90:False 91:False 92:False 93:False 94:False 95:False 96:False 97:False 98:False 99:False 100:False 101:False 102:False 103:False 104:False 105:False 106:False 107:False 108:False 109:False 110:False 111:False 112:False 113:False 114:False 115:False 116:False 117:False 118:False 119:False 120:False 121:False 122:False 123:False 124:False 125:False 126:False 127:False 128:False 129:False 130:False 131:False 132:True 133:True 134:True 135:True 136:True 137:True 138:True 139:True 140:True 141:True 142:True 143:True 144:True 145:True 146:True 147:True 148:True 149:True 150:True 151:True 152:True 153:True 154:True 155:True 156:True 157:True 158:True 159:True 160:True 161:True 162:True 163:True 164:True 165:True 166:True 167:True 168:True 169:True 170:True 171:True 172:True 173:True 174:True 175:True 176:True 177:True 178:True 179:True 180:True 181:True 182:True 183:True 184:True 185:True 186:True 187:True 188:True 189:True 190:True 191:True 192:True 193:True 194:True 195:True 196:True 197:True 198:True 199:True 200:True 201:True 202:True 203:True 204:True 205:True 206:True 207:True 208:True 209:True 210:True 211:True 212:True 213:True 214:True 215:True 216:True 217:True 218:True 219:True 220:True 221:True 222:True 223:True 224:True 225:True 226:True 227:True 228:True 229:True 230:True 231:True 232:True 233:True 234:True 235:True 236:True 237:True 238:True 239:True 240:True 241:True 242:True 243:True 244:True 245:True 246:True 247:True 248:True 249:True 250:True 251:True 252:True 253:True 254:True 255:True 256:True 257:True 258:True 259:True 260:False 261:False 262:False 263:False 264:False 265:False 266:False 267:False 268:False 269:False 270:False 271:False 272:False 273:False 274:False 275:False 276:False 277:False 278:False 279:False 280:False 281:False 282:False 283:False 284:False 285:False 286:False 287:False 288:False 289:False 290:False 291:False 292:False 293:False 294:False 295:False 296:False 297:False 298:False 299:False 300:False 301:False 302:False 303:False 304:False 305:False 306:False 307:False 308:False 309:False 310:False 311:False 312:False 313:False 314:False 315:False 316:False 317:False 318:False 319:False 320:False 321:False 322:False 323:False 324:False 325:False 326:False 327:False 328:False 329:False 330:False 331:False 332:False 333:False 334:False 335:False 336:False 337:False 338:False 339:False 340:False 341:False 342:False 343:False 344:False 345:False 346:False 347:False 348:False 349:False 350:False 351:False 352:False 353:False 354:False 355:False 356:False 357:False 358:False 359:False 360:False 361:False 362:False 363:False 364:False 365:False 366:False 367:False 368:False 369:False 370:False 371:False 372:False 373:False 374:False 375:False 376:False 377:False 378:False 379:False 380:False 381:False 382:False\n",
      "I1208 12:27:37.028527 139883775852736 run_factoid.py:447] token_is_max_context: 8:False 9:False 10:False 11:False 12:False 13:False 14:False 15:False 16:False 17:False 18:False 19:False 20:False 21:False 22:False 23:False 24:False 25:False 26:False 27:False 28:False 29:False 30:False 31:False 32:False 33:False 34:False 35:False 36:False 37:False 38:False 39:False 40:False 41:False 42:False 43:False 44:False 45:False 46:False 47:False 48:False 49:False 50:False 51:False 52:False 53:False 54:False 55:False 56:False 57:False 58:False 59:False 60:False 61:False 62:False 63:False 64:False 65:False 66:False 67:False 68:False 69:False 70:False 71:False 72:False 73:False 74:False 75:False 76:False 77:False 78:False 79:False 80:False 81:False 82:False 83:False 84:False 85:False 86:False 87:False 88:False 89:False 90:False 91:False 92:False 93:False 94:False 95:False 96:False 97:False 98:False 99:False 100:False 101:False 102:False 103:False 104:False 105:False 106:False 107:False 108:False 109:False 110:False 111:False 112:False 113:False 114:False 115:False 116:False 117:False 118:False 119:False 120:False 121:False 122:False 123:False 124:False 125:False 126:False 127:False 128:False 129:False 130:False 131:False 132:True 133:True 134:True 135:True 136:True 137:True 138:True 139:True 140:True 141:True 142:True 143:True 144:True 145:True 146:True 147:True 148:True 149:True 150:True 151:True 152:True 153:True 154:True 155:True 156:True 157:True 158:True 159:True 160:True 161:True 162:True 163:True 164:True 165:True 166:True 167:True 168:True 169:True 170:True 171:True 172:True 173:True 174:True 175:True 176:True 177:True 178:True 179:True 180:True 181:True 182:True 183:True 184:True 185:True 186:True 187:True 188:True 189:True 190:True 191:True 192:True 193:True 194:True 195:True 196:True 197:True 198:True 199:True 200:True 201:True 202:True 203:True 204:True 205:True 206:True 207:True 208:True 209:True 210:True 211:True 212:True 213:True 214:True 215:True 216:True 217:True 218:True 219:True 220:True 221:True 222:True 223:True 224:True 225:True 226:True 227:True 228:True 229:True 230:True 231:True 232:True 233:True 234:True 235:True 236:True 237:True 238:True 239:True 240:True 241:True 242:True 243:True 244:True 245:True 246:True 247:True 248:True 249:True 250:True 251:True 252:True 253:True 254:True 255:True 256:True 257:True 258:True 259:True 260:False 261:False 262:False 263:False 264:False 265:False 266:False 267:False 268:False 269:False 270:False 271:False 272:False 273:False 274:False 275:False 276:False 277:False 278:False 279:False 280:False 281:False 282:False 283:False 284:False 285:False 286:False 287:False 288:False 289:False 290:False 291:False 292:False 293:False 294:False 295:False 296:False 297:False 298:False 299:False 300:False 301:False 302:False 303:False 304:False 305:False 306:False 307:False 308:False 309:False 310:False 311:False 312:False 313:False 314:False 315:False 316:False 317:False 318:False 319:False 320:False 321:False 322:False 323:False 324:False 325:False 326:False 327:False 328:False 329:False 330:False 331:False 332:False 333:False 334:False 335:False 336:False 337:False 338:False 339:False 340:False 341:False 342:False 343:False 344:False 345:False 346:False 347:False 348:False 349:False 350:False 351:False 352:False 353:False 354:False 355:False 356:False 357:False 358:False 359:False 360:False 361:False 362:False 363:False 364:False 365:False 366:False 367:False 368:False 369:False 370:False 371:False 372:False 373:False 374:False 375:False 376:False 377:False 378:False 379:False 380:False 381:False 382:False\n",
      "INFO:tensorflow:input_ids: 101 1327 1225 1103 2526 1202 136 102 2794 113 12029 1708 114 117 1983 2926 1582 4184 5024 13328 1791 18417 113 147 23579 114 117 152 1116 14291 6013 12120 3202 5474 10146 113 23882 114 119 1960 2457 17718 16939 1103 1378 2233 1121 1103 1529 2527 131 1148 2351 787 1271 117 4128 1214 117 2025 1902 117 1583 117 1295 1104 4420 1107 1296 1372 117 4420 787 5924 117 1105 9386 2233 113 2244 2603 117 1231 10182 21629 2603 117 3254 15534 2603 117 2805 1159 117 2704 2215 117 1892 2445 117 19497 1708 7432 1111 1171 2489 1105 3420 2489 117 147 23579 117 18659 11964 118 12029 1708 120 7054 1708 117 1105 23882 114 119 1409 1103 2025 1225 1136 2194 1103 1696 2233 117 1195 1156 3232 1103 7671 5752 1111 1103 3764 1869 119 1284 17428 1103 3187 1104 15069 1107 25157 1942 1116 1114 1103 3442 6315 1118 24763 9518 1742 12207 1891 119 164 1853 166 4222 4454 117 1259 22350 117 3442 1104 7091 2734 117 18205 14255 118 172 13003 1880 117 2812 118 1146 117 1105 6247 118 1106 118 7299 3622 1127 1215 1106 15187 1103 3068 1104 2025 119 164 1853 166 1262 1296 2025 1108 5667 1112 1344 117 1822 117 1137 10527 3187 1104 15069 119 1284 17428 1103 3442 7542 3068 1104 1664 118 7091 2200 2527 113 1884 13252 1204 2025 117 1137 1692 118 1654 2025 114 1606 1103 5847 7685 118 7711 3418 119 164 1476 166 1109 1703 3418 1104 1142 3442 1108 130 1827 117 1105 2299 1553 4668 1618 3068 119 164 1476 166 6291 2025 1108 1737 1106 1129 1344 3068 1191 1103 2794 1108 1167 1190 126 1827 119 1960 2457 17718 1215 1103 23676 13821 1592 1683 1367 119 121 113 1457 6575 3436 117 1531 2874 117 21514 117 3066 114 1106 3870 1103 11435 3622 119 25911 2603 117 1231 10182 21629 2603 117 1105 3254 1643 9538 118 189 1988 2603 117 1127 5165 1112 4267 8401 18778 2285 10986 1105 1127 4448 1112 5236 3187 113 155 2069 114 1114 4573 110 6595 14662 119 5158 1159 117 2704 2215 117 1892 2445 117 1171 118 2489 102\n",
      "I1208 12:27:37.028628 139883775852736 run_factoid.py:449] input_ids: 101 1327 1225 1103 2526 1202 136 102 2794 113 12029 1708 114 117 1983 2926 1582 4184 5024 13328 1791 18417 113 147 23579 114 117 152 1116 14291 6013 12120 3202 5474 10146 113 23882 114 119 1960 2457 17718 16939 1103 1378 2233 1121 1103 1529 2527 131 1148 2351 787 1271 117 4128 1214 117 2025 1902 117 1583 117 1295 1104 4420 1107 1296 1372 117 4420 787 5924 117 1105 9386 2233 113 2244 2603 117 1231 10182 21629 2603 117 3254 15534 2603 117 2805 1159 117 2704 2215 117 1892 2445 117 19497 1708 7432 1111 1171 2489 1105 3420 2489 117 147 23579 117 18659 11964 118 12029 1708 120 7054 1708 117 1105 23882 114 119 1409 1103 2025 1225 1136 2194 1103 1696 2233 117 1195 1156 3232 1103 7671 5752 1111 1103 3764 1869 119 1284 17428 1103 3187 1104 15069 1107 25157 1942 1116 1114 1103 3442 6315 1118 24763 9518 1742 12207 1891 119 164 1853 166 4222 4454 117 1259 22350 117 3442 1104 7091 2734 117 18205 14255 118 172 13003 1880 117 2812 118 1146 117 1105 6247 118 1106 118 7299 3622 1127 1215 1106 15187 1103 3068 1104 2025 119 164 1853 166 1262 1296 2025 1108 5667 1112 1344 117 1822 117 1137 10527 3187 1104 15069 119 1284 17428 1103 3442 7542 3068 1104 1664 118 7091 2200 2527 113 1884 13252 1204 2025 117 1137 1692 118 1654 2025 114 1606 1103 5847 7685 118 7711 3418 119 164 1476 166 1109 1703 3418 1104 1142 3442 1108 130 1827 117 1105 2299 1553 4668 1618 3068 119 164 1476 166 6291 2025 1108 1737 1106 1129 1344 3068 1191 1103 2794 1108 1167 1190 126 1827 119 1960 2457 17718 1215 1103 23676 13821 1592 1683 1367 119 121 113 1457 6575 3436 117 1531 2874 117 21514 117 3066 114 1106 3870 1103 11435 3622 119 25911 2603 117 1231 10182 21629 2603 117 1105 3254 1643 9538 118 189 1988 2603 117 1127 5165 1112 4267 8401 18778 2285 10986 1105 1127 4448 1112 5236 3187 113 155 2069 114 1114 4573 110 6595 14662 119 5158 1159 117 2704 2215 117 1892 2445 117 1171 118 2489 102\n",
      "INFO:tensorflow:input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      "I1208 12:27:37.028724 139883775852736 run_factoid.py:451] input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      "INFO:tensorflow:segment_ids: 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      "I1208 12:27:37.028813 139883775852736 run_factoid.py:453] segment_ids: 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      "INFO:tensorflow:*** Example ***\n",
      "I1208 12:27:37.030299 139883775852736 run_factoid.py:438] *** Example ***\n",
      "INFO:tensorflow:unique_id: 1000000016\n",
      "I1208 12:27:37.030356 139883775852736 run_factoid.py:439] unique_id: 1000000016\n",
      "INFO:tensorflow:example_index: 5\n",
      "I1208 12:27:37.030394 139883775852736 run_factoid.py:440] example_index: 5\n",
      "INFO:tensorflow:doc_span_index: 5\n",
      "I1208 12:27:37.030428 139883775852736 run_factoid.py:441] doc_span_index: 5\n",
      "INFO:tensorflow:tokens: [CLS] What did the paper do ? [SEP] we would contact the corresponding authors for the missing information . We evaluated the risk of bias in RC ##T ##s with the method recommended by Cochrane Col ##la ##bor ##ation . [ 29 ] Five items , including blinding , method of random ##ization , allocation con - c ##eal ##ment , follow - up , and intention - to - treat analysis were used to assess the quality of study . [ 29 ] And each study was classified as high , low , or unclear risk of bias . We evaluated the method ##ological quality of non - random ##ized studies ( co ##hor ##t study , or case - control study ) using the modified Newcastle - Ottawa scale . [ 30 ] The total scale of this method was 9 points , and higher point indicated better quality . [ 30 ] Any study was considered to be high quality if the score was more than 5 points . Two independent investigators used the ST ##AT ##A version 12 . 0 ( St ##ata Corporation , College Station , TX , USA ) to perform the statistical analysis . Success rate , re ##cu ##rrence rate , and com ##p ##lica - t ##ion rate , were treated as di ##cho ##tom ##ous variables and were expressed as relative risk ( R ##R ) with 95 % confidence intervals . Operation time , hospital stay , blood loss , back - pain VA ##S score , leg - pain VA ##S score , J ##OA score , and SF ##12 - MC ##S / PC ##S , were treated as continuous variables , thus they were expressed as weighted mean difference ( W ##MD ) with 95 % confidence intervals . Before the data were pool ##ed , Q - s ##tat ##istic and I ##2 s ##tat ##istic were used to detect the he ##tero ##gene ##ity among the studies , in which a P value < . 10 or I ##2 > 50 % were defined as significant he ##tero ##gene ##ity . Poole ##d estimates were generated by using a fixed - effects model ( Man ##tel – Ha ##ens ##zel method ) [ 31 ] or [SEP]\n",
      "I1208 12:27:37.030545 139883775852736 run_factoid.py:443] tokens: [CLS] What did the paper do ? [SEP] we would contact the corresponding authors for the missing information . We evaluated the risk of bias in RC ##T ##s with the method recommended by Cochrane Col ##la ##bor ##ation . [ 29 ] Five items , including blinding , method of random ##ization , allocation con - c ##eal ##ment , follow - up , and intention - to - treat analysis were used to assess the quality of study . [ 29 ] And each study was classified as high , low , or unclear risk of bias . We evaluated the method ##ological quality of non - random ##ized studies ( co ##hor ##t study , or case - control study ) using the modified Newcastle - Ottawa scale . [ 30 ] The total scale of this method was 9 points , and higher point indicated better quality . [ 30 ] Any study was considered to be high quality if the score was more than 5 points . Two independent investigators used the ST ##AT ##A version 12 . 0 ( St ##ata Corporation , College Station , TX , USA ) to perform the statistical analysis . Success rate , re ##cu ##rrence rate , and com ##p ##lica - t ##ion rate , were treated as di ##cho ##tom ##ous variables and were expressed as relative risk ( R ##R ) with 95 % confidence intervals . Operation time , hospital stay , blood loss , back - pain VA ##S score , leg - pain VA ##S score , J ##OA score , and SF ##12 - MC ##S / PC ##S , were treated as continuous variables , thus they were expressed as weighted mean difference ( W ##MD ) with 95 % confidence intervals . Before the data were pool ##ed , Q - s ##tat ##istic and I ##2 s ##tat ##istic were used to detect the he ##tero ##gene ##ity among the studies , in which a P value < . 10 or I ##2 > 50 % were defined as significant he ##tero ##gene ##ity . Poole ##d estimates were generated by using a fixed - effects model ( Man ##tel – Ha ##ens ##zel method ) [ 31 ] or [SEP]\n",
      "INFO:tensorflow:token_to_orig_map: 8:309 9:310 10:311 11:312 12:313 13:314 14:315 15:316 16:317 17:318 18:318 19:319 20:320 21:321 22:322 23:323 24:324 25:325 26:326 27:326 28:326 29:327 30:328 31:329 32:330 33:331 34:332 35:333 36:333 37:333 38:333 39:333 40:333 41:333 42:333 43:334 44:335 45:335 46:336 47:337 48:337 49:338 50:339 51:340 52:340 53:340 54:341 55:342 56:342 57:343 58:343 59:343 60:343 61:344 62:344 63:344 64:344 65:345 66:346 67:346 68:346 69:346 70:346 71:347 72:348 73:349 74:350 75:351 76:352 77:353 78:354 79:355 80:355 81:355 82:355 83:355 84:356 85:357 86:358 87:359 88:360 89:361 90:362 91:362 92:363 93:363 94:364 95:365 96:366 97:367 98:368 99:368 100:369 101:370 102:371 103:372 104:372 105:373 106:374 107:375 108:375 109:375 110:375 111:376 112:377 113:377 114:377 115:377 116:378 117:378 118:379 119:380 120:380 121:380 122:381 123:381 124:382 125:383 126:384 127:385 128:385 129:385 130:386 131:386 132:386 133:386 134:386 135:387 136:388 137:389 138:390 139:391 140:392 141:393 142:394 143:395 144:395 145:396 146:397 147:398 148:399 149:400 150:401 151:401 152:401 153:401 154:401 155:402 156:403 157:404 158:405 159:406 160:407 161:408 162:409 163:410 164:411 165:412 166:413 167:414 168:415 169:416 170:417 171:417 172:418 173:419 174:420 175:421 176:422 177:423 178:423 179:423 180:424 181:425 182:425 183:425 184:426 185:426 186:426 187:427 188:427 189:428 190:429 191:429 192:430 193:430 194:431 195:431 196:432 197:433 198:434 199:435 200:436 201:436 202:437 203:438 204:438 205:439 206:439 207:439 208:440 209:440 210:441 211:442 212:442 213:442 214:442 215:443 216:443 217:444 218:444 219:445 220:446 221:447 222:448 223:448 224:448 225:448 226:449 227:450 228:451 229:452 230:453 231:454 232:455 233:456 234:456 235:456 236:456 237:457 238:458 239:458 240:459 241:460 242:460 243:461 244:462 245:462 246:463 247:464 248:464 249:465 250:466 251:466 252:467 253:467 254:467 255:468 256:468 257:469 258:469 259:470 260:470 261:470 262:471 263:471 264:472 265:472 266:473 267:473 268:474 269:474 270:475 271:476 272:476 273:476 274:476 275:476 276:476 277:476 278:476 279:476 280:477 281:478 282:479 283:480 284:481 285:481 286:482 287:483 288:484 289:485 290:486 291:487 292:488 293:489 294:490 295:490 296:490 297:490 298:491 299:492 300:492 301:493 302:494 303:494 304:495 305:496 306:497 307:498 308:499 309:499 310:499 311:500 312:500 313:500 314:500 315:500 316:501 317:502 318:502 319:503 320:503 321:503 322:504 323:505 324:506 325:507 326:508 327:509 328:509 329:509 330:509 331:510 332:511 333:512 334:512 335:513 336:514 337:515 338:516 339:517 340:518 341:519 342:519 343:520 344:521 345:521 346:522 347:523 348:523 349:524 350:525 351:526 352:527 353:528 354:528 355:528 356:528 357:528 358:529 359:529 360:530 361:531 362:532 363:533 364:534 365:535 366:536 367:536 368:536 369:537 370:538 371:538 372:538 373:538 374:538 375:538 376:538 377:539 378:539 379:539 380:539 381:539 382:540\n",
      "I1208 12:27:37.030667 139883775852736 run_factoid.py:445] token_to_orig_map: 8:309 9:310 10:311 11:312 12:313 13:314 14:315 15:316 16:317 17:318 18:318 19:319 20:320 21:321 22:322 23:323 24:324 25:325 26:326 27:326 28:326 29:327 30:328 31:329 32:330 33:331 34:332 35:333 36:333 37:333 38:333 39:333 40:333 41:333 42:333 43:334 44:335 45:335 46:336 47:337 48:337 49:338 50:339 51:340 52:340 53:340 54:341 55:342 56:342 57:343 58:343 59:343 60:343 61:344 62:344 63:344 64:344 65:345 66:346 67:346 68:346 69:346 70:346 71:347 72:348 73:349 74:350 75:351 76:352 77:353 78:354 79:355 80:355 81:355 82:355 83:355 84:356 85:357 86:358 87:359 88:360 89:361 90:362 91:362 92:363 93:363 94:364 95:365 96:366 97:367 98:368 99:368 100:369 101:370 102:371 103:372 104:372 105:373 106:374 107:375 108:375 109:375 110:375 111:376 112:377 113:377 114:377 115:377 116:378 117:378 118:379 119:380 120:380 121:380 122:381 123:381 124:382 125:383 126:384 127:385 128:385 129:385 130:386 131:386 132:386 133:386 134:386 135:387 136:388 137:389 138:390 139:391 140:392 141:393 142:394 143:395 144:395 145:396 146:397 147:398 148:399 149:400 150:401 151:401 152:401 153:401 154:401 155:402 156:403 157:404 158:405 159:406 160:407 161:408 162:409 163:410 164:411 165:412 166:413 167:414 168:415 169:416 170:417 171:417 172:418 173:419 174:420 175:421 176:422 177:423 178:423 179:423 180:424 181:425 182:425 183:425 184:426 185:426 186:426 187:427 188:427 189:428 190:429 191:429 192:430 193:430 194:431 195:431 196:432 197:433 198:434 199:435 200:436 201:436 202:437 203:438 204:438 205:439 206:439 207:439 208:440 209:440 210:441 211:442 212:442 213:442 214:442 215:443 216:443 217:444 218:444 219:445 220:446 221:447 222:448 223:448 224:448 225:448 226:449 227:450 228:451 229:452 230:453 231:454 232:455 233:456 234:456 235:456 236:456 237:457 238:458 239:458 240:459 241:460 242:460 243:461 244:462 245:462 246:463 247:464 248:464 249:465 250:466 251:466 252:467 253:467 254:467 255:468 256:468 257:469 258:469 259:470 260:470 261:470 262:471 263:471 264:472 265:472 266:473 267:473 268:474 269:474 270:475 271:476 272:476 273:476 274:476 275:476 276:476 277:476 278:476 279:476 280:477 281:478 282:479 283:480 284:481 285:481 286:482 287:483 288:484 289:485 290:486 291:487 292:488 293:489 294:490 295:490 296:490 297:490 298:491 299:492 300:492 301:493 302:494 303:494 304:495 305:496 306:497 307:498 308:499 309:499 310:499 311:500 312:500 313:500 314:500 315:500 316:501 317:502 318:502 319:503 320:503 321:503 322:504 323:505 324:506 325:507 326:508 327:509 328:509 329:509 330:509 331:510 332:511 333:512 334:512 335:513 336:514 337:515 338:516 339:517 340:518 341:519 342:519 343:520 344:521 345:521 346:522 347:523 348:523 349:524 350:525 351:526 352:527 353:528 354:528 355:528 356:528 357:528 358:529 359:529 360:530 361:531 362:532 363:533 364:534 365:535 366:536 367:536 368:536 369:537 370:538 371:538 372:538 373:538 374:538 375:538 376:538 377:539 378:539 379:539 380:539 381:539 382:540\n",
      "INFO:tensorflow:token_is_max_context: 8:False 9:False 10:False 11:False 12:False 13:False 14:False 15:False 16:False 17:False 18:False 19:False 20:False 21:False 22:False 23:False 24:False 25:False 26:False 27:False 28:False 29:False 30:False 31:False 32:False 33:False 34:False 35:False 36:False 37:False 38:False 39:False 40:False 41:False 42:False 43:False 44:False 45:False 46:False 47:False 48:False 49:False 50:False 51:False 52:False 53:False 54:False 55:False 56:False 57:False 58:False 59:False 60:False 61:False 62:False 63:False 64:False 65:False 66:False 67:False 68:False 69:False 70:False 71:False 72:False 73:False 74:False 75:False 76:False 77:False 78:False 79:False 80:False 81:False 82:False 83:False 84:False 85:False 86:False 87:False 88:False 89:False 90:False 91:False 92:False 93:False 94:False 95:False 96:False 97:False 98:False 99:False 100:False 101:False 102:False 103:False 104:False 105:False 106:False 107:False 108:False 109:False 110:False 111:False 112:False 113:False 114:False 115:False 116:False 117:False 118:False 119:False 120:False 121:False 122:False 123:False 124:False 125:False 126:False 127:False 128:False 129:False 130:False 131:False 132:True 133:True 134:True 135:True 136:True 137:True 138:True 139:True 140:True 141:True 142:True 143:True 144:True 145:True 146:True 147:True 148:True 149:True 150:True 151:True 152:True 153:True 154:True 155:True 156:True 157:True 158:True 159:True 160:True 161:True 162:True 163:True 164:True 165:True 166:True 167:True 168:True 169:True 170:True 171:True 172:True 173:True 174:True 175:True 176:True 177:True 178:True 179:True 180:True 181:True 182:True 183:True 184:True 185:True 186:True 187:True 188:True 189:True 190:True 191:True 192:True 193:True 194:True 195:True 196:True 197:True 198:True 199:True 200:True 201:True 202:True 203:True 204:True 205:True 206:True 207:True 208:True 209:True 210:True 211:True 212:True 213:True 214:True 215:True 216:True 217:True 218:True 219:True 220:True 221:True 222:True 223:True 224:True 225:True 226:True 227:True 228:True 229:True 230:True 231:True 232:True 233:True 234:True 235:True 236:True 237:True 238:True 239:True 240:True 241:True 242:True 243:True 244:True 245:True 246:True 247:True 248:True 249:True 250:True 251:True 252:True 253:True 254:True 255:True 256:True 257:True 258:True 259:True 260:False 261:False 262:False 263:False 264:False 265:False 266:False 267:False 268:False 269:False 270:False 271:False 272:False 273:False 274:False 275:False 276:False 277:False 278:False 279:False 280:False 281:False 282:False 283:False 284:False 285:False 286:False 287:False 288:False 289:False 290:False 291:False 292:False 293:False 294:False 295:False 296:False 297:False 298:False 299:False 300:False 301:False 302:False 303:False 304:False 305:False 306:False 307:False 308:False 309:False 310:False 311:False 312:False 313:False 314:False 315:False 316:False 317:False 318:False 319:False 320:False 321:False 322:False 323:False 324:False 325:False 326:False 327:False 328:False 329:False 330:False 331:False 332:False 333:False 334:False 335:False 336:False 337:False 338:False 339:False 340:False 341:False 342:False 343:False 344:False 345:False 346:False 347:False 348:False 349:False 350:False 351:False 352:False 353:False 354:False 355:False 356:False 357:False 358:False 359:False 360:False 361:False 362:False 363:False 364:False 365:False 366:False 367:False 368:False 369:False 370:False 371:False 372:False 373:False 374:False 375:False 376:False 377:False 378:False 379:False 380:False 381:False 382:False\n",
      "I1208 12:27:37.030774 139883775852736 run_factoid.py:447] token_is_max_context: 8:False 9:False 10:False 11:False 12:False 13:False 14:False 15:False 16:False 17:False 18:False 19:False 20:False 21:False 22:False 23:False 24:False 25:False 26:False 27:False 28:False 29:False 30:False 31:False 32:False 33:False 34:False 35:False 36:False 37:False 38:False 39:False 40:False 41:False 42:False 43:False 44:False 45:False 46:False 47:False 48:False 49:False 50:False 51:False 52:False 53:False 54:False 55:False 56:False 57:False 58:False 59:False 60:False 61:False 62:False 63:False 64:False 65:False 66:False 67:False 68:False 69:False 70:False 71:False 72:False 73:False 74:False 75:False 76:False 77:False 78:False 79:False 80:False 81:False 82:False 83:False 84:False 85:False 86:False 87:False 88:False 89:False 90:False 91:False 92:False 93:False 94:False 95:False 96:False 97:False 98:False 99:False 100:False 101:False 102:False 103:False 104:False 105:False 106:False 107:False 108:False 109:False 110:False 111:False 112:False 113:False 114:False 115:False 116:False 117:False 118:False 119:False 120:False 121:False 122:False 123:False 124:False 125:False 126:False 127:False 128:False 129:False 130:False 131:False 132:True 133:True 134:True 135:True 136:True 137:True 138:True 139:True 140:True 141:True 142:True 143:True 144:True 145:True 146:True 147:True 148:True 149:True 150:True 151:True 152:True 153:True 154:True 155:True 156:True 157:True 158:True 159:True 160:True 161:True 162:True 163:True 164:True 165:True 166:True 167:True 168:True 169:True 170:True 171:True 172:True 173:True 174:True 175:True 176:True 177:True 178:True 179:True 180:True 181:True 182:True 183:True 184:True 185:True 186:True 187:True 188:True 189:True 190:True 191:True 192:True 193:True 194:True 195:True 196:True 197:True 198:True 199:True 200:True 201:True 202:True 203:True 204:True 205:True 206:True 207:True 208:True 209:True 210:True 211:True 212:True 213:True 214:True 215:True 216:True 217:True 218:True 219:True 220:True 221:True 222:True 223:True 224:True 225:True 226:True 227:True 228:True 229:True 230:True 231:True 232:True 233:True 234:True 235:True 236:True 237:True 238:True 239:True 240:True 241:True 242:True 243:True 244:True 245:True 246:True 247:True 248:True 249:True 250:True 251:True 252:True 253:True 254:True 255:True 256:True 257:True 258:True 259:True 260:False 261:False 262:False 263:False 264:False 265:False 266:False 267:False 268:False 269:False 270:False 271:False 272:False 273:False 274:False 275:False 276:False 277:False 278:False 279:False 280:False 281:False 282:False 283:False 284:False 285:False 286:False 287:False 288:False 289:False 290:False 291:False 292:False 293:False 294:False 295:False 296:False 297:False 298:False 299:False 300:False 301:False 302:False 303:False 304:False 305:False 306:False 307:False 308:False 309:False 310:False 311:False 312:False 313:False 314:False 315:False 316:False 317:False 318:False 319:False 320:False 321:False 322:False 323:False 324:False 325:False 326:False 327:False 328:False 329:False 330:False 331:False 332:False 333:False 334:False 335:False 336:False 337:False 338:False 339:False 340:False 341:False 342:False 343:False 344:False 345:False 346:False 347:False 348:False 349:False 350:False 351:False 352:False 353:False 354:False 355:False 356:False 357:False 358:False 359:False 360:False 361:False 362:False 363:False 364:False 365:False 366:False 367:False 368:False 369:False 370:False 371:False 372:False 373:False 374:False 375:False 376:False 377:False 378:False 379:False 380:False 381:False 382:False\n",
      "INFO:tensorflow:input_ids: 101 1327 1225 1103 2526 1202 136 102 1195 1156 3232 1103 7671 5752 1111 1103 3764 1869 119 1284 17428 1103 3187 1104 15069 1107 25157 1942 1116 1114 1103 3442 6315 1118 24763 9518 1742 12207 1891 119 164 1853 166 4222 4454 117 1259 22350 117 3442 1104 7091 2734 117 18205 14255 118 172 13003 1880 117 2812 118 1146 117 1105 6247 118 1106 118 7299 3622 1127 1215 1106 15187 1103 3068 1104 2025 119 164 1853 166 1262 1296 2025 1108 5667 1112 1344 117 1822 117 1137 10527 3187 1104 15069 119 1284 17428 1103 3442 7542 3068 1104 1664 118 7091 2200 2527 113 1884 13252 1204 2025 117 1137 1692 118 1654 2025 114 1606 1103 5847 7685 118 7711 3418 119 164 1476 166 1109 1703 3418 1104 1142 3442 1108 130 1827 117 1105 2299 1553 4668 1618 3068 119 164 1476 166 6291 2025 1108 1737 1106 1129 1344 3068 1191 1103 2794 1108 1167 1190 126 1827 119 1960 2457 17718 1215 1103 23676 13821 1592 1683 1367 119 121 113 1457 6575 3436 117 1531 2874 117 21514 117 3066 114 1106 3870 1103 11435 3622 119 25911 2603 117 1231 10182 21629 2603 117 1105 3254 1643 9538 118 189 1988 2603 117 1127 5165 1112 4267 8401 18778 2285 10986 1105 1127 4448 1112 5236 3187 113 155 2069 114 1114 4573 110 6595 14662 119 5158 1159 117 2704 2215 117 1892 2445 117 1171 118 2489 19497 1708 2794 117 3420 118 2489 19497 1708 2794 117 147 23579 2794 117 1105 18659 11964 118 12029 1708 120 7054 1708 117 1127 5165 1112 6803 10986 117 2456 1152 1127 4448 1112 20167 1928 3719 113 160 18219 114 1114 4573 110 6595 14662 119 2577 1103 2233 1127 4528 1174 117 154 118 188 19756 5562 1105 146 1477 188 19756 5562 1127 1215 1106 11552 1103 1119 25710 27054 1785 1621 1103 2527 117 1107 1134 170 153 2860 133 119 1275 1137 146 1477 135 1851 110 1127 3393 1112 2418 1119 25710 27054 1785 119 20784 1181 10777 1127 6455 1118 1606 170 4275 118 3154 2235 113 2268 7854 782 11679 5026 13430 3442 114 164 1955 166 1137 102\n",
      "I1208 12:27:37.030878 139883775852736 run_factoid.py:449] input_ids: 101 1327 1225 1103 2526 1202 136 102 1195 1156 3232 1103 7671 5752 1111 1103 3764 1869 119 1284 17428 1103 3187 1104 15069 1107 25157 1942 1116 1114 1103 3442 6315 1118 24763 9518 1742 12207 1891 119 164 1853 166 4222 4454 117 1259 22350 117 3442 1104 7091 2734 117 18205 14255 118 172 13003 1880 117 2812 118 1146 117 1105 6247 118 1106 118 7299 3622 1127 1215 1106 15187 1103 3068 1104 2025 119 164 1853 166 1262 1296 2025 1108 5667 1112 1344 117 1822 117 1137 10527 3187 1104 15069 119 1284 17428 1103 3442 7542 3068 1104 1664 118 7091 2200 2527 113 1884 13252 1204 2025 117 1137 1692 118 1654 2025 114 1606 1103 5847 7685 118 7711 3418 119 164 1476 166 1109 1703 3418 1104 1142 3442 1108 130 1827 117 1105 2299 1553 4668 1618 3068 119 164 1476 166 6291 2025 1108 1737 1106 1129 1344 3068 1191 1103 2794 1108 1167 1190 126 1827 119 1960 2457 17718 1215 1103 23676 13821 1592 1683 1367 119 121 113 1457 6575 3436 117 1531 2874 117 21514 117 3066 114 1106 3870 1103 11435 3622 119 25911 2603 117 1231 10182 21629 2603 117 1105 3254 1643 9538 118 189 1988 2603 117 1127 5165 1112 4267 8401 18778 2285 10986 1105 1127 4448 1112 5236 3187 113 155 2069 114 1114 4573 110 6595 14662 119 5158 1159 117 2704 2215 117 1892 2445 117 1171 118 2489 19497 1708 2794 117 3420 118 2489 19497 1708 2794 117 147 23579 2794 117 1105 18659 11964 118 12029 1708 120 7054 1708 117 1127 5165 1112 6803 10986 117 2456 1152 1127 4448 1112 20167 1928 3719 113 160 18219 114 1114 4573 110 6595 14662 119 2577 1103 2233 1127 4528 1174 117 154 118 188 19756 5562 1105 146 1477 188 19756 5562 1127 1215 1106 11552 1103 1119 25710 27054 1785 1621 1103 2527 117 1107 1134 170 153 2860 133 119 1275 1137 146 1477 135 1851 110 1127 3393 1112 2418 1119 25710 27054 1785 119 20784 1181 10777 1127 6455 1118 1606 170 4275 118 3154 2235 113 2268 7854 782 11679 5026 13430 3442 114 164 1955 166 1137 102\n",
      "INFO:tensorflow:input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      "I1208 12:27:37.030969 139883775852736 run_factoid.py:451] input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      "INFO:tensorflow:segment_ids: 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      "I1208 12:27:37.031058 139883775852736 run_factoid.py:453] segment_ids: 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      "INFO:tensorflow:*** Example ***\n",
      "I1208 12:27:37.032506 139883775852736 run_factoid.py:438] *** Example ***\n",
      "INFO:tensorflow:unique_id: 1000000017\n",
      "I1208 12:27:37.032562 139883775852736 run_factoid.py:439] unique_id: 1000000017\n",
      "INFO:tensorflow:example_index: 5\n",
      "I1208 12:27:37.032600 139883775852736 run_factoid.py:440] example_index: 5\n",
      "INFO:tensorflow:doc_span_index: 6\n",
      "I1208 12:27:37.032634 139883775852736 run_factoid.py:441] doc_span_index: 6\n",
      "INFO:tensorflow:tokens: [CLS] What did the paper do ? [SEP] total scale of this method was 9 points , and higher point indicated better quality . [ 30 ] Any study was considered to be high quality if the score was more than 5 points . Two independent investigators used the ST ##AT ##A version 12 . 0 ( St ##ata Corporation , College Station , TX , USA ) to perform the statistical analysis . Success rate , re ##cu ##rrence rate , and com ##p ##lica - t ##ion rate , were treated as di ##cho ##tom ##ous variables and were expressed as relative risk ( R ##R ) with 95 % confidence intervals . Operation time , hospital stay , blood loss , back - pain VA ##S score , leg - pain VA ##S score , J ##OA score , and SF ##12 - MC ##S / PC ##S , were treated as continuous variables , thus they were expressed as weighted mean difference ( W ##MD ) with 95 % confidence intervals . Before the data were pool ##ed , Q - s ##tat ##istic and I ##2 s ##tat ##istic were used to detect the he ##tero ##gene ##ity among the studies , in which a P value < . 10 or I ##2 > 50 % were defined as significant he ##tero ##gene ##ity . Poole ##d estimates were generated by using a fixed - effects model ( Man ##tel – Ha ##ens ##zel method ) [ 31 ] or random - effect model ( Der ##S ##i - mon ##ian – Lai ##rd method ) , [ 32 ] depending on the he ##tero ##gene ##ity among the included studies . When he ##tero ##gene ##ity was identified , we conducted sensitivity analysis by o ##mit ##ting one study at each turn to explore the influence of each individual study on the overall risk estimate . We also performed subgroup analysis based on the com ##par ##ators and duration of following - up to explore the sources of he ##tero ##gene ##ity and the impacts of these variables on the overall estimates . Public ##ation bias was assessed by the Be ##gg [ 33 ] and Egg ##er test . [ 34 ] A 2 - tailed [SEP]\n",
      "I1208 12:27:37.032761 139883775852736 run_factoid.py:443] tokens: [CLS] What did the paper do ? [SEP] total scale of this method was 9 points , and higher point indicated better quality . [ 30 ] Any study was considered to be high quality if the score was more than 5 points . Two independent investigators used the ST ##AT ##A version 12 . 0 ( St ##ata Corporation , College Station , TX , USA ) to perform the statistical analysis . Success rate , re ##cu ##rrence rate , and com ##p ##lica - t ##ion rate , were treated as di ##cho ##tom ##ous variables and were expressed as relative risk ( R ##R ) with 95 % confidence intervals . Operation time , hospital stay , blood loss , back - pain VA ##S score , leg - pain VA ##S score , J ##OA score , and SF ##12 - MC ##S / PC ##S , were treated as continuous variables , thus they were expressed as weighted mean difference ( W ##MD ) with 95 % confidence intervals . Before the data were pool ##ed , Q - s ##tat ##istic and I ##2 s ##tat ##istic were used to detect the he ##tero ##gene ##ity among the studies , in which a P value < . 10 or I ##2 > 50 % were defined as significant he ##tero ##gene ##ity . Poole ##d estimates were generated by using a fixed - effects model ( Man ##tel – Ha ##ens ##zel method ) [ 31 ] or random - effect model ( Der ##S ##i - mon ##ian – Lai ##rd method ) , [ 32 ] depending on the he ##tero ##gene ##ity among the included studies . When he ##tero ##gene ##ity was identified , we conducted sensitivity analysis by o ##mit ##ting one study at each turn to explore the influence of each individual study on the overall risk estimate . We also performed subgroup analysis based on the com ##par ##ators and duration of following - up to explore the sources of he ##tero ##gene ##ity and the impacts of these variables on the overall estimates . Public ##ation bias was assessed by the Be ##gg [ 33 ] and Egg ##er test . [ 34 ] A 2 - tailed [SEP]\n",
      "INFO:tensorflow:token_to_orig_map: 8:388 9:389 10:390 11:391 12:392 13:393 14:394 15:395 16:395 17:396 18:397 19:398 20:399 21:400 22:401 23:401 24:401 25:401 26:401 27:402 28:403 29:404 30:405 31:406 32:407 33:408 34:409 35:410 36:411 37:412 38:413 39:414 40:415 41:416 42:417 43:417 44:418 45:419 46:420 47:421 48:422 49:423 50:423 51:423 52:424 53:425 54:425 55:425 56:426 57:426 58:426 59:427 60:427 61:428 62:429 63:429 64:430 65:430 66:431 67:431 68:432 69:433 70:434 71:435 72:436 73:436 74:437 75:438 76:438 77:439 78:439 79:439 80:440 81:440 82:441 83:442 84:442 85:442 86:442 87:443 88:443 89:444 90:444 91:445 92:446 93:447 94:448 95:448 96:448 97:448 98:449 99:450 100:451 101:452 102:453 103:454 104:455 105:456 106:456 107:456 108:456 109:457 110:458 111:458 112:459 113:460 114:460 115:461 116:462 117:462 118:463 119:464 120:464 121:465 122:466 123:466 124:467 125:467 126:467 127:468 128:468 129:469 130:469 131:470 132:470 133:470 134:471 135:471 136:472 137:472 138:473 139:473 140:474 141:474 142:475 143:476 144:476 145:476 146:476 147:476 148:476 149:476 150:476 151:476 152:477 153:478 154:479 155:480 156:481 157:481 158:482 159:483 160:484 161:485 162:486 163:487 164:488 165:489 166:490 167:490 168:490 169:490 170:491 171:492 172:492 173:493 174:494 175:494 176:495 177:496 178:497 179:498 180:499 181:499 182:499 183:500 184:500 185:500 186:500 187:500 188:501 189:502 190:502 191:503 192:503 193:503 194:504 195:505 196:506 197:507 198:508 199:509 200:509 201:509 202:509 203:510 204:511 205:512 206:512 207:513 208:514 209:515 210:516 211:517 212:518 213:519 214:519 215:520 216:521 217:521 218:522 219:523 220:523 221:524 222:525 223:526 224:527 225:528 226:528 227:528 228:528 229:528 230:529 231:529 232:530 233:531 234:532 235:533 236:534 237:535 238:536 239:536 240:536 241:537 242:538 243:538 244:538 245:538 246:538 247:538 248:538 249:539 250:539 251:539 252:539 253:539 254:540 255:541 256:541 257:541 258:542 259:543 260:543 261:543 262:543 263:543 264:544 265:544 266:544 267:544 268:544 269:545 270:545 271:545 272:545 273:545 274:545 275:546 276:547 277:548 278:549 279:549 280:549 281:549 282:550 283:551 284:552 285:553 286:553 287:554 288:555 289:555 290:555 291:555 292:556 293:557 294:557 295:558 296:559 297:560 298:561 299:562 300:563 301:563 302:563 303:564 304:565 305:566 306:567 307:568 308:569 309:570 310:571 311:572 312:573 313:574 314:575 315:576 316:577 317:578 318:579 319:580 320:581 321:581 322:582 323:583 324:584 325:585 326:586 327:587 328:588 329:589 330:590 331:590 332:590 333:591 334:592 335:593 336:594 337:594 338:594 339:595 340:596 341:597 342:598 343:599 344:600 345:600 346:600 347:600 348:601 349:602 350:603 351:604 352:605 353:606 354:607 355:608 356:609 357:610 358:610 359:611 360:611 361:612 362:613 363:614 364:615 365:616 366:617 367:617 368:617 369:617 370:617 371:618 372:619 373:619 374:620 375:620 376:620 377:620 378:620 379:621 380:622 381:622 382:622\n",
      "I1208 12:27:37.032891 139883775852736 run_factoid.py:445] token_to_orig_map: 8:388 9:389 10:390 11:391 12:392 13:393 14:394 15:395 16:395 17:396 18:397 19:398 20:399 21:400 22:401 23:401 24:401 25:401 26:401 27:402 28:403 29:404 30:405 31:406 32:407 33:408 34:409 35:410 36:411 37:412 38:413 39:414 40:415 41:416 42:417 43:417 44:418 45:419 46:420 47:421 48:422 49:423 50:423 51:423 52:424 53:425 54:425 55:425 56:426 57:426 58:426 59:427 60:427 61:428 62:429 63:429 64:430 65:430 66:431 67:431 68:432 69:433 70:434 71:435 72:436 73:436 74:437 75:438 76:438 77:439 78:439 79:439 80:440 81:440 82:441 83:442 84:442 85:442 86:442 87:443 88:443 89:444 90:444 91:445 92:446 93:447 94:448 95:448 96:448 97:448 98:449 99:450 100:451 101:452 102:453 103:454 104:455 105:456 106:456 107:456 108:456 109:457 110:458 111:458 112:459 113:460 114:460 115:461 116:462 117:462 118:463 119:464 120:464 121:465 122:466 123:466 124:467 125:467 126:467 127:468 128:468 129:469 130:469 131:470 132:470 133:470 134:471 135:471 136:472 137:472 138:473 139:473 140:474 141:474 142:475 143:476 144:476 145:476 146:476 147:476 148:476 149:476 150:476 151:476 152:477 153:478 154:479 155:480 156:481 157:481 158:482 159:483 160:484 161:485 162:486 163:487 164:488 165:489 166:490 167:490 168:490 169:490 170:491 171:492 172:492 173:493 174:494 175:494 176:495 177:496 178:497 179:498 180:499 181:499 182:499 183:500 184:500 185:500 186:500 187:500 188:501 189:502 190:502 191:503 192:503 193:503 194:504 195:505 196:506 197:507 198:508 199:509 200:509 201:509 202:509 203:510 204:511 205:512 206:512 207:513 208:514 209:515 210:516 211:517 212:518 213:519 214:519 215:520 216:521 217:521 218:522 219:523 220:523 221:524 222:525 223:526 224:527 225:528 226:528 227:528 228:528 229:528 230:529 231:529 232:530 233:531 234:532 235:533 236:534 237:535 238:536 239:536 240:536 241:537 242:538 243:538 244:538 245:538 246:538 247:538 248:538 249:539 250:539 251:539 252:539 253:539 254:540 255:541 256:541 257:541 258:542 259:543 260:543 261:543 262:543 263:543 264:544 265:544 266:544 267:544 268:544 269:545 270:545 271:545 272:545 273:545 274:545 275:546 276:547 277:548 278:549 279:549 280:549 281:549 282:550 283:551 284:552 285:553 286:553 287:554 288:555 289:555 290:555 291:555 292:556 293:557 294:557 295:558 296:559 297:560 298:561 299:562 300:563 301:563 302:563 303:564 304:565 305:566 306:567 307:568 308:569 309:570 310:571 311:572 312:573 313:574 314:575 315:576 316:577 317:578 318:579 319:580 320:581 321:581 322:582 323:583 324:584 325:585 326:586 327:587 328:588 329:589 330:590 331:590 332:590 333:591 334:592 335:593 336:594 337:594 338:594 339:595 340:596 341:597 342:598 343:599 344:600 345:600 346:600 347:600 348:601 349:602 350:603 351:604 352:605 353:606 354:607 355:608 356:609 357:610 358:610 359:611 360:611 361:612 362:613 363:614 364:615 365:616 366:617 367:617 368:617 369:617 370:617 371:618 372:619 373:619 374:620 375:620 376:620 377:620 378:620 379:621 380:622 381:622 382:622\n",
      "INFO:tensorflow:token_is_max_context: 8:False 9:False 10:False 11:False 12:False 13:False 14:False 15:False 16:False 17:False 18:False 19:False 20:False 21:False 22:False 23:False 24:False 25:False 26:False 27:False 28:False 29:False 30:False 31:False 32:False 33:False 34:False 35:False 36:False 37:False 38:False 39:False 40:False 41:False 42:False 43:False 44:False 45:False 46:False 47:False 48:False 49:False 50:False 51:False 52:False 53:False 54:False 55:False 56:False 57:False 58:False 59:False 60:False 61:False 62:False 63:False 64:False 65:False 66:False 67:False 68:False 69:False 70:False 71:False 72:False 73:False 74:False 75:False 76:False 77:False 78:False 79:False 80:False 81:False 82:False 83:False 84:False 85:False 86:False 87:False 88:False 89:False 90:False 91:False 92:False 93:False 94:False 95:False 96:False 97:False 98:False 99:False 100:False 101:False 102:False 103:False 104:False 105:False 106:False 107:False 108:False 109:False 110:False 111:False 112:False 113:False 114:False 115:False 116:False 117:False 118:False 119:False 120:False 121:False 122:False 123:False 124:False 125:False 126:False 127:False 128:False 129:False 130:False 131:False 132:True 133:True 134:True 135:True 136:True 137:True 138:True 139:True 140:True 141:True 142:True 143:True 144:True 145:True 146:True 147:True 148:True 149:True 150:True 151:True 152:True 153:True 154:True 155:True 156:True 157:True 158:True 159:True 160:True 161:True 162:True 163:True 164:True 165:True 166:True 167:True 168:True 169:True 170:True 171:True 172:True 173:True 174:True 175:True 176:True 177:True 178:True 179:True 180:True 181:True 182:True 183:True 184:True 185:True 186:True 187:True 188:True 189:True 190:True 191:True 192:True 193:True 194:True 195:True 196:True 197:True 198:True 199:True 200:True 201:True 202:True 203:True 204:True 205:True 206:True 207:True 208:True 209:True 210:True 211:True 212:True 213:True 214:True 215:True 216:True 217:True 218:True 219:True 220:True 221:True 222:True 223:True 224:True 225:True 226:True 227:True 228:True 229:True 230:True 231:True 232:True 233:True 234:True 235:True 236:True 237:True 238:True 239:True 240:True 241:True 242:True 243:True 244:True 245:True 246:True 247:True 248:True 249:True 250:True 251:True 252:True 253:True 254:True 255:True 256:True 257:True 258:True 259:True 260:False 261:False 262:False 263:False 264:False 265:False 266:False 267:False 268:False 269:False 270:False 271:False 272:False 273:False 274:False 275:False 276:False 277:False 278:False 279:False 280:False 281:False 282:False 283:False 284:False 285:False 286:False 287:False 288:False 289:False 290:False 291:False 292:False 293:False 294:False 295:False 296:False 297:False 298:False 299:False 300:False 301:False 302:False 303:False 304:False 305:False 306:False 307:False 308:False 309:False 310:False 311:False 312:False 313:False 314:False 315:False 316:False 317:False 318:False 319:False 320:False 321:False 322:False 323:False 324:False 325:False 326:False 327:False 328:False 329:False 330:False 331:False 332:False 333:False 334:False 335:False 336:False 337:False 338:False 339:False 340:False 341:False 342:False 343:False 344:False 345:False 346:False 347:False 348:False 349:False 350:False 351:False 352:False 353:False 354:False 355:False 356:False 357:False 358:False 359:False 360:False 361:False 362:False 363:False 364:False 365:False 366:False 367:False 368:False 369:False 370:False 371:False 372:False 373:False 374:False 375:False 376:False 377:False 378:False 379:False 380:False 381:False 382:False\n",
      "I1208 12:27:37.032999 139883775852736 run_factoid.py:447] token_is_max_context: 8:False 9:False 10:False 11:False 12:False 13:False 14:False 15:False 16:False 17:False 18:False 19:False 20:False 21:False 22:False 23:False 24:False 25:False 26:False 27:False 28:False 29:False 30:False 31:False 32:False 33:False 34:False 35:False 36:False 37:False 38:False 39:False 40:False 41:False 42:False 43:False 44:False 45:False 46:False 47:False 48:False 49:False 50:False 51:False 52:False 53:False 54:False 55:False 56:False 57:False 58:False 59:False 60:False 61:False 62:False 63:False 64:False 65:False 66:False 67:False 68:False 69:False 70:False 71:False 72:False 73:False 74:False 75:False 76:False 77:False 78:False 79:False 80:False 81:False 82:False 83:False 84:False 85:False 86:False 87:False 88:False 89:False 90:False 91:False 92:False 93:False 94:False 95:False 96:False 97:False 98:False 99:False 100:False 101:False 102:False 103:False 104:False 105:False 106:False 107:False 108:False 109:False 110:False 111:False 112:False 113:False 114:False 115:False 116:False 117:False 118:False 119:False 120:False 121:False 122:False 123:False 124:False 125:False 126:False 127:False 128:False 129:False 130:False 131:False 132:True 133:True 134:True 135:True 136:True 137:True 138:True 139:True 140:True 141:True 142:True 143:True 144:True 145:True 146:True 147:True 148:True 149:True 150:True 151:True 152:True 153:True 154:True 155:True 156:True 157:True 158:True 159:True 160:True 161:True 162:True 163:True 164:True 165:True 166:True 167:True 168:True 169:True 170:True 171:True 172:True 173:True 174:True 175:True 176:True 177:True 178:True 179:True 180:True 181:True 182:True 183:True 184:True 185:True 186:True 187:True 188:True 189:True 190:True 191:True 192:True 193:True 194:True 195:True 196:True 197:True 198:True 199:True 200:True 201:True 202:True 203:True 204:True 205:True 206:True 207:True 208:True 209:True 210:True 211:True 212:True 213:True 214:True 215:True 216:True 217:True 218:True 219:True 220:True 221:True 222:True 223:True 224:True 225:True 226:True 227:True 228:True 229:True 230:True 231:True 232:True 233:True 234:True 235:True 236:True 237:True 238:True 239:True 240:True 241:True 242:True 243:True 244:True 245:True 246:True 247:True 248:True 249:True 250:True 251:True 252:True 253:True 254:True 255:True 256:True 257:True 258:True 259:True 260:False 261:False 262:False 263:False 264:False 265:False 266:False 267:False 268:False 269:False 270:False 271:False 272:False 273:False 274:False 275:False 276:False 277:False 278:False 279:False 280:False 281:False 282:False 283:False 284:False 285:False 286:False 287:False 288:False 289:False 290:False 291:False 292:False 293:False 294:False 295:False 296:False 297:False 298:False 299:False 300:False 301:False 302:False 303:False 304:False 305:False 306:False 307:False 308:False 309:False 310:False 311:False 312:False 313:False 314:False 315:False 316:False 317:False 318:False 319:False 320:False 321:False 322:False 323:False 324:False 325:False 326:False 327:False 328:False 329:False 330:False 331:False 332:False 333:False 334:False 335:False 336:False 337:False 338:False 339:False 340:False 341:False 342:False 343:False 344:False 345:False 346:False 347:False 348:False 349:False 350:False 351:False 352:False 353:False 354:False 355:False 356:False 357:False 358:False 359:False 360:False 361:False 362:False 363:False 364:False 365:False 366:False 367:False 368:False 369:False 370:False 371:False 372:False 373:False 374:False 375:False 376:False 377:False 378:False 379:False 380:False 381:False 382:False\n",
      "INFO:tensorflow:input_ids: 101 1327 1225 1103 2526 1202 136 102 1703 3418 1104 1142 3442 1108 130 1827 117 1105 2299 1553 4668 1618 3068 119 164 1476 166 6291 2025 1108 1737 1106 1129 1344 3068 1191 1103 2794 1108 1167 1190 126 1827 119 1960 2457 17718 1215 1103 23676 13821 1592 1683 1367 119 121 113 1457 6575 3436 117 1531 2874 117 21514 117 3066 114 1106 3870 1103 11435 3622 119 25911 2603 117 1231 10182 21629 2603 117 1105 3254 1643 9538 118 189 1988 2603 117 1127 5165 1112 4267 8401 18778 2285 10986 1105 1127 4448 1112 5236 3187 113 155 2069 114 1114 4573 110 6595 14662 119 5158 1159 117 2704 2215 117 1892 2445 117 1171 118 2489 19497 1708 2794 117 3420 118 2489 19497 1708 2794 117 147 23579 2794 117 1105 18659 11964 118 12029 1708 120 7054 1708 117 1127 5165 1112 6803 10986 117 2456 1152 1127 4448 1112 20167 1928 3719 113 160 18219 114 1114 4573 110 6595 14662 119 2577 1103 2233 1127 4528 1174 117 154 118 188 19756 5562 1105 146 1477 188 19756 5562 1127 1215 1106 11552 1103 1119 25710 27054 1785 1621 1103 2527 117 1107 1134 170 153 2860 133 119 1275 1137 146 1477 135 1851 110 1127 3393 1112 2418 1119 25710 27054 1785 119 20784 1181 10777 1127 6455 1118 1606 170 4275 118 3154 2235 113 2268 7854 782 11679 5026 13430 3442 114 164 1955 166 1137 7091 118 2629 2235 113 9682 1708 1182 118 19863 1811 782 25489 2956 3442 114 117 164 2724 166 5763 1113 1103 1119 25710 27054 1785 1621 1103 1529 2527 119 1332 1119 25710 27054 1785 1108 3626 117 1195 3303 15750 3622 1118 184 9084 1916 1141 2025 1120 1296 1885 1106 8664 1103 2933 1104 1296 2510 2025 1113 1103 2905 3187 10301 119 1284 1145 1982 23470 3622 1359 1113 1103 3254 17482 11664 1105 9355 1104 1378 118 1146 1106 8664 1103 3509 1104 1119 25710 27054 1785 1105 1103 15791 1104 1292 10986 1113 1103 2905 10777 119 2710 1891 15069 1108 14758 1118 1103 4108 9705 164 3081 166 1105 25861 1200 2774 119 164 3236 166 138 123 118 15376 102\n",
      "I1208 12:27:37.033104 139883775852736 run_factoid.py:449] input_ids: 101 1327 1225 1103 2526 1202 136 102 1703 3418 1104 1142 3442 1108 130 1827 117 1105 2299 1553 4668 1618 3068 119 164 1476 166 6291 2025 1108 1737 1106 1129 1344 3068 1191 1103 2794 1108 1167 1190 126 1827 119 1960 2457 17718 1215 1103 23676 13821 1592 1683 1367 119 121 113 1457 6575 3436 117 1531 2874 117 21514 117 3066 114 1106 3870 1103 11435 3622 119 25911 2603 117 1231 10182 21629 2603 117 1105 3254 1643 9538 118 189 1988 2603 117 1127 5165 1112 4267 8401 18778 2285 10986 1105 1127 4448 1112 5236 3187 113 155 2069 114 1114 4573 110 6595 14662 119 5158 1159 117 2704 2215 117 1892 2445 117 1171 118 2489 19497 1708 2794 117 3420 118 2489 19497 1708 2794 117 147 23579 2794 117 1105 18659 11964 118 12029 1708 120 7054 1708 117 1127 5165 1112 6803 10986 117 2456 1152 1127 4448 1112 20167 1928 3719 113 160 18219 114 1114 4573 110 6595 14662 119 2577 1103 2233 1127 4528 1174 117 154 118 188 19756 5562 1105 146 1477 188 19756 5562 1127 1215 1106 11552 1103 1119 25710 27054 1785 1621 1103 2527 117 1107 1134 170 153 2860 133 119 1275 1137 146 1477 135 1851 110 1127 3393 1112 2418 1119 25710 27054 1785 119 20784 1181 10777 1127 6455 1118 1606 170 4275 118 3154 2235 113 2268 7854 782 11679 5026 13430 3442 114 164 1955 166 1137 7091 118 2629 2235 113 9682 1708 1182 118 19863 1811 782 25489 2956 3442 114 117 164 2724 166 5763 1113 1103 1119 25710 27054 1785 1621 1103 1529 2527 119 1332 1119 25710 27054 1785 1108 3626 117 1195 3303 15750 3622 1118 184 9084 1916 1141 2025 1120 1296 1885 1106 8664 1103 2933 1104 1296 2510 2025 1113 1103 2905 3187 10301 119 1284 1145 1982 23470 3622 1359 1113 1103 3254 17482 11664 1105 9355 1104 1378 118 1146 1106 8664 1103 3509 1104 1119 25710 27054 1785 1105 1103 15791 1104 1292 10986 1113 1103 2905 10777 119 2710 1891 15069 1108 14758 1118 1103 4108 9705 164 3081 166 1105 25861 1200 2774 119 164 3236 166 138 123 118 15376 102\n",
      "INFO:tensorflow:input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      "I1208 12:27:37.033195 139883775852736 run_factoid.py:451] input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      "INFO:tensorflow:segment_ids: 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      "I1208 12:27:37.033284 139883775852736 run_factoid.py:453] segment_ids: 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      "INFO:tensorflow:*** Example ***\n",
      "I1208 12:27:37.034506 139883775852736 run_factoid.py:438] *** Example ***\n",
      "INFO:tensorflow:unique_id: 1000000018\n",
      "I1208 12:27:37.034566 139883775852736 run_factoid.py:439] unique_id: 1000000018\n",
      "INFO:tensorflow:example_index: 5\n",
      "I1208 12:27:37.034603 139883775852736 run_factoid.py:440] example_index: 5\n",
      "INFO:tensorflow:doc_span_index: 7\n",
      "I1208 12:27:37.034637 139883775852736 run_factoid.py:441] doc_span_index: 7\n",
      "INFO:tensorflow:tokens: [CLS] What did the paper do ? [SEP] score , J ##OA score , and SF ##12 - MC ##S / PC ##S , were treated as continuous variables , thus they were expressed as weighted mean difference ( W ##MD ) with 95 % confidence intervals . Before the data were pool ##ed , Q - s ##tat ##istic and I ##2 s ##tat ##istic were used to detect the he ##tero ##gene ##ity among the studies , in which a P value < . 10 or I ##2 > 50 % were defined as significant he ##tero ##gene ##ity . Poole ##d estimates were generated by using a fixed - effects model ( Man ##tel – Ha ##ens ##zel method ) [ 31 ] or random - effect model ( Der ##S ##i - mon ##ian – Lai ##rd method ) , [ 32 ] depending on the he ##tero ##gene ##ity among the included studies . When he ##tero ##gene ##ity was identified , we conducted sensitivity analysis by o ##mit ##ting one study at each turn to explore the influence of each individual study on the overall risk estimate . We also performed subgroup analysis based on the com ##par ##ators and duration of following - up to explore the sources of he ##tero ##gene ##ity and the impacts of these variables on the overall estimates . Public ##ation bias was assessed by the Be ##gg [ 33 ] and Egg ##er test . [ 34 ] A 2 - tailed P value < . 05 was considered statistical ##ly significant except where a certain P - value had been specified . This is meta - analysis , so et ##hic approval is not required . Figure 1 . Eli ##gi ##bility of studies for inclusion in meta - analysis . Basel ##ine characteristics of patients in the trials included in the meta - analysis . [SEP]\n",
      "I1208 12:27:37.034739 139883775852736 run_factoid.py:443] tokens: [CLS] What did the paper do ? [SEP] score , J ##OA score , and SF ##12 - MC ##S / PC ##S , were treated as continuous variables , thus they were expressed as weighted mean difference ( W ##MD ) with 95 % confidence intervals . Before the data were pool ##ed , Q - s ##tat ##istic and I ##2 s ##tat ##istic were used to detect the he ##tero ##gene ##ity among the studies , in which a P value < . 10 or I ##2 > 50 % were defined as significant he ##tero ##gene ##ity . Poole ##d estimates were generated by using a fixed - effects model ( Man ##tel – Ha ##ens ##zel method ) [ 31 ] or random - effect model ( Der ##S ##i - mon ##ian – Lai ##rd method ) , [ 32 ] depending on the he ##tero ##gene ##ity among the included studies . When he ##tero ##gene ##ity was identified , we conducted sensitivity analysis by o ##mit ##ting one study at each turn to explore the influence of each individual study on the overall risk estimate . We also performed subgroup analysis based on the com ##par ##ators and duration of following - up to explore the sources of he ##tero ##gene ##ity and the impacts of these variables on the overall estimates . Public ##ation bias was assessed by the Be ##gg [ 33 ] and Egg ##er test . [ 34 ] A 2 - tailed P value < . 05 was considered statistical ##ly significant except where a certain P - value had been specified . This is meta - analysis , so et ##hic approval is not required . Figure 1 . Eli ##gi ##bility of studies for inclusion in meta - analysis . Basel ##ine characteristics of patients in the trials included in the meta - analysis . [SEP]\n",
      "INFO:tensorflow:token_to_orig_map: 8:472 9:472 10:473 11:473 12:474 13:474 14:475 15:476 16:476 17:476 18:476 19:476 20:476 21:476 22:476 23:476 24:477 25:478 26:479 27:480 28:481 29:481 30:482 31:483 32:484 33:485 34:486 35:487 36:488 37:489 38:490 39:490 40:490 41:490 42:491 43:492 44:492 45:493 46:494 47:494 48:495 49:496 50:497 51:498 52:499 53:499 54:499 55:500 56:500 57:500 58:500 59:500 60:501 61:502 62:502 63:503 64:503 65:503 66:504 67:505 68:506 69:507 70:508 71:509 72:509 73:509 74:509 75:510 76:511 77:512 78:512 79:513 80:514 81:515 82:516 83:517 84:518 85:519 86:519 87:520 88:521 89:521 90:522 91:523 92:523 93:524 94:525 95:526 96:527 97:528 98:528 99:528 100:528 101:528 102:529 103:529 104:530 105:531 106:532 107:533 108:534 109:535 110:536 111:536 112:536 113:537 114:538 115:538 116:538 117:538 118:538 119:538 120:538 121:539 122:539 123:539 124:539 125:539 126:540 127:541 128:541 129:541 130:542 131:543 132:543 133:543 134:543 135:543 136:544 137:544 138:544 139:544 140:544 141:545 142:545 143:545 144:545 145:545 146:545 147:546 148:547 149:548 150:549 151:549 152:549 153:549 154:550 155:551 156:552 157:553 158:553 159:554 160:555 161:555 162:555 163:555 164:556 165:557 166:557 167:558 168:559 169:560 170:561 171:562 172:563 173:563 174:563 175:564 176:565 177:566 178:567 179:568 180:569 181:570 182:571 183:572 184:573 185:574 186:575 187:576 188:577 189:578 190:579 191:580 192:581 193:581 194:582 195:583 196:584 197:585 198:586 199:587 200:588 201:589 202:590 203:590 204:590 205:591 206:592 207:593 208:594 209:594 210:594 211:595 212:596 213:597 214:598 215:599 216:600 217:600 218:600 219:600 220:601 221:602 222:603 223:604 224:605 225:606 226:607 227:608 228:609 229:610 230:610 231:611 232:611 233:612 234:613 235:614 236:615 237:616 238:617 239:617 240:617 241:617 242:617 243:618 244:619 245:619 246:620 247:620 248:620 249:620 250:620 251:621 252:622 253:622 254:622 255:623 256:624 257:625 258:625 259:625 260:626 261:627 262:628 263:628 264:629 265:630 266:631 267:632 268:633 269:634 270:634 271:634 272:635 273:636 274:637 275:637 276:638 277:639 278:640 279:640 280:640 281:640 282:641 283:642 284:642 285:643 286:644 287:645 288:646 289:646 290:647 291:648 292:648 293:649 294:649 295:649 296:650 297:651 298:652 299:653 300:654 301:655 302:655 303:655 304:655 305:656 306:656 307:657 308:658 309:659 310:660 311:661 312:662 313:663 314:664 315:665 316:666 317:666 318:666 319:666\n",
      "I1208 12:27:37.034843 139883775852736 run_factoid.py:445] token_to_orig_map: 8:472 9:472 10:473 11:473 12:474 13:474 14:475 15:476 16:476 17:476 18:476 19:476 20:476 21:476 22:476 23:476 24:477 25:478 26:479 27:480 28:481 29:481 30:482 31:483 32:484 33:485 34:486 35:487 36:488 37:489 38:490 39:490 40:490 41:490 42:491 43:492 44:492 45:493 46:494 47:494 48:495 49:496 50:497 51:498 52:499 53:499 54:499 55:500 56:500 57:500 58:500 59:500 60:501 61:502 62:502 63:503 64:503 65:503 66:504 67:505 68:506 69:507 70:508 71:509 72:509 73:509 74:509 75:510 76:511 77:512 78:512 79:513 80:514 81:515 82:516 83:517 84:518 85:519 86:519 87:520 88:521 89:521 90:522 91:523 92:523 93:524 94:525 95:526 96:527 97:528 98:528 99:528 100:528 101:528 102:529 103:529 104:530 105:531 106:532 107:533 108:534 109:535 110:536 111:536 112:536 113:537 114:538 115:538 116:538 117:538 118:538 119:538 120:538 121:539 122:539 123:539 124:539 125:539 126:540 127:541 128:541 129:541 130:542 131:543 132:543 133:543 134:543 135:543 136:544 137:544 138:544 139:544 140:544 141:545 142:545 143:545 144:545 145:545 146:545 147:546 148:547 149:548 150:549 151:549 152:549 153:549 154:550 155:551 156:552 157:553 158:553 159:554 160:555 161:555 162:555 163:555 164:556 165:557 166:557 167:558 168:559 169:560 170:561 171:562 172:563 173:563 174:563 175:564 176:565 177:566 178:567 179:568 180:569 181:570 182:571 183:572 184:573 185:574 186:575 187:576 188:577 189:578 190:579 191:580 192:581 193:581 194:582 195:583 196:584 197:585 198:586 199:587 200:588 201:589 202:590 203:590 204:590 205:591 206:592 207:593 208:594 209:594 210:594 211:595 212:596 213:597 214:598 215:599 216:600 217:600 218:600 219:600 220:601 221:602 222:603 223:604 224:605 225:606 226:607 227:608 228:609 229:610 230:610 231:611 232:611 233:612 234:613 235:614 236:615 237:616 238:617 239:617 240:617 241:617 242:617 243:618 244:619 245:619 246:620 247:620 248:620 249:620 250:620 251:621 252:622 253:622 254:622 255:623 256:624 257:625 258:625 259:625 260:626 261:627 262:628 263:628 264:629 265:630 266:631 267:632 268:633 269:634 270:634 271:634 272:635 273:636 274:637 275:637 276:638 277:639 278:640 279:640 280:640 281:640 282:641 283:642 284:642 285:643 286:644 287:645 288:646 289:646 290:647 291:648 292:648 293:649 294:649 295:649 296:650 297:651 298:652 299:653 300:654 301:655 302:655 303:655 304:655 305:656 306:656 307:657 308:658 309:659 310:660 311:661 312:662 313:663 314:664 315:665 316:666 317:666 318:666 319:666\n",
      "INFO:tensorflow:token_is_max_context: 8:False 9:False 10:False 11:False 12:False 13:False 14:False 15:False 16:False 17:False 18:False 19:False 20:False 21:False 22:False 23:False 24:False 25:False 26:False 27:False 28:False 29:False 30:False 31:False 32:False 33:False 34:False 35:False 36:False 37:False 38:False 39:False 40:False 41:False 42:False 43:False 44:False 45:False 46:False 47:False 48:False 49:False 50:False 51:False 52:False 53:False 54:False 55:False 56:False 57:False 58:False 59:False 60:False 61:False 62:False 63:False 64:False 65:False 66:False 67:False 68:False 69:False 70:False 71:False 72:False 73:False 74:False 75:False 76:False 77:False 78:False 79:False 80:False 81:False 82:False 83:False 84:False 85:False 86:False 87:False 88:False 89:False 90:False 91:False 92:False 93:False 94:False 95:False 96:False 97:False 98:False 99:False 100:False 101:False 102:False 103:False 104:False 105:False 106:False 107:False 108:False 109:False 110:False 111:False 112:False 113:False 114:False 115:False 116:False 117:False 118:False 119:False 120:False 121:False 122:False 123:False 124:False 125:False 126:False 127:False 128:False 129:False 130:False 131:False 132:True 133:True 134:True 135:True 136:True 137:True 138:True 139:True 140:True 141:True 142:True 143:True 144:True 145:True 146:True 147:True 148:True 149:True 150:True 151:True 152:True 153:True 154:True 155:True 156:True 157:True 158:True 159:True 160:True 161:True 162:True 163:True 164:True 165:True 166:True 167:True 168:True 169:True 170:True 171:True 172:True 173:True 174:True 175:True 176:True 177:True 178:True 179:True 180:True 181:True 182:True 183:True 184:True 185:True 186:True 187:True 188:True 189:True 190:True 191:True 192:True 193:True 194:True 195:True 196:True 197:True 198:True 199:True 200:True 201:True 202:True 203:True 204:True 205:True 206:True 207:True 208:True 209:True 210:True 211:True 212:True 213:True 214:True 215:True 216:True 217:True 218:True 219:True 220:True 221:True 222:True 223:True 224:True 225:True 226:True 227:True 228:True 229:True 230:True 231:True 232:True 233:True 234:True 235:True 236:True 237:True 238:True 239:True 240:True 241:True 242:True 243:True 244:True 245:True 246:True 247:True 248:True 249:True 250:True 251:True 252:True 253:True 254:True 255:True 256:True 257:True 258:True 259:True 260:True 261:True 262:True 263:True 264:True 265:True 266:True 267:True 268:True 269:True 270:True 271:True 272:True 273:True 274:True 275:True 276:True 277:True 278:True 279:True 280:True 281:True 282:True 283:True 284:True 285:True 286:True 287:True 288:True 289:True 290:True 291:True 292:True 293:True 294:True 295:True 296:True 297:True 298:True 299:True 300:True 301:True 302:True 303:True 304:True 305:True 306:True 307:True 308:True 309:True 310:True 311:True 312:True 313:True 314:True 315:True 316:True 317:True 318:True 319:True\n",
      "I1208 12:27:37.034940 139883775852736 run_factoid.py:447] token_is_max_context: 8:False 9:False 10:False 11:False 12:False 13:False 14:False 15:False 16:False 17:False 18:False 19:False 20:False 21:False 22:False 23:False 24:False 25:False 26:False 27:False 28:False 29:False 30:False 31:False 32:False 33:False 34:False 35:False 36:False 37:False 38:False 39:False 40:False 41:False 42:False 43:False 44:False 45:False 46:False 47:False 48:False 49:False 50:False 51:False 52:False 53:False 54:False 55:False 56:False 57:False 58:False 59:False 60:False 61:False 62:False 63:False 64:False 65:False 66:False 67:False 68:False 69:False 70:False 71:False 72:False 73:False 74:False 75:False 76:False 77:False 78:False 79:False 80:False 81:False 82:False 83:False 84:False 85:False 86:False 87:False 88:False 89:False 90:False 91:False 92:False 93:False 94:False 95:False 96:False 97:False 98:False 99:False 100:False 101:False 102:False 103:False 104:False 105:False 106:False 107:False 108:False 109:False 110:False 111:False 112:False 113:False 114:False 115:False 116:False 117:False 118:False 119:False 120:False 121:False 122:False 123:False 124:False 125:False 126:False 127:False 128:False 129:False 130:False 131:False 132:True 133:True 134:True 135:True 136:True 137:True 138:True 139:True 140:True 141:True 142:True 143:True 144:True 145:True 146:True 147:True 148:True 149:True 150:True 151:True 152:True 153:True 154:True 155:True 156:True 157:True 158:True 159:True 160:True 161:True 162:True 163:True 164:True 165:True 166:True 167:True 168:True 169:True 170:True 171:True 172:True 173:True 174:True 175:True 176:True 177:True 178:True 179:True 180:True 181:True 182:True 183:True 184:True 185:True 186:True 187:True 188:True 189:True 190:True 191:True 192:True 193:True 194:True 195:True 196:True 197:True 198:True 199:True 200:True 201:True 202:True 203:True 204:True 205:True 206:True 207:True 208:True 209:True 210:True 211:True 212:True 213:True 214:True 215:True 216:True 217:True 218:True 219:True 220:True 221:True 222:True 223:True 224:True 225:True 226:True 227:True 228:True 229:True 230:True 231:True 232:True 233:True 234:True 235:True 236:True 237:True 238:True 239:True 240:True 241:True 242:True 243:True 244:True 245:True 246:True 247:True 248:True 249:True 250:True 251:True 252:True 253:True 254:True 255:True 256:True 257:True 258:True 259:True 260:True 261:True 262:True 263:True 264:True 265:True 266:True 267:True 268:True 269:True 270:True 271:True 272:True 273:True 274:True 275:True 276:True 277:True 278:True 279:True 280:True 281:True 282:True 283:True 284:True 285:True 286:True 287:True 288:True 289:True 290:True 291:True 292:True 293:True 294:True 295:True 296:True 297:True 298:True 299:True 300:True 301:True 302:True 303:True 304:True 305:True 306:True 307:True 308:True 309:True 310:True 311:True 312:True 313:True 314:True 315:True 316:True 317:True 318:True 319:True\n",
      "INFO:tensorflow:input_ids: 101 1327 1225 1103 2526 1202 136 102 2794 117 147 23579 2794 117 1105 18659 11964 118 12029 1708 120 7054 1708 117 1127 5165 1112 6803 10986 117 2456 1152 1127 4448 1112 20167 1928 3719 113 160 18219 114 1114 4573 110 6595 14662 119 2577 1103 2233 1127 4528 1174 117 154 118 188 19756 5562 1105 146 1477 188 19756 5562 1127 1215 1106 11552 1103 1119 25710 27054 1785 1621 1103 2527 117 1107 1134 170 153 2860 133 119 1275 1137 146 1477 135 1851 110 1127 3393 1112 2418 1119 25710 27054 1785 119 20784 1181 10777 1127 6455 1118 1606 170 4275 118 3154 2235 113 2268 7854 782 11679 5026 13430 3442 114 164 1955 166 1137 7091 118 2629 2235 113 9682 1708 1182 118 19863 1811 782 25489 2956 3442 114 117 164 2724 166 5763 1113 1103 1119 25710 27054 1785 1621 1103 1529 2527 119 1332 1119 25710 27054 1785 1108 3626 117 1195 3303 15750 3622 1118 184 9084 1916 1141 2025 1120 1296 1885 1106 8664 1103 2933 1104 1296 2510 2025 1113 1103 2905 3187 10301 119 1284 1145 1982 23470 3622 1359 1113 1103 3254 17482 11664 1105 9355 1104 1378 118 1146 1106 8664 1103 3509 1104 1119 25710 27054 1785 1105 1103 15791 1104 1292 10986 1113 1103 2905 10777 119 2710 1891 15069 1108 14758 1118 1103 4108 9705 164 3081 166 1105 25861 1200 2774 119 164 3236 166 138 123 118 15376 153 2860 133 119 4991 1108 1737 11435 1193 2418 2589 1187 170 2218 153 118 2860 1125 1151 9467 119 1188 1110 27154 118 3622 117 1177 3084 11239 5684 1110 1136 2320 119 15982 122 119 12224 5389 5474 1104 2527 1111 10838 1107 27154 118 3622 119 14562 2042 5924 1104 4420 1107 1103 7356 1529 1107 1103 27154 118 3622 119 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "I1208 12:27:37.035040 139883775852736 run_factoid.py:449] input_ids: 101 1327 1225 1103 2526 1202 136 102 2794 117 147 23579 2794 117 1105 18659 11964 118 12029 1708 120 7054 1708 117 1127 5165 1112 6803 10986 117 2456 1152 1127 4448 1112 20167 1928 3719 113 160 18219 114 1114 4573 110 6595 14662 119 2577 1103 2233 1127 4528 1174 117 154 118 188 19756 5562 1105 146 1477 188 19756 5562 1127 1215 1106 11552 1103 1119 25710 27054 1785 1621 1103 2527 117 1107 1134 170 153 2860 133 119 1275 1137 146 1477 135 1851 110 1127 3393 1112 2418 1119 25710 27054 1785 119 20784 1181 10777 1127 6455 1118 1606 170 4275 118 3154 2235 113 2268 7854 782 11679 5026 13430 3442 114 164 1955 166 1137 7091 118 2629 2235 113 9682 1708 1182 118 19863 1811 782 25489 2956 3442 114 117 164 2724 166 5763 1113 1103 1119 25710 27054 1785 1621 1103 1529 2527 119 1332 1119 25710 27054 1785 1108 3626 117 1195 3303 15750 3622 1118 184 9084 1916 1141 2025 1120 1296 1885 1106 8664 1103 2933 1104 1296 2510 2025 1113 1103 2905 3187 10301 119 1284 1145 1982 23470 3622 1359 1113 1103 3254 17482 11664 1105 9355 1104 1378 118 1146 1106 8664 1103 3509 1104 1119 25710 27054 1785 1105 1103 15791 1104 1292 10986 1113 1103 2905 10777 119 2710 1891 15069 1108 14758 1118 1103 4108 9705 164 3081 166 1105 25861 1200 2774 119 164 3236 166 138 123 118 15376 153 2860 133 119 4991 1108 1737 11435 1193 2418 2589 1187 170 2218 153 118 2860 1125 1151 9467 119 1188 1110 27154 118 3622 117 1177 3084 11239 5684 1110 1136 2320 119 15982 122 119 12224 5389 5474 1104 2527 1111 10838 1107 27154 118 3622 119 14562 2042 5924 1104 4420 1107 1103 7356 1529 1107 1103 27154 118 3622 119 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "INFO:tensorflow:input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "I1208 12:27:37.035131 139883775852736 run_factoid.py:451] input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "INFO:tensorflow:segment_ids: 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "I1208 12:27:37.035219 139883775852736 run_factoid.py:453] segment_ids: 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "INFO:tensorflow:*** Example ***\n",
      "I1208 12:27:37.047688 139883775852736 run_factoid.py:438] *** Example ***\n",
      "INFO:tensorflow:unique_id: 1000000019\n",
      "I1208 12:27:37.047764 139883775852736 run_factoid.py:439] unique_id: 1000000019\n",
      "INFO:tensorflow:example_index: 6\n",
      "I1208 12:27:37.047804 139883775852736 run_factoid.py:440] example_index: 6\n",
      "INFO:tensorflow:doc_span_index: 0\n",
      "I1208 12:27:37.047840 139883775852736 run_factoid.py:441] doc_span_index: 0\n",
      "INFO:tensorflow:tokens: [CLS] Are the findings different depending on a person ' s demographic ##s ? [SEP] We conducted this meta - analysis in compliance with the Pre ##ferred Report ##ing It ##ems for System ##atic Reviews and Met ##a - analysis ( PR ##IS ##MA ) statement guidelines . [ 28 ] Multiple databases , including Pub ##M ##ed , Em ##base , and Web of Science were system ##ati - call ##y searched before February 2018 . The structured search strategies were listed as following ##s : ( ( “ l ##um ##bos ##ac ##ral region ” [ - Me ##S ##H Te ##rms ] OR ( “ l ##um ##bos ##ac ##ral ” [ All Fields ] AND “ region ” [ All Fields ] ) OR “ l ##um ##bos ##ac ##ral region ” [ All Fields ] OR “ l ##umba ##r ” [ All Fields ] ) AND disc [ All Fields ] AND ( “ her ##nia ” [ Me ##S ##H Te ##rms ] OR “ her ##nia ” [ All Fields ] OR “ her ##nia ##tion ” [ All Fields ] ) ) AND ( per ##cu - tan ##eous [ All Fields ] AND ( “ end ##os ##copy ” [ Me ##S ##H Te ##rms ] OR “ end ##os ##copy ” [ All Fields ] OR “ end ##os ##copic ” [ All Fields ] ) AND ( “ l ##um ##bos ##ac ##ral region ” [ Me ##S ##H Te ##rms ] OR ( “ l ##um ##bos ##ac ##ral ” [ All Fields ] AND “ region ” [ All Fields ] ) OR “ l ##um ##bos ##ac ##ral region ” [ All Fields ] OR “ l ##umba ##r ” [ All Fields ] ) AND ( “ disk ##ec ##tom ##y ” [ Me ##S ##H Te ##rms ] OR “ disk ##ec ##tom ##y ” [ All Fields ] OR “ disc ##ec ##tom ##y ” [ All Fields ] ) ) . This search was limited to human subjects , and no language or publication status was imposed . In addition , we also manually searched the reference lists of the included studies and previous review , systematic review and meta - analysis to identify [SEP]\n",
      "I1208 12:27:37.047957 139883775852736 run_factoid.py:443] tokens: [CLS] Are the findings different depending on a person ' s demographic ##s ? [SEP] We conducted this meta - analysis in compliance with the Pre ##ferred Report ##ing It ##ems for System ##atic Reviews and Met ##a - analysis ( PR ##IS ##MA ) statement guidelines . [ 28 ] Multiple databases , including Pub ##M ##ed , Em ##base , and Web of Science were system ##ati - call ##y searched before February 2018 . The structured search strategies were listed as following ##s : ( ( “ l ##um ##bos ##ac ##ral region ” [ - Me ##S ##H Te ##rms ] OR ( “ l ##um ##bos ##ac ##ral ” [ All Fields ] AND “ region ” [ All Fields ] ) OR “ l ##um ##bos ##ac ##ral region ” [ All Fields ] OR “ l ##umba ##r ” [ All Fields ] ) AND disc [ All Fields ] AND ( “ her ##nia ” [ Me ##S ##H Te ##rms ] OR “ her ##nia ” [ All Fields ] OR “ her ##nia ##tion ” [ All Fields ] ) ) AND ( per ##cu - tan ##eous [ All Fields ] AND ( “ end ##os ##copy ” [ Me ##S ##H Te ##rms ] OR “ end ##os ##copy ” [ All Fields ] OR “ end ##os ##copic ” [ All Fields ] ) AND ( “ l ##um ##bos ##ac ##ral region ” [ Me ##S ##H Te ##rms ] OR ( “ l ##um ##bos ##ac ##ral ” [ All Fields ] AND “ region ” [ All Fields ] ) OR “ l ##um ##bos ##ac ##ral region ” [ All Fields ] OR “ l ##umba ##r ” [ All Fields ] ) AND ( “ disk ##ec ##tom ##y ” [ Me ##S ##H Te ##rms ] OR “ disk ##ec ##tom ##y ” [ All Fields ] OR “ disc ##ec ##tom ##y ” [ All Fields ] ) ) . This search was limited to human subjects , and no language or publication status was imposed . In addition , we also manually searched the reference lists of the included studies and previous review , systematic review and meta - analysis to identify [SEP]\n",
      "INFO:tensorflow:token_to_orig_map: 15:0 16:1 17:2 18:3 19:3 20:3 21:4 22:5 23:6 24:7 25:8 26:8 27:9 28:9 29:10 30:10 31:11 32:12 33:12 34:13 35:14 36:15 37:15 38:15 39:16 40:17 41:17 42:17 43:17 44:17 45:18 46:19 47:19 48:19 49:19 50:19 51:20 52:21 53:21 54:22 55:23 56:23 57:23 58:23 59:24 60:24 61:24 62:25 63:26 64:27 65:28 66:29 67:30 68:30 69:30 70:31 71:31 72:32 73:33 74:34 75:35 76:35 77:36 78:37 79:38 80:39 81:40 82:41 83:42 84:43 85:43 86:43 87:44 88:44 89:44 90:44 91:44 92:44 93:44 94:44 95:45 96:45 97:45 98:45 99:46 100:46 101:46 102:47 103:47 104:47 105:48 106:49 107:49 108:49 109:49 110:49 111:49 112:49 113:49 114:49 115:49 116:50 117:50 118:51 119:52 120:52 121:52 122:52 123:52 124:53 125:53 126:53 127:54 128:55 129:55 130:55 131:55 132:55 133:55 134:56 135:56 136:56 137:56 138:57 139:57 140:58 141:59 142:59 143:59 144:59 145:59 146:59 147:59 148:60 149:60 150:60 151:61 152:62 153:62 154:62 155:63 156:63 157:64 158:65 159:65 160:65 161:65 162:65 163:65 164:65 165:65 166:65 167:66 168:66 169:66 170:67 171:68 172:68 173:68 174:68 175:68 176:68 177:69 178:69 179:70 180:71 181:71 182:71 183:71 184:71 185:71 186:71 187:72 188:72 189:72 190:72 191:73 192:74 193:74 194:74 195:74 196:75 197:75 198:75 199:75 200:76 201:76 202:77 203:78 204:78 205:78 206:78 207:78 208:78 209:78 210:78 211:78 212:78 213:79 214:79 215:79 216:80 217:81 218:81 219:81 220:81 221:81 222:81 223:81 224:82 225:82 226:83 227:84 228:84 229:84 230:84 231:84 232:84 233:84 234:85 235:85 236:85 237:86 238:87 239:87 240:87 241:87 242:87 243:87 244:87 245:88 246:88 247:88 248:88 249:88 250:88 251:89 252:89 253:89 254:90 255:91 256:91 257:91 258:91 259:91 260:91 261:91 262:91 263:91 264:91 265:92 266:92 267:93 268:94 269:94 270:94 271:94 272:94 273:95 274:95 275:95 276:96 277:97 278:97 279:97 280:97 281:97 282:97 283:98 284:98 285:98 286:98 287:99 288:99 289:100 290:101 291:101 292:101 293:101 294:101 295:101 296:101 297:102 298:102 299:102 300:103 301:104 302:104 303:104 304:104 305:104 306:104 307:104 308:104 309:104 310:104 311:104 312:105 313:105 314:105 315:106 316:107 317:107 318:107 319:107 320:107 321:107 322:107 323:107 324:108 325:108 326:109 327:110 328:110 329:110 330:110 331:110 332:110 333:110 334:110 335:111 336:111 337:111 338:111 339:111 340:112 341:113 342:114 343:115 344:116 345:117 346:118 347:118 348:119 349:120 350:121 351:122 352:123 353:124 354:125 355:126 356:126 357:127 358:128 359:128 360:129 361:130 362:131 363:132 364:133 365:134 366:135 367:136 368:137 369:138 370:139 371:140 372:141 373:142 374:142 375:143 376:144 377:145 378:146 379:146 380:146 381:147 382:148\n",
      "I1208 12:27:37.048075 139883775852736 run_factoid.py:445] token_to_orig_map: 15:0 16:1 17:2 18:3 19:3 20:3 21:4 22:5 23:6 24:7 25:8 26:8 27:9 28:9 29:10 30:10 31:11 32:12 33:12 34:13 35:14 36:15 37:15 38:15 39:16 40:17 41:17 42:17 43:17 44:17 45:18 46:19 47:19 48:19 49:19 50:19 51:20 52:21 53:21 54:22 55:23 56:23 57:23 58:23 59:24 60:24 61:24 62:25 63:26 64:27 65:28 66:29 67:30 68:30 69:30 70:31 71:31 72:32 73:33 74:34 75:35 76:35 77:36 78:37 79:38 80:39 81:40 82:41 83:42 84:43 85:43 86:43 87:44 88:44 89:44 90:44 91:44 92:44 93:44 94:44 95:45 96:45 97:45 98:45 99:46 100:46 101:46 102:47 103:47 104:47 105:48 106:49 107:49 108:49 109:49 110:49 111:49 112:49 113:49 114:49 115:49 116:50 117:50 118:51 119:52 120:52 121:52 122:52 123:52 124:53 125:53 126:53 127:54 128:55 129:55 130:55 131:55 132:55 133:55 134:56 135:56 136:56 137:56 138:57 139:57 140:58 141:59 142:59 143:59 144:59 145:59 146:59 147:59 148:60 149:60 150:60 151:61 152:62 153:62 154:62 155:63 156:63 157:64 158:65 159:65 160:65 161:65 162:65 163:65 164:65 165:65 166:65 167:66 168:66 169:66 170:67 171:68 172:68 173:68 174:68 175:68 176:68 177:69 178:69 179:70 180:71 181:71 182:71 183:71 184:71 185:71 186:71 187:72 188:72 189:72 190:72 191:73 192:74 193:74 194:74 195:74 196:75 197:75 198:75 199:75 200:76 201:76 202:77 203:78 204:78 205:78 206:78 207:78 208:78 209:78 210:78 211:78 212:78 213:79 214:79 215:79 216:80 217:81 218:81 219:81 220:81 221:81 222:81 223:81 224:82 225:82 226:83 227:84 228:84 229:84 230:84 231:84 232:84 233:84 234:85 235:85 236:85 237:86 238:87 239:87 240:87 241:87 242:87 243:87 244:87 245:88 246:88 247:88 248:88 249:88 250:88 251:89 252:89 253:89 254:90 255:91 256:91 257:91 258:91 259:91 260:91 261:91 262:91 263:91 264:91 265:92 266:92 267:93 268:94 269:94 270:94 271:94 272:94 273:95 274:95 275:95 276:96 277:97 278:97 279:97 280:97 281:97 282:97 283:98 284:98 285:98 286:98 287:99 288:99 289:100 290:101 291:101 292:101 293:101 294:101 295:101 296:101 297:102 298:102 299:102 300:103 301:104 302:104 303:104 304:104 305:104 306:104 307:104 308:104 309:104 310:104 311:104 312:105 313:105 314:105 315:106 316:107 317:107 318:107 319:107 320:107 321:107 322:107 323:107 324:108 325:108 326:109 327:110 328:110 329:110 330:110 331:110 332:110 333:110 334:110 335:111 336:111 337:111 338:111 339:111 340:112 341:113 342:114 343:115 344:116 345:117 346:118 347:118 348:119 349:120 350:121 351:122 352:123 353:124 354:125 355:126 356:126 357:127 358:128 359:128 360:129 361:130 362:131 363:132 364:133 365:134 366:135 367:136 368:137 369:138 370:139 371:140 372:141 373:142 374:142 375:143 376:144 377:145 378:146 379:146 380:146 381:147 382:148\n",
      "INFO:tensorflow:token_is_max_context: 15:True 16:True 17:True 18:True 19:True 20:True 21:True 22:True 23:True 24:True 25:True 26:True 27:True 28:True 29:True 30:True 31:True 32:True 33:True 34:True 35:True 36:True 37:True 38:True 39:True 40:True 41:True 42:True 43:True 44:True 45:True 46:True 47:True 48:True 49:True 50:True 51:True 52:True 53:True 54:True 55:True 56:True 57:True 58:True 59:True 60:True 61:True 62:True 63:True 64:True 65:True 66:True 67:True 68:True 69:True 70:True 71:True 72:True 73:True 74:True 75:True 76:True 77:True 78:True 79:True 80:True 81:True 82:True 83:True 84:True 85:True 86:True 87:True 88:True 89:True 90:True 91:True 92:True 93:True 94:True 95:True 96:True 97:True 98:True 99:True 100:True 101:True 102:True 103:True 104:True 105:True 106:True 107:True 108:True 109:True 110:True 111:True 112:True 113:True 114:True 115:True 116:True 117:True 118:True 119:True 120:True 121:True 122:True 123:True 124:True 125:True 126:True 127:True 128:True 129:True 130:True 131:True 132:True 133:True 134:True 135:True 136:True 137:True 138:True 139:True 140:True 141:True 142:True 143:True 144:True 145:True 146:True 147:True 148:True 149:True 150:True 151:True 152:True 153:True 154:True 155:True 156:True 157:True 158:True 159:True 160:True 161:True 162:True 163:True 164:True 165:True 166:True 167:True 168:True 169:True 170:True 171:True 172:True 173:True 174:True 175:True 176:True 177:True 178:True 179:True 180:True 181:True 182:True 183:True 184:True 185:True 186:True 187:True 188:True 189:True 190:True 191:True 192:True 193:True 194:True 195:True 196:True 197:True 198:True 199:True 200:True 201:True 202:True 203:True 204:True 205:True 206:True 207:True 208:True 209:True 210:True 211:True 212:True 213:True 214:True 215:True 216:True 217:True 218:True 219:True 220:True 221:True 222:True 223:True 224:True 225:True 226:True 227:True 228:True 229:True 230:True 231:True 232:True 233:True 234:True 235:True 236:True 237:True 238:True 239:True 240:True 241:True 242:True 243:True 244:True 245:True 246:True 247:True 248:True 249:True 250:True 251:True 252:True 253:True 254:True 255:True 256:True 257:True 258:True 259:True 260:True 261:True 262:True 263:False 264:False 265:False 266:False 267:False 268:False 269:False 270:False 271:False 272:False 273:False 274:False 275:False 276:False 277:False 278:False 279:False 280:False 281:False 282:False 283:False 284:False 285:False 286:False 287:False 288:False 289:False 290:False 291:False 292:False 293:False 294:False 295:False 296:False 297:False 298:False 299:False 300:False 301:False 302:False 303:False 304:False 305:False 306:False 307:False 308:False 309:False 310:False 311:False 312:False 313:False 314:False 315:False 316:False 317:False 318:False 319:False 320:False 321:False 322:False 323:False 324:False 325:False 326:False 327:False 328:False 329:False 330:False 331:False 332:False 333:False 334:False 335:False 336:False 337:False 338:False 339:False 340:False 341:False 342:False 343:False 344:False 345:False 346:False 347:False 348:False 349:False 350:False 351:False 352:False 353:False 354:False 355:False 356:False 357:False 358:False 359:False 360:False 361:False 362:False 363:False 364:False 365:False 366:False 367:False 368:False 369:False 370:False 371:False 372:False 373:False 374:False 375:False 376:False 377:False 378:False 379:False 380:False 381:False 382:False\n",
      "I1208 12:27:37.048182 139883775852736 run_factoid.py:447] token_is_max_context: 15:True 16:True 17:True 18:True 19:True 20:True 21:True 22:True 23:True 24:True 25:True 26:True 27:True 28:True 29:True 30:True 31:True 32:True 33:True 34:True 35:True 36:True 37:True 38:True 39:True 40:True 41:True 42:True 43:True 44:True 45:True 46:True 47:True 48:True 49:True 50:True 51:True 52:True 53:True 54:True 55:True 56:True 57:True 58:True 59:True 60:True 61:True 62:True 63:True 64:True 65:True 66:True 67:True 68:True 69:True 70:True 71:True 72:True 73:True 74:True 75:True 76:True 77:True 78:True 79:True 80:True 81:True 82:True 83:True 84:True 85:True 86:True 87:True 88:True 89:True 90:True 91:True 92:True 93:True 94:True 95:True 96:True 97:True 98:True 99:True 100:True 101:True 102:True 103:True 104:True 105:True 106:True 107:True 108:True 109:True 110:True 111:True 112:True 113:True 114:True 115:True 116:True 117:True 118:True 119:True 120:True 121:True 122:True 123:True 124:True 125:True 126:True 127:True 128:True 129:True 130:True 131:True 132:True 133:True 134:True 135:True 136:True 137:True 138:True 139:True 140:True 141:True 142:True 143:True 144:True 145:True 146:True 147:True 148:True 149:True 150:True 151:True 152:True 153:True 154:True 155:True 156:True 157:True 158:True 159:True 160:True 161:True 162:True 163:True 164:True 165:True 166:True 167:True 168:True 169:True 170:True 171:True 172:True 173:True 174:True 175:True 176:True 177:True 178:True 179:True 180:True 181:True 182:True 183:True 184:True 185:True 186:True 187:True 188:True 189:True 190:True 191:True 192:True 193:True 194:True 195:True 196:True 197:True 198:True 199:True 200:True 201:True 202:True 203:True 204:True 205:True 206:True 207:True 208:True 209:True 210:True 211:True 212:True 213:True 214:True 215:True 216:True 217:True 218:True 219:True 220:True 221:True 222:True 223:True 224:True 225:True 226:True 227:True 228:True 229:True 230:True 231:True 232:True 233:True 234:True 235:True 236:True 237:True 238:True 239:True 240:True 241:True 242:True 243:True 244:True 245:True 246:True 247:True 248:True 249:True 250:True 251:True 252:True 253:True 254:True 255:True 256:True 257:True 258:True 259:True 260:True 261:True 262:True 263:False 264:False 265:False 266:False 267:False 268:False 269:False 270:False 271:False 272:False 273:False 274:False 275:False 276:False 277:False 278:False 279:False 280:False 281:False 282:False 283:False 284:False 285:False 286:False 287:False 288:False 289:False 290:False 291:False 292:False 293:False 294:False 295:False 296:False 297:False 298:False 299:False 300:False 301:False 302:False 303:False 304:False 305:False 306:False 307:False 308:False 309:False 310:False 311:False 312:False 313:False 314:False 315:False 316:False 317:False 318:False 319:False 320:False 321:False 322:False 323:False 324:False 325:False 326:False 327:False 328:False 329:False 330:False 331:False 332:False 333:False 334:False 335:False 336:False 337:False 338:False 339:False 340:False 341:False 342:False 343:False 344:False 345:False 346:False 347:False 348:False 349:False 350:False 351:False 352:False 353:False 354:False 355:False 356:False 357:False 358:False 359:False 360:False 361:False 362:False 363:False 364:False 365:False 366:False 367:False 368:False 369:False 370:False 371:False 372:False 373:False 374:False 375:False 376:False 377:False 378:False 379:False 380:False 381:False 382:False\n",
      "INFO:tensorflow:input_ids: 101 2372 1103 9505 1472 5763 1113 170 1825 112 188 17898 1116 136 102 1284 3303 1142 27154 118 3622 1107 14037 1114 1103 11689 26025 7178 1158 1135 14587 1111 3910 7698 20321 1105 19415 1161 118 3622 113 11629 6258 8271 114 4195 13112 119 164 1743 166 17476 19908 117 1259 21385 2107 1174 117 18653 14017 117 1105 9059 1104 2444 1127 1449 11745 118 1840 1183 8703 1196 1428 1857 119 1109 15695 3403 10700 1127 2345 1112 1378 1116 131 113 113 789 181 1818 18071 7409 4412 1805 790 164 118 2508 1708 3048 12008 19995 166 23066 113 789 181 1818 18071 7409 4412 790 164 1398 11628 166 16716 789 1805 790 164 1398 11628 166 114 23066 789 181 1818 18071 7409 4412 1805 790 164 1398 11628 166 23066 789 181 25509 1197 790 164 1398 11628 166 114 16716 6187 164 1398 11628 166 16716 113 789 1123 5813 790 164 2508 1708 3048 12008 19995 166 23066 789 1123 5813 790 164 1398 11628 166 23066 789 1123 5813 2116 790 164 1398 11628 166 114 114 16716 113 1679 10182 118 15925 13169 164 1398 11628 166 16716 113 789 1322 2155 20739 790 164 2508 1708 3048 12008 19995 166 23066 789 1322 2155 20739 790 164 1398 11628 166 23066 789 1322 2155 22258 790 164 1398 11628 166 114 16716 113 789 181 1818 18071 7409 4412 1805 790 164 2508 1708 3048 12008 19995 166 23066 113 789 181 1818 18071 7409 4412 790 164 1398 11628 166 16716 789 1805 790 164 1398 11628 166 114 23066 789 181 1818 18071 7409 4412 1805 790 164 1398 11628 166 23066 789 181 25509 1197 790 164 1398 11628 166 114 16716 113 789 10437 10294 18778 1183 790 164 2508 1708 3048 12008 19995 166 23066 789 10437 10294 18778 1183 790 164 1398 11628 166 23066 789 6187 10294 18778 1183 790 164 1398 11628 166 114 114 119 1188 3403 1108 2609 1106 1769 5174 117 1105 1185 1846 1137 4128 2781 1108 9520 119 1130 1901 117 1195 1145 23465 8703 1103 3835 6802 1104 1103 1529 2527 1105 2166 3189 117 12818 3189 1105 27154 118 3622 1106 6183 102\n",
      "I1208 12:27:37.048285 139883775852736 run_factoid.py:449] input_ids: 101 2372 1103 9505 1472 5763 1113 170 1825 112 188 17898 1116 136 102 1284 3303 1142 27154 118 3622 1107 14037 1114 1103 11689 26025 7178 1158 1135 14587 1111 3910 7698 20321 1105 19415 1161 118 3622 113 11629 6258 8271 114 4195 13112 119 164 1743 166 17476 19908 117 1259 21385 2107 1174 117 18653 14017 117 1105 9059 1104 2444 1127 1449 11745 118 1840 1183 8703 1196 1428 1857 119 1109 15695 3403 10700 1127 2345 1112 1378 1116 131 113 113 789 181 1818 18071 7409 4412 1805 790 164 118 2508 1708 3048 12008 19995 166 23066 113 789 181 1818 18071 7409 4412 790 164 1398 11628 166 16716 789 1805 790 164 1398 11628 166 114 23066 789 181 1818 18071 7409 4412 1805 790 164 1398 11628 166 23066 789 181 25509 1197 790 164 1398 11628 166 114 16716 6187 164 1398 11628 166 16716 113 789 1123 5813 790 164 2508 1708 3048 12008 19995 166 23066 789 1123 5813 790 164 1398 11628 166 23066 789 1123 5813 2116 790 164 1398 11628 166 114 114 16716 113 1679 10182 118 15925 13169 164 1398 11628 166 16716 113 789 1322 2155 20739 790 164 2508 1708 3048 12008 19995 166 23066 789 1322 2155 20739 790 164 1398 11628 166 23066 789 1322 2155 22258 790 164 1398 11628 166 114 16716 113 789 181 1818 18071 7409 4412 1805 790 164 2508 1708 3048 12008 19995 166 23066 113 789 181 1818 18071 7409 4412 790 164 1398 11628 166 16716 789 1805 790 164 1398 11628 166 114 23066 789 181 1818 18071 7409 4412 1805 790 164 1398 11628 166 23066 789 181 25509 1197 790 164 1398 11628 166 114 16716 113 789 10437 10294 18778 1183 790 164 2508 1708 3048 12008 19995 166 23066 789 10437 10294 18778 1183 790 164 1398 11628 166 23066 789 6187 10294 18778 1183 790 164 1398 11628 166 114 114 119 1188 3403 1108 2609 1106 1769 5174 117 1105 1185 1846 1137 4128 2781 1108 9520 119 1130 1901 117 1195 1145 23465 8703 1103 3835 6802 1104 1103 1529 2527 1105 2166 3189 117 12818 3189 1105 27154 118 3622 1106 6183 102\n",
      "INFO:tensorflow:input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      "I1208 12:27:37.048376 139883775852736 run_factoid.py:451] input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      "INFO:tensorflow:segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      "I1208 12:27:37.048465 139883775852736 run_factoid.py:453] segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      "INFO:tensorflow:*** Example ***\n",
      "I1208 12:27:37.049859 139883775852736 run_factoid.py:438] *** Example ***\n",
      "INFO:tensorflow:unique_id: 1000000020\n",
      "I1208 12:27:37.049919 139883775852736 run_factoid.py:439] unique_id: 1000000020\n",
      "INFO:tensorflow:example_index: 6\n",
      "I1208 12:27:37.049955 139883775852736 run_factoid.py:440] example_index: 6\n",
      "INFO:tensorflow:doc_span_index: 1\n",
      "I1208 12:27:37.049989 139883775852736 run_factoid.py:441] doc_span_index: 1\n",
      "INFO:tensorflow:tokens: [CLS] Are the findings different depending on a person ' s demographic ##s ? [SEP] ##umba ##r ” [ All Fields ] ) AND disc [ All Fields ] AND ( “ her ##nia ” [ Me ##S ##H Te ##rms ] OR “ her ##nia ” [ All Fields ] OR “ her ##nia ##tion ” [ All Fields ] ) ) AND ( per ##cu - tan ##eous [ All Fields ] AND ( “ end ##os ##copy ” [ Me ##S ##H Te ##rms ] OR “ end ##os ##copy ” [ All Fields ] OR “ end ##os ##copic ” [ All Fields ] ) AND ( “ l ##um ##bos ##ac ##ral region ” [ Me ##S ##H Te ##rms ] OR ( “ l ##um ##bos ##ac ##ral ” [ All Fields ] AND “ region ” [ All Fields ] ) OR “ l ##um ##bos ##ac ##ral region ” [ All Fields ] OR “ l ##umba ##r ” [ All Fields ] ) AND ( “ disk ##ec ##tom ##y ” [ Me ##S ##H Te ##rms ] OR “ disk ##ec ##tom ##y ” [ All Fields ] OR “ disc ##ec ##tom ##y ” [ All Fields ] ) ) . This search was limited to human subjects , and no language or publication status was imposed . In addition , we also manually searched the reference lists of the included studies and previous review , systematic review and meta - analysis to identify potential studies until no additional articles could be found . The inclusion criteria were as follows : . ( 1 ) study design : random ##ized control trial ( RC ##T ) , co ##hor ##t study , or case - control study ; ( 2 ) population : patients who were diagnosed with L ##D ##H ( 3 ) intervention : P ##EL ##D ; ( 4 ) comparison : other surgical approaches ; ( 5 ) outcome measures : one of the following ##s : success rate , re ##cu ##rrence rate , com ##plication rate , operation time , hospital stay , blood loss , visual analog scale ( VA ##S ) score for back pain and leg pain , 12 - item Short Form [SEP]\n",
      "I1208 12:27:37.050104 139883775852736 run_factoid.py:443] tokens: [CLS] Are the findings different depending on a person ' s demographic ##s ? [SEP] ##umba ##r ” [ All Fields ] ) AND disc [ All Fields ] AND ( “ her ##nia ” [ Me ##S ##H Te ##rms ] OR “ her ##nia ” [ All Fields ] OR “ her ##nia ##tion ” [ All Fields ] ) ) AND ( per ##cu - tan ##eous [ All Fields ] AND ( “ end ##os ##copy ” [ Me ##S ##H Te ##rms ] OR “ end ##os ##copy ” [ All Fields ] OR “ end ##os ##copic ” [ All Fields ] ) AND ( “ l ##um ##bos ##ac ##ral region ” [ Me ##S ##H Te ##rms ] OR ( “ l ##um ##bos ##ac ##ral ” [ All Fields ] AND “ region ” [ All Fields ] ) OR “ l ##um ##bos ##ac ##ral region ” [ All Fields ] OR “ l ##umba ##r ” [ All Fields ] ) AND ( “ disk ##ec ##tom ##y ” [ Me ##S ##H Te ##rms ] OR “ disk ##ec ##tom ##y ” [ All Fields ] OR “ disc ##ec ##tom ##y ” [ All Fields ] ) ) . This search was limited to human subjects , and no language or publication status was imposed . In addition , we also manually searched the reference lists of the included studies and previous review , systematic review and meta - analysis to identify potential studies until no additional articles could be found . The inclusion criteria were as follows : . ( 1 ) study design : random ##ized control trial ( RC ##T ) , co ##hor ##t study , or case - control study ; ( 2 ) population : patients who were diagnosed with L ##D ##H ( 3 ) intervention : P ##EL ##D ; ( 4 ) comparison : other surgical approaches ; ( 5 ) outcome measures : one of the following ##s : success rate , re ##cu ##rrence rate , com ##plication rate , operation time , hospital stay , blood loss , visual analog scale ( VA ##S ) score for back pain and leg pain , 12 - item Short Form [SEP]\n",
      "INFO:tensorflow:token_to_orig_map: 15:59 16:59 17:59 18:59 19:59 20:60 21:60 22:60 23:61 24:62 25:62 26:62 27:63 28:63 29:64 30:65 31:65 32:65 33:65 34:65 35:65 36:65 37:65 38:65 39:66 40:66 41:66 42:67 43:68 44:68 45:68 46:68 47:68 48:68 49:69 50:69 51:70 52:71 53:71 54:71 55:71 56:71 57:71 58:71 59:72 60:72 61:72 62:72 63:73 64:74 65:74 66:74 67:74 68:75 69:75 70:75 71:75 72:76 73:76 74:77 75:78 76:78 77:78 78:78 79:78 80:78 81:78 82:78 83:78 84:78 85:79 86:79 87:79 88:80 89:81 90:81 91:81 92:81 93:81 94:81 95:81 96:82 97:82 98:83 99:84 100:84 101:84 102:84 103:84 104:84 105:84 106:85 107:85 108:85 109:86 110:87 111:87 112:87 113:87 114:87 115:87 116:87 117:88 118:88 119:88 120:88 121:88 122:88 123:89 124:89 125:89 126:90 127:91 128:91 129:91 130:91 131:91 132:91 133:91 134:91 135:91 136:91 137:92 138:92 139:93 140:94 141:94 142:94 143:94 144:94 145:95 146:95 147:95 148:96 149:97 150:97 151:97 152:97 153:97 154:97 155:98 156:98 157:98 158:98 159:99 160:99 161:100 162:101 163:101 164:101 165:101 166:101 167:101 168:101 169:102 170:102 171:102 172:103 173:104 174:104 175:104 176:104 177:104 178:104 179:104 180:104 181:104 182:104 183:104 184:105 185:105 186:105 187:106 188:107 189:107 190:107 191:107 192:107 193:107 194:107 195:107 196:108 197:108 198:109 199:110 200:110 201:110 202:110 203:110 204:110 205:110 206:110 207:111 208:111 209:111 210:111 211:111 212:112 213:113 214:114 215:115 216:116 217:117 218:118 219:118 220:119 221:120 222:121 223:122 224:123 225:124 226:125 227:126 228:126 229:127 230:128 231:128 232:129 233:130 234:131 235:132 236:133 237:134 238:135 239:136 240:137 241:138 242:139 243:140 244:141 245:142 246:142 247:143 248:144 249:145 250:146 251:146 252:146 253:147 254:148 255:149 256:150 257:151 258:152 259:153 260:154 261:155 262:156 263:157 264:157 265:158 266:159 267:160 268:161 269:162 270:163 271:163 272:164 273:165 274:165 275:165 276:166 277:167 278:167 279:168 280:168 281:169 282:170 283:171 284:171 285:171 286:171 287:171 288:172 289:172 290:172 291:173 292:173 293:174 294:175 295:175 296:175 297:176 298:176 299:177 300:177 301:177 302:178 303:178 304:179 305:180 306:181 307:182 308:183 309:184 310:184 311:184 312:185 313:185 314:185 315:186 316:186 317:187 318:187 319:187 320:187 321:188 322:188 323:188 324:189 325:189 326:190 327:191 328:192 329:192 330:193 331:193 332:193 333:194 334:195 335:195 336:196 337:197 338:198 339:199 340:199 341:199 342:200 343:201 344:201 345:202 346:202 347:202 348:203 349:203 350:204 351:204 352:205 353:205 354:206 355:207 356:207 357:208 358:209 359:209 360:210 361:211 362:211 363:212 364:213 365:214 366:215 367:215 368:215 369:215 370:216 371:217 372:218 373:219 374:220 375:221 376:222 377:222 378:223 379:223 380:223 381:224 382:225\n",
      "I1208 12:27:37.050220 139883775852736 run_factoid.py:445] token_to_orig_map: 15:59 16:59 17:59 18:59 19:59 20:60 21:60 22:60 23:61 24:62 25:62 26:62 27:63 28:63 29:64 30:65 31:65 32:65 33:65 34:65 35:65 36:65 37:65 38:65 39:66 40:66 41:66 42:67 43:68 44:68 45:68 46:68 47:68 48:68 49:69 50:69 51:70 52:71 53:71 54:71 55:71 56:71 57:71 58:71 59:72 60:72 61:72 62:72 63:73 64:74 65:74 66:74 67:74 68:75 69:75 70:75 71:75 72:76 73:76 74:77 75:78 76:78 77:78 78:78 79:78 80:78 81:78 82:78 83:78 84:78 85:79 86:79 87:79 88:80 89:81 90:81 91:81 92:81 93:81 94:81 95:81 96:82 97:82 98:83 99:84 100:84 101:84 102:84 103:84 104:84 105:84 106:85 107:85 108:85 109:86 110:87 111:87 112:87 113:87 114:87 115:87 116:87 117:88 118:88 119:88 120:88 121:88 122:88 123:89 124:89 125:89 126:90 127:91 128:91 129:91 130:91 131:91 132:91 133:91 134:91 135:91 136:91 137:92 138:92 139:93 140:94 141:94 142:94 143:94 144:94 145:95 146:95 147:95 148:96 149:97 150:97 151:97 152:97 153:97 154:97 155:98 156:98 157:98 158:98 159:99 160:99 161:100 162:101 163:101 164:101 165:101 166:101 167:101 168:101 169:102 170:102 171:102 172:103 173:104 174:104 175:104 176:104 177:104 178:104 179:104 180:104 181:104 182:104 183:104 184:105 185:105 186:105 187:106 188:107 189:107 190:107 191:107 192:107 193:107 194:107 195:107 196:108 197:108 198:109 199:110 200:110 201:110 202:110 203:110 204:110 205:110 206:110 207:111 208:111 209:111 210:111 211:111 212:112 213:113 214:114 215:115 216:116 217:117 218:118 219:118 220:119 221:120 222:121 223:122 224:123 225:124 226:125 227:126 228:126 229:127 230:128 231:128 232:129 233:130 234:131 235:132 236:133 237:134 238:135 239:136 240:137 241:138 242:139 243:140 244:141 245:142 246:142 247:143 248:144 249:145 250:146 251:146 252:146 253:147 254:148 255:149 256:150 257:151 258:152 259:153 260:154 261:155 262:156 263:157 264:157 265:158 266:159 267:160 268:161 269:162 270:163 271:163 272:164 273:165 274:165 275:165 276:166 277:167 278:167 279:168 280:168 281:169 282:170 283:171 284:171 285:171 286:171 287:171 288:172 289:172 290:172 291:173 292:173 293:174 294:175 295:175 296:175 297:176 298:176 299:177 300:177 301:177 302:178 303:178 304:179 305:180 306:181 307:182 308:183 309:184 310:184 311:184 312:185 313:185 314:185 315:186 316:186 317:187 318:187 319:187 320:187 321:188 322:188 323:188 324:189 325:189 326:190 327:191 328:192 329:192 330:193 331:193 332:193 333:194 334:195 335:195 336:196 337:197 338:198 339:199 340:199 341:199 342:200 343:201 344:201 345:202 346:202 347:202 348:203 349:203 350:204 351:204 352:205 353:205 354:206 355:207 356:207 357:208 358:209 359:209 360:210 361:211 362:211 363:212 364:213 365:214 366:215 367:215 368:215 369:215 370:216 371:217 372:218 373:219 374:220 375:221 376:222 377:222 378:223 379:223 380:223 381:224 382:225\n",
      "INFO:tensorflow:token_is_max_context: 15:False 16:False 17:False 18:False 19:False 20:False 21:False 22:False 23:False 24:False 25:False 26:False 27:False 28:False 29:False 30:False 31:False 32:False 33:False 34:False 35:False 36:False 37:False 38:False 39:False 40:False 41:False 42:False 43:False 44:False 45:False 46:False 47:False 48:False 49:False 50:False 51:False 52:False 53:False 54:False 55:False 56:False 57:False 58:False 59:False 60:False 61:False 62:False 63:False 64:False 65:False 66:False 67:False 68:False 69:False 70:False 71:False 72:False 73:False 74:False 75:False 76:False 77:False 78:False 79:False 80:False 81:False 82:False 83:False 84:False 85:False 86:False 87:False 88:False 89:False 90:False 91:False 92:False 93:False 94:False 95:False 96:False 97:False 98:False 99:False 100:False 101:False 102:False 103:False 104:False 105:False 106:False 107:False 108:False 109:False 110:False 111:False 112:False 113:False 114:False 115:False 116:False 117:False 118:False 119:False 120:False 121:False 122:False 123:False 124:False 125:False 126:False 127:False 128:False 129:False 130:False 131:False 132:False 133:False 134:False 135:True 136:True 137:True 138:True 139:True 140:True 141:True 142:True 143:True 144:True 145:True 146:True 147:True 148:True 149:True 150:True 151:True 152:True 153:True 154:True 155:True 156:True 157:True 158:True 159:True 160:True 161:True 162:True 163:True 164:True 165:True 166:True 167:True 168:True 169:True 170:True 171:True 172:True 173:True 174:True 175:True 176:True 177:True 178:True 179:True 180:True 181:True 182:True 183:True 184:True 185:True 186:True 187:True 188:True 189:True 190:True 191:True 192:True 193:True 194:True 195:True 196:True 197:True 198:True 199:True 200:True 201:True 202:True 203:True 204:True 205:True 206:True 207:True 208:True 209:True 210:True 211:True 212:True 213:True 214:True 215:True 216:True 217:True 218:True 219:True 220:True 221:True 222:True 223:True 224:True 225:True 226:True 227:True 228:True 229:True 230:True 231:True 232:True 233:True 234:True 235:True 236:True 237:True 238:True 239:True 240:True 241:True 242:True 243:True 244:True 245:True 246:True 247:True 248:True 249:True 250:True 251:True 252:True 253:True 254:True 255:True 256:True 257:True 258:True 259:True 260:True 261:True 262:True 263:False 264:False 265:False 266:False 267:False 268:False 269:False 270:False 271:False 272:False 273:False 274:False 275:False 276:False 277:False 278:False 279:False 280:False 281:False 282:False 283:False 284:False 285:False 286:False 287:False 288:False 289:False 290:False 291:False 292:False 293:False 294:False 295:False 296:False 297:False 298:False 299:False 300:False 301:False 302:False 303:False 304:False 305:False 306:False 307:False 308:False 309:False 310:False 311:False 312:False 313:False 314:False 315:False 316:False 317:False 318:False 319:False 320:False 321:False 322:False 323:False 324:False 325:False 326:False 327:False 328:False 329:False 330:False 331:False 332:False 333:False 334:False 335:False 336:False 337:False 338:False 339:False 340:False 341:False 342:False 343:False 344:False 345:False 346:False 347:False 348:False 349:False 350:False 351:False 352:False 353:False 354:False 355:False 356:False 357:False 358:False 359:False 360:False 361:False 362:False 363:False 364:False 365:False 366:False 367:False 368:False 369:False 370:False 371:False 372:False 373:False 374:False 375:False 376:False 377:False 378:False 379:False 380:False 381:False 382:False\n",
      "I1208 12:27:37.050328 139883775852736 run_factoid.py:447] token_is_max_context: 15:False 16:False 17:False 18:False 19:False 20:False 21:False 22:False 23:False 24:False 25:False 26:False 27:False 28:False 29:False 30:False 31:False 32:False 33:False 34:False 35:False 36:False 37:False 38:False 39:False 40:False 41:False 42:False 43:False 44:False 45:False 46:False 47:False 48:False 49:False 50:False 51:False 52:False 53:False 54:False 55:False 56:False 57:False 58:False 59:False 60:False 61:False 62:False 63:False 64:False 65:False 66:False 67:False 68:False 69:False 70:False 71:False 72:False 73:False 74:False 75:False 76:False 77:False 78:False 79:False 80:False 81:False 82:False 83:False 84:False 85:False 86:False 87:False 88:False 89:False 90:False 91:False 92:False 93:False 94:False 95:False 96:False 97:False 98:False 99:False 100:False 101:False 102:False 103:False 104:False 105:False 106:False 107:False 108:False 109:False 110:False 111:False 112:False 113:False 114:False 115:False 116:False 117:False 118:False 119:False 120:False 121:False 122:False 123:False 124:False 125:False 126:False 127:False 128:False 129:False 130:False 131:False 132:False 133:False 134:False 135:True 136:True 137:True 138:True 139:True 140:True 141:True 142:True 143:True 144:True 145:True 146:True 147:True 148:True 149:True 150:True 151:True 152:True 153:True 154:True 155:True 156:True 157:True 158:True 159:True 160:True 161:True 162:True 163:True 164:True 165:True 166:True 167:True 168:True 169:True 170:True 171:True 172:True 173:True 174:True 175:True 176:True 177:True 178:True 179:True 180:True 181:True 182:True 183:True 184:True 185:True 186:True 187:True 188:True 189:True 190:True 191:True 192:True 193:True 194:True 195:True 196:True 197:True 198:True 199:True 200:True 201:True 202:True 203:True 204:True 205:True 206:True 207:True 208:True 209:True 210:True 211:True 212:True 213:True 214:True 215:True 216:True 217:True 218:True 219:True 220:True 221:True 222:True 223:True 224:True 225:True 226:True 227:True 228:True 229:True 230:True 231:True 232:True 233:True 234:True 235:True 236:True 237:True 238:True 239:True 240:True 241:True 242:True 243:True 244:True 245:True 246:True 247:True 248:True 249:True 250:True 251:True 252:True 253:True 254:True 255:True 256:True 257:True 258:True 259:True 260:True 261:True 262:True 263:False 264:False 265:False 266:False 267:False 268:False 269:False 270:False 271:False 272:False 273:False 274:False 275:False 276:False 277:False 278:False 279:False 280:False 281:False 282:False 283:False 284:False 285:False 286:False 287:False 288:False 289:False 290:False 291:False 292:False 293:False 294:False 295:False 296:False 297:False 298:False 299:False 300:False 301:False 302:False 303:False 304:False 305:False 306:False 307:False 308:False 309:False 310:False 311:False 312:False 313:False 314:False 315:False 316:False 317:False 318:False 319:False 320:False 321:False 322:False 323:False 324:False 325:False 326:False 327:False 328:False 329:False 330:False 331:False 332:False 333:False 334:False 335:False 336:False 337:False 338:False 339:False 340:False 341:False 342:False 343:False 344:False 345:False 346:False 347:False 348:False 349:False 350:False 351:False 352:False 353:False 354:False 355:False 356:False 357:False 358:False 359:False 360:False 361:False 362:False 363:False 364:False 365:False 366:False 367:False 368:False 369:False 370:False 371:False 372:False 373:False 374:False 375:False 376:False 377:False 378:False 379:False 380:False 381:False 382:False\n",
      "INFO:tensorflow:input_ids: 101 2372 1103 9505 1472 5763 1113 170 1825 112 188 17898 1116 136 102 25509 1197 790 164 1398 11628 166 114 16716 6187 164 1398 11628 166 16716 113 789 1123 5813 790 164 2508 1708 3048 12008 19995 166 23066 789 1123 5813 790 164 1398 11628 166 23066 789 1123 5813 2116 790 164 1398 11628 166 114 114 16716 113 1679 10182 118 15925 13169 164 1398 11628 166 16716 113 789 1322 2155 20739 790 164 2508 1708 3048 12008 19995 166 23066 789 1322 2155 20739 790 164 1398 11628 166 23066 789 1322 2155 22258 790 164 1398 11628 166 114 16716 113 789 181 1818 18071 7409 4412 1805 790 164 2508 1708 3048 12008 19995 166 23066 113 789 181 1818 18071 7409 4412 790 164 1398 11628 166 16716 789 1805 790 164 1398 11628 166 114 23066 789 181 1818 18071 7409 4412 1805 790 164 1398 11628 166 23066 789 181 25509 1197 790 164 1398 11628 166 114 16716 113 789 10437 10294 18778 1183 790 164 2508 1708 3048 12008 19995 166 23066 789 10437 10294 18778 1183 790 164 1398 11628 166 23066 789 6187 10294 18778 1183 790 164 1398 11628 166 114 114 119 1188 3403 1108 2609 1106 1769 5174 117 1105 1185 1846 1137 4128 2781 1108 9520 119 1130 1901 117 1195 1145 23465 8703 1103 3835 6802 1104 1103 1529 2527 1105 2166 3189 117 12818 3189 1105 27154 118 3622 1106 6183 3209 2527 1235 1185 2509 4237 1180 1129 1276 119 1109 10838 9173 1127 1112 3226 131 119 113 122 114 2025 1902 131 7091 2200 1654 3443 113 25157 1942 114 117 1884 13252 1204 2025 117 1137 1692 118 1654 2025 132 113 123 114 1416 131 4420 1150 1127 11534 1114 149 2137 3048 113 124 114 9108 131 153 21678 2137 132 113 125 114 7577 131 1168 13467 8015 132 113 126 114 9386 5252 131 1141 1104 1103 1378 1116 131 2244 2603 117 1231 10182 21629 2603 117 3254 15534 2603 117 2805 1159 117 2704 2215 117 1892 2445 117 5173 13022 3418 113 19497 1708 114 2794 1111 1171 2489 1105 3420 2489 117 1367 118 8926 6373 15075 102\n",
      "I1208 12:27:37.050431 139883775852736 run_factoid.py:449] input_ids: 101 2372 1103 9505 1472 5763 1113 170 1825 112 188 17898 1116 136 102 25509 1197 790 164 1398 11628 166 114 16716 6187 164 1398 11628 166 16716 113 789 1123 5813 790 164 2508 1708 3048 12008 19995 166 23066 789 1123 5813 790 164 1398 11628 166 23066 789 1123 5813 2116 790 164 1398 11628 166 114 114 16716 113 1679 10182 118 15925 13169 164 1398 11628 166 16716 113 789 1322 2155 20739 790 164 2508 1708 3048 12008 19995 166 23066 789 1322 2155 20739 790 164 1398 11628 166 23066 789 1322 2155 22258 790 164 1398 11628 166 114 16716 113 789 181 1818 18071 7409 4412 1805 790 164 2508 1708 3048 12008 19995 166 23066 113 789 181 1818 18071 7409 4412 790 164 1398 11628 166 16716 789 1805 790 164 1398 11628 166 114 23066 789 181 1818 18071 7409 4412 1805 790 164 1398 11628 166 23066 789 181 25509 1197 790 164 1398 11628 166 114 16716 113 789 10437 10294 18778 1183 790 164 2508 1708 3048 12008 19995 166 23066 789 10437 10294 18778 1183 790 164 1398 11628 166 23066 789 6187 10294 18778 1183 790 164 1398 11628 166 114 114 119 1188 3403 1108 2609 1106 1769 5174 117 1105 1185 1846 1137 4128 2781 1108 9520 119 1130 1901 117 1195 1145 23465 8703 1103 3835 6802 1104 1103 1529 2527 1105 2166 3189 117 12818 3189 1105 27154 118 3622 1106 6183 3209 2527 1235 1185 2509 4237 1180 1129 1276 119 1109 10838 9173 1127 1112 3226 131 119 113 122 114 2025 1902 131 7091 2200 1654 3443 113 25157 1942 114 117 1884 13252 1204 2025 117 1137 1692 118 1654 2025 132 113 123 114 1416 131 4420 1150 1127 11534 1114 149 2137 3048 113 124 114 9108 131 153 21678 2137 132 113 125 114 7577 131 1168 13467 8015 132 113 126 114 9386 5252 131 1141 1104 1103 1378 1116 131 2244 2603 117 1231 10182 21629 2603 117 3254 15534 2603 117 2805 1159 117 2704 2215 117 1892 2445 117 5173 13022 3418 113 19497 1708 114 2794 1111 1171 2489 1105 3420 2489 117 1367 118 8926 6373 15075 102\n",
      "INFO:tensorflow:input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      "I1208 12:27:37.050522 139883775852736 run_factoid.py:451] input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      "INFO:tensorflow:segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      "I1208 12:27:37.050612 139883775852736 run_factoid.py:453] segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      "INFO:tensorflow:*** Example ***\n",
      "I1208 12:27:37.052059 139883775852736 run_factoid.py:438] *** Example ***\n",
      "INFO:tensorflow:unique_id: 1000000021\n",
      "I1208 12:27:37.052119 139883775852736 run_factoid.py:439] unique_id: 1000000021\n",
      "INFO:tensorflow:example_index: 6\n",
      "I1208 12:27:37.052157 139883775852736 run_factoid.py:440] example_index: 6\n",
      "INFO:tensorflow:doc_span_index: 2\n",
      "I1208 12:27:37.052191 139883775852736 run_factoid.py:441] doc_span_index: 2\n",
      "INFO:tensorflow:tokens: [CLS] Are the findings different depending on a person ' s demographic ##s ? [SEP] [ All Fields ] ) OR “ l ##um ##bos ##ac ##ral region ” [ All Fields ] OR “ l ##umba ##r ” [ All Fields ] ) AND ( “ disk ##ec ##tom ##y ” [ Me ##S ##H Te ##rms ] OR “ disk ##ec ##tom ##y ” [ All Fields ] OR “ disc ##ec ##tom ##y ” [ All Fields ] ) ) . This search was limited to human subjects , and no language or publication status was imposed . In addition , we also manually searched the reference lists of the included studies and previous review , systematic review and meta - analysis to identify potential studies until no additional articles could be found . The inclusion criteria were as follows : . ( 1 ) study design : random ##ized control trial ( RC ##T ) , co ##hor ##t study , or case - control study ; ( 2 ) population : patients who were diagnosed with L ##D ##H ( 3 ) intervention : P ##EL ##D ; ( 4 ) comparison : other surgical approaches ; ( 5 ) outcome measures : one of the following ##s : success rate , re ##cu ##rrence rate , com ##plication rate , operation time , hospital stay , blood loss , visual analog scale ( VA ##S ) score for back pain and leg pain , 12 - item Short Form Health Survey ( SF ##12 ) physical component score ( PC ##S ) , mental component score ( MC ##S ) , Japanese Or ##th ##op ##ae ##dic Association Score ( J ##OA ) , O ##s ##wes ##try Di ##sa ##bility Index ( ODI ) . Two independent investigators extracted the following data from the included studies : first author ’ name , publication year , study design , country , number of patients in each group , patients ’ characteristics , and outcome data ( success rate , re ##cu ##rrence rate , com ##plication rate , operation time , hospital stay , blood loss , VA ##S scores for back pain and leg pain , J ##OA , SF ##12 - MC ##S / PC [SEP]\n",
      "I1208 12:27:37.052306 139883775852736 run_factoid.py:443] tokens: [CLS] Are the findings different depending on a person ' s demographic ##s ? [SEP] [ All Fields ] ) OR “ l ##um ##bos ##ac ##ral region ” [ All Fields ] OR “ l ##umba ##r ” [ All Fields ] ) AND ( “ disk ##ec ##tom ##y ” [ Me ##S ##H Te ##rms ] OR “ disk ##ec ##tom ##y ” [ All Fields ] OR “ disc ##ec ##tom ##y ” [ All Fields ] ) ) . This search was limited to human subjects , and no language or publication status was imposed . In addition , we also manually searched the reference lists of the included studies and previous review , systematic review and meta - analysis to identify potential studies until no additional articles could be found . The inclusion criteria were as follows : . ( 1 ) study design : random ##ized control trial ( RC ##T ) , co ##hor ##t study , or case - control study ; ( 2 ) population : patients who were diagnosed with L ##D ##H ( 3 ) intervention : P ##EL ##D ; ( 4 ) comparison : other surgical approaches ; ( 5 ) outcome measures : one of the following ##s : success rate , re ##cu ##rrence rate , com ##plication rate , operation time , hospital stay , blood loss , visual analog scale ( VA ##S ) score for back pain and leg pain , 12 - item Short Form Health Survey ( SF ##12 ) physical component score ( PC ##S ) , mental component score ( MC ##S ) , Japanese Or ##th ##op ##ae ##dic Association Score ( J ##OA ) , O ##s ##wes ##try Di ##sa ##bility Index ( ODI ) . Two independent investigators extracted the following data from the included studies : first author ’ name , publication year , study design , country , number of patients in each group , patients ’ characteristics , and outcome data ( success rate , re ##cu ##rrence rate , com ##plication rate , operation time , hospital stay , blood loss , VA ##S scores for back pain and leg pain , J ##OA , SF ##12 - MC ##S / PC [SEP]\n",
      "INFO:tensorflow:token_to_orig_map: 15:94 16:94 17:95 18:95 19:95 20:96 21:97 22:97 23:97 24:97 25:97 26:97 27:98 28:98 29:98 30:98 31:99 32:99 33:100 34:101 35:101 36:101 37:101 38:101 39:101 40:101 41:102 42:102 43:102 44:103 45:104 46:104 47:104 48:104 49:104 50:104 51:104 52:104 53:104 54:104 55:104 56:105 57:105 58:105 59:106 60:107 61:107 62:107 63:107 64:107 65:107 66:107 67:107 68:108 69:108 70:109 71:110 72:110 73:110 74:110 75:110 76:110 77:110 78:110 79:111 80:111 81:111 82:111 83:111 84:112 85:113 86:114 87:115 88:116 89:117 90:118 91:118 92:119 93:120 94:121 95:122 96:123 97:124 98:125 99:126 100:126 101:127 102:128 103:128 104:129 105:130 106:131 107:132 108:133 109:134 110:135 111:136 112:137 113:138 114:139 115:140 116:141 117:142 118:142 119:143 120:144 121:145 122:146 123:146 124:146 125:147 126:148 127:149 128:150 129:151 130:152 131:153 132:154 133:155 134:156 135:157 136:157 137:158 138:159 139:160 140:161 141:162 142:163 143:163 144:164 145:165 146:165 147:165 148:166 149:167 150:167 151:168 152:168 153:169 154:170 155:171 156:171 157:171 158:171 159:171 160:172 161:172 162:172 163:173 164:173 165:174 166:175 167:175 168:175 169:176 170:176 171:177 172:177 173:177 174:178 175:178 176:179 177:180 178:181 179:182 180:183 181:184 182:184 183:184 184:185 185:185 186:185 187:186 188:186 189:187 190:187 191:187 192:187 193:188 194:188 195:188 196:189 197:189 198:190 199:191 200:192 201:192 202:193 203:193 204:193 205:194 206:195 207:195 208:196 209:197 210:198 211:199 212:199 213:199 214:200 215:201 216:201 217:202 218:202 219:202 220:203 221:203 222:204 223:204 224:205 225:205 226:206 227:207 228:207 229:208 230:209 231:209 232:210 233:211 234:211 235:212 236:213 237:214 238:215 239:215 240:215 241:215 242:216 243:217 244:218 245:219 246:220 247:221 248:222 249:222 250:223 251:223 252:223 253:224 254:225 255:226 256:227 257:228 258:228 259:228 260:228 261:229 262:230 263:231 264:232 265:232 266:232 267:232 268:232 269:233 270:234 271:235 272:236 273:236 274:236 275:236 276:236 277:237 278:238 279:238 280:238 281:238 282:238 283:239 284:240 285:241 286:241 287:241 288:241 289:241 290:242 291:242 292:242 293:242 294:243 295:243 296:243 297:244 298:245 299:245 300:245 301:245 302:246 303:247 304:248 305:249 306:250 307:251 308:252 309:253 310:254 311:255 312:256 313:256 314:257 315:258 316:258 317:259 318:259 319:260 320:261 321:261 322:262 323:263 324:263 325:264 326:264 327:265 328:266 329:267 330:268 331:269 332:270 333:270 334:271 335:271 336:272 337:272 338:273 339:274 340:275 341:276 342:276 343:277 344:277 345:278 346:278 347:278 348:279 349:279 350:280 351:280 352:281 353:281 354:282 355:283 356:283 357:284 358:285 359:285 360:286 361:287 362:287 363:288 364:288 365:289 366:290 367:291 368:292 369:293 370:294 371:295 372:295 373:296 374:296 375:296 376:297 377:297 378:297 379:297 380:297 381:297 382:297\n",
      "I1208 12:27:37.052424 139883775852736 run_factoid.py:445] token_to_orig_map: 15:94 16:94 17:95 18:95 19:95 20:96 21:97 22:97 23:97 24:97 25:97 26:97 27:98 28:98 29:98 30:98 31:99 32:99 33:100 34:101 35:101 36:101 37:101 38:101 39:101 40:101 41:102 42:102 43:102 44:103 45:104 46:104 47:104 48:104 49:104 50:104 51:104 52:104 53:104 54:104 55:104 56:105 57:105 58:105 59:106 60:107 61:107 62:107 63:107 64:107 65:107 66:107 67:107 68:108 69:108 70:109 71:110 72:110 73:110 74:110 75:110 76:110 77:110 78:110 79:111 80:111 81:111 82:111 83:111 84:112 85:113 86:114 87:115 88:116 89:117 90:118 91:118 92:119 93:120 94:121 95:122 96:123 97:124 98:125 99:126 100:126 101:127 102:128 103:128 104:129 105:130 106:131 107:132 108:133 109:134 110:135 111:136 112:137 113:138 114:139 115:140 116:141 117:142 118:142 119:143 120:144 121:145 122:146 123:146 124:146 125:147 126:148 127:149 128:150 129:151 130:152 131:153 132:154 133:155 134:156 135:157 136:157 137:158 138:159 139:160 140:161 141:162 142:163 143:163 144:164 145:165 146:165 147:165 148:166 149:167 150:167 151:168 152:168 153:169 154:170 155:171 156:171 157:171 158:171 159:171 160:172 161:172 162:172 163:173 164:173 165:174 166:175 167:175 168:175 169:176 170:176 171:177 172:177 173:177 174:178 175:178 176:179 177:180 178:181 179:182 180:183 181:184 182:184 183:184 184:185 185:185 186:185 187:186 188:186 189:187 190:187 191:187 192:187 193:188 194:188 195:188 196:189 197:189 198:190 199:191 200:192 201:192 202:193 203:193 204:193 205:194 206:195 207:195 208:196 209:197 210:198 211:199 212:199 213:199 214:200 215:201 216:201 217:202 218:202 219:202 220:203 221:203 222:204 223:204 224:205 225:205 226:206 227:207 228:207 229:208 230:209 231:209 232:210 233:211 234:211 235:212 236:213 237:214 238:215 239:215 240:215 241:215 242:216 243:217 244:218 245:219 246:220 247:221 248:222 249:222 250:223 251:223 252:223 253:224 254:225 255:226 256:227 257:228 258:228 259:228 260:228 261:229 262:230 263:231 264:232 265:232 266:232 267:232 268:232 269:233 270:234 271:235 272:236 273:236 274:236 275:236 276:236 277:237 278:238 279:238 280:238 281:238 282:238 283:239 284:240 285:241 286:241 287:241 288:241 289:241 290:242 291:242 292:242 293:242 294:243 295:243 296:243 297:244 298:245 299:245 300:245 301:245 302:246 303:247 304:248 305:249 306:250 307:251 308:252 309:253 310:254 311:255 312:256 313:256 314:257 315:258 316:258 317:259 318:259 319:260 320:261 321:261 322:262 323:263 324:263 325:264 326:264 327:265 328:266 329:267 330:268 331:269 332:270 333:270 334:271 335:271 336:272 337:272 338:273 339:274 340:275 341:276 342:276 343:277 344:277 345:278 346:278 347:278 348:279 349:279 350:280 351:280 352:281 353:281 354:282 355:283 356:283 357:284 358:285 359:285 360:286 361:287 362:287 363:288 364:288 365:289 366:290 367:291 368:292 369:293 370:294 371:295 372:295 373:296 374:296 375:296 376:297 377:297 378:297 379:297 380:297 381:297 382:297\n",
      "INFO:tensorflow:token_is_max_context: 15:False 16:False 17:False 18:False 19:False 20:False 21:False 22:False 23:False 24:False 25:False 26:False 27:False 28:False 29:False 30:False 31:False 32:False 33:False 34:False 35:False 36:False 37:False 38:False 39:False 40:False 41:False 42:False 43:False 44:False 45:False 46:False 47:False 48:False 49:False 50:False 51:False 52:False 53:False 54:False 55:False 56:False 57:False 58:False 59:False 60:False 61:False 62:False 63:False 64:False 65:False 66:False 67:False 68:False 69:False 70:False 71:False 72:False 73:False 74:False 75:False 76:False 77:False 78:False 79:False 80:False 81:False 82:False 83:False 84:False 85:False 86:False 87:False 88:False 89:False 90:False 91:False 92:False 93:False 94:False 95:False 96:False 97:False 98:False 99:False 100:False 101:False 102:False 103:False 104:False 105:False 106:False 107:False 108:False 109:False 110:False 111:False 112:False 113:False 114:False 115:False 116:False 117:False 118:False 119:False 120:False 121:False 122:False 123:False 124:False 125:False 126:False 127:False 128:False 129:False 130:False 131:False 132:False 133:False 134:False 135:True 136:True 137:True 138:True 139:True 140:True 141:True 142:True 143:True 144:True 145:True 146:True 147:True 148:True 149:True 150:True 151:True 152:True 153:True 154:True 155:True 156:True 157:True 158:True 159:True 160:True 161:True 162:True 163:True 164:True 165:True 166:True 167:True 168:True 169:True 170:True 171:True 172:True 173:True 174:True 175:True 176:True 177:True 178:True 179:True 180:True 181:True 182:True 183:True 184:True 185:True 186:True 187:True 188:True 189:True 190:True 191:True 192:True 193:True 194:True 195:True 196:True 197:True 198:True 199:True 200:True 201:True 202:True 203:True 204:True 205:True 206:True 207:True 208:True 209:True 210:True 211:True 212:True 213:True 214:True 215:True 216:True 217:True 218:True 219:True 220:True 221:True 222:True 223:True 224:True 225:True 226:True 227:True 228:True 229:True 230:True 231:True 232:True 233:True 234:True 235:True 236:True 237:True 238:True 239:True 240:True 241:True 242:True 243:True 244:True 245:True 246:True 247:True 248:True 249:True 250:True 251:True 252:True 253:True 254:True 255:True 256:True 257:True 258:True 259:True 260:True 261:True 262:True 263:False 264:False 265:False 266:False 267:False 268:False 269:False 270:False 271:False 272:False 273:False 274:False 275:False 276:False 277:False 278:False 279:False 280:False 281:False 282:False 283:False 284:False 285:False 286:False 287:False 288:False 289:False 290:False 291:False 292:False 293:False 294:False 295:False 296:False 297:False 298:False 299:False 300:False 301:False 302:False 303:False 304:False 305:False 306:False 307:False 308:False 309:False 310:False 311:False 312:False 313:False 314:False 315:False 316:False 317:False 318:False 319:False 320:False 321:False 322:False 323:False 324:False 325:False 326:False 327:False 328:False 329:False 330:False 331:False 332:False 333:False 334:False 335:False 336:False 337:False 338:False 339:False 340:False 341:False 342:False 343:False 344:False 345:False 346:False 347:False 348:False 349:False 350:False 351:False 352:False 353:False 354:False 355:False 356:False 357:False 358:False 359:False 360:False 361:False 362:False 363:False 364:False 365:False 366:False 367:False 368:False 369:False 370:False 371:False 372:False 373:False 374:False 375:False 376:False 377:False 378:False 379:False 380:False 381:False 382:False\n",
      "I1208 12:27:37.052542 139883775852736 run_factoid.py:447] token_is_max_context: 15:False 16:False 17:False 18:False 19:False 20:False 21:False 22:False 23:False 24:False 25:False 26:False 27:False 28:False 29:False 30:False 31:False 32:False 33:False 34:False 35:False 36:False 37:False 38:False 39:False 40:False 41:False 42:False 43:False 44:False 45:False 46:False 47:False 48:False 49:False 50:False 51:False 52:False 53:False 54:False 55:False 56:False 57:False 58:False 59:False 60:False 61:False 62:False 63:False 64:False 65:False 66:False 67:False 68:False 69:False 70:False 71:False 72:False 73:False 74:False 75:False 76:False 77:False 78:False 79:False 80:False 81:False 82:False 83:False 84:False 85:False 86:False 87:False 88:False 89:False 90:False 91:False 92:False 93:False 94:False 95:False 96:False 97:False 98:False 99:False 100:False 101:False 102:False 103:False 104:False 105:False 106:False 107:False 108:False 109:False 110:False 111:False 112:False 113:False 114:False 115:False 116:False 117:False 118:False 119:False 120:False 121:False 122:False 123:False 124:False 125:False 126:False 127:False 128:False 129:False 130:False 131:False 132:False 133:False 134:False 135:True 136:True 137:True 138:True 139:True 140:True 141:True 142:True 143:True 144:True 145:True 146:True 147:True 148:True 149:True 150:True 151:True 152:True 153:True 154:True 155:True 156:True 157:True 158:True 159:True 160:True 161:True 162:True 163:True 164:True 165:True 166:True 167:True 168:True 169:True 170:True 171:True 172:True 173:True 174:True 175:True 176:True 177:True 178:True 179:True 180:True 181:True 182:True 183:True 184:True 185:True 186:True 187:True 188:True 189:True 190:True 191:True 192:True 193:True 194:True 195:True 196:True 197:True 198:True 199:True 200:True 201:True 202:True 203:True 204:True 205:True 206:True 207:True 208:True 209:True 210:True 211:True 212:True 213:True 214:True 215:True 216:True 217:True 218:True 219:True 220:True 221:True 222:True 223:True 224:True 225:True 226:True 227:True 228:True 229:True 230:True 231:True 232:True 233:True 234:True 235:True 236:True 237:True 238:True 239:True 240:True 241:True 242:True 243:True 244:True 245:True 246:True 247:True 248:True 249:True 250:True 251:True 252:True 253:True 254:True 255:True 256:True 257:True 258:True 259:True 260:True 261:True 262:True 263:False 264:False 265:False 266:False 267:False 268:False 269:False 270:False 271:False 272:False 273:False 274:False 275:False 276:False 277:False 278:False 279:False 280:False 281:False 282:False 283:False 284:False 285:False 286:False 287:False 288:False 289:False 290:False 291:False 292:False 293:False 294:False 295:False 296:False 297:False 298:False 299:False 300:False 301:False 302:False 303:False 304:False 305:False 306:False 307:False 308:False 309:False 310:False 311:False 312:False 313:False 314:False 315:False 316:False 317:False 318:False 319:False 320:False 321:False 322:False 323:False 324:False 325:False 326:False 327:False 328:False 329:False 330:False 331:False 332:False 333:False 334:False 335:False 336:False 337:False 338:False 339:False 340:False 341:False 342:False 343:False 344:False 345:False 346:False 347:False 348:False 349:False 350:False 351:False 352:False 353:False 354:False 355:False 356:False 357:False 358:False 359:False 360:False 361:False 362:False 363:False 364:False 365:False 366:False 367:False 368:False 369:False 370:False 371:False 372:False 373:False 374:False 375:False 376:False 377:False 378:False 379:False 380:False 381:False 382:False\n",
      "INFO:tensorflow:input_ids: 101 2372 1103 9505 1472 5763 1113 170 1825 112 188 17898 1116 136 102 164 1398 11628 166 114 23066 789 181 1818 18071 7409 4412 1805 790 164 1398 11628 166 23066 789 181 25509 1197 790 164 1398 11628 166 114 16716 113 789 10437 10294 18778 1183 790 164 2508 1708 3048 12008 19995 166 23066 789 10437 10294 18778 1183 790 164 1398 11628 166 23066 789 6187 10294 18778 1183 790 164 1398 11628 166 114 114 119 1188 3403 1108 2609 1106 1769 5174 117 1105 1185 1846 1137 4128 2781 1108 9520 119 1130 1901 117 1195 1145 23465 8703 1103 3835 6802 1104 1103 1529 2527 1105 2166 3189 117 12818 3189 1105 27154 118 3622 1106 6183 3209 2527 1235 1185 2509 4237 1180 1129 1276 119 1109 10838 9173 1127 1112 3226 131 119 113 122 114 2025 1902 131 7091 2200 1654 3443 113 25157 1942 114 117 1884 13252 1204 2025 117 1137 1692 118 1654 2025 132 113 123 114 1416 131 4420 1150 1127 11534 1114 149 2137 3048 113 124 114 9108 131 153 21678 2137 132 113 125 114 7577 131 1168 13467 8015 132 113 126 114 9386 5252 131 1141 1104 1103 1378 1116 131 2244 2603 117 1231 10182 21629 2603 117 3254 15534 2603 117 2805 1159 117 2704 2215 117 1892 2445 117 5173 13022 3418 113 19497 1708 114 2794 1111 1171 2489 1105 3420 2489 117 1367 118 8926 6373 15075 3225 8157 113 18659 11964 114 2952 6552 2794 113 7054 1708 114 117 4910 6552 2794 113 12029 1708 114 117 1983 2926 1582 4184 5024 13328 1791 18417 113 147 23579 114 117 152 1116 14291 6013 12120 3202 5474 10146 113 23882 114 119 1960 2457 17718 16939 1103 1378 2233 1121 1103 1529 2527 131 1148 2351 787 1271 117 4128 1214 117 2025 1902 117 1583 117 1295 1104 4420 1107 1296 1372 117 4420 787 5924 117 1105 9386 2233 113 2244 2603 117 1231 10182 21629 2603 117 3254 15534 2603 117 2805 1159 117 2704 2215 117 1892 2445 117 19497 1708 7432 1111 1171 2489 1105 3420 2489 117 147 23579 117 18659 11964 118 12029 1708 120 7054 102\n",
      "I1208 12:27:37.052651 139883775852736 run_factoid.py:449] input_ids: 101 2372 1103 9505 1472 5763 1113 170 1825 112 188 17898 1116 136 102 164 1398 11628 166 114 23066 789 181 1818 18071 7409 4412 1805 790 164 1398 11628 166 23066 789 181 25509 1197 790 164 1398 11628 166 114 16716 113 789 10437 10294 18778 1183 790 164 2508 1708 3048 12008 19995 166 23066 789 10437 10294 18778 1183 790 164 1398 11628 166 23066 789 6187 10294 18778 1183 790 164 1398 11628 166 114 114 119 1188 3403 1108 2609 1106 1769 5174 117 1105 1185 1846 1137 4128 2781 1108 9520 119 1130 1901 117 1195 1145 23465 8703 1103 3835 6802 1104 1103 1529 2527 1105 2166 3189 117 12818 3189 1105 27154 118 3622 1106 6183 3209 2527 1235 1185 2509 4237 1180 1129 1276 119 1109 10838 9173 1127 1112 3226 131 119 113 122 114 2025 1902 131 7091 2200 1654 3443 113 25157 1942 114 117 1884 13252 1204 2025 117 1137 1692 118 1654 2025 132 113 123 114 1416 131 4420 1150 1127 11534 1114 149 2137 3048 113 124 114 9108 131 153 21678 2137 132 113 125 114 7577 131 1168 13467 8015 132 113 126 114 9386 5252 131 1141 1104 1103 1378 1116 131 2244 2603 117 1231 10182 21629 2603 117 3254 15534 2603 117 2805 1159 117 2704 2215 117 1892 2445 117 5173 13022 3418 113 19497 1708 114 2794 1111 1171 2489 1105 3420 2489 117 1367 118 8926 6373 15075 3225 8157 113 18659 11964 114 2952 6552 2794 113 7054 1708 114 117 4910 6552 2794 113 12029 1708 114 117 1983 2926 1582 4184 5024 13328 1791 18417 113 147 23579 114 117 152 1116 14291 6013 12120 3202 5474 10146 113 23882 114 119 1960 2457 17718 16939 1103 1378 2233 1121 1103 1529 2527 131 1148 2351 787 1271 117 4128 1214 117 2025 1902 117 1583 117 1295 1104 4420 1107 1296 1372 117 4420 787 5924 117 1105 9386 2233 113 2244 2603 117 1231 10182 21629 2603 117 3254 15534 2603 117 2805 1159 117 2704 2215 117 1892 2445 117 19497 1708 7432 1111 1171 2489 1105 3420 2489 117 147 23579 117 18659 11964 118 12029 1708 120 7054 102\n",
      "INFO:tensorflow:input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      "I1208 12:27:37.052744 139883775852736 run_factoid.py:451] input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      "INFO:tensorflow:segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      "I1208 12:27:37.052834 139883775852736 run_factoid.py:453] segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      "INFO:tensorflow:*** Example ***\n",
      "I1208 12:27:37.054320 139883775852736 run_factoid.py:438] *** Example ***\n",
      "INFO:tensorflow:unique_id: 1000000022\n",
      "I1208 12:27:37.054379 139883775852736 run_factoid.py:439] unique_id: 1000000022\n",
      "INFO:tensorflow:example_index: 6\n",
      "I1208 12:27:37.054417 139883775852736 run_factoid.py:440] example_index: 6\n",
      "INFO:tensorflow:doc_span_index: 3\n",
      "I1208 12:27:37.054451 139883775852736 run_factoid.py:441] doc_span_index: 3\n",
      "INFO:tensorflow:tokens: [CLS] Are the findings different depending on a person ' s demographic ##s ? [SEP] : . ( 1 ) study design : random ##ized control trial ( RC ##T ) , co ##hor ##t study , or case - control study ; ( 2 ) population : patients who were diagnosed with L ##D ##H ( 3 ) intervention : P ##EL ##D ; ( 4 ) comparison : other surgical approaches ; ( 5 ) outcome measures : one of the following ##s : success rate , re ##cu ##rrence rate , com ##plication rate , operation time , hospital stay , blood loss , visual analog scale ( VA ##S ) score for back pain and leg pain , 12 - item Short Form Health Survey ( SF ##12 ) physical component score ( PC ##S ) , mental component score ( MC ##S ) , Japanese Or ##th ##op ##ae ##dic Association Score ( J ##OA ) , O ##s ##wes ##try Di ##sa ##bility Index ( ODI ) . Two independent investigators extracted the following data from the included studies : first author ’ name , publication year , study design , country , number of patients in each group , patients ’ characteristics , and outcome data ( success rate , re ##cu ##rrence rate , com ##plication rate , operation time , hospital stay , blood loss , VA ##S scores for back pain and leg pain , J ##OA , SF ##12 - MC ##S / PC ##S , and ODI ) . If the study did not provide the important data , we would contact the corresponding authors for the missing information . We evaluated the risk of bias in RC ##T ##s with the method recommended by Cochrane Col ##la ##bor ##ation . [ 29 ] Five items , including blinding , method of random ##ization , allocation con - c ##eal ##ment , follow - up , and intention - to - treat analysis were used to assess the quality of study . [ 29 ] And each study was classified as high , low , or unclear risk of bias . We evaluated the method ##ological quality of non - random ##ized studies ( co ##hor ##t study , or case [SEP]\n",
      "I1208 12:27:37.054566 139883775852736 run_factoid.py:443] tokens: [CLS] Are the findings different depending on a person ' s demographic ##s ? [SEP] : . ( 1 ) study design : random ##ized control trial ( RC ##T ) , co ##hor ##t study , or case - control study ; ( 2 ) population : patients who were diagnosed with L ##D ##H ( 3 ) intervention : P ##EL ##D ; ( 4 ) comparison : other surgical approaches ; ( 5 ) outcome measures : one of the following ##s : success rate , re ##cu ##rrence rate , com ##plication rate , operation time , hospital stay , blood loss , visual analog scale ( VA ##S ) score for back pain and leg pain , 12 - item Short Form Health Survey ( SF ##12 ) physical component score ( PC ##S ) , mental component score ( MC ##S ) , Japanese Or ##th ##op ##ae ##dic Association Score ( J ##OA ) , O ##s ##wes ##try Di ##sa ##bility Index ( ODI ) . Two independent investigators extracted the following data from the included studies : first author ’ name , publication year , study design , country , number of patients in each group , patients ’ characteristics , and outcome data ( success rate , re ##cu ##rrence rate , com ##plication rate , operation time , hospital stay , blood loss , VA ##S scores for back pain and leg pain , J ##OA , SF ##12 - MC ##S / PC ##S , and ODI ) . If the study did not provide the important data , we would contact the corresponding authors for the missing information . We evaluated the risk of bias in RC ##T ##s with the method recommended by Cochrane Col ##la ##bor ##ation . [ 29 ] Five items , including blinding , method of random ##ization , allocation con - c ##eal ##ment , follow - up , and intention - to - treat analysis were used to assess the quality of study . [ 29 ] And each study was classified as high , low , or unclear risk of bias . We evaluated the method ##ological quality of non - random ##ized studies ( co ##hor ##t study , or case [SEP]\n",
      "INFO:tensorflow:token_to_orig_map: 15:163 16:164 17:165 18:165 19:165 20:166 21:167 22:167 23:168 24:168 25:169 26:170 27:171 28:171 29:171 30:171 31:171 32:172 33:172 34:172 35:173 36:173 37:174 38:175 39:175 40:175 41:176 42:176 43:177 44:177 45:177 46:178 47:178 48:179 49:180 50:181 51:182 52:183 53:184 54:184 55:184 56:185 57:185 58:185 59:186 60:186 61:187 62:187 63:187 64:187 65:188 66:188 67:188 68:189 69:189 70:190 71:191 72:192 73:192 74:193 75:193 76:193 77:194 78:195 79:195 80:196 81:197 82:198 83:199 84:199 85:199 86:200 87:201 88:201 89:202 90:202 91:202 92:203 93:203 94:204 95:204 96:205 97:205 98:206 99:207 100:207 101:208 102:209 103:209 104:210 105:211 106:211 107:212 108:213 109:214 110:215 111:215 112:215 113:215 114:216 115:217 116:218 117:219 118:220 119:221 120:222 121:222 122:223 123:223 124:223 125:224 126:225 127:226 128:227 129:228 130:228 131:228 132:228 133:229 134:230 135:231 136:232 137:232 138:232 139:232 140:232 141:233 142:234 143:235 144:236 145:236 146:236 147:236 148:236 149:237 150:238 151:238 152:238 153:238 154:238 155:239 156:240 157:241 158:241 159:241 160:241 161:241 162:242 163:242 164:242 165:242 166:243 167:243 168:243 169:244 170:245 171:245 172:245 173:245 174:246 175:247 176:248 177:249 178:250 179:251 180:252 181:253 182:254 183:255 184:256 185:256 186:257 187:258 188:258 189:259 190:259 191:260 192:261 193:261 194:262 195:263 196:263 197:264 198:264 199:265 200:266 201:267 202:268 203:269 204:270 205:270 206:271 207:271 208:272 209:272 210:273 211:274 212:275 213:276 214:276 215:277 216:277 217:278 218:278 219:278 220:279 221:279 222:280 223:280 224:281 225:281 226:282 227:283 228:283 229:284 230:285 231:285 232:286 233:287 234:287 235:288 236:288 237:289 238:290 239:291 240:292 241:293 242:294 243:295 244:295 245:296 246:296 247:296 248:297 249:297 250:297 251:297 252:297 253:297 254:297 255:297 256:297 257:298 258:299 259:299 260:299 261:300 262:301 263:302 264:303 265:304 266:305 267:306 268:307 269:308 270:308 271:309 272:310 273:311 274:312 275:313 276:314 277:315 278:316 279:317 280:318 281:318 282:319 283:320 284:321 285:322 286:323 287:324 288:325 289:326 290:326 291:326 292:327 293:328 294:329 295:330 296:331 297:332 298:333 299:333 300:333 301:333 302:333 303:333 304:333 305:333 306:334 307:335 308:335 309:336 310:337 311:337 312:338 313:339 314:340 315:340 316:340 317:341 318:342 319:342 320:343 321:343 322:343 323:343 324:344 325:344 326:344 327:344 328:345 329:346 330:346 331:346 332:346 333:346 334:347 335:348 336:349 337:350 338:351 339:352 340:353 341:354 342:355 343:355 344:355 345:355 346:355 347:356 348:357 349:358 350:359 351:360 352:361 353:362 354:362 355:363 356:363 357:364 358:365 359:366 360:367 361:368 362:368 363:369 364:370 365:371 366:372 367:372 368:373 369:374 370:375 371:375 372:375 373:375 374:376 375:377 376:377 377:377 378:377 379:378 380:378 381:379 382:380\n",
      "I1208 12:27:37.054695 139883775852736 run_factoid.py:445] token_to_orig_map: 15:163 16:164 17:165 18:165 19:165 20:166 21:167 22:167 23:168 24:168 25:169 26:170 27:171 28:171 29:171 30:171 31:171 32:172 33:172 34:172 35:173 36:173 37:174 38:175 39:175 40:175 41:176 42:176 43:177 44:177 45:177 46:178 47:178 48:179 49:180 50:181 51:182 52:183 53:184 54:184 55:184 56:185 57:185 58:185 59:186 60:186 61:187 62:187 63:187 64:187 65:188 66:188 67:188 68:189 69:189 70:190 71:191 72:192 73:192 74:193 75:193 76:193 77:194 78:195 79:195 80:196 81:197 82:198 83:199 84:199 85:199 86:200 87:201 88:201 89:202 90:202 91:202 92:203 93:203 94:204 95:204 96:205 97:205 98:206 99:207 100:207 101:208 102:209 103:209 104:210 105:211 106:211 107:212 108:213 109:214 110:215 111:215 112:215 113:215 114:216 115:217 116:218 117:219 118:220 119:221 120:222 121:222 122:223 123:223 124:223 125:224 126:225 127:226 128:227 129:228 130:228 131:228 132:228 133:229 134:230 135:231 136:232 137:232 138:232 139:232 140:232 141:233 142:234 143:235 144:236 145:236 146:236 147:236 148:236 149:237 150:238 151:238 152:238 153:238 154:238 155:239 156:240 157:241 158:241 159:241 160:241 161:241 162:242 163:242 164:242 165:242 166:243 167:243 168:243 169:244 170:245 171:245 172:245 173:245 174:246 175:247 176:248 177:249 178:250 179:251 180:252 181:253 182:254 183:255 184:256 185:256 186:257 187:258 188:258 189:259 190:259 191:260 192:261 193:261 194:262 195:263 196:263 197:264 198:264 199:265 200:266 201:267 202:268 203:269 204:270 205:270 206:271 207:271 208:272 209:272 210:273 211:274 212:275 213:276 214:276 215:277 216:277 217:278 218:278 219:278 220:279 221:279 222:280 223:280 224:281 225:281 226:282 227:283 228:283 229:284 230:285 231:285 232:286 233:287 234:287 235:288 236:288 237:289 238:290 239:291 240:292 241:293 242:294 243:295 244:295 245:296 246:296 247:296 248:297 249:297 250:297 251:297 252:297 253:297 254:297 255:297 256:297 257:298 258:299 259:299 260:299 261:300 262:301 263:302 264:303 265:304 266:305 267:306 268:307 269:308 270:308 271:309 272:310 273:311 274:312 275:313 276:314 277:315 278:316 279:317 280:318 281:318 282:319 283:320 284:321 285:322 286:323 287:324 288:325 289:326 290:326 291:326 292:327 293:328 294:329 295:330 296:331 297:332 298:333 299:333 300:333 301:333 302:333 303:333 304:333 305:333 306:334 307:335 308:335 309:336 310:337 311:337 312:338 313:339 314:340 315:340 316:340 317:341 318:342 319:342 320:343 321:343 322:343 323:343 324:344 325:344 326:344 327:344 328:345 329:346 330:346 331:346 332:346 333:346 334:347 335:348 336:349 337:350 338:351 339:352 340:353 341:354 342:355 343:355 344:355 345:355 346:355 347:356 348:357 349:358 350:359 351:360 352:361 353:362 354:362 355:363 356:363 357:364 358:365 359:366 360:367 361:368 362:368 363:369 364:370 365:371 366:372 367:372 368:373 369:374 370:375 371:375 372:375 373:375 374:376 375:377 376:377 377:377 378:377 379:378 380:378 381:379 382:380\n",
      "INFO:tensorflow:token_is_max_context: 15:False 16:False 17:False 18:False 19:False 20:False 21:False 22:False 23:False 24:False 25:False 26:False 27:False 28:False 29:False 30:False 31:False 32:False 33:False 34:False 35:False 36:False 37:False 38:False 39:False 40:False 41:False 42:False 43:False 44:False 45:False 46:False 47:False 48:False 49:False 50:False 51:False 52:False 53:False 54:False 55:False 56:False 57:False 58:False 59:False 60:False 61:False 62:False 63:False 64:False 65:False 66:False 67:False 68:False 69:False 70:False 71:False 72:False 73:False 74:False 75:False 76:False 77:False 78:False 79:False 80:False 81:False 82:False 83:False 84:False 85:False 86:False 87:False 88:False 89:False 90:False 91:False 92:False 93:False 94:False 95:False 96:False 97:False 98:False 99:False 100:False 101:False 102:False 103:False 104:False 105:False 106:False 107:False 108:False 109:False 110:False 111:False 112:False 113:False 114:False 115:False 116:False 117:False 118:False 119:False 120:False 121:False 122:False 123:False 124:False 125:False 126:False 127:False 128:False 129:False 130:False 131:False 132:False 133:False 134:False 135:True 136:True 137:True 138:True 139:True 140:True 141:True 142:True 143:True 144:True 145:True 146:True 147:True 148:True 149:True 150:True 151:True 152:True 153:True 154:True 155:True 156:True 157:True 158:True 159:True 160:True 161:True 162:True 163:True 164:True 165:True 166:True 167:True 168:True 169:True 170:True 171:True 172:True 173:True 174:True 175:True 176:True 177:True 178:True 179:True 180:True 181:True 182:True 183:True 184:True 185:True 186:True 187:True 188:True 189:True 190:True 191:True 192:True 193:True 194:True 195:True 196:True 197:True 198:True 199:True 200:True 201:True 202:True 203:True 204:True 205:True 206:True 207:True 208:True 209:True 210:True 211:True 212:True 213:True 214:True 215:True 216:True 217:True 218:True 219:True 220:True 221:True 222:True 223:True 224:True 225:True 226:True 227:True 228:True 229:True 230:True 231:True 232:True 233:True 234:True 235:True 236:True 237:True 238:True 239:True 240:True 241:True 242:True 243:True 244:True 245:True 246:True 247:True 248:True 249:True 250:True 251:True 252:True 253:True 254:True 255:True 256:True 257:True 258:True 259:True 260:True 261:True 262:True 263:False 264:False 265:False 266:False 267:False 268:False 269:False 270:False 271:False 272:False 273:False 274:False 275:False 276:False 277:False 278:False 279:False 280:False 281:False 282:False 283:False 284:False 285:False 286:False 287:False 288:False 289:False 290:False 291:False 292:False 293:False 294:False 295:False 296:False 297:False 298:False 299:False 300:False 301:False 302:False 303:False 304:False 305:False 306:False 307:False 308:False 309:False 310:False 311:False 312:False 313:False 314:False 315:False 316:False 317:False 318:False 319:False 320:False 321:False 322:False 323:False 324:False 325:False 326:False 327:False 328:False 329:False 330:False 331:False 332:False 333:False 334:False 335:False 336:False 337:False 338:False 339:False 340:False 341:False 342:False 343:False 344:False 345:False 346:False 347:False 348:False 349:False 350:False 351:False 352:False 353:False 354:False 355:False 356:False 357:False 358:False 359:False 360:False 361:False 362:False 363:False 364:False 365:False 366:False 367:False 368:False 369:False 370:False 371:False 372:False 373:False 374:False 375:False 376:False 377:False 378:False 379:False 380:False 381:False 382:False\n",
      "I1208 12:27:37.054811 139883775852736 run_factoid.py:447] token_is_max_context: 15:False 16:False 17:False 18:False 19:False 20:False 21:False 22:False 23:False 24:False 25:False 26:False 27:False 28:False 29:False 30:False 31:False 32:False 33:False 34:False 35:False 36:False 37:False 38:False 39:False 40:False 41:False 42:False 43:False 44:False 45:False 46:False 47:False 48:False 49:False 50:False 51:False 52:False 53:False 54:False 55:False 56:False 57:False 58:False 59:False 60:False 61:False 62:False 63:False 64:False 65:False 66:False 67:False 68:False 69:False 70:False 71:False 72:False 73:False 74:False 75:False 76:False 77:False 78:False 79:False 80:False 81:False 82:False 83:False 84:False 85:False 86:False 87:False 88:False 89:False 90:False 91:False 92:False 93:False 94:False 95:False 96:False 97:False 98:False 99:False 100:False 101:False 102:False 103:False 104:False 105:False 106:False 107:False 108:False 109:False 110:False 111:False 112:False 113:False 114:False 115:False 116:False 117:False 118:False 119:False 120:False 121:False 122:False 123:False 124:False 125:False 126:False 127:False 128:False 129:False 130:False 131:False 132:False 133:False 134:False 135:True 136:True 137:True 138:True 139:True 140:True 141:True 142:True 143:True 144:True 145:True 146:True 147:True 148:True 149:True 150:True 151:True 152:True 153:True 154:True 155:True 156:True 157:True 158:True 159:True 160:True 161:True 162:True 163:True 164:True 165:True 166:True 167:True 168:True 169:True 170:True 171:True 172:True 173:True 174:True 175:True 176:True 177:True 178:True 179:True 180:True 181:True 182:True 183:True 184:True 185:True 186:True 187:True 188:True 189:True 190:True 191:True 192:True 193:True 194:True 195:True 196:True 197:True 198:True 199:True 200:True 201:True 202:True 203:True 204:True 205:True 206:True 207:True 208:True 209:True 210:True 211:True 212:True 213:True 214:True 215:True 216:True 217:True 218:True 219:True 220:True 221:True 222:True 223:True 224:True 225:True 226:True 227:True 228:True 229:True 230:True 231:True 232:True 233:True 234:True 235:True 236:True 237:True 238:True 239:True 240:True 241:True 242:True 243:True 244:True 245:True 246:True 247:True 248:True 249:True 250:True 251:True 252:True 253:True 254:True 255:True 256:True 257:True 258:True 259:True 260:True 261:True 262:True 263:False 264:False 265:False 266:False 267:False 268:False 269:False 270:False 271:False 272:False 273:False 274:False 275:False 276:False 277:False 278:False 279:False 280:False 281:False 282:False 283:False 284:False 285:False 286:False 287:False 288:False 289:False 290:False 291:False 292:False 293:False 294:False 295:False 296:False 297:False 298:False 299:False 300:False 301:False 302:False 303:False 304:False 305:False 306:False 307:False 308:False 309:False 310:False 311:False 312:False 313:False 314:False 315:False 316:False 317:False 318:False 319:False 320:False 321:False 322:False 323:False 324:False 325:False 326:False 327:False 328:False 329:False 330:False 331:False 332:False 333:False 334:False 335:False 336:False 337:False 338:False 339:False 340:False 341:False 342:False 343:False 344:False 345:False 346:False 347:False 348:False 349:False 350:False 351:False 352:False 353:False 354:False 355:False 356:False 357:False 358:False 359:False 360:False 361:False 362:False 363:False 364:False 365:False 366:False 367:False 368:False 369:False 370:False 371:False 372:False 373:False 374:False 375:False 376:False 377:False 378:False 379:False 380:False 381:False 382:False\n",
      "INFO:tensorflow:input_ids: 101 2372 1103 9505 1472 5763 1113 170 1825 112 188 17898 1116 136 102 131 119 113 122 114 2025 1902 131 7091 2200 1654 3443 113 25157 1942 114 117 1884 13252 1204 2025 117 1137 1692 118 1654 2025 132 113 123 114 1416 131 4420 1150 1127 11534 1114 149 2137 3048 113 124 114 9108 131 153 21678 2137 132 113 125 114 7577 131 1168 13467 8015 132 113 126 114 9386 5252 131 1141 1104 1103 1378 1116 131 2244 2603 117 1231 10182 21629 2603 117 3254 15534 2603 117 2805 1159 117 2704 2215 117 1892 2445 117 5173 13022 3418 113 19497 1708 114 2794 1111 1171 2489 1105 3420 2489 117 1367 118 8926 6373 15075 3225 8157 113 18659 11964 114 2952 6552 2794 113 7054 1708 114 117 4910 6552 2794 113 12029 1708 114 117 1983 2926 1582 4184 5024 13328 1791 18417 113 147 23579 114 117 152 1116 14291 6013 12120 3202 5474 10146 113 23882 114 119 1960 2457 17718 16939 1103 1378 2233 1121 1103 1529 2527 131 1148 2351 787 1271 117 4128 1214 117 2025 1902 117 1583 117 1295 1104 4420 1107 1296 1372 117 4420 787 5924 117 1105 9386 2233 113 2244 2603 117 1231 10182 21629 2603 117 3254 15534 2603 117 2805 1159 117 2704 2215 117 1892 2445 117 19497 1708 7432 1111 1171 2489 1105 3420 2489 117 147 23579 117 18659 11964 118 12029 1708 120 7054 1708 117 1105 23882 114 119 1409 1103 2025 1225 1136 2194 1103 1696 2233 117 1195 1156 3232 1103 7671 5752 1111 1103 3764 1869 119 1284 17428 1103 3187 1104 15069 1107 25157 1942 1116 1114 1103 3442 6315 1118 24763 9518 1742 12207 1891 119 164 1853 166 4222 4454 117 1259 22350 117 3442 1104 7091 2734 117 18205 14255 118 172 13003 1880 117 2812 118 1146 117 1105 6247 118 1106 118 7299 3622 1127 1215 1106 15187 1103 3068 1104 2025 119 164 1853 166 1262 1296 2025 1108 5667 1112 1344 117 1822 117 1137 10527 3187 1104 15069 119 1284 17428 1103 3442 7542 3068 1104 1664 118 7091 2200 2527 113 1884 13252 1204 2025 117 1137 1692 102\n",
      "I1208 12:27:37.054919 139883775852736 run_factoid.py:449] input_ids: 101 2372 1103 9505 1472 5763 1113 170 1825 112 188 17898 1116 136 102 131 119 113 122 114 2025 1902 131 7091 2200 1654 3443 113 25157 1942 114 117 1884 13252 1204 2025 117 1137 1692 118 1654 2025 132 113 123 114 1416 131 4420 1150 1127 11534 1114 149 2137 3048 113 124 114 9108 131 153 21678 2137 132 113 125 114 7577 131 1168 13467 8015 132 113 126 114 9386 5252 131 1141 1104 1103 1378 1116 131 2244 2603 117 1231 10182 21629 2603 117 3254 15534 2603 117 2805 1159 117 2704 2215 117 1892 2445 117 5173 13022 3418 113 19497 1708 114 2794 1111 1171 2489 1105 3420 2489 117 1367 118 8926 6373 15075 3225 8157 113 18659 11964 114 2952 6552 2794 113 7054 1708 114 117 4910 6552 2794 113 12029 1708 114 117 1983 2926 1582 4184 5024 13328 1791 18417 113 147 23579 114 117 152 1116 14291 6013 12120 3202 5474 10146 113 23882 114 119 1960 2457 17718 16939 1103 1378 2233 1121 1103 1529 2527 131 1148 2351 787 1271 117 4128 1214 117 2025 1902 117 1583 117 1295 1104 4420 1107 1296 1372 117 4420 787 5924 117 1105 9386 2233 113 2244 2603 117 1231 10182 21629 2603 117 3254 15534 2603 117 2805 1159 117 2704 2215 117 1892 2445 117 19497 1708 7432 1111 1171 2489 1105 3420 2489 117 147 23579 117 18659 11964 118 12029 1708 120 7054 1708 117 1105 23882 114 119 1409 1103 2025 1225 1136 2194 1103 1696 2233 117 1195 1156 3232 1103 7671 5752 1111 1103 3764 1869 119 1284 17428 1103 3187 1104 15069 1107 25157 1942 1116 1114 1103 3442 6315 1118 24763 9518 1742 12207 1891 119 164 1853 166 4222 4454 117 1259 22350 117 3442 1104 7091 2734 117 18205 14255 118 172 13003 1880 117 2812 118 1146 117 1105 6247 118 1106 118 7299 3622 1127 1215 1106 15187 1103 3068 1104 2025 119 164 1853 166 1262 1296 2025 1108 5667 1112 1344 117 1822 117 1137 10527 3187 1104 15069 119 1284 17428 1103 3442 7542 3068 1104 1664 118 7091 2200 2527 113 1884 13252 1204 2025 117 1137 1692 102\n",
      "INFO:tensorflow:input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      "I1208 12:27:37.055016 139883775852736 run_factoid.py:451] input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      "INFO:tensorflow:segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      "I1208 12:27:37.055112 139883775852736 run_factoid.py:453] segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      "INFO:tensorflow:*** Example ***\n",
      "I1208 12:27:37.056585 139883775852736 run_factoid.py:438] *** Example ***\n",
      "INFO:tensorflow:unique_id: 1000000023\n",
      "I1208 12:27:37.056659 139883775852736 run_factoid.py:439] unique_id: 1000000023\n",
      "INFO:tensorflow:example_index: 6\n",
      "I1208 12:27:37.056701 139883775852736 run_factoid.py:440] example_index: 6\n",
      "INFO:tensorflow:doc_span_index: 4\n",
      "I1208 12:27:37.056735 139883775852736 run_factoid.py:441] doc_span_index: 4\n",
      "INFO:tensorflow:tokens: [CLS] Are the findings different depending on a person ' s demographic ##s ? [SEP] score ( MC ##S ) , Japanese Or ##th ##op ##ae ##dic Association Score ( J ##OA ) , O ##s ##wes ##try Di ##sa ##bility Index ( ODI ) . Two independent investigators extracted the following data from the included studies : first author ’ name , publication year , study design , country , number of patients in each group , patients ’ characteristics , and outcome data ( success rate , re ##cu ##rrence rate , com ##plication rate , operation time , hospital stay , blood loss , VA ##S scores for back pain and leg pain , J ##OA , SF ##12 - MC ##S / PC ##S , and ODI ) . If the study did not provide the important data , we would contact the corresponding authors for the missing information . We evaluated the risk of bias in RC ##T ##s with the method recommended by Cochrane Col ##la ##bor ##ation . [ 29 ] Five items , including blinding , method of random ##ization , allocation con - c ##eal ##ment , follow - up , and intention - to - treat analysis were used to assess the quality of study . [ 29 ] And each study was classified as high , low , or unclear risk of bias . We evaluated the method ##ological quality of non - random ##ized studies ( co ##hor ##t study , or case - control study ) using the modified Newcastle - Ottawa scale . [ 30 ] The total scale of this method was 9 points , and higher point indicated better quality . [ 30 ] Any study was considered to be high quality if the score was more than 5 points . Two independent investigators used the ST ##AT ##A version 12 . 0 ( St ##ata Corporation , College Station , TX , USA ) to perform the statistical analysis . Success rate , re ##cu ##rrence rate , and com ##p ##lica - t ##ion rate , were treated as di ##cho ##tom ##ous variables and were expressed as relative risk ( R ##R ) with 95 % confidence intervals . Operation time , hospital stay [SEP]\n",
      "I1208 12:27:37.056853 139883775852736 run_factoid.py:443] tokens: [CLS] Are the findings different depending on a person ' s demographic ##s ? [SEP] score ( MC ##S ) , Japanese Or ##th ##op ##ae ##dic Association Score ( J ##OA ) , O ##s ##wes ##try Di ##sa ##bility Index ( ODI ) . Two independent investigators extracted the following data from the included studies : first author ’ name , publication year , study design , country , number of patients in each group , patients ’ characteristics , and outcome data ( success rate , re ##cu ##rrence rate , com ##plication rate , operation time , hospital stay , blood loss , VA ##S scores for back pain and leg pain , J ##OA , SF ##12 - MC ##S / PC ##S , and ODI ) . If the study did not provide the important data , we would contact the corresponding authors for the missing information . We evaluated the risk of bias in RC ##T ##s with the method recommended by Cochrane Col ##la ##bor ##ation . [ 29 ] Five items , including blinding , method of random ##ization , allocation con - c ##eal ##ment , follow - up , and intention - to - treat analysis were used to assess the quality of study . [ 29 ] And each study was classified as high , low , or unclear risk of bias . We evaluated the method ##ological quality of non - random ##ized studies ( co ##hor ##t study , or case - control study ) using the modified Newcastle - Ottawa scale . [ 30 ] The total scale of this method was 9 points , and higher point indicated better quality . [ 30 ] Any study was considered to be high quality if the score was more than 5 points . Two independent investigators used the ST ##AT ##A version 12 . 0 ( St ##ata Corporation , College Station , TX , USA ) to perform the statistical analysis . Success rate , re ##cu ##rrence rate , and com ##p ##lica - t ##ion rate , were treated as di ##cho ##tom ##ous variables and were expressed as relative risk ( R ##R ) with 95 % confidence intervals . Operation time , hospital stay [SEP]\n",
      "INFO:tensorflow:token_to_orig_map: 15:235 16:236 17:236 18:236 19:236 20:236 21:237 22:238 23:238 24:238 25:238 26:238 27:239 28:240 29:241 30:241 31:241 32:241 33:241 34:242 35:242 36:242 37:242 38:243 39:243 40:243 41:244 42:245 43:245 44:245 45:245 46:246 47:247 48:248 49:249 50:250 51:251 52:252 53:253 54:254 55:255 56:256 57:256 58:257 59:258 60:258 61:259 62:259 63:260 64:261 65:261 66:262 67:263 68:263 69:264 70:264 71:265 72:266 73:267 74:268 75:269 76:270 77:270 78:271 79:271 80:272 81:272 82:273 83:274 84:275 85:276 86:276 87:277 88:277 89:278 90:278 91:278 92:279 93:279 94:280 95:280 96:281 97:281 98:282 99:283 100:283 101:284 102:285 103:285 104:286 105:287 106:287 107:288 108:288 109:289 110:290 111:291 112:292 113:293 114:294 115:295 116:295 117:296 118:296 119:296 120:297 121:297 122:297 123:297 124:297 125:297 126:297 127:297 128:297 129:298 130:299 131:299 132:299 133:300 134:301 135:302 136:303 137:304 138:305 139:306 140:307 141:308 142:308 143:309 144:310 145:311 146:312 147:313 148:314 149:315 150:316 151:317 152:318 153:318 154:319 155:320 156:321 157:322 158:323 159:324 160:325 161:326 162:326 163:326 164:327 165:328 166:329 167:330 168:331 169:332 170:333 171:333 172:333 173:333 174:333 175:333 176:333 177:333 178:334 179:335 180:335 181:336 182:337 183:337 184:338 185:339 186:340 187:340 188:340 189:341 190:342 191:342 192:343 193:343 194:343 195:343 196:344 197:344 198:344 199:344 200:345 201:346 202:346 203:346 204:346 205:346 206:347 207:348 208:349 209:350 210:351 211:352 212:353 213:354 214:355 215:355 216:355 217:355 218:355 219:356 220:357 221:358 222:359 223:360 224:361 225:362 226:362 227:363 228:363 229:364 230:365 231:366 232:367 233:368 234:368 235:369 236:370 237:371 238:372 239:372 240:373 241:374 242:375 243:375 244:375 245:375 246:376 247:377 248:377 249:377 250:377 251:378 252:378 253:379 254:380 255:380 256:380 257:381 258:381 259:382 260:383 261:384 262:385 263:385 264:385 265:386 266:386 267:386 268:386 269:386 270:387 271:388 272:389 273:390 274:391 275:392 276:393 277:394 278:395 279:395 280:396 281:397 282:398 283:399 284:400 285:401 286:401 287:401 288:401 289:401 290:402 291:403 292:404 293:405 294:406 295:407 296:408 297:409 298:410 299:411 300:412 301:413 302:414 303:415 304:416 305:417 306:417 307:418 308:419 309:420 310:421 311:422 312:423 313:423 314:423 315:424 316:425 317:425 318:425 319:426 320:426 321:426 322:427 323:427 324:428 325:429 326:429 327:430 328:430 329:431 330:431 331:432 332:433 333:434 334:435 335:436 336:436 337:437 338:438 339:438 340:439 341:439 342:439 343:440 344:440 345:441 346:442 347:442 348:442 349:442 350:443 351:443 352:444 353:444 354:445 355:446 356:447 357:448 358:448 359:448 360:448 361:449 362:450 363:451 364:452 365:453 366:454 367:455 368:456 369:456 370:456 371:456 372:457 373:458 374:458 375:459 376:460 377:460 378:461 379:462 380:462 381:463 382:464\n",
      "I1208 12:27:37.056989 139883775852736 run_factoid.py:445] token_to_orig_map: 15:235 16:236 17:236 18:236 19:236 20:236 21:237 22:238 23:238 24:238 25:238 26:238 27:239 28:240 29:241 30:241 31:241 32:241 33:241 34:242 35:242 36:242 37:242 38:243 39:243 40:243 41:244 42:245 43:245 44:245 45:245 46:246 47:247 48:248 49:249 50:250 51:251 52:252 53:253 54:254 55:255 56:256 57:256 58:257 59:258 60:258 61:259 62:259 63:260 64:261 65:261 66:262 67:263 68:263 69:264 70:264 71:265 72:266 73:267 74:268 75:269 76:270 77:270 78:271 79:271 80:272 81:272 82:273 83:274 84:275 85:276 86:276 87:277 88:277 89:278 90:278 91:278 92:279 93:279 94:280 95:280 96:281 97:281 98:282 99:283 100:283 101:284 102:285 103:285 104:286 105:287 106:287 107:288 108:288 109:289 110:290 111:291 112:292 113:293 114:294 115:295 116:295 117:296 118:296 119:296 120:297 121:297 122:297 123:297 124:297 125:297 126:297 127:297 128:297 129:298 130:299 131:299 132:299 133:300 134:301 135:302 136:303 137:304 138:305 139:306 140:307 141:308 142:308 143:309 144:310 145:311 146:312 147:313 148:314 149:315 150:316 151:317 152:318 153:318 154:319 155:320 156:321 157:322 158:323 159:324 160:325 161:326 162:326 163:326 164:327 165:328 166:329 167:330 168:331 169:332 170:333 171:333 172:333 173:333 174:333 175:333 176:333 177:333 178:334 179:335 180:335 181:336 182:337 183:337 184:338 185:339 186:340 187:340 188:340 189:341 190:342 191:342 192:343 193:343 194:343 195:343 196:344 197:344 198:344 199:344 200:345 201:346 202:346 203:346 204:346 205:346 206:347 207:348 208:349 209:350 210:351 211:352 212:353 213:354 214:355 215:355 216:355 217:355 218:355 219:356 220:357 221:358 222:359 223:360 224:361 225:362 226:362 227:363 228:363 229:364 230:365 231:366 232:367 233:368 234:368 235:369 236:370 237:371 238:372 239:372 240:373 241:374 242:375 243:375 244:375 245:375 246:376 247:377 248:377 249:377 250:377 251:378 252:378 253:379 254:380 255:380 256:380 257:381 258:381 259:382 260:383 261:384 262:385 263:385 264:385 265:386 266:386 267:386 268:386 269:386 270:387 271:388 272:389 273:390 274:391 275:392 276:393 277:394 278:395 279:395 280:396 281:397 282:398 283:399 284:400 285:401 286:401 287:401 288:401 289:401 290:402 291:403 292:404 293:405 294:406 295:407 296:408 297:409 298:410 299:411 300:412 301:413 302:414 303:415 304:416 305:417 306:417 307:418 308:419 309:420 310:421 311:422 312:423 313:423 314:423 315:424 316:425 317:425 318:425 319:426 320:426 321:426 322:427 323:427 324:428 325:429 326:429 327:430 328:430 329:431 330:431 331:432 332:433 333:434 334:435 335:436 336:436 337:437 338:438 339:438 340:439 341:439 342:439 343:440 344:440 345:441 346:442 347:442 348:442 349:442 350:443 351:443 352:444 353:444 354:445 355:446 356:447 357:448 358:448 359:448 360:448 361:449 362:450 363:451 364:452 365:453 366:454 367:455 368:456 369:456 370:456 371:456 372:457 373:458 374:458 375:459 376:460 377:460 378:461 379:462 380:462 381:463 382:464\n",
      "INFO:tensorflow:token_is_max_context: 15:False 16:False 17:False 18:False 19:False 20:False 21:False 22:False 23:False 24:False 25:False 26:False 27:False 28:False 29:False 30:False 31:False 32:False 33:False 34:False 35:False 36:False 37:False 38:False 39:False 40:False 41:False 42:False 43:False 44:False 45:False 46:False 47:False 48:False 49:False 50:False 51:False 52:False 53:False 54:False 55:False 56:False 57:False 58:False 59:False 60:False 61:False 62:False 63:False 64:False 65:False 66:False 67:False 68:False 69:False 70:False 71:False 72:False 73:False 74:False 75:False 76:False 77:False 78:False 79:False 80:False 81:False 82:False 83:False 84:False 85:False 86:False 87:False 88:False 89:False 90:False 91:False 92:False 93:False 94:False 95:False 96:False 97:False 98:False 99:False 100:False 101:False 102:False 103:False 104:False 105:False 106:False 107:False 108:False 109:False 110:False 111:False 112:False 113:False 114:False 115:False 116:False 117:False 118:False 119:False 120:False 121:False 122:False 123:False 124:False 125:False 126:False 127:False 128:False 129:False 130:False 131:False 132:False 133:False 134:False 135:True 136:True 137:True 138:True 139:True 140:True 141:True 142:True 143:True 144:True 145:True 146:True 147:True 148:True 149:True 150:True 151:True 152:True 153:True 154:True 155:True 156:True 157:True 158:True 159:True 160:True 161:True 162:True 163:True 164:True 165:True 166:True 167:True 168:True 169:True 170:True 171:True 172:True 173:True 174:True 175:True 176:True 177:True 178:True 179:True 180:True 181:True 182:True 183:True 184:True 185:True 186:True 187:True 188:True 189:True 190:True 191:True 192:True 193:True 194:True 195:True 196:True 197:True 198:True 199:True 200:True 201:True 202:True 203:True 204:True 205:True 206:True 207:True 208:True 209:True 210:True 211:True 212:True 213:True 214:True 215:True 216:True 217:True 218:True 219:True 220:True 221:True 222:True 223:True 224:True 225:True 226:True 227:True 228:True 229:True 230:True 231:True 232:True 233:True 234:True 235:True 236:True 237:True 238:True 239:True 240:True 241:True 242:True 243:True 244:True 245:True 246:True 247:True 248:True 249:True 250:True 251:True 252:True 253:True 254:True 255:True 256:True 257:True 258:True 259:True 260:True 261:True 262:True 263:False 264:False 265:False 266:False 267:False 268:False 269:False 270:False 271:False 272:False 273:False 274:False 275:False 276:False 277:False 278:False 279:False 280:False 281:False 282:False 283:False 284:False 285:False 286:False 287:False 288:False 289:False 290:False 291:False 292:False 293:False 294:False 295:False 296:False 297:False 298:False 299:False 300:False 301:False 302:False 303:False 304:False 305:False 306:False 307:False 308:False 309:False 310:False 311:False 312:False 313:False 314:False 315:False 316:False 317:False 318:False 319:False 320:False 321:False 322:False 323:False 324:False 325:False 326:False 327:False 328:False 329:False 330:False 331:False 332:False 333:False 334:False 335:False 336:False 337:False 338:False 339:False 340:False 341:False 342:False 343:False 344:False 345:False 346:False 347:False 348:False 349:False 350:False 351:False 352:False 353:False 354:False 355:False 356:False 357:False 358:False 359:False 360:False 361:False 362:False 363:False 364:False 365:False 366:False 367:False 368:False 369:False 370:False 371:False 372:False 373:False 374:False 375:False 376:False 377:False 378:False 379:False 380:False 381:False 382:False\n",
      "I1208 12:27:37.057106 139883775852736 run_factoid.py:447] token_is_max_context: 15:False 16:False 17:False 18:False 19:False 20:False 21:False 22:False 23:False 24:False 25:False 26:False 27:False 28:False 29:False 30:False 31:False 32:False 33:False 34:False 35:False 36:False 37:False 38:False 39:False 40:False 41:False 42:False 43:False 44:False 45:False 46:False 47:False 48:False 49:False 50:False 51:False 52:False 53:False 54:False 55:False 56:False 57:False 58:False 59:False 60:False 61:False 62:False 63:False 64:False 65:False 66:False 67:False 68:False 69:False 70:False 71:False 72:False 73:False 74:False 75:False 76:False 77:False 78:False 79:False 80:False 81:False 82:False 83:False 84:False 85:False 86:False 87:False 88:False 89:False 90:False 91:False 92:False 93:False 94:False 95:False 96:False 97:False 98:False 99:False 100:False 101:False 102:False 103:False 104:False 105:False 106:False 107:False 108:False 109:False 110:False 111:False 112:False 113:False 114:False 115:False 116:False 117:False 118:False 119:False 120:False 121:False 122:False 123:False 124:False 125:False 126:False 127:False 128:False 129:False 130:False 131:False 132:False 133:False 134:False 135:True 136:True 137:True 138:True 139:True 140:True 141:True 142:True 143:True 144:True 145:True 146:True 147:True 148:True 149:True 150:True 151:True 152:True 153:True 154:True 155:True 156:True 157:True 158:True 159:True 160:True 161:True 162:True 163:True 164:True 165:True 166:True 167:True 168:True 169:True 170:True 171:True 172:True 173:True 174:True 175:True 176:True 177:True 178:True 179:True 180:True 181:True 182:True 183:True 184:True 185:True 186:True 187:True 188:True 189:True 190:True 191:True 192:True 193:True 194:True 195:True 196:True 197:True 198:True 199:True 200:True 201:True 202:True 203:True 204:True 205:True 206:True 207:True 208:True 209:True 210:True 211:True 212:True 213:True 214:True 215:True 216:True 217:True 218:True 219:True 220:True 221:True 222:True 223:True 224:True 225:True 226:True 227:True 228:True 229:True 230:True 231:True 232:True 233:True 234:True 235:True 236:True 237:True 238:True 239:True 240:True 241:True 242:True 243:True 244:True 245:True 246:True 247:True 248:True 249:True 250:True 251:True 252:True 253:True 254:True 255:True 256:True 257:True 258:True 259:True 260:True 261:True 262:True 263:False 264:False 265:False 266:False 267:False 268:False 269:False 270:False 271:False 272:False 273:False 274:False 275:False 276:False 277:False 278:False 279:False 280:False 281:False 282:False 283:False 284:False 285:False 286:False 287:False 288:False 289:False 290:False 291:False 292:False 293:False 294:False 295:False 296:False 297:False 298:False 299:False 300:False 301:False 302:False 303:False 304:False 305:False 306:False 307:False 308:False 309:False 310:False 311:False 312:False 313:False 314:False 315:False 316:False 317:False 318:False 319:False 320:False 321:False 322:False 323:False 324:False 325:False 326:False 327:False 328:False 329:False 330:False 331:False 332:False 333:False 334:False 335:False 336:False 337:False 338:False 339:False 340:False 341:False 342:False 343:False 344:False 345:False 346:False 347:False 348:False 349:False 350:False 351:False 352:False 353:False 354:False 355:False 356:False 357:False 358:False 359:False 360:False 361:False 362:False 363:False 364:False 365:False 366:False 367:False 368:False 369:False 370:False 371:False 372:False 373:False 374:False 375:False 376:False 377:False 378:False 379:False 380:False 381:False 382:False\n",
      "INFO:tensorflow:input_ids: 101 2372 1103 9505 1472 5763 1113 170 1825 112 188 17898 1116 136 102 2794 113 12029 1708 114 117 1983 2926 1582 4184 5024 13328 1791 18417 113 147 23579 114 117 152 1116 14291 6013 12120 3202 5474 10146 113 23882 114 119 1960 2457 17718 16939 1103 1378 2233 1121 1103 1529 2527 131 1148 2351 787 1271 117 4128 1214 117 2025 1902 117 1583 117 1295 1104 4420 1107 1296 1372 117 4420 787 5924 117 1105 9386 2233 113 2244 2603 117 1231 10182 21629 2603 117 3254 15534 2603 117 2805 1159 117 2704 2215 117 1892 2445 117 19497 1708 7432 1111 1171 2489 1105 3420 2489 117 147 23579 117 18659 11964 118 12029 1708 120 7054 1708 117 1105 23882 114 119 1409 1103 2025 1225 1136 2194 1103 1696 2233 117 1195 1156 3232 1103 7671 5752 1111 1103 3764 1869 119 1284 17428 1103 3187 1104 15069 1107 25157 1942 1116 1114 1103 3442 6315 1118 24763 9518 1742 12207 1891 119 164 1853 166 4222 4454 117 1259 22350 117 3442 1104 7091 2734 117 18205 14255 118 172 13003 1880 117 2812 118 1146 117 1105 6247 118 1106 118 7299 3622 1127 1215 1106 15187 1103 3068 1104 2025 119 164 1853 166 1262 1296 2025 1108 5667 1112 1344 117 1822 117 1137 10527 3187 1104 15069 119 1284 17428 1103 3442 7542 3068 1104 1664 118 7091 2200 2527 113 1884 13252 1204 2025 117 1137 1692 118 1654 2025 114 1606 1103 5847 7685 118 7711 3418 119 164 1476 166 1109 1703 3418 1104 1142 3442 1108 130 1827 117 1105 2299 1553 4668 1618 3068 119 164 1476 166 6291 2025 1108 1737 1106 1129 1344 3068 1191 1103 2794 1108 1167 1190 126 1827 119 1960 2457 17718 1215 1103 23676 13821 1592 1683 1367 119 121 113 1457 6575 3436 117 1531 2874 117 21514 117 3066 114 1106 3870 1103 11435 3622 119 25911 2603 117 1231 10182 21629 2603 117 1105 3254 1643 9538 118 189 1988 2603 117 1127 5165 1112 4267 8401 18778 2285 10986 1105 1127 4448 1112 5236 3187 113 155 2069 114 1114 4573 110 6595 14662 119 5158 1159 117 2704 2215 102\n",
      "I1208 12:27:37.057215 139883775852736 run_factoid.py:449] input_ids: 101 2372 1103 9505 1472 5763 1113 170 1825 112 188 17898 1116 136 102 2794 113 12029 1708 114 117 1983 2926 1582 4184 5024 13328 1791 18417 113 147 23579 114 117 152 1116 14291 6013 12120 3202 5474 10146 113 23882 114 119 1960 2457 17718 16939 1103 1378 2233 1121 1103 1529 2527 131 1148 2351 787 1271 117 4128 1214 117 2025 1902 117 1583 117 1295 1104 4420 1107 1296 1372 117 4420 787 5924 117 1105 9386 2233 113 2244 2603 117 1231 10182 21629 2603 117 3254 15534 2603 117 2805 1159 117 2704 2215 117 1892 2445 117 19497 1708 7432 1111 1171 2489 1105 3420 2489 117 147 23579 117 18659 11964 118 12029 1708 120 7054 1708 117 1105 23882 114 119 1409 1103 2025 1225 1136 2194 1103 1696 2233 117 1195 1156 3232 1103 7671 5752 1111 1103 3764 1869 119 1284 17428 1103 3187 1104 15069 1107 25157 1942 1116 1114 1103 3442 6315 1118 24763 9518 1742 12207 1891 119 164 1853 166 4222 4454 117 1259 22350 117 3442 1104 7091 2734 117 18205 14255 118 172 13003 1880 117 2812 118 1146 117 1105 6247 118 1106 118 7299 3622 1127 1215 1106 15187 1103 3068 1104 2025 119 164 1853 166 1262 1296 2025 1108 5667 1112 1344 117 1822 117 1137 10527 3187 1104 15069 119 1284 17428 1103 3442 7542 3068 1104 1664 118 7091 2200 2527 113 1884 13252 1204 2025 117 1137 1692 118 1654 2025 114 1606 1103 5847 7685 118 7711 3418 119 164 1476 166 1109 1703 3418 1104 1142 3442 1108 130 1827 117 1105 2299 1553 4668 1618 3068 119 164 1476 166 6291 2025 1108 1737 1106 1129 1344 3068 1191 1103 2794 1108 1167 1190 126 1827 119 1960 2457 17718 1215 1103 23676 13821 1592 1683 1367 119 121 113 1457 6575 3436 117 1531 2874 117 21514 117 3066 114 1106 3870 1103 11435 3622 119 25911 2603 117 1231 10182 21629 2603 117 1105 3254 1643 9538 118 189 1988 2603 117 1127 5165 1112 4267 8401 18778 2285 10986 1105 1127 4448 1112 5236 3187 113 155 2069 114 1114 4573 110 6595 14662 119 5158 1159 117 2704 2215 102\n",
      "INFO:tensorflow:input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      "I1208 12:27:37.057315 139883775852736 run_factoid.py:451] input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      "INFO:tensorflow:segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      "I1208 12:27:37.057412 139883775852736 run_factoid.py:453] segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      "INFO:tensorflow:*** Example ***\n",
      "I1208 12:27:37.058879 139883775852736 run_factoid.py:438] *** Example ***\n",
      "INFO:tensorflow:unique_id: 1000000024\n",
      "I1208 12:27:37.058940 139883775852736 run_factoid.py:439] unique_id: 1000000024\n",
      "INFO:tensorflow:example_index: 6\n",
      "I1208 12:27:37.058975 139883775852736 run_factoid.py:440] example_index: 6\n",
      "INFO:tensorflow:doc_span_index: 5\n",
      "I1208 12:27:37.059008 139883775852736 run_factoid.py:441] doc_span_index: 5\n",
      "INFO:tensorflow:tokens: [CLS] Are the findings different depending on a person ' s demographic ##s ? [SEP] we would contact the corresponding authors for the missing information . We evaluated the risk of bias in RC ##T ##s with the method recommended by Cochrane Col ##la ##bor ##ation . [ 29 ] Five items , including blinding , method of random ##ization , allocation con - c ##eal ##ment , follow - up , and intention - to - treat analysis were used to assess the quality of study . [ 29 ] And each study was classified as high , low , or unclear risk of bias . We evaluated the method ##ological quality of non - random ##ized studies ( co ##hor ##t study , or case - control study ) using the modified Newcastle - Ottawa scale . [ 30 ] The total scale of this method was 9 points , and higher point indicated better quality . [ 30 ] Any study was considered to be high quality if the score was more than 5 points . Two independent investigators used the ST ##AT ##A version 12 . 0 ( St ##ata Corporation , College Station , TX , USA ) to perform the statistical analysis . Success rate , re ##cu ##rrence rate , and com ##p ##lica - t ##ion rate , were treated as di ##cho ##tom ##ous variables and were expressed as relative risk ( R ##R ) with 95 % confidence intervals . Operation time , hospital stay , blood loss , back - pain VA ##S score , leg - pain VA ##S score , J ##OA score , and SF ##12 - MC ##S / PC ##S , were treated as continuous variables , thus they were expressed as weighted mean difference ( W ##MD ) with 95 % confidence intervals . Before the data were pool ##ed , Q - s ##tat ##istic and I ##2 s ##tat ##istic were used to detect the he ##tero ##gene ##ity among the studies , in which a P value < . 10 or I ##2 > 50 % were defined as significant he ##tero ##gene ##ity . Poole ##d estimates were generated by using a fixed - effects model ( Man ##tel – Ha ##ens [SEP]\n",
      "I1208 12:27:37.059123 139883775852736 run_factoid.py:443] tokens: [CLS] Are the findings different depending on a person ' s demographic ##s ? [SEP] we would contact the corresponding authors for the missing information . We evaluated the risk of bias in RC ##T ##s with the method recommended by Cochrane Col ##la ##bor ##ation . [ 29 ] Five items , including blinding , method of random ##ization , allocation con - c ##eal ##ment , follow - up , and intention - to - treat analysis were used to assess the quality of study . [ 29 ] And each study was classified as high , low , or unclear risk of bias . We evaluated the method ##ological quality of non - random ##ized studies ( co ##hor ##t study , or case - control study ) using the modified Newcastle - Ottawa scale . [ 30 ] The total scale of this method was 9 points , and higher point indicated better quality . [ 30 ] Any study was considered to be high quality if the score was more than 5 points . Two independent investigators used the ST ##AT ##A version 12 . 0 ( St ##ata Corporation , College Station , TX , USA ) to perform the statistical analysis . Success rate , re ##cu ##rrence rate , and com ##p ##lica - t ##ion rate , were treated as di ##cho ##tom ##ous variables and were expressed as relative risk ( R ##R ) with 95 % confidence intervals . Operation time , hospital stay , blood loss , back - pain VA ##S score , leg - pain VA ##S score , J ##OA score , and SF ##12 - MC ##S / PC ##S , were treated as continuous variables , thus they were expressed as weighted mean difference ( W ##MD ) with 95 % confidence intervals . Before the data were pool ##ed , Q - s ##tat ##istic and I ##2 s ##tat ##istic were used to detect the he ##tero ##gene ##ity among the studies , in which a P value < . 10 or I ##2 > 50 % were defined as significant he ##tero ##gene ##ity . Poole ##d estimates were generated by using a fixed - effects model ( Man ##tel – Ha ##ens [SEP]\n",
      "INFO:tensorflow:token_to_orig_map: 15:309 16:310 17:311 18:312 19:313 20:314 21:315 22:316 23:317 24:318 25:318 26:319 27:320 28:321 29:322 30:323 31:324 32:325 33:326 34:326 35:326 36:327 37:328 38:329 39:330 40:331 41:332 42:333 43:333 44:333 45:333 46:333 47:333 48:333 49:333 50:334 51:335 52:335 53:336 54:337 55:337 56:338 57:339 58:340 59:340 60:340 61:341 62:342 63:342 64:343 65:343 66:343 67:343 68:344 69:344 70:344 71:344 72:345 73:346 74:346 75:346 76:346 77:346 78:347 79:348 80:349 81:350 82:351 83:352 84:353 85:354 86:355 87:355 88:355 89:355 90:355 91:356 92:357 93:358 94:359 95:360 96:361 97:362 98:362 99:363 100:363 101:364 102:365 103:366 104:367 105:368 106:368 107:369 108:370 109:371 110:372 111:372 112:373 113:374 114:375 115:375 116:375 117:375 118:376 119:377 120:377 121:377 122:377 123:378 124:378 125:379 126:380 127:380 128:380 129:381 130:381 131:382 132:383 133:384 134:385 135:385 136:385 137:386 138:386 139:386 140:386 141:386 142:387 143:388 144:389 145:390 146:391 147:392 148:393 149:394 150:395 151:395 152:396 153:397 154:398 155:399 156:400 157:401 158:401 159:401 160:401 161:401 162:402 163:403 164:404 165:405 166:406 167:407 168:408 169:409 170:410 171:411 172:412 173:413 174:414 175:415 176:416 177:417 178:417 179:418 180:419 181:420 182:421 183:422 184:423 185:423 186:423 187:424 188:425 189:425 190:425 191:426 192:426 193:426 194:427 195:427 196:428 197:429 198:429 199:430 200:430 201:431 202:431 203:432 204:433 205:434 206:435 207:436 208:436 209:437 210:438 211:438 212:439 213:439 214:439 215:440 216:440 217:441 218:442 219:442 220:442 221:442 222:443 223:443 224:444 225:444 226:445 227:446 228:447 229:448 230:448 231:448 232:448 233:449 234:450 235:451 236:452 237:453 238:454 239:455 240:456 241:456 242:456 243:456 244:457 245:458 246:458 247:459 248:460 249:460 250:461 251:462 252:462 253:463 254:464 255:464 256:465 257:466 258:466 259:467 260:467 261:467 262:468 263:468 264:469 265:469 266:470 267:470 268:470 269:471 270:471 271:472 272:472 273:473 274:473 275:474 276:474 277:475 278:476 279:476 280:476 281:476 282:476 283:476 284:476 285:476 286:476 287:477 288:478 289:479 290:480 291:481 292:481 293:482 294:483 295:484 296:485 297:486 298:487 299:488 300:489 301:490 302:490 303:490 304:490 305:491 306:492 307:492 308:493 309:494 310:494 311:495 312:496 313:497 314:498 315:499 316:499 317:499 318:500 319:500 320:500 321:500 322:500 323:501 324:502 325:502 326:503 327:503 328:503 329:504 330:505 331:506 332:507 333:508 334:509 335:509 336:509 337:509 338:510 339:511 340:512 341:512 342:513 343:514 344:515 345:516 346:517 347:518 348:519 349:519 350:520 351:521 352:521 353:522 354:523 355:523 356:524 357:525 358:526 359:527 360:528 361:528 362:528 363:528 364:528 365:529 366:529 367:530 368:531 369:532 370:533 371:534 372:535 373:536 374:536 375:536 376:537 377:538 378:538 379:538 380:538 381:538 382:538\n",
      "I1208 12:27:37.059250 139883775852736 run_factoid.py:445] token_to_orig_map: 15:309 16:310 17:311 18:312 19:313 20:314 21:315 22:316 23:317 24:318 25:318 26:319 27:320 28:321 29:322 30:323 31:324 32:325 33:326 34:326 35:326 36:327 37:328 38:329 39:330 40:331 41:332 42:333 43:333 44:333 45:333 46:333 47:333 48:333 49:333 50:334 51:335 52:335 53:336 54:337 55:337 56:338 57:339 58:340 59:340 60:340 61:341 62:342 63:342 64:343 65:343 66:343 67:343 68:344 69:344 70:344 71:344 72:345 73:346 74:346 75:346 76:346 77:346 78:347 79:348 80:349 81:350 82:351 83:352 84:353 85:354 86:355 87:355 88:355 89:355 90:355 91:356 92:357 93:358 94:359 95:360 96:361 97:362 98:362 99:363 100:363 101:364 102:365 103:366 104:367 105:368 106:368 107:369 108:370 109:371 110:372 111:372 112:373 113:374 114:375 115:375 116:375 117:375 118:376 119:377 120:377 121:377 122:377 123:378 124:378 125:379 126:380 127:380 128:380 129:381 130:381 131:382 132:383 133:384 134:385 135:385 136:385 137:386 138:386 139:386 140:386 141:386 142:387 143:388 144:389 145:390 146:391 147:392 148:393 149:394 150:395 151:395 152:396 153:397 154:398 155:399 156:400 157:401 158:401 159:401 160:401 161:401 162:402 163:403 164:404 165:405 166:406 167:407 168:408 169:409 170:410 171:411 172:412 173:413 174:414 175:415 176:416 177:417 178:417 179:418 180:419 181:420 182:421 183:422 184:423 185:423 186:423 187:424 188:425 189:425 190:425 191:426 192:426 193:426 194:427 195:427 196:428 197:429 198:429 199:430 200:430 201:431 202:431 203:432 204:433 205:434 206:435 207:436 208:436 209:437 210:438 211:438 212:439 213:439 214:439 215:440 216:440 217:441 218:442 219:442 220:442 221:442 222:443 223:443 224:444 225:444 226:445 227:446 228:447 229:448 230:448 231:448 232:448 233:449 234:450 235:451 236:452 237:453 238:454 239:455 240:456 241:456 242:456 243:456 244:457 245:458 246:458 247:459 248:460 249:460 250:461 251:462 252:462 253:463 254:464 255:464 256:465 257:466 258:466 259:467 260:467 261:467 262:468 263:468 264:469 265:469 266:470 267:470 268:470 269:471 270:471 271:472 272:472 273:473 274:473 275:474 276:474 277:475 278:476 279:476 280:476 281:476 282:476 283:476 284:476 285:476 286:476 287:477 288:478 289:479 290:480 291:481 292:481 293:482 294:483 295:484 296:485 297:486 298:487 299:488 300:489 301:490 302:490 303:490 304:490 305:491 306:492 307:492 308:493 309:494 310:494 311:495 312:496 313:497 314:498 315:499 316:499 317:499 318:500 319:500 320:500 321:500 322:500 323:501 324:502 325:502 326:503 327:503 328:503 329:504 330:505 331:506 332:507 333:508 334:509 335:509 336:509 337:509 338:510 339:511 340:512 341:512 342:513 343:514 344:515 345:516 346:517 347:518 348:519 349:519 350:520 351:521 352:521 353:522 354:523 355:523 356:524 357:525 358:526 359:527 360:528 361:528 362:528 363:528 364:528 365:529 366:529 367:530 368:531 369:532 370:533 371:534 372:535 373:536 374:536 375:536 376:537 377:538 378:538 379:538 380:538 381:538 382:538\n",
      "INFO:tensorflow:token_is_max_context: 15:False 16:False 17:False 18:False 19:False 20:False 21:False 22:False 23:False 24:False 25:False 26:False 27:False 28:False 29:False 30:False 31:False 32:False 33:False 34:False 35:False 36:False 37:False 38:False 39:False 40:False 41:False 42:False 43:False 44:False 45:False 46:False 47:False 48:False 49:False 50:False 51:False 52:False 53:False 54:False 55:False 56:False 57:False 58:False 59:False 60:False 61:False 62:False 63:False 64:False 65:False 66:False 67:False 68:False 69:False 70:False 71:False 72:False 73:False 74:False 75:False 76:False 77:False 78:False 79:False 80:False 81:False 82:False 83:False 84:False 85:False 86:False 87:False 88:False 89:False 90:False 91:False 92:False 93:False 94:False 95:False 96:False 97:False 98:False 99:False 100:False 101:False 102:False 103:False 104:False 105:False 106:False 107:False 108:False 109:False 110:False 111:False 112:False 113:False 114:False 115:False 116:False 117:False 118:False 119:False 120:False 121:False 122:False 123:False 124:False 125:False 126:False 127:False 128:False 129:False 130:False 131:False 132:False 133:False 134:False 135:True 136:True 137:True 138:True 139:True 140:True 141:True 142:True 143:True 144:True 145:True 146:True 147:True 148:True 149:True 150:True 151:True 152:True 153:True 154:True 155:True 156:True 157:True 158:True 159:True 160:True 161:True 162:True 163:True 164:True 165:True 166:True 167:True 168:True 169:True 170:True 171:True 172:True 173:True 174:True 175:True 176:True 177:True 178:True 179:True 180:True 181:True 182:True 183:True 184:True 185:True 186:True 187:True 188:True 189:True 190:True 191:True 192:True 193:True 194:True 195:True 196:True 197:True 198:True 199:True 200:True 201:True 202:True 203:True 204:True 205:True 206:True 207:True 208:True 209:True 210:True 211:True 212:True 213:True 214:True 215:True 216:True 217:True 218:True 219:True 220:True 221:True 222:True 223:True 224:True 225:True 226:True 227:True 228:True 229:True 230:True 231:True 232:True 233:True 234:True 235:True 236:True 237:True 238:True 239:True 240:True 241:True 242:True 243:True 244:True 245:True 246:True 247:True 248:True 249:True 250:True 251:True 252:True 253:True 254:True 255:True 256:True 257:True 258:True 259:True 260:True 261:True 262:True 263:False 264:False 265:False 266:False 267:False 268:False 269:False 270:False 271:False 272:False 273:False 274:False 275:False 276:False 277:False 278:False 279:False 280:False 281:False 282:False 283:False 284:False 285:False 286:False 287:False 288:False 289:False 290:False 291:False 292:False 293:False 294:False 295:False 296:False 297:False 298:False 299:False 300:False 301:False 302:False 303:False 304:False 305:False 306:False 307:False 308:False 309:False 310:False 311:False 312:False 313:False 314:False 315:False 316:False 317:False 318:False 319:False 320:False 321:False 322:False 323:False 324:False 325:False 326:False 327:False 328:False 329:False 330:False 331:False 332:False 333:False 334:False 335:False 336:False 337:False 338:False 339:False 340:False 341:False 342:False 343:False 344:False 345:False 346:False 347:False 348:False 349:False 350:False 351:False 352:False 353:False 354:False 355:False 356:False 357:False 358:False 359:False 360:False 361:False 362:False 363:False 364:False 365:False 366:False 367:False 368:False 369:False 370:False 371:False 372:False 373:False 374:False 375:False 376:False 377:False 378:False 379:False 380:False 381:False 382:False\n",
      "I1208 12:27:37.059358 139883775852736 run_factoid.py:447] token_is_max_context: 15:False 16:False 17:False 18:False 19:False 20:False 21:False 22:False 23:False 24:False 25:False 26:False 27:False 28:False 29:False 30:False 31:False 32:False 33:False 34:False 35:False 36:False 37:False 38:False 39:False 40:False 41:False 42:False 43:False 44:False 45:False 46:False 47:False 48:False 49:False 50:False 51:False 52:False 53:False 54:False 55:False 56:False 57:False 58:False 59:False 60:False 61:False 62:False 63:False 64:False 65:False 66:False 67:False 68:False 69:False 70:False 71:False 72:False 73:False 74:False 75:False 76:False 77:False 78:False 79:False 80:False 81:False 82:False 83:False 84:False 85:False 86:False 87:False 88:False 89:False 90:False 91:False 92:False 93:False 94:False 95:False 96:False 97:False 98:False 99:False 100:False 101:False 102:False 103:False 104:False 105:False 106:False 107:False 108:False 109:False 110:False 111:False 112:False 113:False 114:False 115:False 116:False 117:False 118:False 119:False 120:False 121:False 122:False 123:False 124:False 125:False 126:False 127:False 128:False 129:False 130:False 131:False 132:False 133:False 134:False 135:True 136:True 137:True 138:True 139:True 140:True 141:True 142:True 143:True 144:True 145:True 146:True 147:True 148:True 149:True 150:True 151:True 152:True 153:True 154:True 155:True 156:True 157:True 158:True 159:True 160:True 161:True 162:True 163:True 164:True 165:True 166:True 167:True 168:True 169:True 170:True 171:True 172:True 173:True 174:True 175:True 176:True 177:True 178:True 179:True 180:True 181:True 182:True 183:True 184:True 185:True 186:True 187:True 188:True 189:True 190:True 191:True 192:True 193:True 194:True 195:True 196:True 197:True 198:True 199:True 200:True 201:True 202:True 203:True 204:True 205:True 206:True 207:True 208:True 209:True 210:True 211:True 212:True 213:True 214:True 215:True 216:True 217:True 218:True 219:True 220:True 221:True 222:True 223:True 224:True 225:True 226:True 227:True 228:True 229:True 230:True 231:True 232:True 233:True 234:True 235:True 236:True 237:True 238:True 239:True 240:True 241:True 242:True 243:True 244:True 245:True 246:True 247:True 248:True 249:True 250:True 251:True 252:True 253:True 254:True 255:True 256:True 257:True 258:True 259:True 260:True 261:True 262:True 263:False 264:False 265:False 266:False 267:False 268:False 269:False 270:False 271:False 272:False 273:False 274:False 275:False 276:False 277:False 278:False 279:False 280:False 281:False 282:False 283:False 284:False 285:False 286:False 287:False 288:False 289:False 290:False 291:False 292:False 293:False 294:False 295:False 296:False 297:False 298:False 299:False 300:False 301:False 302:False 303:False 304:False 305:False 306:False 307:False 308:False 309:False 310:False 311:False 312:False 313:False 314:False 315:False 316:False 317:False 318:False 319:False 320:False 321:False 322:False 323:False 324:False 325:False 326:False 327:False 328:False 329:False 330:False 331:False 332:False 333:False 334:False 335:False 336:False 337:False 338:False 339:False 340:False 341:False 342:False 343:False 344:False 345:False 346:False 347:False 348:False 349:False 350:False 351:False 352:False 353:False 354:False 355:False 356:False 357:False 358:False 359:False 360:False 361:False 362:False 363:False 364:False 365:False 366:False 367:False 368:False 369:False 370:False 371:False 372:False 373:False 374:False 375:False 376:False 377:False 378:False 379:False 380:False 381:False 382:False\n",
      "INFO:tensorflow:input_ids: 101 2372 1103 9505 1472 5763 1113 170 1825 112 188 17898 1116 136 102 1195 1156 3232 1103 7671 5752 1111 1103 3764 1869 119 1284 17428 1103 3187 1104 15069 1107 25157 1942 1116 1114 1103 3442 6315 1118 24763 9518 1742 12207 1891 119 164 1853 166 4222 4454 117 1259 22350 117 3442 1104 7091 2734 117 18205 14255 118 172 13003 1880 117 2812 118 1146 117 1105 6247 118 1106 118 7299 3622 1127 1215 1106 15187 1103 3068 1104 2025 119 164 1853 166 1262 1296 2025 1108 5667 1112 1344 117 1822 117 1137 10527 3187 1104 15069 119 1284 17428 1103 3442 7542 3068 1104 1664 118 7091 2200 2527 113 1884 13252 1204 2025 117 1137 1692 118 1654 2025 114 1606 1103 5847 7685 118 7711 3418 119 164 1476 166 1109 1703 3418 1104 1142 3442 1108 130 1827 117 1105 2299 1553 4668 1618 3068 119 164 1476 166 6291 2025 1108 1737 1106 1129 1344 3068 1191 1103 2794 1108 1167 1190 126 1827 119 1960 2457 17718 1215 1103 23676 13821 1592 1683 1367 119 121 113 1457 6575 3436 117 1531 2874 117 21514 117 3066 114 1106 3870 1103 11435 3622 119 25911 2603 117 1231 10182 21629 2603 117 1105 3254 1643 9538 118 189 1988 2603 117 1127 5165 1112 4267 8401 18778 2285 10986 1105 1127 4448 1112 5236 3187 113 155 2069 114 1114 4573 110 6595 14662 119 5158 1159 117 2704 2215 117 1892 2445 117 1171 118 2489 19497 1708 2794 117 3420 118 2489 19497 1708 2794 117 147 23579 2794 117 1105 18659 11964 118 12029 1708 120 7054 1708 117 1127 5165 1112 6803 10986 117 2456 1152 1127 4448 1112 20167 1928 3719 113 160 18219 114 1114 4573 110 6595 14662 119 2577 1103 2233 1127 4528 1174 117 154 118 188 19756 5562 1105 146 1477 188 19756 5562 1127 1215 1106 11552 1103 1119 25710 27054 1785 1621 1103 2527 117 1107 1134 170 153 2860 133 119 1275 1137 146 1477 135 1851 110 1127 3393 1112 2418 1119 25710 27054 1785 119 20784 1181 10777 1127 6455 1118 1606 170 4275 118 3154 2235 113 2268 7854 782 11679 5026 102\n",
      "I1208 12:27:37.059458 139883775852736 run_factoid.py:449] input_ids: 101 2372 1103 9505 1472 5763 1113 170 1825 112 188 17898 1116 136 102 1195 1156 3232 1103 7671 5752 1111 1103 3764 1869 119 1284 17428 1103 3187 1104 15069 1107 25157 1942 1116 1114 1103 3442 6315 1118 24763 9518 1742 12207 1891 119 164 1853 166 4222 4454 117 1259 22350 117 3442 1104 7091 2734 117 18205 14255 118 172 13003 1880 117 2812 118 1146 117 1105 6247 118 1106 118 7299 3622 1127 1215 1106 15187 1103 3068 1104 2025 119 164 1853 166 1262 1296 2025 1108 5667 1112 1344 117 1822 117 1137 10527 3187 1104 15069 119 1284 17428 1103 3442 7542 3068 1104 1664 118 7091 2200 2527 113 1884 13252 1204 2025 117 1137 1692 118 1654 2025 114 1606 1103 5847 7685 118 7711 3418 119 164 1476 166 1109 1703 3418 1104 1142 3442 1108 130 1827 117 1105 2299 1553 4668 1618 3068 119 164 1476 166 6291 2025 1108 1737 1106 1129 1344 3068 1191 1103 2794 1108 1167 1190 126 1827 119 1960 2457 17718 1215 1103 23676 13821 1592 1683 1367 119 121 113 1457 6575 3436 117 1531 2874 117 21514 117 3066 114 1106 3870 1103 11435 3622 119 25911 2603 117 1231 10182 21629 2603 117 1105 3254 1643 9538 118 189 1988 2603 117 1127 5165 1112 4267 8401 18778 2285 10986 1105 1127 4448 1112 5236 3187 113 155 2069 114 1114 4573 110 6595 14662 119 5158 1159 117 2704 2215 117 1892 2445 117 1171 118 2489 19497 1708 2794 117 3420 118 2489 19497 1708 2794 117 147 23579 2794 117 1105 18659 11964 118 12029 1708 120 7054 1708 117 1127 5165 1112 6803 10986 117 2456 1152 1127 4448 1112 20167 1928 3719 113 160 18219 114 1114 4573 110 6595 14662 119 2577 1103 2233 1127 4528 1174 117 154 118 188 19756 5562 1105 146 1477 188 19756 5562 1127 1215 1106 11552 1103 1119 25710 27054 1785 1621 1103 2527 117 1107 1134 170 153 2860 133 119 1275 1137 146 1477 135 1851 110 1127 3393 1112 2418 1119 25710 27054 1785 119 20784 1181 10777 1127 6455 1118 1606 170 4275 118 3154 2235 113 2268 7854 782 11679 5026 102\n",
      "INFO:tensorflow:input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      "I1208 12:27:37.059550 139883775852736 run_factoid.py:451] input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      "INFO:tensorflow:segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      "I1208 12:27:37.059640 139883775852736 run_factoid.py:453] segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      "INFO:tensorflow:*** Example ***\n",
      "I1208 12:27:37.061074 139883775852736 run_factoid.py:438] *** Example ***\n",
      "INFO:tensorflow:unique_id: 1000000025\n",
      "I1208 12:27:37.061135 139883775852736 run_factoid.py:439] unique_id: 1000000025\n",
      "INFO:tensorflow:example_index: 6\n",
      "I1208 12:27:37.061173 139883775852736 run_factoid.py:440] example_index: 6\n",
      "INFO:tensorflow:doc_span_index: 6\n",
      "I1208 12:27:37.061207 139883775852736 run_factoid.py:441] doc_span_index: 6\n",
      "INFO:tensorflow:tokens: [CLS] Are the findings different depending on a person ' s demographic ##s ? [SEP] total scale of this method was 9 points , and higher point indicated better quality . [ 30 ] Any study was considered to be high quality if the score was more than 5 points . Two independent investigators used the ST ##AT ##A version 12 . 0 ( St ##ata Corporation , College Station , TX , USA ) to perform the statistical analysis . Success rate , re ##cu ##rrence rate , and com ##p ##lica - t ##ion rate , were treated as di ##cho ##tom ##ous variables and were expressed as relative risk ( R ##R ) with 95 % confidence intervals . Operation time , hospital stay , blood loss , back - pain VA ##S score , leg - pain VA ##S score , J ##OA score , and SF ##12 - MC ##S / PC ##S , were treated as continuous variables , thus they were expressed as weighted mean difference ( W ##MD ) with 95 % confidence intervals . Before the data were pool ##ed , Q - s ##tat ##istic and I ##2 s ##tat ##istic were used to detect the he ##tero ##gene ##ity among the studies , in which a P value < . 10 or I ##2 > 50 % were defined as significant he ##tero ##gene ##ity . Poole ##d estimates were generated by using a fixed - effects model ( Man ##tel – Ha ##ens ##zel method ) [ 31 ] or random - effect model ( Der ##S ##i - mon ##ian – Lai ##rd method ) , [ 32 ] depending on the he ##tero ##gene ##ity among the included studies . When he ##tero ##gene ##ity was identified , we conducted sensitivity analysis by o ##mit ##ting one study at each turn to explore the influence of each individual study on the overall risk estimate . We also performed subgroup analysis based on the com ##par ##ators and duration of following - up to explore the sources of he ##tero ##gene ##ity and the impacts of these variables on the overall estimates . Public ##ation bias was assessed by the Be ##gg [ 33 ] and Egg ##er test . [SEP]\n",
      "I1208 12:27:37.061324 139883775852736 run_factoid.py:443] tokens: [CLS] Are the findings different depending on a person ' s demographic ##s ? [SEP] total scale of this method was 9 points , and higher point indicated better quality . [ 30 ] Any study was considered to be high quality if the score was more than 5 points . Two independent investigators used the ST ##AT ##A version 12 . 0 ( St ##ata Corporation , College Station , TX , USA ) to perform the statistical analysis . Success rate , re ##cu ##rrence rate , and com ##p ##lica - t ##ion rate , were treated as di ##cho ##tom ##ous variables and were expressed as relative risk ( R ##R ) with 95 % confidence intervals . Operation time , hospital stay , blood loss , back - pain VA ##S score , leg - pain VA ##S score , J ##OA score , and SF ##12 - MC ##S / PC ##S , were treated as continuous variables , thus they were expressed as weighted mean difference ( W ##MD ) with 95 % confidence intervals . Before the data were pool ##ed , Q - s ##tat ##istic and I ##2 s ##tat ##istic were used to detect the he ##tero ##gene ##ity among the studies , in which a P value < . 10 or I ##2 > 50 % were defined as significant he ##tero ##gene ##ity . Poole ##d estimates were generated by using a fixed - effects model ( Man ##tel – Ha ##ens ##zel method ) [ 31 ] or random - effect model ( Der ##S ##i - mon ##ian – Lai ##rd method ) , [ 32 ] depending on the he ##tero ##gene ##ity among the included studies . When he ##tero ##gene ##ity was identified , we conducted sensitivity analysis by o ##mit ##ting one study at each turn to explore the influence of each individual study on the overall risk estimate . We also performed subgroup analysis based on the com ##par ##ators and duration of following - up to explore the sources of he ##tero ##gene ##ity and the impacts of these variables on the overall estimates . Public ##ation bias was assessed by the Be ##gg [ 33 ] and Egg ##er test . [SEP]\n",
      "INFO:tensorflow:token_to_orig_map: 15:388 16:389 17:390 18:391 19:392 20:393 21:394 22:395 23:395 24:396 25:397 26:398 27:399 28:400 29:401 30:401 31:401 32:401 33:401 34:402 35:403 36:404 37:405 38:406 39:407 40:408 41:409 42:410 43:411 44:412 45:413 46:414 47:415 48:416 49:417 50:417 51:418 52:419 53:420 54:421 55:422 56:423 57:423 58:423 59:424 60:425 61:425 62:425 63:426 64:426 65:426 66:427 67:427 68:428 69:429 70:429 71:430 72:430 73:431 74:431 75:432 76:433 77:434 78:435 79:436 80:436 81:437 82:438 83:438 84:439 85:439 86:439 87:440 88:440 89:441 90:442 91:442 92:442 93:442 94:443 95:443 96:444 97:444 98:445 99:446 100:447 101:448 102:448 103:448 104:448 105:449 106:450 107:451 108:452 109:453 110:454 111:455 112:456 113:456 114:456 115:456 116:457 117:458 118:458 119:459 120:460 121:460 122:461 123:462 124:462 125:463 126:464 127:464 128:465 129:466 130:466 131:467 132:467 133:467 134:468 135:468 136:469 137:469 138:470 139:470 140:470 141:471 142:471 143:472 144:472 145:473 146:473 147:474 148:474 149:475 150:476 151:476 152:476 153:476 154:476 155:476 156:476 157:476 158:476 159:477 160:478 161:479 162:480 163:481 164:481 165:482 166:483 167:484 168:485 169:486 170:487 171:488 172:489 173:490 174:490 175:490 176:490 177:491 178:492 179:492 180:493 181:494 182:494 183:495 184:496 185:497 186:498 187:499 188:499 189:499 190:500 191:500 192:500 193:500 194:500 195:501 196:502 197:502 198:503 199:503 200:503 201:504 202:505 203:506 204:507 205:508 206:509 207:509 208:509 209:509 210:510 211:511 212:512 213:512 214:513 215:514 216:515 217:516 218:517 219:518 220:519 221:519 222:520 223:521 224:521 225:522 226:523 227:523 228:524 229:525 230:526 231:527 232:528 233:528 234:528 235:528 236:528 237:529 238:529 239:530 240:531 241:532 242:533 243:534 244:535 245:536 246:536 247:536 248:537 249:538 250:538 251:538 252:538 253:538 254:538 255:538 256:539 257:539 258:539 259:539 260:539 261:540 262:541 263:541 264:541 265:542 266:543 267:543 268:543 269:543 270:543 271:544 272:544 273:544 274:544 275:544 276:545 277:545 278:545 279:545 280:545 281:545 282:546 283:547 284:548 285:549 286:549 287:549 288:549 289:550 290:551 291:552 292:553 293:553 294:554 295:555 296:555 297:555 298:555 299:556 300:557 301:557 302:558 303:559 304:560 305:561 306:562 307:563 308:563 309:563 310:564 311:565 312:566 313:567 314:568 315:569 316:570 317:571 318:572 319:573 320:574 321:575 322:576 323:577 324:578 325:579 326:580 327:581 328:581 329:582 330:583 331:584 332:585 333:586 334:587 335:588 336:589 337:590 338:590 339:590 340:591 341:592 342:593 343:594 344:594 345:594 346:595 347:596 348:597 349:598 350:599 351:600 352:600 353:600 354:600 355:601 356:602 357:603 358:604 359:605 360:606 361:607 362:608 363:609 364:610 365:610 366:611 367:611 368:612 369:613 370:614 371:615 372:616 373:617 374:617 375:617 376:617 377:617 378:618 379:619 380:619 381:620 382:620\n",
      "I1208 12:27:37.061446 139883775852736 run_factoid.py:445] token_to_orig_map: 15:388 16:389 17:390 18:391 19:392 20:393 21:394 22:395 23:395 24:396 25:397 26:398 27:399 28:400 29:401 30:401 31:401 32:401 33:401 34:402 35:403 36:404 37:405 38:406 39:407 40:408 41:409 42:410 43:411 44:412 45:413 46:414 47:415 48:416 49:417 50:417 51:418 52:419 53:420 54:421 55:422 56:423 57:423 58:423 59:424 60:425 61:425 62:425 63:426 64:426 65:426 66:427 67:427 68:428 69:429 70:429 71:430 72:430 73:431 74:431 75:432 76:433 77:434 78:435 79:436 80:436 81:437 82:438 83:438 84:439 85:439 86:439 87:440 88:440 89:441 90:442 91:442 92:442 93:442 94:443 95:443 96:444 97:444 98:445 99:446 100:447 101:448 102:448 103:448 104:448 105:449 106:450 107:451 108:452 109:453 110:454 111:455 112:456 113:456 114:456 115:456 116:457 117:458 118:458 119:459 120:460 121:460 122:461 123:462 124:462 125:463 126:464 127:464 128:465 129:466 130:466 131:467 132:467 133:467 134:468 135:468 136:469 137:469 138:470 139:470 140:470 141:471 142:471 143:472 144:472 145:473 146:473 147:474 148:474 149:475 150:476 151:476 152:476 153:476 154:476 155:476 156:476 157:476 158:476 159:477 160:478 161:479 162:480 163:481 164:481 165:482 166:483 167:484 168:485 169:486 170:487 171:488 172:489 173:490 174:490 175:490 176:490 177:491 178:492 179:492 180:493 181:494 182:494 183:495 184:496 185:497 186:498 187:499 188:499 189:499 190:500 191:500 192:500 193:500 194:500 195:501 196:502 197:502 198:503 199:503 200:503 201:504 202:505 203:506 204:507 205:508 206:509 207:509 208:509 209:509 210:510 211:511 212:512 213:512 214:513 215:514 216:515 217:516 218:517 219:518 220:519 221:519 222:520 223:521 224:521 225:522 226:523 227:523 228:524 229:525 230:526 231:527 232:528 233:528 234:528 235:528 236:528 237:529 238:529 239:530 240:531 241:532 242:533 243:534 244:535 245:536 246:536 247:536 248:537 249:538 250:538 251:538 252:538 253:538 254:538 255:538 256:539 257:539 258:539 259:539 260:539 261:540 262:541 263:541 264:541 265:542 266:543 267:543 268:543 269:543 270:543 271:544 272:544 273:544 274:544 275:544 276:545 277:545 278:545 279:545 280:545 281:545 282:546 283:547 284:548 285:549 286:549 287:549 288:549 289:550 290:551 291:552 292:553 293:553 294:554 295:555 296:555 297:555 298:555 299:556 300:557 301:557 302:558 303:559 304:560 305:561 306:562 307:563 308:563 309:563 310:564 311:565 312:566 313:567 314:568 315:569 316:570 317:571 318:572 319:573 320:574 321:575 322:576 323:577 324:578 325:579 326:580 327:581 328:581 329:582 330:583 331:584 332:585 333:586 334:587 335:588 336:589 337:590 338:590 339:590 340:591 341:592 342:593 343:594 344:594 345:594 346:595 347:596 348:597 349:598 350:599 351:600 352:600 353:600 354:600 355:601 356:602 357:603 358:604 359:605 360:606 361:607 362:608 363:609 364:610 365:610 366:611 367:611 368:612 369:613 370:614 371:615 372:616 373:617 374:617 375:617 376:617 377:617 378:618 379:619 380:619 381:620 382:620\n",
      "INFO:tensorflow:token_is_max_context: 15:False 16:False 17:False 18:False 19:False 20:False 21:False 22:False 23:False 24:False 25:False 26:False 27:False 28:False 29:False 30:False 31:False 32:False 33:False 34:False 35:False 36:False 37:False 38:False 39:False 40:False 41:False 42:False 43:False 44:False 45:False 46:False 47:False 48:False 49:False 50:False 51:False 52:False 53:False 54:False 55:False 56:False 57:False 58:False 59:False 60:False 61:False 62:False 63:False 64:False 65:False 66:False 67:False 68:False 69:False 70:False 71:False 72:False 73:False 74:False 75:False 76:False 77:False 78:False 79:False 80:False 81:False 82:False 83:False 84:False 85:False 86:False 87:False 88:False 89:False 90:False 91:False 92:False 93:False 94:False 95:False 96:False 97:False 98:False 99:False 100:False 101:False 102:False 103:False 104:False 105:False 106:False 107:False 108:False 109:False 110:False 111:False 112:False 113:False 114:False 115:False 116:False 117:False 118:False 119:False 120:False 121:False 122:False 123:False 124:False 125:False 126:False 127:False 128:False 129:False 130:False 131:False 132:False 133:False 134:False 135:True 136:True 137:True 138:True 139:True 140:True 141:True 142:True 143:True 144:True 145:True 146:True 147:True 148:True 149:True 150:True 151:True 152:True 153:True 154:True 155:True 156:True 157:True 158:True 159:True 160:True 161:True 162:True 163:True 164:True 165:True 166:True 167:True 168:True 169:True 170:True 171:True 172:True 173:True 174:True 175:True 176:True 177:True 178:True 179:True 180:True 181:True 182:True 183:True 184:True 185:True 186:True 187:True 188:True 189:True 190:True 191:True 192:True 193:True 194:True 195:True 196:True 197:True 198:True 199:True 200:True 201:True 202:True 203:True 204:True 205:True 206:True 207:True 208:True 209:True 210:True 211:True 212:True 213:True 214:True 215:True 216:True 217:True 218:True 219:True 220:True 221:True 222:True 223:True 224:True 225:True 226:True 227:True 228:True 229:True 230:True 231:True 232:True 233:True 234:True 235:True 236:True 237:True 238:True 239:True 240:True 241:True 242:True 243:True 244:True 245:True 246:True 247:True 248:True 249:True 250:True 251:True 252:True 253:True 254:True 255:True 256:True 257:True 258:True 259:True 260:True 261:True 262:True 263:False 264:False 265:False 266:False 267:False 268:False 269:False 270:False 271:False 272:False 273:False 274:False 275:False 276:False 277:False 278:False 279:False 280:False 281:False 282:False 283:False 284:False 285:False 286:False 287:False 288:False 289:False 290:False 291:False 292:False 293:False 294:False 295:False 296:False 297:False 298:False 299:False 300:False 301:False 302:False 303:False 304:False 305:False 306:False 307:False 308:False 309:False 310:False 311:False 312:False 313:False 314:False 315:False 316:False 317:False 318:False 319:False 320:False 321:False 322:False 323:False 324:False 325:False 326:False 327:False 328:False 329:False 330:False 331:False 332:False 333:False 334:False 335:False 336:False 337:False 338:False 339:False 340:False 341:False 342:False 343:False 344:False 345:False 346:False 347:False 348:False 349:False 350:False 351:False 352:False 353:False 354:False 355:False 356:False 357:False 358:False 359:False 360:False 361:False 362:False 363:False 364:False 365:False 366:False 367:False 368:False 369:False 370:False 371:False 372:False 373:False 374:False 375:False 376:False 377:False 378:False 379:False 380:False 381:False 382:False\n",
      "I1208 12:27:37.061552 139883775852736 run_factoid.py:447] token_is_max_context: 15:False 16:False 17:False 18:False 19:False 20:False 21:False 22:False 23:False 24:False 25:False 26:False 27:False 28:False 29:False 30:False 31:False 32:False 33:False 34:False 35:False 36:False 37:False 38:False 39:False 40:False 41:False 42:False 43:False 44:False 45:False 46:False 47:False 48:False 49:False 50:False 51:False 52:False 53:False 54:False 55:False 56:False 57:False 58:False 59:False 60:False 61:False 62:False 63:False 64:False 65:False 66:False 67:False 68:False 69:False 70:False 71:False 72:False 73:False 74:False 75:False 76:False 77:False 78:False 79:False 80:False 81:False 82:False 83:False 84:False 85:False 86:False 87:False 88:False 89:False 90:False 91:False 92:False 93:False 94:False 95:False 96:False 97:False 98:False 99:False 100:False 101:False 102:False 103:False 104:False 105:False 106:False 107:False 108:False 109:False 110:False 111:False 112:False 113:False 114:False 115:False 116:False 117:False 118:False 119:False 120:False 121:False 122:False 123:False 124:False 125:False 126:False 127:False 128:False 129:False 130:False 131:False 132:False 133:False 134:False 135:True 136:True 137:True 138:True 139:True 140:True 141:True 142:True 143:True 144:True 145:True 146:True 147:True 148:True 149:True 150:True 151:True 152:True 153:True 154:True 155:True 156:True 157:True 158:True 159:True 160:True 161:True 162:True 163:True 164:True 165:True 166:True 167:True 168:True 169:True 170:True 171:True 172:True 173:True 174:True 175:True 176:True 177:True 178:True 179:True 180:True 181:True 182:True 183:True 184:True 185:True 186:True 187:True 188:True 189:True 190:True 191:True 192:True 193:True 194:True 195:True 196:True 197:True 198:True 199:True 200:True 201:True 202:True 203:True 204:True 205:True 206:True 207:True 208:True 209:True 210:True 211:True 212:True 213:True 214:True 215:True 216:True 217:True 218:True 219:True 220:True 221:True 222:True 223:True 224:True 225:True 226:True 227:True 228:True 229:True 230:True 231:True 232:True 233:True 234:True 235:True 236:True 237:True 238:True 239:True 240:True 241:True 242:True 243:True 244:True 245:True 246:True 247:True 248:True 249:True 250:True 251:True 252:True 253:True 254:True 255:True 256:True 257:True 258:True 259:True 260:True 261:True 262:True 263:False 264:False 265:False 266:False 267:False 268:False 269:False 270:False 271:False 272:False 273:False 274:False 275:False 276:False 277:False 278:False 279:False 280:False 281:False 282:False 283:False 284:False 285:False 286:False 287:False 288:False 289:False 290:False 291:False 292:False 293:False 294:False 295:False 296:False 297:False 298:False 299:False 300:False 301:False 302:False 303:False 304:False 305:False 306:False 307:False 308:False 309:False 310:False 311:False 312:False 313:False 314:False 315:False 316:False 317:False 318:False 319:False 320:False 321:False 322:False 323:False 324:False 325:False 326:False 327:False 328:False 329:False 330:False 331:False 332:False 333:False 334:False 335:False 336:False 337:False 338:False 339:False 340:False 341:False 342:False 343:False 344:False 345:False 346:False 347:False 348:False 349:False 350:False 351:False 352:False 353:False 354:False 355:False 356:False 357:False 358:False 359:False 360:False 361:False 362:False 363:False 364:False 365:False 366:False 367:False 368:False 369:False 370:False 371:False 372:False 373:False 374:False 375:False 376:False 377:False 378:False 379:False 380:False 381:False 382:False\n",
      "INFO:tensorflow:input_ids: 101 2372 1103 9505 1472 5763 1113 170 1825 112 188 17898 1116 136 102 1703 3418 1104 1142 3442 1108 130 1827 117 1105 2299 1553 4668 1618 3068 119 164 1476 166 6291 2025 1108 1737 1106 1129 1344 3068 1191 1103 2794 1108 1167 1190 126 1827 119 1960 2457 17718 1215 1103 23676 13821 1592 1683 1367 119 121 113 1457 6575 3436 117 1531 2874 117 21514 117 3066 114 1106 3870 1103 11435 3622 119 25911 2603 117 1231 10182 21629 2603 117 1105 3254 1643 9538 118 189 1988 2603 117 1127 5165 1112 4267 8401 18778 2285 10986 1105 1127 4448 1112 5236 3187 113 155 2069 114 1114 4573 110 6595 14662 119 5158 1159 117 2704 2215 117 1892 2445 117 1171 118 2489 19497 1708 2794 117 3420 118 2489 19497 1708 2794 117 147 23579 2794 117 1105 18659 11964 118 12029 1708 120 7054 1708 117 1127 5165 1112 6803 10986 117 2456 1152 1127 4448 1112 20167 1928 3719 113 160 18219 114 1114 4573 110 6595 14662 119 2577 1103 2233 1127 4528 1174 117 154 118 188 19756 5562 1105 146 1477 188 19756 5562 1127 1215 1106 11552 1103 1119 25710 27054 1785 1621 1103 2527 117 1107 1134 170 153 2860 133 119 1275 1137 146 1477 135 1851 110 1127 3393 1112 2418 1119 25710 27054 1785 119 20784 1181 10777 1127 6455 1118 1606 170 4275 118 3154 2235 113 2268 7854 782 11679 5026 13430 3442 114 164 1955 166 1137 7091 118 2629 2235 113 9682 1708 1182 118 19863 1811 782 25489 2956 3442 114 117 164 2724 166 5763 1113 1103 1119 25710 27054 1785 1621 1103 1529 2527 119 1332 1119 25710 27054 1785 1108 3626 117 1195 3303 15750 3622 1118 184 9084 1916 1141 2025 1120 1296 1885 1106 8664 1103 2933 1104 1296 2510 2025 1113 1103 2905 3187 10301 119 1284 1145 1982 23470 3622 1359 1113 1103 3254 17482 11664 1105 9355 1104 1378 118 1146 1106 8664 1103 3509 1104 1119 25710 27054 1785 1105 1103 15791 1104 1292 10986 1113 1103 2905 10777 119 2710 1891 15069 1108 14758 1118 1103 4108 9705 164 3081 166 1105 25861 1200 2774 119 102\n",
      "I1208 12:27:37.061656 139883775852736 run_factoid.py:449] input_ids: 101 2372 1103 9505 1472 5763 1113 170 1825 112 188 17898 1116 136 102 1703 3418 1104 1142 3442 1108 130 1827 117 1105 2299 1553 4668 1618 3068 119 164 1476 166 6291 2025 1108 1737 1106 1129 1344 3068 1191 1103 2794 1108 1167 1190 126 1827 119 1960 2457 17718 1215 1103 23676 13821 1592 1683 1367 119 121 113 1457 6575 3436 117 1531 2874 117 21514 117 3066 114 1106 3870 1103 11435 3622 119 25911 2603 117 1231 10182 21629 2603 117 1105 3254 1643 9538 118 189 1988 2603 117 1127 5165 1112 4267 8401 18778 2285 10986 1105 1127 4448 1112 5236 3187 113 155 2069 114 1114 4573 110 6595 14662 119 5158 1159 117 2704 2215 117 1892 2445 117 1171 118 2489 19497 1708 2794 117 3420 118 2489 19497 1708 2794 117 147 23579 2794 117 1105 18659 11964 118 12029 1708 120 7054 1708 117 1127 5165 1112 6803 10986 117 2456 1152 1127 4448 1112 20167 1928 3719 113 160 18219 114 1114 4573 110 6595 14662 119 2577 1103 2233 1127 4528 1174 117 154 118 188 19756 5562 1105 146 1477 188 19756 5562 1127 1215 1106 11552 1103 1119 25710 27054 1785 1621 1103 2527 117 1107 1134 170 153 2860 133 119 1275 1137 146 1477 135 1851 110 1127 3393 1112 2418 1119 25710 27054 1785 119 20784 1181 10777 1127 6455 1118 1606 170 4275 118 3154 2235 113 2268 7854 782 11679 5026 13430 3442 114 164 1955 166 1137 7091 118 2629 2235 113 9682 1708 1182 118 19863 1811 782 25489 2956 3442 114 117 164 2724 166 5763 1113 1103 1119 25710 27054 1785 1621 1103 1529 2527 119 1332 1119 25710 27054 1785 1108 3626 117 1195 3303 15750 3622 1118 184 9084 1916 1141 2025 1120 1296 1885 1106 8664 1103 2933 1104 1296 2510 2025 1113 1103 2905 3187 10301 119 1284 1145 1982 23470 3622 1359 1113 1103 3254 17482 11664 1105 9355 1104 1378 118 1146 1106 8664 1103 3509 1104 1119 25710 27054 1785 1105 1103 15791 1104 1292 10986 1113 1103 2905 10777 119 2710 1891 15069 1108 14758 1118 1103 4108 9705 164 3081 166 1105 25861 1200 2774 119 102\n",
      "INFO:tensorflow:input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      "I1208 12:27:37.061748 139883775852736 run_factoid.py:451] input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      "INFO:tensorflow:segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      "I1208 12:27:37.061836 139883775852736 run_factoid.py:453] segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      "INFO:tensorflow:*** Example ***\n",
      "I1208 12:27:37.063049 139883775852736 run_factoid.py:438] *** Example ***\n",
      "INFO:tensorflow:unique_id: 1000000026\n",
      "I1208 12:27:37.063108 139883775852736 run_factoid.py:439] unique_id: 1000000026\n",
      "INFO:tensorflow:example_index: 6\n",
      "I1208 12:27:37.063145 139883775852736 run_factoid.py:440] example_index: 6\n",
      "INFO:tensorflow:doc_span_index: 7\n",
      "I1208 12:27:37.063179 139883775852736 run_factoid.py:441] doc_span_index: 7\n",
      "INFO:tensorflow:tokens: [CLS] Are the findings different depending on a person ' s demographic ##s ? [SEP] score , J ##OA score , and SF ##12 - MC ##S / PC ##S , were treated as continuous variables , thus they were expressed as weighted mean difference ( W ##MD ) with 95 % confidence intervals . Before the data were pool ##ed , Q - s ##tat ##istic and I ##2 s ##tat ##istic were used to detect the he ##tero ##gene ##ity among the studies , in which a P value < . 10 or I ##2 > 50 % were defined as significant he ##tero ##gene ##ity . Poole ##d estimates were generated by using a fixed - effects model ( Man ##tel – Ha ##ens ##zel method ) [ 31 ] or random - effect model ( Der ##S ##i - mon ##ian – Lai ##rd method ) , [ 32 ] depending on the he ##tero ##gene ##ity among the included studies . When he ##tero ##gene ##ity was identified , we conducted sensitivity analysis by o ##mit ##ting one study at each turn to explore the influence of each individual study on the overall risk estimate . We also performed subgroup analysis based on the com ##par ##ators and duration of following - up to explore the sources of he ##tero ##gene ##ity and the impacts of these variables on the overall estimates . Public ##ation bias was assessed by the Be ##gg [ 33 ] and Egg ##er test . [ 34 ] A 2 - tailed P value < . 05 was considered statistical ##ly significant except where a certain P - value had been specified . This is meta - analysis , so et ##hic approval is not required . Figure 1 . Eli ##gi ##bility of studies for inclusion in meta - analysis . Basel ##ine characteristics of patients in the trials included in the meta - analysis . [SEP]\n",
      "I1208 12:27:37.063284 139883775852736 run_factoid.py:443] tokens: [CLS] Are the findings different depending on a person ' s demographic ##s ? [SEP] score , J ##OA score , and SF ##12 - MC ##S / PC ##S , were treated as continuous variables , thus they were expressed as weighted mean difference ( W ##MD ) with 95 % confidence intervals . Before the data were pool ##ed , Q - s ##tat ##istic and I ##2 s ##tat ##istic were used to detect the he ##tero ##gene ##ity among the studies , in which a P value < . 10 or I ##2 > 50 % were defined as significant he ##tero ##gene ##ity . Poole ##d estimates were generated by using a fixed - effects model ( Man ##tel – Ha ##ens ##zel method ) [ 31 ] or random - effect model ( Der ##S ##i - mon ##ian – Lai ##rd method ) , [ 32 ] depending on the he ##tero ##gene ##ity among the included studies . When he ##tero ##gene ##ity was identified , we conducted sensitivity analysis by o ##mit ##ting one study at each turn to explore the influence of each individual study on the overall risk estimate . We also performed subgroup analysis based on the com ##par ##ators and duration of following - up to explore the sources of he ##tero ##gene ##ity and the impacts of these variables on the overall estimates . Public ##ation bias was assessed by the Be ##gg [ 33 ] and Egg ##er test . [ 34 ] A 2 - tailed P value < . 05 was considered statistical ##ly significant except where a certain P - value had been specified . This is meta - analysis , so et ##hic approval is not required . Figure 1 . Eli ##gi ##bility of studies for inclusion in meta - analysis . Basel ##ine characteristics of patients in the trials included in the meta - analysis . [SEP]\n",
      "INFO:tensorflow:token_to_orig_map: 15:472 16:472 17:473 18:473 19:474 20:474 21:475 22:476 23:476 24:476 25:476 26:476 27:476 28:476 29:476 30:476 31:477 32:478 33:479 34:480 35:481 36:481 37:482 38:483 39:484 40:485 41:486 42:487 43:488 44:489 45:490 46:490 47:490 48:490 49:491 50:492 51:492 52:493 53:494 54:494 55:495 56:496 57:497 58:498 59:499 60:499 61:499 62:500 63:500 64:500 65:500 66:500 67:501 68:502 69:502 70:503 71:503 72:503 73:504 74:505 75:506 76:507 77:508 78:509 79:509 80:509 81:509 82:510 83:511 84:512 85:512 86:513 87:514 88:515 89:516 90:517 91:518 92:519 93:519 94:520 95:521 96:521 97:522 98:523 99:523 100:524 101:525 102:526 103:527 104:528 105:528 106:528 107:528 108:528 109:529 110:529 111:530 112:531 113:532 114:533 115:534 116:535 117:536 118:536 119:536 120:537 121:538 122:538 123:538 124:538 125:538 126:538 127:538 128:539 129:539 130:539 131:539 132:539 133:540 134:541 135:541 136:541 137:542 138:543 139:543 140:543 141:543 142:543 143:544 144:544 145:544 146:544 147:544 148:545 149:545 150:545 151:545 152:545 153:545 154:546 155:547 156:548 157:549 158:549 159:549 160:549 161:550 162:551 163:552 164:553 165:553 166:554 167:555 168:555 169:555 170:555 171:556 172:557 173:557 174:558 175:559 176:560 177:561 178:562 179:563 180:563 181:563 182:564 183:565 184:566 185:567 186:568 187:569 188:570 189:571 190:572 191:573 192:574 193:575 194:576 195:577 196:578 197:579 198:580 199:581 200:581 201:582 202:583 203:584 204:585 205:586 206:587 207:588 208:589 209:590 210:590 211:590 212:591 213:592 214:593 215:594 216:594 217:594 218:595 219:596 220:597 221:598 222:599 223:600 224:600 225:600 226:600 227:601 228:602 229:603 230:604 231:605 232:606 233:607 234:608 235:609 236:610 237:610 238:611 239:611 240:612 241:613 242:614 243:615 244:616 245:617 246:617 247:617 248:617 249:617 250:618 251:619 252:619 253:620 254:620 255:620 256:620 257:620 258:621 259:622 260:622 261:622 262:623 263:624 264:625 265:625 266:625 267:626 268:627 269:628 270:628 271:629 272:630 273:631 274:632 275:633 276:634 277:634 278:634 279:635 280:636 281:637 282:637 283:638 284:639 285:640 286:640 287:640 288:640 289:641 290:642 291:642 292:643 293:644 294:645 295:646 296:646 297:647 298:648 299:648 300:649 301:649 302:649 303:650 304:651 305:652 306:653 307:654 308:655 309:655 310:655 311:655 312:656 313:656 314:657 315:658 316:659 317:660 318:661 319:662 320:663 321:664 322:665 323:666 324:666 325:666 326:666\n",
      "I1208 12:27:37.063391 139883775852736 run_factoid.py:445] token_to_orig_map: 15:472 16:472 17:473 18:473 19:474 20:474 21:475 22:476 23:476 24:476 25:476 26:476 27:476 28:476 29:476 30:476 31:477 32:478 33:479 34:480 35:481 36:481 37:482 38:483 39:484 40:485 41:486 42:487 43:488 44:489 45:490 46:490 47:490 48:490 49:491 50:492 51:492 52:493 53:494 54:494 55:495 56:496 57:497 58:498 59:499 60:499 61:499 62:500 63:500 64:500 65:500 66:500 67:501 68:502 69:502 70:503 71:503 72:503 73:504 74:505 75:506 76:507 77:508 78:509 79:509 80:509 81:509 82:510 83:511 84:512 85:512 86:513 87:514 88:515 89:516 90:517 91:518 92:519 93:519 94:520 95:521 96:521 97:522 98:523 99:523 100:524 101:525 102:526 103:527 104:528 105:528 106:528 107:528 108:528 109:529 110:529 111:530 112:531 113:532 114:533 115:534 116:535 117:536 118:536 119:536 120:537 121:538 122:538 123:538 124:538 125:538 126:538 127:538 128:539 129:539 130:539 131:539 132:539 133:540 134:541 135:541 136:541 137:542 138:543 139:543 140:543 141:543 142:543 143:544 144:544 145:544 146:544 147:544 148:545 149:545 150:545 151:545 152:545 153:545 154:546 155:547 156:548 157:549 158:549 159:549 160:549 161:550 162:551 163:552 164:553 165:553 166:554 167:555 168:555 169:555 170:555 171:556 172:557 173:557 174:558 175:559 176:560 177:561 178:562 179:563 180:563 181:563 182:564 183:565 184:566 185:567 186:568 187:569 188:570 189:571 190:572 191:573 192:574 193:575 194:576 195:577 196:578 197:579 198:580 199:581 200:581 201:582 202:583 203:584 204:585 205:586 206:587 207:588 208:589 209:590 210:590 211:590 212:591 213:592 214:593 215:594 216:594 217:594 218:595 219:596 220:597 221:598 222:599 223:600 224:600 225:600 226:600 227:601 228:602 229:603 230:604 231:605 232:606 233:607 234:608 235:609 236:610 237:610 238:611 239:611 240:612 241:613 242:614 243:615 244:616 245:617 246:617 247:617 248:617 249:617 250:618 251:619 252:619 253:620 254:620 255:620 256:620 257:620 258:621 259:622 260:622 261:622 262:623 263:624 264:625 265:625 266:625 267:626 268:627 269:628 270:628 271:629 272:630 273:631 274:632 275:633 276:634 277:634 278:634 279:635 280:636 281:637 282:637 283:638 284:639 285:640 286:640 287:640 288:640 289:641 290:642 291:642 292:643 293:644 294:645 295:646 296:646 297:647 298:648 299:648 300:649 301:649 302:649 303:650 304:651 305:652 306:653 307:654 308:655 309:655 310:655 311:655 312:656 313:656 314:657 315:658 316:659 317:660 318:661 319:662 320:663 321:664 322:665 323:666 324:666 325:666 326:666\n",
      "INFO:tensorflow:token_is_max_context: 15:False 16:False 17:False 18:False 19:False 20:False 21:False 22:False 23:False 24:False 25:False 26:False 27:False 28:False 29:False 30:False 31:False 32:False 33:False 34:False 35:False 36:False 37:False 38:False 39:False 40:False 41:False 42:False 43:False 44:False 45:False 46:False 47:False 48:False 49:False 50:False 51:False 52:False 53:False 54:False 55:False 56:False 57:False 58:False 59:False 60:False 61:False 62:False 63:False 64:False 65:False 66:False 67:False 68:False 69:False 70:False 71:False 72:False 73:False 74:False 75:False 76:False 77:False 78:False 79:False 80:False 81:False 82:False 83:False 84:False 85:False 86:False 87:False 88:False 89:False 90:False 91:False 92:False 93:False 94:False 95:False 96:False 97:False 98:False 99:False 100:False 101:False 102:False 103:False 104:False 105:False 106:False 107:False 108:False 109:False 110:False 111:False 112:False 113:False 114:False 115:False 116:False 117:False 118:False 119:False 120:False 121:False 122:False 123:False 124:False 125:False 126:False 127:False 128:False 129:False 130:False 131:False 132:False 133:False 134:False 135:True 136:True 137:True 138:True 139:True 140:True 141:True 142:True 143:True 144:True 145:True 146:True 147:True 148:True 149:True 150:True 151:True 152:True 153:True 154:True 155:True 156:True 157:True 158:True 159:True 160:True 161:True 162:True 163:True 164:True 165:True 166:True 167:True 168:True 169:True 170:True 171:True 172:True 173:True 174:True 175:True 176:True 177:True 178:True 179:True 180:True 181:True 182:True 183:True 184:True 185:True 186:True 187:True 188:True 189:True 190:True 191:True 192:True 193:True 194:True 195:True 196:True 197:True 198:True 199:True 200:True 201:True 202:True 203:True 204:True 205:True 206:True 207:True 208:True 209:True 210:True 211:True 212:True 213:True 214:True 215:True 216:True 217:True 218:True 219:True 220:True 221:True 222:True 223:True 224:True 225:True 226:True 227:True 228:True 229:True 230:True 231:True 232:True 233:True 234:True 235:True 236:True 237:True 238:True 239:True 240:True 241:True 242:True 243:True 244:True 245:True 246:True 247:True 248:True 249:True 250:True 251:True 252:True 253:True 254:True 255:True 256:True 257:True 258:True 259:True 260:True 261:True 262:True 263:True 264:True 265:True 266:True 267:True 268:True 269:True 270:True 271:True 272:True 273:True 274:True 275:True 276:True 277:True 278:True 279:True 280:True 281:True 282:True 283:True 284:True 285:True 286:True 287:True 288:True 289:True 290:True 291:True 292:True 293:True 294:True 295:True 296:True 297:True 298:True 299:True 300:True 301:True 302:True 303:True 304:True 305:True 306:True 307:True 308:True 309:True 310:True 311:True 312:True 313:True 314:True 315:True 316:True 317:True 318:True 319:True 320:True 321:True 322:True 323:True 324:True 325:True 326:True\n",
      "I1208 12:27:37.063494 139883775852736 run_factoid.py:447] token_is_max_context: 15:False 16:False 17:False 18:False 19:False 20:False 21:False 22:False 23:False 24:False 25:False 26:False 27:False 28:False 29:False 30:False 31:False 32:False 33:False 34:False 35:False 36:False 37:False 38:False 39:False 40:False 41:False 42:False 43:False 44:False 45:False 46:False 47:False 48:False 49:False 50:False 51:False 52:False 53:False 54:False 55:False 56:False 57:False 58:False 59:False 60:False 61:False 62:False 63:False 64:False 65:False 66:False 67:False 68:False 69:False 70:False 71:False 72:False 73:False 74:False 75:False 76:False 77:False 78:False 79:False 80:False 81:False 82:False 83:False 84:False 85:False 86:False 87:False 88:False 89:False 90:False 91:False 92:False 93:False 94:False 95:False 96:False 97:False 98:False 99:False 100:False 101:False 102:False 103:False 104:False 105:False 106:False 107:False 108:False 109:False 110:False 111:False 112:False 113:False 114:False 115:False 116:False 117:False 118:False 119:False 120:False 121:False 122:False 123:False 124:False 125:False 126:False 127:False 128:False 129:False 130:False 131:False 132:False 133:False 134:False 135:True 136:True 137:True 138:True 139:True 140:True 141:True 142:True 143:True 144:True 145:True 146:True 147:True 148:True 149:True 150:True 151:True 152:True 153:True 154:True 155:True 156:True 157:True 158:True 159:True 160:True 161:True 162:True 163:True 164:True 165:True 166:True 167:True 168:True 169:True 170:True 171:True 172:True 173:True 174:True 175:True 176:True 177:True 178:True 179:True 180:True 181:True 182:True 183:True 184:True 185:True 186:True 187:True 188:True 189:True 190:True 191:True 192:True 193:True 194:True 195:True 196:True 197:True 198:True 199:True 200:True 201:True 202:True 203:True 204:True 205:True 206:True 207:True 208:True 209:True 210:True 211:True 212:True 213:True 214:True 215:True 216:True 217:True 218:True 219:True 220:True 221:True 222:True 223:True 224:True 225:True 226:True 227:True 228:True 229:True 230:True 231:True 232:True 233:True 234:True 235:True 236:True 237:True 238:True 239:True 240:True 241:True 242:True 243:True 244:True 245:True 246:True 247:True 248:True 249:True 250:True 251:True 252:True 253:True 254:True 255:True 256:True 257:True 258:True 259:True 260:True 261:True 262:True 263:True 264:True 265:True 266:True 267:True 268:True 269:True 270:True 271:True 272:True 273:True 274:True 275:True 276:True 277:True 278:True 279:True 280:True 281:True 282:True 283:True 284:True 285:True 286:True 287:True 288:True 289:True 290:True 291:True 292:True 293:True 294:True 295:True 296:True 297:True 298:True 299:True 300:True 301:True 302:True 303:True 304:True 305:True 306:True 307:True 308:True 309:True 310:True 311:True 312:True 313:True 314:True 315:True 316:True 317:True 318:True 319:True 320:True 321:True 322:True 323:True 324:True 325:True 326:True\n",
      "INFO:tensorflow:input_ids: 101 2372 1103 9505 1472 5763 1113 170 1825 112 188 17898 1116 136 102 2794 117 147 23579 2794 117 1105 18659 11964 118 12029 1708 120 7054 1708 117 1127 5165 1112 6803 10986 117 2456 1152 1127 4448 1112 20167 1928 3719 113 160 18219 114 1114 4573 110 6595 14662 119 2577 1103 2233 1127 4528 1174 117 154 118 188 19756 5562 1105 146 1477 188 19756 5562 1127 1215 1106 11552 1103 1119 25710 27054 1785 1621 1103 2527 117 1107 1134 170 153 2860 133 119 1275 1137 146 1477 135 1851 110 1127 3393 1112 2418 1119 25710 27054 1785 119 20784 1181 10777 1127 6455 1118 1606 170 4275 118 3154 2235 113 2268 7854 782 11679 5026 13430 3442 114 164 1955 166 1137 7091 118 2629 2235 113 9682 1708 1182 118 19863 1811 782 25489 2956 3442 114 117 164 2724 166 5763 1113 1103 1119 25710 27054 1785 1621 1103 1529 2527 119 1332 1119 25710 27054 1785 1108 3626 117 1195 3303 15750 3622 1118 184 9084 1916 1141 2025 1120 1296 1885 1106 8664 1103 2933 1104 1296 2510 2025 1113 1103 2905 3187 10301 119 1284 1145 1982 23470 3622 1359 1113 1103 3254 17482 11664 1105 9355 1104 1378 118 1146 1106 8664 1103 3509 1104 1119 25710 27054 1785 1105 1103 15791 1104 1292 10986 1113 1103 2905 10777 119 2710 1891 15069 1108 14758 1118 1103 4108 9705 164 3081 166 1105 25861 1200 2774 119 164 3236 166 138 123 118 15376 153 2860 133 119 4991 1108 1737 11435 1193 2418 2589 1187 170 2218 153 118 2860 1125 1151 9467 119 1188 1110 27154 118 3622 117 1177 3084 11239 5684 1110 1136 2320 119 15982 122 119 12224 5389 5474 1104 2527 1111 10838 1107 27154 118 3622 119 14562 2042 5924 1104 4420 1107 1103 7356 1529 1107 1103 27154 118 3622 119 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "I1208 12:27:37.063594 139883775852736 run_factoid.py:449] input_ids: 101 2372 1103 9505 1472 5763 1113 170 1825 112 188 17898 1116 136 102 2794 117 147 23579 2794 117 1105 18659 11964 118 12029 1708 120 7054 1708 117 1127 5165 1112 6803 10986 117 2456 1152 1127 4448 1112 20167 1928 3719 113 160 18219 114 1114 4573 110 6595 14662 119 2577 1103 2233 1127 4528 1174 117 154 118 188 19756 5562 1105 146 1477 188 19756 5562 1127 1215 1106 11552 1103 1119 25710 27054 1785 1621 1103 2527 117 1107 1134 170 153 2860 133 119 1275 1137 146 1477 135 1851 110 1127 3393 1112 2418 1119 25710 27054 1785 119 20784 1181 10777 1127 6455 1118 1606 170 4275 118 3154 2235 113 2268 7854 782 11679 5026 13430 3442 114 164 1955 166 1137 7091 118 2629 2235 113 9682 1708 1182 118 19863 1811 782 25489 2956 3442 114 117 164 2724 166 5763 1113 1103 1119 25710 27054 1785 1621 1103 1529 2527 119 1332 1119 25710 27054 1785 1108 3626 117 1195 3303 15750 3622 1118 184 9084 1916 1141 2025 1120 1296 1885 1106 8664 1103 2933 1104 1296 2510 2025 1113 1103 2905 3187 10301 119 1284 1145 1982 23470 3622 1359 1113 1103 3254 17482 11664 1105 9355 1104 1378 118 1146 1106 8664 1103 3509 1104 1119 25710 27054 1785 1105 1103 15791 1104 1292 10986 1113 1103 2905 10777 119 2710 1891 15069 1108 14758 1118 1103 4108 9705 164 3081 166 1105 25861 1200 2774 119 164 3236 166 138 123 118 15376 153 2860 133 119 4991 1108 1737 11435 1193 2418 2589 1187 170 2218 153 118 2860 1125 1151 9467 119 1188 1110 27154 118 3622 117 1177 3084 11239 5684 1110 1136 2320 119 15982 122 119 12224 5389 5474 1104 2527 1111 10838 1107 27154 118 3622 119 14562 2042 5924 1104 4420 1107 1103 7356 1529 1107 1103 27154 118 3622 119 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "INFO:tensorflow:input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "I1208 12:27:37.063685 139883775852736 run_factoid.py:451] input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "INFO:tensorflow:segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "I1208 12:27:37.063774 139883775852736 run_factoid.py:453] segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "INFO:tensorflow:*** Example ***\n",
      "I1208 12:27:37.082466 139883775852736 run_factoid.py:438] *** Example ***\n",
      "INFO:tensorflow:unique_id: 1000000027\n",
      "I1208 12:27:37.082540 139883775852736 run_factoid.py:439] unique_id: 1000000027\n",
      "INFO:tensorflow:example_index: 7\n",
      "I1208 12:27:37.082579 139883775852736 run_factoid.py:440] example_index: 7\n",
      "INFO:tensorflow:doc_span_index: 0\n",
      "I1208 12:27:37.082615 139883775852736 run_factoid.py:441] doc_span_index: 0\n",
      "INFO:tensorflow:tokens: [CLS] What did the paper find ? [SEP] The present meta - analysis of 14 trials involving 2 , 52 ##8 patients provided evidence that P ##EL ##D had favorable clinical outcomes for L ##DF , including shorter operation time and hospital stay , less blood loss , and improved SF ##12 - MC ##S and SF ##12 - PC ##S score . However , it also was associated with a significantly higher rate of re ##current disc her ##nia ##tion . In the present study , we found that patients who underwent P ##EL ##D had a significantly higher re ##cu ##rrence rate than those treated with other surgical interventions . However , in the subgroup analysis based on the com ##par ##ators , the higher rate of re ##current di ##s her ##nia ##tion was only observed in the comparison with MI ##S - T ##L ##IF . Yao Y , et al . [ 45 ] performed a retrospective co ##hor ##t study to compare the outcomes of three minimal ##ly invasive spine surge ##ries ( MI ##S - T ##L ##IF , ME ##D , and P ##EL ##D ) in the treatment of re ##current her ##nia ##tion . At the follow - up duration of 12 ##mont ##hs , no patients ( 0 . 0 % ) in the MI ##S - T ##L ##IF group , 3 patients ( 15 . 0 % ) in the ME ##D group , and 7 patients ( 25 . 0 % ) in the P ##EL ##D group developed re ##cu ##rrence . [ 45 ] The re ##cu ##rrence rate in the P ##EL ##D group was significantly higher than that in the MI ##S - T ##L ##IF group . Similarly , in their another recently published trial , [ 54 ] they also reported a higher re ##cu ##rrence rate of P ##EL ##D than MI ##S - T ##L ##IF . In that study , the authors enrolled 105 patients who underwent either P ##EL ##D ( n = 47 ) or MI ##S - T ##L ##IF ( n = 58 ) for revision of ME ##D re ##cu ##rrence . [ 54 ] At the 12 - month follow - up , patients [SEP]\n",
      "I1208 12:27:37.082732 139883775852736 run_factoid.py:443] tokens: [CLS] What did the paper find ? [SEP] The present meta - analysis of 14 trials involving 2 , 52 ##8 patients provided evidence that P ##EL ##D had favorable clinical outcomes for L ##DF , including shorter operation time and hospital stay , less blood loss , and improved SF ##12 - MC ##S and SF ##12 - PC ##S score . However , it also was associated with a significantly higher rate of re ##current disc her ##nia ##tion . In the present study , we found that patients who underwent P ##EL ##D had a significantly higher re ##cu ##rrence rate than those treated with other surgical interventions . However , in the subgroup analysis based on the com ##par ##ators , the higher rate of re ##current di ##s her ##nia ##tion was only observed in the comparison with MI ##S - T ##L ##IF . Yao Y , et al . [ 45 ] performed a retrospective co ##hor ##t study to compare the outcomes of three minimal ##ly invasive spine surge ##ries ( MI ##S - T ##L ##IF , ME ##D , and P ##EL ##D ) in the treatment of re ##current her ##nia ##tion . At the follow - up duration of 12 ##mont ##hs , no patients ( 0 . 0 % ) in the MI ##S - T ##L ##IF group , 3 patients ( 15 . 0 % ) in the ME ##D group , and 7 patients ( 25 . 0 % ) in the P ##EL ##D group developed re ##cu ##rrence . [ 45 ] The re ##cu ##rrence rate in the P ##EL ##D group was significantly higher than that in the MI ##S - T ##L ##IF group . Similarly , in their another recently published trial , [ 54 ] they also reported a higher re ##cu ##rrence rate of P ##EL ##D than MI ##S - T ##L ##IF . In that study , the authors enrolled 105 patients who underwent either P ##EL ##D ( n = 47 ) or MI ##S - T ##L ##IF ( n = 58 ) for revision of ME ##D re ##cu ##rrence . [ 54 ] At the 12 - month follow - up , patients [SEP]\n",
      "INFO:tensorflow:token_to_orig_map: 8:0 9:1 10:2 11:2 12:2 13:3 14:4 15:5 16:6 17:7 18:7 19:7 20:7 21:8 22:9 23:10 24:11 25:12 26:12 27:12 28:13 29:14 30:15 31:16 32:17 33:18 34:18 35:18 36:19 37:20 38:21 39:22 40:23 41:24 42:25 43:25 44:26 45:27 46:28 47:28 48:29 49:30 50:31 51:31 52:31 53:31 54:31 55:32 56:33 57:33 58:33 59:33 60:33 61:34 62:34 63:35 64:35 65:36 66:37 67:38 68:39 69:40 70:41 71:42 72:43 73:44 74:45 75:46 76:46 77:47 78:48 79:48 80:48 81:48 82:49 83:50 84:51 85:52 86:52 87:53 88:54 89:55 90:56 91:57 92:58 93:59 94:59 95:59 96:60 97:61 98:62 99:63 100:64 101:64 102:64 103:65 104:66 105:67 106:68 107:69 108:70 109:71 110:72 111:72 112:73 113:73 114:74 115:75 116:76 117:77 118:78 119:79 120:80 121:81 122:81 123:81 124:81 125:82 126:83 127:84 128:85 129:86 130:86 131:87 132:87 133:88 134:88 135:88 136:89 137:90 138:91 139:92 140:93 141:94 142:95 143:96 144:96 145:96 146:96 147:96 148:96 149:96 150:97 151:98 152:98 153:99 154:100 155:100 156:100 157:100 158:100 159:101 160:102 161:103 162:104 163:104 164:104 165:105 166:106 167:107 168:108 169:109 170:110 171:111 172:112 173:112 174:113 175:114 176:115 177:115 178:116 179:116 180:116 181:116 182:117 183:117 184:117 185:117 186:118 187:118 188:118 189:119 190:120 191:120 192:120 193:120 194:121 195:122 196:123 197:124 198:125 199:125 200:126 201:126 202:126 203:126 204:127 205:128 206:129 207:129 208:129 209:130 210:131 211:132 212:132 213:132 214:132 215:133 216:134 217:135 218:135 219:135 220:135 221:135 222:135 223:136 224:137 225:138 226:138 227:138 228:138 229:138 230:138 231:139 232:139 233:140 234:141 235:142 236:142 237:142 238:142 239:142 240:142 241:143 242:144 243:145 244:145 245:146 246:146 247:147 248:148 249:149 250:150 251:150 252:150 253:150 254:150 255:150 256:151 257:152 258:153 259:153 260:153 261:154 262:155 263:156 264:156 265:156 266:156 267:156 268:156 269:156 270:157 271:158 272:158 273:158 274:159 275:160 276:161 277:162 278:162 279:162 280:163 281:164 282:165 283:166 284:167 285:168 286:169 287:170 288:171 289:171 290:171 291:171 292:171 293:171 294:172 295:172 296:173 297:173 298:174 299:175 300:176 301:177 302:178 303:179 304:179 305:179 306:179 307:179 308:180 309:181 310:182 311:183 312:184 313:185 314:185 315:185 316:186 317:187 318:188 319:188 320:188 321:189 322:190 323:190 324:190 325:190 326:190 327:190 328:190 329:191 330:192 331:193 332:193 333:194 334:195 335:196 336:197 337:198 338:199 339:200 340:201 341:202 342:202 343:202 344:203 345:203 346:204 347:205 348:205 349:206 350:207 351:207 352:207 353:207 354:207 355:207 356:208 357:208 358:209 359:210 360:210 361:211 362:212 363:213 364:214 365:214 366:215 367:215 368:215 369:215 370:215 371:215 372:215 373:216 374:217 375:218 376:218 377:218 378:219 379:219 380:219 381:219 382:220\n",
      "I1208 12:27:37.082848 139883775852736 run_factoid.py:445] token_to_orig_map: 8:0 9:1 10:2 11:2 12:2 13:3 14:4 15:5 16:6 17:7 18:7 19:7 20:7 21:8 22:9 23:10 24:11 25:12 26:12 27:12 28:13 29:14 30:15 31:16 32:17 33:18 34:18 35:18 36:19 37:20 38:21 39:22 40:23 41:24 42:25 43:25 44:26 45:27 46:28 47:28 48:29 49:30 50:31 51:31 52:31 53:31 54:31 55:32 56:33 57:33 58:33 59:33 60:33 61:34 62:34 63:35 64:35 65:36 66:37 67:38 68:39 69:40 70:41 71:42 72:43 73:44 74:45 75:46 76:46 77:47 78:48 79:48 80:48 81:48 82:49 83:50 84:51 85:52 86:52 87:53 88:54 89:55 90:56 91:57 92:58 93:59 94:59 95:59 96:60 97:61 98:62 99:63 100:64 101:64 102:64 103:65 104:66 105:67 106:68 107:69 108:70 109:71 110:72 111:72 112:73 113:73 114:74 115:75 116:76 117:77 118:78 119:79 120:80 121:81 122:81 123:81 124:81 125:82 126:83 127:84 128:85 129:86 130:86 131:87 132:87 133:88 134:88 135:88 136:89 137:90 138:91 139:92 140:93 141:94 142:95 143:96 144:96 145:96 146:96 147:96 148:96 149:96 150:97 151:98 152:98 153:99 154:100 155:100 156:100 157:100 158:100 159:101 160:102 161:103 162:104 163:104 164:104 165:105 166:106 167:107 168:108 169:109 170:110 171:111 172:112 173:112 174:113 175:114 176:115 177:115 178:116 179:116 180:116 181:116 182:117 183:117 184:117 185:117 186:118 187:118 188:118 189:119 190:120 191:120 192:120 193:120 194:121 195:122 196:123 197:124 198:125 199:125 200:126 201:126 202:126 203:126 204:127 205:128 206:129 207:129 208:129 209:130 210:131 211:132 212:132 213:132 214:132 215:133 216:134 217:135 218:135 219:135 220:135 221:135 222:135 223:136 224:137 225:138 226:138 227:138 228:138 229:138 230:138 231:139 232:139 233:140 234:141 235:142 236:142 237:142 238:142 239:142 240:142 241:143 242:144 243:145 244:145 245:146 246:146 247:147 248:148 249:149 250:150 251:150 252:150 253:150 254:150 255:150 256:151 257:152 258:153 259:153 260:153 261:154 262:155 263:156 264:156 265:156 266:156 267:156 268:156 269:156 270:157 271:158 272:158 273:158 274:159 275:160 276:161 277:162 278:162 279:162 280:163 281:164 282:165 283:166 284:167 285:168 286:169 287:170 288:171 289:171 290:171 291:171 292:171 293:171 294:172 295:172 296:173 297:173 298:174 299:175 300:176 301:177 302:178 303:179 304:179 305:179 306:179 307:179 308:180 309:181 310:182 311:183 312:184 313:185 314:185 315:185 316:186 317:187 318:188 319:188 320:188 321:189 322:190 323:190 324:190 325:190 326:190 327:190 328:190 329:191 330:192 331:193 332:193 333:194 334:195 335:196 336:197 337:198 338:199 339:200 340:201 341:202 342:202 343:202 344:203 345:203 346:204 347:205 348:205 349:206 350:207 351:207 352:207 353:207 354:207 355:207 356:208 357:208 358:209 359:210 360:210 361:211 362:212 363:213 364:214 365:214 366:215 367:215 368:215 369:215 370:215 371:215 372:215 373:216 374:217 375:218 376:218 377:218 378:219 379:219 380:219 381:219 382:220\n",
      "INFO:tensorflow:token_is_max_context: 8:True 9:True 10:True 11:True 12:True 13:True 14:True 15:True 16:True 17:True 18:True 19:True 20:True 21:True 22:True 23:True 24:True 25:True 26:True 27:True 28:True 29:True 30:True 31:True 32:True 33:True 34:True 35:True 36:True 37:True 38:True 39:True 40:True 41:True 42:True 43:True 44:True 45:True 46:True 47:True 48:True 49:True 50:True 51:True 52:True 53:True 54:True 55:True 56:True 57:True 58:True 59:True 60:True 61:True 62:True 63:True 64:True 65:True 66:True 67:True 68:True 69:True 70:True 71:True 72:True 73:True 74:True 75:True 76:True 77:True 78:True 79:True 80:True 81:True 82:True 83:True 84:True 85:True 86:True 87:True 88:True 89:True 90:True 91:True 92:True 93:True 94:True 95:True 96:True 97:True 98:True 99:True 100:True 101:True 102:True 103:True 104:True 105:True 106:True 107:True 108:True 109:True 110:True 111:True 112:True 113:True 114:True 115:True 116:True 117:True 118:True 119:True 120:True 121:True 122:True 123:True 124:True 125:True 126:True 127:True 128:True 129:True 130:True 131:True 132:True 133:True 134:True 135:True 136:True 137:True 138:True 139:True 140:True 141:True 142:True 143:True 144:True 145:True 146:True 147:True 148:True 149:True 150:True 151:True 152:True 153:True 154:True 155:True 156:True 157:True 158:True 159:True 160:True 161:True 162:True 163:True 164:True 165:True 166:True 167:True 168:True 169:True 170:True 171:True 172:True 173:True 174:True 175:True 176:True 177:True 178:True 179:True 180:True 181:True 182:True 183:True 184:True 185:True 186:True 187:True 188:True 189:True 190:True 191:True 192:True 193:True 194:True 195:True 196:True 197:True 198:True 199:True 200:True 201:True 202:True 203:True 204:True 205:True 206:True 207:True 208:True 209:True 210:True 211:True 212:True 213:True 214:True 215:True 216:True 217:True 218:True 219:True 220:True 221:True 222:True 223:True 224:True 225:True 226:True 227:True 228:True 229:True 230:True 231:True 232:True 233:True 234:True 235:True 236:True 237:True 238:True 239:True 240:True 241:True 242:True 243:True 244:True 245:True 246:True 247:True 248:True 249:True 250:True 251:True 252:True 253:True 254:True 255:True 256:True 257:True 258:True 259:True 260:False 261:False 262:False 263:False 264:False 265:False 266:False 267:False 268:False 269:False 270:False 271:False 272:False 273:False 274:False 275:False 276:False 277:False 278:False 279:False 280:False 281:False 282:False 283:False 284:False 285:False 286:False 287:False 288:False 289:False 290:False 291:False 292:False 293:False 294:False 295:False 296:False 297:False 298:False 299:False 300:False 301:False 302:False 303:False 304:False 305:False 306:False 307:False 308:False 309:False 310:False 311:False 312:False 313:False 314:False 315:False 316:False 317:False 318:False 319:False 320:False 321:False 322:False 323:False 324:False 325:False 326:False 327:False 328:False 329:False 330:False 331:False 332:False 333:False 334:False 335:False 336:False 337:False 338:False 339:False 340:False 341:False 342:False 343:False 344:False 345:False 346:False 347:False 348:False 349:False 350:False 351:False 352:False 353:False 354:False 355:False 356:False 357:False 358:False 359:False 360:False 361:False 362:False 363:False 364:False 365:False 366:False 367:False 368:False 369:False 370:False 371:False 372:False 373:False 374:False 375:False 376:False 377:False 378:False 379:False 380:False 381:False 382:False\n",
      "I1208 12:27:37.082957 139883775852736 run_factoid.py:447] token_is_max_context: 8:True 9:True 10:True 11:True 12:True 13:True 14:True 15:True 16:True 17:True 18:True 19:True 20:True 21:True 22:True 23:True 24:True 25:True 26:True 27:True 28:True 29:True 30:True 31:True 32:True 33:True 34:True 35:True 36:True 37:True 38:True 39:True 40:True 41:True 42:True 43:True 44:True 45:True 46:True 47:True 48:True 49:True 50:True 51:True 52:True 53:True 54:True 55:True 56:True 57:True 58:True 59:True 60:True 61:True 62:True 63:True 64:True 65:True 66:True 67:True 68:True 69:True 70:True 71:True 72:True 73:True 74:True 75:True 76:True 77:True 78:True 79:True 80:True 81:True 82:True 83:True 84:True 85:True 86:True 87:True 88:True 89:True 90:True 91:True 92:True 93:True 94:True 95:True 96:True 97:True 98:True 99:True 100:True 101:True 102:True 103:True 104:True 105:True 106:True 107:True 108:True 109:True 110:True 111:True 112:True 113:True 114:True 115:True 116:True 117:True 118:True 119:True 120:True 121:True 122:True 123:True 124:True 125:True 126:True 127:True 128:True 129:True 130:True 131:True 132:True 133:True 134:True 135:True 136:True 137:True 138:True 139:True 140:True 141:True 142:True 143:True 144:True 145:True 146:True 147:True 148:True 149:True 150:True 151:True 152:True 153:True 154:True 155:True 156:True 157:True 158:True 159:True 160:True 161:True 162:True 163:True 164:True 165:True 166:True 167:True 168:True 169:True 170:True 171:True 172:True 173:True 174:True 175:True 176:True 177:True 178:True 179:True 180:True 181:True 182:True 183:True 184:True 185:True 186:True 187:True 188:True 189:True 190:True 191:True 192:True 193:True 194:True 195:True 196:True 197:True 198:True 199:True 200:True 201:True 202:True 203:True 204:True 205:True 206:True 207:True 208:True 209:True 210:True 211:True 212:True 213:True 214:True 215:True 216:True 217:True 218:True 219:True 220:True 221:True 222:True 223:True 224:True 225:True 226:True 227:True 228:True 229:True 230:True 231:True 232:True 233:True 234:True 235:True 236:True 237:True 238:True 239:True 240:True 241:True 242:True 243:True 244:True 245:True 246:True 247:True 248:True 249:True 250:True 251:True 252:True 253:True 254:True 255:True 256:True 257:True 258:True 259:True 260:False 261:False 262:False 263:False 264:False 265:False 266:False 267:False 268:False 269:False 270:False 271:False 272:False 273:False 274:False 275:False 276:False 277:False 278:False 279:False 280:False 281:False 282:False 283:False 284:False 285:False 286:False 287:False 288:False 289:False 290:False 291:False 292:False 293:False 294:False 295:False 296:False 297:False 298:False 299:False 300:False 301:False 302:False 303:False 304:False 305:False 306:False 307:False 308:False 309:False 310:False 311:False 312:False 313:False 314:False 315:False 316:False 317:False 318:False 319:False 320:False 321:False 322:False 323:False 324:False 325:False 326:False 327:False 328:False 329:False 330:False 331:False 332:False 333:False 334:False 335:False 336:False 337:False 338:False 339:False 340:False 341:False 342:False 343:False 344:False 345:False 346:False 347:False 348:False 349:False 350:False 351:False 352:False 353:False 354:False 355:False 356:False 357:False 358:False 359:False 360:False 361:False 362:False 363:False 364:False 365:False 366:False 367:False 368:False 369:False 370:False 371:False 372:False 373:False 374:False 375:False 376:False 377:False 378:False 379:False 380:False 381:False 382:False\n",
      "INFO:tensorflow:input_ids: 101 1327 1225 1103 2526 1525 136 102 1109 1675 27154 118 3622 1104 1489 7356 5336 123 117 3882 1604 4420 2136 2554 1115 153 21678 2137 1125 11169 7300 13950 1111 149 16395 117 1259 7681 2805 1159 1105 2704 2215 117 1750 1892 2445 117 1105 4725 18659 11964 118 12029 1708 1105 18659 11964 118 7054 1708 2794 119 1438 117 1122 1145 1108 2628 1114 170 5409 2299 2603 1104 1231 21754 6187 1123 5813 2116 119 1130 1103 1675 2025 117 1195 1276 1115 4420 1150 9315 153 21678 2137 1125 170 5409 2299 1231 10182 21629 2603 1190 1343 5165 1114 1168 13467 22496 119 1438 117 1107 1103 23470 3622 1359 1113 1103 3254 17482 11664 117 1103 2299 2603 1104 1231 21754 4267 1116 1123 5813 2116 1108 1178 4379 1107 1103 7577 1114 26574 1708 118 157 2162 15499 119 27762 162 117 3084 2393 119 164 2532 166 1982 170 18675 1884 13252 1204 2025 1106 14133 1103 13950 1104 1210 10298 1193 19849 8340 12814 3377 113 26574 1708 118 157 2162 15499 117 22157 2137 117 1105 153 21678 2137 114 1107 1103 3252 1104 1231 21754 1123 5813 2116 119 1335 1103 2812 118 1146 9355 1104 1367 7578 9524 117 1185 4420 113 121 119 121 110 114 1107 1103 26574 1708 118 157 2162 15499 1372 117 124 4420 113 1405 119 121 110 114 1107 1103 22157 2137 1372 117 1105 128 4420 113 1512 119 121 110 114 1107 1103 153 21678 2137 1372 1872 1231 10182 21629 119 164 2532 166 1109 1231 10182 21629 2603 1107 1103 153 21678 2137 1372 1108 5409 2299 1190 1115 1107 1103 26574 1708 118 157 2162 15499 1372 119 10321 117 1107 1147 1330 3055 1502 3443 117 164 4335 166 1152 1145 2103 170 2299 1231 10182 21629 2603 1104 153 21678 2137 1190 26574 1708 118 157 2162 15499 119 1130 1115 2025 117 1103 5752 7945 8359 4420 1150 9315 1719 153 21678 2137 113 183 134 3862 114 1137 26574 1708 118 157 2162 15499 113 183 134 4650 114 1111 16547 1104 22157 2137 1231 10182 21629 119 164 4335 166 1335 1103 1367 118 2370 2812 118 1146 117 4420 102\n",
      "I1208 12:27:37.083060 139883775852736 run_factoid.py:449] input_ids: 101 1327 1225 1103 2526 1525 136 102 1109 1675 27154 118 3622 1104 1489 7356 5336 123 117 3882 1604 4420 2136 2554 1115 153 21678 2137 1125 11169 7300 13950 1111 149 16395 117 1259 7681 2805 1159 1105 2704 2215 117 1750 1892 2445 117 1105 4725 18659 11964 118 12029 1708 1105 18659 11964 118 7054 1708 2794 119 1438 117 1122 1145 1108 2628 1114 170 5409 2299 2603 1104 1231 21754 6187 1123 5813 2116 119 1130 1103 1675 2025 117 1195 1276 1115 4420 1150 9315 153 21678 2137 1125 170 5409 2299 1231 10182 21629 2603 1190 1343 5165 1114 1168 13467 22496 119 1438 117 1107 1103 23470 3622 1359 1113 1103 3254 17482 11664 117 1103 2299 2603 1104 1231 21754 4267 1116 1123 5813 2116 1108 1178 4379 1107 1103 7577 1114 26574 1708 118 157 2162 15499 119 27762 162 117 3084 2393 119 164 2532 166 1982 170 18675 1884 13252 1204 2025 1106 14133 1103 13950 1104 1210 10298 1193 19849 8340 12814 3377 113 26574 1708 118 157 2162 15499 117 22157 2137 117 1105 153 21678 2137 114 1107 1103 3252 1104 1231 21754 1123 5813 2116 119 1335 1103 2812 118 1146 9355 1104 1367 7578 9524 117 1185 4420 113 121 119 121 110 114 1107 1103 26574 1708 118 157 2162 15499 1372 117 124 4420 113 1405 119 121 110 114 1107 1103 22157 2137 1372 117 1105 128 4420 113 1512 119 121 110 114 1107 1103 153 21678 2137 1372 1872 1231 10182 21629 119 164 2532 166 1109 1231 10182 21629 2603 1107 1103 153 21678 2137 1372 1108 5409 2299 1190 1115 1107 1103 26574 1708 118 157 2162 15499 1372 119 10321 117 1107 1147 1330 3055 1502 3443 117 164 4335 166 1152 1145 2103 170 2299 1231 10182 21629 2603 1104 153 21678 2137 1190 26574 1708 118 157 2162 15499 119 1130 1115 2025 117 1103 5752 7945 8359 4420 1150 9315 1719 153 21678 2137 113 183 134 3862 114 1137 26574 1708 118 157 2162 15499 113 183 134 4650 114 1111 16547 1104 22157 2137 1231 10182 21629 119 164 4335 166 1335 1103 1367 118 2370 2812 118 1146 117 4420 102\n",
      "INFO:tensorflow:input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      "I1208 12:27:37.083151 139883775852736 run_factoid.py:451] input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      "INFO:tensorflow:segment_ids: 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      "I1208 12:27:37.083240 139883775852736 run_factoid.py:453] segment_ids: 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      "INFO:tensorflow:*** Example ***\n",
      "I1208 12:27:37.084995 139883775852736 run_factoid.py:438] *** Example ***\n",
      "INFO:tensorflow:unique_id: 1000000028\n",
      "I1208 12:27:37.085059 139883775852736 run_factoid.py:439] unique_id: 1000000028\n",
      "INFO:tensorflow:example_index: 7\n",
      "I1208 12:27:37.085098 139883775852736 run_factoid.py:440] example_index: 7\n",
      "INFO:tensorflow:doc_span_index: 1\n",
      "I1208 12:27:37.085132 139883775852736 run_factoid.py:441] doc_span_index: 1\n",
      "INFO:tensorflow:tokens: [CLS] What did the paper find ? [SEP] was only observed in the comparison with MI ##S - T ##L ##IF . Yao Y , et al . [ 45 ] performed a retrospective co ##hor ##t study to compare the outcomes of three minimal ##ly invasive spine surge ##ries ( MI ##S - T ##L ##IF , ME ##D , and P ##EL ##D ) in the treatment of re ##current her ##nia ##tion . At the follow - up duration of 12 ##mont ##hs , no patients ( 0 . 0 % ) in the MI ##S - T ##L ##IF group , 3 patients ( 15 . 0 % ) in the ME ##D group , and 7 patients ( 25 . 0 % ) in the P ##EL ##D group developed re ##cu ##rrence . [ 45 ] The re ##cu ##rrence rate in the P ##EL ##D group was significantly higher than that in the MI ##S - T ##L ##IF group . Similarly , in their another recently published trial , [ 54 ] they also reported a higher re ##cu ##rrence rate of P ##EL ##D than MI ##S - T ##L ##IF . In that study , the authors enrolled 105 patients who underwent either P ##EL ##D ( n = 47 ) or MI ##S - T ##L ##IF ( n = 58 ) for revision of ME ##D re ##cu ##rrence . [ 54 ] At the 12 - month follow - up , patients who underwent P ##EL ##D had a significantly higher re ##cu ##rrence rate ( 10 . 64 % ) than those treated with MI ##S - T ##L ##IF ( 0 . 0 % ) . [ 54 ] The authors attributed the findings to the following reasons : ( 1 ) there was some risk factors that were predict ##ive of re ##cu ##rrence in P ##EL ##D patients . For example , old age , o ##besity , and Mo ##dic change have been identified as significant risk factors for the P ##EL ##D re ##cu ##r - re ##nce . [ 58 , 59 ] And the 5 patients who experienced re ##cu ##rrence in the P ##EL ##D group were all relatively old ( [SEP]\n",
      "I1208 12:27:37.085243 139883775852736 run_factoid.py:443] tokens: [CLS] What did the paper find ? [SEP] was only observed in the comparison with MI ##S - T ##L ##IF . Yao Y , et al . [ 45 ] performed a retrospective co ##hor ##t study to compare the outcomes of three minimal ##ly invasive spine surge ##ries ( MI ##S - T ##L ##IF , ME ##D , and P ##EL ##D ) in the treatment of re ##current her ##nia ##tion . At the follow - up duration of 12 ##mont ##hs , no patients ( 0 . 0 % ) in the MI ##S - T ##L ##IF group , 3 patients ( 15 . 0 % ) in the ME ##D group , and 7 patients ( 25 . 0 % ) in the P ##EL ##D group developed re ##cu ##rrence . [ 45 ] The re ##cu ##rrence rate in the P ##EL ##D group was significantly higher than that in the MI ##S - T ##L ##IF group . Similarly , in their another recently published trial , [ 54 ] they also reported a higher re ##cu ##rrence rate of P ##EL ##D than MI ##S - T ##L ##IF . In that study , the authors enrolled 105 patients who underwent either P ##EL ##D ( n = 47 ) or MI ##S - T ##L ##IF ( n = 58 ) for revision of ME ##D re ##cu ##rrence . [ 54 ] At the 12 - month follow - up , patients who underwent P ##EL ##D had a significantly higher re ##cu ##rrence rate ( 10 . 64 % ) than those treated with MI ##S - T ##L ##IF ( 0 . 0 % ) . [ 54 ] The authors attributed the findings to the following reasons : ( 1 ) there was some risk factors that were predict ##ive of re ##cu ##rrence in P ##EL ##D patients . For example , old age , o ##besity , and Mo ##dic change have been identified as significant risk factors for the P ##EL ##D re ##cu ##r - re ##nce . [ 58 , 59 ] And the 5 patients who experienced re ##cu ##rrence in the P ##EL ##D group were all relatively old ( [SEP]\n",
      "INFO:tensorflow:token_to_orig_map: 8:89 9:90 10:91 11:92 12:93 13:94 14:95 15:96 16:96 17:96 18:96 19:96 20:96 21:96 22:97 23:98 24:98 25:99 26:100 27:100 28:100 29:100 30:100 31:101 32:102 33:103 34:104 35:104 36:104 37:105 38:106 39:107 40:108 41:109 42:110 43:111 44:112 45:112 46:113 47:114 48:115 49:115 50:116 51:116 52:116 53:116 54:117 55:117 56:117 57:117 58:118 59:118 60:118 61:119 62:120 63:120 64:120 65:120 66:121 67:122 68:123 69:124 70:125 71:125 72:126 73:126 74:126 75:126 76:127 77:128 78:129 79:129 80:129 81:130 82:131 83:132 84:132 85:132 86:132 87:133 88:134 89:135 90:135 91:135 92:135 93:135 94:135 95:136 96:137 97:138 98:138 99:138 100:138 101:138 102:138 103:139 104:139 105:140 106:141 107:142 108:142 109:142 110:142 111:142 112:142 113:143 114:144 115:145 116:145 117:146 118:146 119:147 120:148 121:149 122:150 123:150 124:150 125:150 126:150 127:150 128:151 129:152 130:153 131:153 132:153 133:154 134:155 135:156 136:156 137:156 138:156 139:156 140:156 141:156 142:157 143:158 144:158 145:158 146:159 147:160 148:161 149:162 150:162 151:162 152:163 153:164 154:165 155:166 156:167 157:168 158:169 159:170 160:171 161:171 162:171 163:171 164:171 165:171 166:172 167:172 168:173 169:173 170:174 171:175 172:176 173:177 174:178 175:179 176:179 177:179 178:179 179:179 180:180 181:181 182:182 183:183 184:184 185:185 186:185 187:185 188:186 189:187 190:188 191:188 192:188 193:189 194:190 195:190 196:190 197:190 198:190 199:190 200:190 201:191 202:192 203:193 204:193 205:194 206:195 207:196 208:197 209:198 210:199 211:200 212:201 213:202 214:202 215:202 216:203 217:203 218:204 219:205 220:205 221:206 222:207 223:207 224:207 225:207 226:207 227:207 228:208 229:208 230:209 231:210 232:210 233:211 234:212 235:213 236:214 237:214 238:215 239:215 240:215 241:215 242:215 243:215 244:215 245:216 246:217 247:218 248:218 249:218 250:219 251:219 252:219 253:219 254:220 255:221 256:222 257:223 258:223 259:223 260:224 261:225 262:226 263:227 264:228 265:228 266:228 267:229 268:230 269:230 270:230 271:230 272:230 273:230 274:231 275:232 276:233 277:234 278:235 279:235 280:235 281:235 282:235 283:235 284:236 285:236 286:236 287:236 288:236 289:236 290:236 291:236 292:236 293:236 294:237 295:238 296:239 297:240 298:241 299:242 300:243 301:244 302:245 303:245 304:246 305:246 306:246 307:247 308:248 309:249 310:250 311:251 312:252 313:253 314:254 315:254 316:255 317:256 318:256 319:256 320:257 321:258 322:258 323:258 324:259 325:259 326:260 327:261 328:261 329:262 330:263 331:263 332:264 333:264 334:264 335:265 336:266 337:266 338:267 339:268 340:269 341:270 342:271 343:272 344:273 345:274 346:275 347:276 348:277 349:277 350:277 351:278 352:278 353:278 354:278 355:279 356:279 357:279 358:279 359:279 360:279 361:279 362:279 363:280 364:281 365:282 366:283 367:284 368:285 369:286 370:286 371:286 372:287 373:288 374:289 375:289 376:289 377:290 378:291 379:292 380:293 381:294 382:295\n",
      "I1208 12:27:37.085357 139883775852736 run_factoid.py:445] token_to_orig_map: 8:89 9:90 10:91 11:92 12:93 13:94 14:95 15:96 16:96 17:96 18:96 19:96 20:96 21:96 22:97 23:98 24:98 25:99 26:100 27:100 28:100 29:100 30:100 31:101 32:102 33:103 34:104 35:104 36:104 37:105 38:106 39:107 40:108 41:109 42:110 43:111 44:112 45:112 46:113 47:114 48:115 49:115 50:116 51:116 52:116 53:116 54:117 55:117 56:117 57:117 58:118 59:118 60:118 61:119 62:120 63:120 64:120 65:120 66:121 67:122 68:123 69:124 70:125 71:125 72:126 73:126 74:126 75:126 76:127 77:128 78:129 79:129 80:129 81:130 82:131 83:132 84:132 85:132 86:132 87:133 88:134 89:135 90:135 91:135 92:135 93:135 94:135 95:136 96:137 97:138 98:138 99:138 100:138 101:138 102:138 103:139 104:139 105:140 106:141 107:142 108:142 109:142 110:142 111:142 112:142 113:143 114:144 115:145 116:145 117:146 118:146 119:147 120:148 121:149 122:150 123:150 124:150 125:150 126:150 127:150 128:151 129:152 130:153 131:153 132:153 133:154 134:155 135:156 136:156 137:156 138:156 139:156 140:156 141:156 142:157 143:158 144:158 145:158 146:159 147:160 148:161 149:162 150:162 151:162 152:163 153:164 154:165 155:166 156:167 157:168 158:169 159:170 160:171 161:171 162:171 163:171 164:171 165:171 166:172 167:172 168:173 169:173 170:174 171:175 172:176 173:177 174:178 175:179 176:179 177:179 178:179 179:179 180:180 181:181 182:182 183:183 184:184 185:185 186:185 187:185 188:186 189:187 190:188 191:188 192:188 193:189 194:190 195:190 196:190 197:190 198:190 199:190 200:190 201:191 202:192 203:193 204:193 205:194 206:195 207:196 208:197 209:198 210:199 211:200 212:201 213:202 214:202 215:202 216:203 217:203 218:204 219:205 220:205 221:206 222:207 223:207 224:207 225:207 226:207 227:207 228:208 229:208 230:209 231:210 232:210 233:211 234:212 235:213 236:214 237:214 238:215 239:215 240:215 241:215 242:215 243:215 244:215 245:216 246:217 247:218 248:218 249:218 250:219 251:219 252:219 253:219 254:220 255:221 256:222 257:223 258:223 259:223 260:224 261:225 262:226 263:227 264:228 265:228 266:228 267:229 268:230 269:230 270:230 271:230 272:230 273:230 274:231 275:232 276:233 277:234 278:235 279:235 280:235 281:235 282:235 283:235 284:236 285:236 286:236 287:236 288:236 289:236 290:236 291:236 292:236 293:236 294:237 295:238 296:239 297:240 298:241 299:242 300:243 301:244 302:245 303:245 304:246 305:246 306:246 307:247 308:248 309:249 310:250 311:251 312:252 313:253 314:254 315:254 316:255 317:256 318:256 319:256 320:257 321:258 322:258 323:258 324:259 325:259 326:260 327:261 328:261 329:262 330:263 331:263 332:264 333:264 334:264 335:265 336:266 337:266 338:267 339:268 340:269 341:270 342:271 343:272 344:273 345:274 346:275 347:276 348:277 349:277 350:277 351:278 352:278 353:278 354:278 355:279 356:279 357:279 358:279 359:279 360:279 361:279 362:279 363:280 364:281 365:282 366:283 367:284 368:285 369:286 370:286 371:286 372:287 373:288 374:289 375:289 376:289 377:290 378:291 379:292 380:293 381:294 382:295\n",
      "INFO:tensorflow:token_is_max_context: 8:False 9:False 10:False 11:False 12:False 13:False 14:False 15:False 16:False 17:False 18:False 19:False 20:False 21:False 22:False 23:False 24:False 25:False 26:False 27:False 28:False 29:False 30:False 31:False 32:False 33:False 34:False 35:False 36:False 37:False 38:False 39:False 40:False 41:False 42:False 43:False 44:False 45:False 46:False 47:False 48:False 49:False 50:False 51:False 52:False 53:False 54:False 55:False 56:False 57:False 58:False 59:False 60:False 61:False 62:False 63:False 64:False 65:False 66:False 67:False 68:False 69:False 70:False 71:False 72:False 73:False 74:False 75:False 76:False 77:False 78:False 79:False 80:False 81:False 82:False 83:False 84:False 85:False 86:False 87:False 88:False 89:False 90:False 91:False 92:False 93:False 94:False 95:False 96:False 97:False 98:False 99:False 100:False 101:False 102:False 103:False 104:False 105:False 106:False 107:False 108:False 109:False 110:False 111:False 112:False 113:False 114:False 115:False 116:False 117:False 118:False 119:False 120:False 121:False 122:False 123:False 124:False 125:False 126:False 127:False 128:False 129:False 130:False 131:False 132:True 133:True 134:True 135:True 136:True 137:True 138:True 139:True 140:True 141:True 142:True 143:True 144:True 145:True 146:True 147:True 148:True 149:True 150:True 151:True 152:True 153:True 154:True 155:True 156:True 157:True 158:True 159:True 160:True 161:True 162:True 163:True 164:True 165:True 166:True 167:True 168:True 169:True 170:True 171:True 172:True 173:True 174:True 175:True 176:True 177:True 178:True 179:True 180:True 181:True 182:True 183:True 184:True 185:True 186:True 187:True 188:True 189:True 190:True 191:True 192:True 193:True 194:True 195:True 196:True 197:True 198:True 199:True 200:True 201:True 202:True 203:True 204:True 205:True 206:True 207:True 208:True 209:True 210:True 211:True 212:True 213:True 214:True 215:True 216:True 217:True 218:True 219:True 220:True 221:True 222:True 223:True 224:True 225:True 226:True 227:True 228:True 229:True 230:True 231:True 232:True 233:True 234:True 235:True 236:True 237:True 238:True 239:True 240:True 241:True 242:True 243:True 244:True 245:True 246:True 247:True 248:True 249:True 250:True 251:True 252:True 253:True 254:True 255:True 256:True 257:True 258:True 259:True 260:False 261:False 262:False 263:False 264:False 265:False 266:False 267:False 268:False 269:False 270:False 271:False 272:False 273:False 274:False 275:False 276:False 277:False 278:False 279:False 280:False 281:False 282:False 283:False 284:False 285:False 286:False 287:False 288:False 289:False 290:False 291:False 292:False 293:False 294:False 295:False 296:False 297:False 298:False 299:False 300:False 301:False 302:False 303:False 304:False 305:False 306:False 307:False 308:False 309:False 310:False 311:False 312:False 313:False 314:False 315:False 316:False 317:False 318:False 319:False 320:False 321:False 322:False 323:False 324:False 325:False 326:False 327:False 328:False 329:False 330:False 331:False 332:False 333:False 334:False 335:False 336:False 337:False 338:False 339:False 340:False 341:False 342:False 343:False 344:False 345:False 346:False 347:False 348:False 349:False 350:False 351:False 352:False 353:False 354:False 355:False 356:False 357:False 358:False 359:False 360:False 361:False 362:False 363:False 364:False 365:False 366:False 367:False 368:False 369:False 370:False 371:False 372:False 373:False 374:False 375:False 376:False 377:False 378:False 379:False 380:False 381:False 382:False\n",
      "I1208 12:27:37.085465 139883775852736 run_factoid.py:447] token_is_max_context: 8:False 9:False 10:False 11:False 12:False 13:False 14:False 15:False 16:False 17:False 18:False 19:False 20:False 21:False 22:False 23:False 24:False 25:False 26:False 27:False 28:False 29:False 30:False 31:False 32:False 33:False 34:False 35:False 36:False 37:False 38:False 39:False 40:False 41:False 42:False 43:False 44:False 45:False 46:False 47:False 48:False 49:False 50:False 51:False 52:False 53:False 54:False 55:False 56:False 57:False 58:False 59:False 60:False 61:False 62:False 63:False 64:False 65:False 66:False 67:False 68:False 69:False 70:False 71:False 72:False 73:False 74:False 75:False 76:False 77:False 78:False 79:False 80:False 81:False 82:False 83:False 84:False 85:False 86:False 87:False 88:False 89:False 90:False 91:False 92:False 93:False 94:False 95:False 96:False 97:False 98:False 99:False 100:False 101:False 102:False 103:False 104:False 105:False 106:False 107:False 108:False 109:False 110:False 111:False 112:False 113:False 114:False 115:False 116:False 117:False 118:False 119:False 120:False 121:False 122:False 123:False 124:False 125:False 126:False 127:False 128:False 129:False 130:False 131:False 132:True 133:True 134:True 135:True 136:True 137:True 138:True 139:True 140:True 141:True 142:True 143:True 144:True 145:True 146:True 147:True 148:True 149:True 150:True 151:True 152:True 153:True 154:True 155:True 156:True 157:True 158:True 159:True 160:True 161:True 162:True 163:True 164:True 165:True 166:True 167:True 168:True 169:True 170:True 171:True 172:True 173:True 174:True 175:True 176:True 177:True 178:True 179:True 180:True 181:True 182:True 183:True 184:True 185:True 186:True 187:True 188:True 189:True 190:True 191:True 192:True 193:True 194:True 195:True 196:True 197:True 198:True 199:True 200:True 201:True 202:True 203:True 204:True 205:True 206:True 207:True 208:True 209:True 210:True 211:True 212:True 213:True 214:True 215:True 216:True 217:True 218:True 219:True 220:True 221:True 222:True 223:True 224:True 225:True 226:True 227:True 228:True 229:True 230:True 231:True 232:True 233:True 234:True 235:True 236:True 237:True 238:True 239:True 240:True 241:True 242:True 243:True 244:True 245:True 246:True 247:True 248:True 249:True 250:True 251:True 252:True 253:True 254:True 255:True 256:True 257:True 258:True 259:True 260:False 261:False 262:False 263:False 264:False 265:False 266:False 267:False 268:False 269:False 270:False 271:False 272:False 273:False 274:False 275:False 276:False 277:False 278:False 279:False 280:False 281:False 282:False 283:False 284:False 285:False 286:False 287:False 288:False 289:False 290:False 291:False 292:False 293:False 294:False 295:False 296:False 297:False 298:False 299:False 300:False 301:False 302:False 303:False 304:False 305:False 306:False 307:False 308:False 309:False 310:False 311:False 312:False 313:False 314:False 315:False 316:False 317:False 318:False 319:False 320:False 321:False 322:False 323:False 324:False 325:False 326:False 327:False 328:False 329:False 330:False 331:False 332:False 333:False 334:False 335:False 336:False 337:False 338:False 339:False 340:False 341:False 342:False 343:False 344:False 345:False 346:False 347:False 348:False 349:False 350:False 351:False 352:False 353:False 354:False 355:False 356:False 357:False 358:False 359:False 360:False 361:False 362:False 363:False 364:False 365:False 366:False 367:False 368:False 369:False 370:False 371:False 372:False 373:False 374:False 375:False 376:False 377:False 378:False 379:False 380:False 381:False 382:False\n",
      "INFO:tensorflow:input_ids: 101 1327 1225 1103 2526 1525 136 102 1108 1178 4379 1107 1103 7577 1114 26574 1708 118 157 2162 15499 119 27762 162 117 3084 2393 119 164 2532 166 1982 170 18675 1884 13252 1204 2025 1106 14133 1103 13950 1104 1210 10298 1193 19849 8340 12814 3377 113 26574 1708 118 157 2162 15499 117 22157 2137 117 1105 153 21678 2137 114 1107 1103 3252 1104 1231 21754 1123 5813 2116 119 1335 1103 2812 118 1146 9355 1104 1367 7578 9524 117 1185 4420 113 121 119 121 110 114 1107 1103 26574 1708 118 157 2162 15499 1372 117 124 4420 113 1405 119 121 110 114 1107 1103 22157 2137 1372 117 1105 128 4420 113 1512 119 121 110 114 1107 1103 153 21678 2137 1372 1872 1231 10182 21629 119 164 2532 166 1109 1231 10182 21629 2603 1107 1103 153 21678 2137 1372 1108 5409 2299 1190 1115 1107 1103 26574 1708 118 157 2162 15499 1372 119 10321 117 1107 1147 1330 3055 1502 3443 117 164 4335 166 1152 1145 2103 170 2299 1231 10182 21629 2603 1104 153 21678 2137 1190 26574 1708 118 157 2162 15499 119 1130 1115 2025 117 1103 5752 7945 8359 4420 1150 9315 1719 153 21678 2137 113 183 134 3862 114 1137 26574 1708 118 157 2162 15499 113 183 134 4650 114 1111 16547 1104 22157 2137 1231 10182 21629 119 164 4335 166 1335 1103 1367 118 2370 2812 118 1146 117 4420 1150 9315 153 21678 2137 1125 170 5409 2299 1231 10182 21629 2603 113 1275 119 3324 110 114 1190 1343 5165 1114 26574 1708 118 157 2162 15499 113 121 119 121 110 114 119 164 4335 166 1109 5752 6547 1103 9505 1106 1103 1378 3672 131 113 122 114 1175 1108 1199 3187 5320 1115 1127 17163 2109 1104 1231 10182 21629 1107 153 21678 2137 4420 119 1370 1859 117 1385 1425 117 184 27655 117 1105 12556 13328 1849 1138 1151 3626 1112 2418 3187 5320 1111 1103 153 21678 2137 1231 10182 1197 118 1231 3633 119 164 4650 117 4589 166 1262 1103 126 4420 1150 4531 1231 10182 21629 1107 1103 153 21678 2137 1372 1127 1155 3860 1385 113 102\n",
      "I1208 12:27:37.085567 139883775852736 run_factoid.py:449] input_ids: 101 1327 1225 1103 2526 1525 136 102 1108 1178 4379 1107 1103 7577 1114 26574 1708 118 157 2162 15499 119 27762 162 117 3084 2393 119 164 2532 166 1982 170 18675 1884 13252 1204 2025 1106 14133 1103 13950 1104 1210 10298 1193 19849 8340 12814 3377 113 26574 1708 118 157 2162 15499 117 22157 2137 117 1105 153 21678 2137 114 1107 1103 3252 1104 1231 21754 1123 5813 2116 119 1335 1103 2812 118 1146 9355 1104 1367 7578 9524 117 1185 4420 113 121 119 121 110 114 1107 1103 26574 1708 118 157 2162 15499 1372 117 124 4420 113 1405 119 121 110 114 1107 1103 22157 2137 1372 117 1105 128 4420 113 1512 119 121 110 114 1107 1103 153 21678 2137 1372 1872 1231 10182 21629 119 164 2532 166 1109 1231 10182 21629 2603 1107 1103 153 21678 2137 1372 1108 5409 2299 1190 1115 1107 1103 26574 1708 118 157 2162 15499 1372 119 10321 117 1107 1147 1330 3055 1502 3443 117 164 4335 166 1152 1145 2103 170 2299 1231 10182 21629 2603 1104 153 21678 2137 1190 26574 1708 118 157 2162 15499 119 1130 1115 2025 117 1103 5752 7945 8359 4420 1150 9315 1719 153 21678 2137 113 183 134 3862 114 1137 26574 1708 118 157 2162 15499 113 183 134 4650 114 1111 16547 1104 22157 2137 1231 10182 21629 119 164 4335 166 1335 1103 1367 118 2370 2812 118 1146 117 4420 1150 9315 153 21678 2137 1125 170 5409 2299 1231 10182 21629 2603 113 1275 119 3324 110 114 1190 1343 5165 1114 26574 1708 118 157 2162 15499 113 121 119 121 110 114 119 164 4335 166 1109 5752 6547 1103 9505 1106 1103 1378 3672 131 113 122 114 1175 1108 1199 3187 5320 1115 1127 17163 2109 1104 1231 10182 21629 1107 153 21678 2137 4420 119 1370 1859 117 1385 1425 117 184 27655 117 1105 12556 13328 1849 1138 1151 3626 1112 2418 3187 5320 1111 1103 153 21678 2137 1231 10182 1197 118 1231 3633 119 164 4650 117 4589 166 1262 1103 126 4420 1150 4531 1231 10182 21629 1107 1103 153 21678 2137 1372 1127 1155 3860 1385 113 102\n",
      "INFO:tensorflow:input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      "I1208 12:27:37.085658 139883775852736 run_factoid.py:451] input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      "INFO:tensorflow:segment_ids: 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      "I1208 12:27:37.085747 139883775852736 run_factoid.py:453] segment_ids: 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      "INFO:tensorflow:*** Example ***\n",
      "I1208 12:27:37.087575 139883775852736 run_factoid.py:438] *** Example ***\n",
      "INFO:tensorflow:unique_id: 1000000029\n",
      "I1208 12:27:37.087632 139883775852736 run_factoid.py:439] unique_id: 1000000029\n",
      "INFO:tensorflow:example_index: 7\n",
      "I1208 12:27:37.087670 139883775852736 run_factoid.py:440] example_index: 7\n",
      "INFO:tensorflow:doc_span_index: 2\n",
      "I1208 12:27:37.087704 139883775852736 run_factoid.py:441] doc_span_index: 2\n",
      "INFO:tensorflow:tokens: [CLS] What did the paper find ? [SEP] ##cu ##rrence . [ 45 ] The re ##cu ##rrence rate in the P ##EL ##D group was significantly higher than that in the MI ##S - T ##L ##IF group . Similarly , in their another recently published trial , [ 54 ] they also reported a higher re ##cu ##rrence rate of P ##EL ##D than MI ##S - T ##L ##IF . In that study , the authors enrolled 105 patients who underwent either P ##EL ##D ( n = 47 ) or MI ##S - T ##L ##IF ( n = 58 ) for revision of ME ##D re ##cu ##rrence . [ 54 ] At the 12 - month follow - up , patients who underwent P ##EL ##D had a significantly higher re ##cu ##rrence rate ( 10 . 64 % ) than those treated with MI ##S - T ##L ##IF ( 0 . 0 % ) . [ 54 ] The authors attributed the findings to the following reasons : ( 1 ) there was some risk factors that were predict ##ive of re ##cu ##rrence in P ##EL ##D patients . For example , old age , o ##besity , and Mo ##dic change have been identified as significant risk factors for the P ##EL ##D re ##cu ##r - re ##nce . [ 58 , 59 ] And the 5 patients who experienced re ##cu ##rrence in the P ##EL ##D group were all relatively old ( ≥ ##60 years old ) and o ##bes ##e ; thus , they were at high risk of re ##current her ##nia ##tion . [ 54 ] ( 2 ) 3 of the 5 patients had her ##nia ##ted fragment that were highly migrated , and this made the surgery more difficult . [ 60 ] The residual fragment would result in unsuccessful surgical outcomes . [ 58 , 61 ] ( 3 ) After the primary ME ##D surgery , the artificial cracks in an ##nu ##lus fi ##bro ##sus would change the la ##minate structure , and make the an ##nu ##lus be more easily to del ##ami ##nation . [ 54 ] Based on the damage in an ##nu ##lus fi ##bro ##sus , the [SEP]\n",
      "I1208 12:27:37.087819 139883775852736 run_factoid.py:443] tokens: [CLS] What did the paper find ? [SEP] ##cu ##rrence . [ 45 ] The re ##cu ##rrence rate in the P ##EL ##D group was significantly higher than that in the MI ##S - T ##L ##IF group . Similarly , in their another recently published trial , [ 54 ] they also reported a higher re ##cu ##rrence rate of P ##EL ##D than MI ##S - T ##L ##IF . In that study , the authors enrolled 105 patients who underwent either P ##EL ##D ( n = 47 ) or MI ##S - T ##L ##IF ( n = 58 ) for revision of ME ##D re ##cu ##rrence . [ 54 ] At the 12 - month follow - up , patients who underwent P ##EL ##D had a significantly higher re ##cu ##rrence rate ( 10 . 64 % ) than those treated with MI ##S - T ##L ##IF ( 0 . 0 % ) . [ 54 ] The authors attributed the findings to the following reasons : ( 1 ) there was some risk factors that were predict ##ive of re ##cu ##rrence in P ##EL ##D patients . For example , old age , o ##besity , and Mo ##dic change have been identified as significant risk factors for the P ##EL ##D re ##cu ##r - re ##nce . [ 58 , 59 ] And the 5 patients who experienced re ##cu ##rrence in the P ##EL ##D group were all relatively old ( ≥ ##60 years old ) and o ##bes ##e ; thus , they were at high risk of re ##current her ##nia ##tion . [ 54 ] ( 2 ) 3 of the 5 patients had her ##nia ##ted fragment that were highly migrated , and this made the surgery more difficult . [ 60 ] The residual fragment would result in unsuccessful surgical outcomes . [ 58 , 61 ] ( 3 ) After the primary ME ##D surgery , the artificial cracks in an ##nu ##lus fi ##bro ##sus would change the la ##minate structure , and make the an ##nu ##lus be more easily to del ##ami ##nation . [ 54 ] Based on the damage in an ##nu ##lus fi ##bro ##sus , the [SEP]\n",
      "INFO:tensorflow:token_to_orig_map: 8:156 9:156 10:156 11:156 12:156 13:156 14:157 15:158 16:158 17:158 18:159 19:160 20:161 21:162 22:162 23:162 24:163 25:164 26:165 27:166 28:167 29:168 30:169 31:170 32:171 33:171 34:171 35:171 36:171 37:171 38:172 39:172 40:173 41:173 42:174 43:175 44:176 45:177 46:178 47:179 48:179 49:179 50:179 51:179 52:180 53:181 54:182 55:183 56:184 57:185 58:185 59:185 60:186 61:187 62:188 63:188 64:188 65:189 66:190 67:190 68:190 69:190 70:190 71:190 72:190 73:191 74:192 75:193 76:193 77:194 78:195 79:196 80:197 81:198 82:199 83:200 84:201 85:202 86:202 87:202 88:203 89:203 90:204 91:205 92:205 93:206 94:207 95:207 96:207 97:207 98:207 99:207 100:208 101:208 102:209 103:210 104:210 105:211 106:212 107:213 108:214 109:214 110:215 111:215 112:215 113:215 114:215 115:215 116:215 117:216 118:217 119:218 120:218 121:218 122:219 123:219 124:219 125:219 126:220 127:221 128:222 129:223 130:223 131:223 132:224 133:225 134:226 135:227 136:228 137:228 138:228 139:229 140:230 141:230 142:230 143:230 144:230 145:230 146:231 147:232 148:233 149:234 150:235 151:235 152:235 153:235 154:235 155:235 156:236 157:236 158:236 159:236 160:236 161:236 162:236 163:236 164:236 165:236 166:237 167:238 168:239 169:240 170:241 171:242 172:243 173:244 174:245 175:245 176:246 177:246 178:246 179:247 180:248 181:249 182:250 183:251 184:252 185:253 186:254 187:254 188:255 189:256 190:256 191:256 192:257 193:258 194:258 195:258 196:259 197:259 198:260 199:261 200:261 201:262 202:263 203:263 204:264 205:264 206:264 207:265 208:266 209:266 210:267 211:268 212:269 213:270 214:271 215:272 216:273 217:274 218:275 219:276 220:277 221:277 222:277 223:278 224:278 225:278 226:278 227:279 228:279 229:279 230:279 231:279 232:279 233:279 234:279 235:280 236:281 237:282 238:283 239:284 240:285 241:286 242:286 243:286 244:287 245:288 246:289 247:289 248:289 249:290 250:291 251:292 252:293 253:294 254:295 255:295 256:295 257:296 258:297 259:297 260:298 261:299 262:299 263:299 264:299 265:300 266:300 267:301 268:302 269:303 270:304 271:305 272:306 273:307 274:307 275:308 276:308 277:308 278:308 279:308 280:308 281:308 282:309 283:309 284:309 285:310 286:311 287:312 288:313 289:314 290:315 291:316 292:316 293:316 294:317 295:318 296:319 297:320 298:321 299:321 300:322 301:323 302:324 303:325 304:326 305:327 306:328 307:328 308:328 309:328 310:328 311:329 312:330 313:331 314:332 315:333 316:334 317:335 318:336 319:337 320:337 321:337 322:337 323:337 324:337 325:337 326:338 327:338 328:338 329:339 330:340 331:341 332:342 333:342 334:343 335:343 336:344 337:345 338:346 339:347 340:348 341:348 342:348 343:349 344:349 345:349 346:350 347:351 348:352 349:353 350:353 351:354 352:354 353:355 354:356 355:357 356:358 357:358 358:358 359:359 360:360 361:361 362:362 363:363 364:363 365:363 366:363 367:363 368:363 369:363 370:364 371:365 372:366 373:367 374:368 375:369 376:369 377:369 378:370 379:370 380:370 381:370 382:371\n",
      "I1208 12:27:37.087938 139883775852736 run_factoid.py:445] token_to_orig_map: 8:156 9:156 10:156 11:156 12:156 13:156 14:157 15:158 16:158 17:158 18:159 19:160 20:161 21:162 22:162 23:162 24:163 25:164 26:165 27:166 28:167 29:168 30:169 31:170 32:171 33:171 34:171 35:171 36:171 37:171 38:172 39:172 40:173 41:173 42:174 43:175 44:176 45:177 46:178 47:179 48:179 49:179 50:179 51:179 52:180 53:181 54:182 55:183 56:184 57:185 58:185 59:185 60:186 61:187 62:188 63:188 64:188 65:189 66:190 67:190 68:190 69:190 70:190 71:190 72:190 73:191 74:192 75:193 76:193 77:194 78:195 79:196 80:197 81:198 82:199 83:200 84:201 85:202 86:202 87:202 88:203 89:203 90:204 91:205 92:205 93:206 94:207 95:207 96:207 97:207 98:207 99:207 100:208 101:208 102:209 103:210 104:210 105:211 106:212 107:213 108:214 109:214 110:215 111:215 112:215 113:215 114:215 115:215 116:215 117:216 118:217 119:218 120:218 121:218 122:219 123:219 124:219 125:219 126:220 127:221 128:222 129:223 130:223 131:223 132:224 133:225 134:226 135:227 136:228 137:228 138:228 139:229 140:230 141:230 142:230 143:230 144:230 145:230 146:231 147:232 148:233 149:234 150:235 151:235 152:235 153:235 154:235 155:235 156:236 157:236 158:236 159:236 160:236 161:236 162:236 163:236 164:236 165:236 166:237 167:238 168:239 169:240 170:241 171:242 172:243 173:244 174:245 175:245 176:246 177:246 178:246 179:247 180:248 181:249 182:250 183:251 184:252 185:253 186:254 187:254 188:255 189:256 190:256 191:256 192:257 193:258 194:258 195:258 196:259 197:259 198:260 199:261 200:261 201:262 202:263 203:263 204:264 205:264 206:264 207:265 208:266 209:266 210:267 211:268 212:269 213:270 214:271 215:272 216:273 217:274 218:275 219:276 220:277 221:277 222:277 223:278 224:278 225:278 226:278 227:279 228:279 229:279 230:279 231:279 232:279 233:279 234:279 235:280 236:281 237:282 238:283 239:284 240:285 241:286 242:286 243:286 244:287 245:288 246:289 247:289 248:289 249:290 250:291 251:292 252:293 253:294 254:295 255:295 256:295 257:296 258:297 259:297 260:298 261:299 262:299 263:299 264:299 265:300 266:300 267:301 268:302 269:303 270:304 271:305 272:306 273:307 274:307 275:308 276:308 277:308 278:308 279:308 280:308 281:308 282:309 283:309 284:309 285:310 286:311 287:312 288:313 289:314 290:315 291:316 292:316 293:316 294:317 295:318 296:319 297:320 298:321 299:321 300:322 301:323 302:324 303:325 304:326 305:327 306:328 307:328 308:328 309:328 310:328 311:329 312:330 313:331 314:332 315:333 316:334 317:335 318:336 319:337 320:337 321:337 322:337 323:337 324:337 325:337 326:338 327:338 328:338 329:339 330:340 331:341 332:342 333:342 334:343 335:343 336:344 337:345 338:346 339:347 340:348 341:348 342:348 343:349 344:349 345:349 346:350 347:351 348:352 349:353 350:353 351:354 352:354 353:355 354:356 355:357 356:358 357:358 358:358 359:359 360:360 361:361 362:362 363:363 364:363 365:363 366:363 367:363 368:363 369:363 370:364 371:365 372:366 373:367 374:368 375:369 376:369 377:369 378:370 379:370 380:370 381:370 382:371\n",
      "INFO:tensorflow:token_is_max_context: 8:False 9:False 10:False 11:False 12:False 13:False 14:False 15:False 16:False 17:False 18:False 19:False 20:False 21:False 22:False 23:False 24:False 25:False 26:False 27:False 28:False 29:False 30:False 31:False 32:False 33:False 34:False 35:False 36:False 37:False 38:False 39:False 40:False 41:False 42:False 43:False 44:False 45:False 46:False 47:False 48:False 49:False 50:False 51:False 52:False 53:False 54:False 55:False 56:False 57:False 58:False 59:False 60:False 61:False 62:False 63:False 64:False 65:False 66:False 67:False 68:False 69:False 70:False 71:False 72:False 73:False 74:False 75:False 76:False 77:False 78:False 79:False 80:False 81:False 82:False 83:False 84:False 85:False 86:False 87:False 88:False 89:False 90:False 91:False 92:False 93:False 94:False 95:False 96:False 97:False 98:False 99:False 100:False 101:False 102:False 103:False 104:False 105:False 106:False 107:False 108:False 109:False 110:False 111:False 112:False 113:False 114:False 115:False 116:False 117:False 118:False 119:False 120:False 121:False 122:False 123:False 124:False 125:False 126:False 127:False 128:False 129:False 130:False 131:False 132:True 133:True 134:True 135:True 136:True 137:True 138:True 139:True 140:True 141:True 142:True 143:True 144:True 145:True 146:True 147:True 148:True 149:True 150:True 151:True 152:True 153:True 154:True 155:True 156:True 157:True 158:True 159:True 160:True 161:True 162:True 163:True 164:True 165:True 166:True 167:True 168:True 169:True 170:True 171:True 172:True 173:True 174:True 175:True 176:True 177:True 178:True 179:True 180:True 181:True 182:True 183:True 184:True 185:True 186:True 187:True 188:True 189:True 190:True 191:True 192:True 193:True 194:True 195:True 196:True 197:True 198:True 199:True 200:True 201:True 202:True 203:True 204:True 205:True 206:True 207:True 208:True 209:True 210:True 211:True 212:True 213:True 214:True 215:True 216:True 217:True 218:True 219:True 220:True 221:True 222:True 223:True 224:True 225:True 226:True 227:True 228:True 229:True 230:True 231:True 232:True 233:True 234:True 235:True 236:True 237:True 238:True 239:True 240:True 241:True 242:True 243:True 244:True 245:True 246:True 247:True 248:True 249:True 250:True 251:True 252:True 253:True 254:True 255:True 256:True 257:True 258:True 259:True 260:False 261:False 262:False 263:False 264:False 265:False 266:False 267:False 268:False 269:False 270:False 271:False 272:False 273:False 274:False 275:False 276:False 277:False 278:False 279:False 280:False 281:False 282:False 283:False 284:False 285:False 286:False 287:False 288:False 289:False 290:False 291:False 292:False 293:False 294:False 295:False 296:False 297:False 298:False 299:False 300:False 301:False 302:False 303:False 304:False 305:False 306:False 307:False 308:False 309:False 310:False 311:False 312:False 313:False 314:False 315:False 316:False 317:False 318:False 319:False 320:False 321:False 322:False 323:False 324:False 325:False 326:False 327:False 328:False 329:False 330:False 331:False 332:False 333:False 334:False 335:False 336:False 337:False 338:False 339:False 340:False 341:False 342:False 343:False 344:False 345:False 346:False 347:False 348:False 349:False 350:False 351:False 352:False 353:False 354:False 355:False 356:False 357:False 358:False 359:False 360:False 361:False 362:False 363:False 364:False 365:False 366:False 367:False 368:False 369:False 370:False 371:False 372:False 373:False 374:False 375:False 376:False 377:False 378:False 379:False 380:False 381:False 382:False\n",
      "I1208 12:27:37.088045 139883775852736 run_factoid.py:447] token_is_max_context: 8:False 9:False 10:False 11:False 12:False 13:False 14:False 15:False 16:False 17:False 18:False 19:False 20:False 21:False 22:False 23:False 24:False 25:False 26:False 27:False 28:False 29:False 30:False 31:False 32:False 33:False 34:False 35:False 36:False 37:False 38:False 39:False 40:False 41:False 42:False 43:False 44:False 45:False 46:False 47:False 48:False 49:False 50:False 51:False 52:False 53:False 54:False 55:False 56:False 57:False 58:False 59:False 60:False 61:False 62:False 63:False 64:False 65:False 66:False 67:False 68:False 69:False 70:False 71:False 72:False 73:False 74:False 75:False 76:False 77:False 78:False 79:False 80:False 81:False 82:False 83:False 84:False 85:False 86:False 87:False 88:False 89:False 90:False 91:False 92:False 93:False 94:False 95:False 96:False 97:False 98:False 99:False 100:False 101:False 102:False 103:False 104:False 105:False 106:False 107:False 108:False 109:False 110:False 111:False 112:False 113:False 114:False 115:False 116:False 117:False 118:False 119:False 120:False 121:False 122:False 123:False 124:False 125:False 126:False 127:False 128:False 129:False 130:False 131:False 132:True 133:True 134:True 135:True 136:True 137:True 138:True 139:True 140:True 141:True 142:True 143:True 144:True 145:True 146:True 147:True 148:True 149:True 150:True 151:True 152:True 153:True 154:True 155:True 156:True 157:True 158:True 159:True 160:True 161:True 162:True 163:True 164:True 165:True 166:True 167:True 168:True 169:True 170:True 171:True 172:True 173:True 174:True 175:True 176:True 177:True 178:True 179:True 180:True 181:True 182:True 183:True 184:True 185:True 186:True 187:True 188:True 189:True 190:True 191:True 192:True 193:True 194:True 195:True 196:True 197:True 198:True 199:True 200:True 201:True 202:True 203:True 204:True 205:True 206:True 207:True 208:True 209:True 210:True 211:True 212:True 213:True 214:True 215:True 216:True 217:True 218:True 219:True 220:True 221:True 222:True 223:True 224:True 225:True 226:True 227:True 228:True 229:True 230:True 231:True 232:True 233:True 234:True 235:True 236:True 237:True 238:True 239:True 240:True 241:True 242:True 243:True 244:True 245:True 246:True 247:True 248:True 249:True 250:True 251:True 252:True 253:True 254:True 255:True 256:True 257:True 258:True 259:True 260:False 261:False 262:False 263:False 264:False 265:False 266:False 267:False 268:False 269:False 270:False 271:False 272:False 273:False 274:False 275:False 276:False 277:False 278:False 279:False 280:False 281:False 282:False 283:False 284:False 285:False 286:False 287:False 288:False 289:False 290:False 291:False 292:False 293:False 294:False 295:False 296:False 297:False 298:False 299:False 300:False 301:False 302:False 303:False 304:False 305:False 306:False 307:False 308:False 309:False 310:False 311:False 312:False 313:False 314:False 315:False 316:False 317:False 318:False 319:False 320:False 321:False 322:False 323:False 324:False 325:False 326:False 327:False 328:False 329:False 330:False 331:False 332:False 333:False 334:False 335:False 336:False 337:False 338:False 339:False 340:False 341:False 342:False 343:False 344:False 345:False 346:False 347:False 348:False 349:False 350:False 351:False 352:False 353:False 354:False 355:False 356:False 357:False 358:False 359:False 360:False 361:False 362:False 363:False 364:False 365:False 366:False 367:False 368:False 369:False 370:False 371:False 372:False 373:False 374:False 375:False 376:False 377:False 378:False 379:False 380:False 381:False 382:False\n",
      "INFO:tensorflow:input_ids: 101 1327 1225 1103 2526 1525 136 102 10182 21629 119 164 2532 166 1109 1231 10182 21629 2603 1107 1103 153 21678 2137 1372 1108 5409 2299 1190 1115 1107 1103 26574 1708 118 157 2162 15499 1372 119 10321 117 1107 1147 1330 3055 1502 3443 117 164 4335 166 1152 1145 2103 170 2299 1231 10182 21629 2603 1104 153 21678 2137 1190 26574 1708 118 157 2162 15499 119 1130 1115 2025 117 1103 5752 7945 8359 4420 1150 9315 1719 153 21678 2137 113 183 134 3862 114 1137 26574 1708 118 157 2162 15499 113 183 134 4650 114 1111 16547 1104 22157 2137 1231 10182 21629 119 164 4335 166 1335 1103 1367 118 2370 2812 118 1146 117 4420 1150 9315 153 21678 2137 1125 170 5409 2299 1231 10182 21629 2603 113 1275 119 3324 110 114 1190 1343 5165 1114 26574 1708 118 157 2162 15499 113 121 119 121 110 114 119 164 4335 166 1109 5752 6547 1103 9505 1106 1103 1378 3672 131 113 122 114 1175 1108 1199 3187 5320 1115 1127 17163 2109 1104 1231 10182 21629 1107 153 21678 2137 4420 119 1370 1859 117 1385 1425 117 184 27655 117 1105 12556 13328 1849 1138 1151 3626 1112 2418 3187 5320 1111 1103 153 21678 2137 1231 10182 1197 118 1231 3633 119 164 4650 117 4589 166 1262 1103 126 4420 1150 4531 1231 10182 21629 1107 1103 153 21678 2137 1372 1127 1155 3860 1385 113 864 16480 1201 1385 114 1105 184 12866 1162 132 2456 117 1152 1127 1120 1344 3187 1104 1231 21754 1123 5813 2116 119 164 4335 166 113 123 114 124 1104 1103 126 4420 1125 1123 5813 1906 17906 1115 1127 3023 13793 117 1105 1142 1189 1103 6059 1167 2846 119 164 2539 166 1109 25399 17906 1156 1871 1107 7285 13467 13950 119 164 4650 117 5391 166 113 124 114 1258 1103 2425 22157 2137 6059 117 1103 8246 16694 1107 1126 14787 5954 20497 12725 14410 1156 1849 1103 2495 17379 2401 117 1105 1294 1103 1126 14787 5954 1129 1167 3253 1106 3687 11787 9199 119 164 4335 166 7457 1113 1103 3290 1107 1126 14787 5954 20497 12725 14410 117 1103 102\n",
      "I1208 12:27:37.088149 139883775852736 run_factoid.py:449] input_ids: 101 1327 1225 1103 2526 1525 136 102 10182 21629 119 164 2532 166 1109 1231 10182 21629 2603 1107 1103 153 21678 2137 1372 1108 5409 2299 1190 1115 1107 1103 26574 1708 118 157 2162 15499 1372 119 10321 117 1107 1147 1330 3055 1502 3443 117 164 4335 166 1152 1145 2103 170 2299 1231 10182 21629 2603 1104 153 21678 2137 1190 26574 1708 118 157 2162 15499 119 1130 1115 2025 117 1103 5752 7945 8359 4420 1150 9315 1719 153 21678 2137 113 183 134 3862 114 1137 26574 1708 118 157 2162 15499 113 183 134 4650 114 1111 16547 1104 22157 2137 1231 10182 21629 119 164 4335 166 1335 1103 1367 118 2370 2812 118 1146 117 4420 1150 9315 153 21678 2137 1125 170 5409 2299 1231 10182 21629 2603 113 1275 119 3324 110 114 1190 1343 5165 1114 26574 1708 118 157 2162 15499 113 121 119 121 110 114 119 164 4335 166 1109 5752 6547 1103 9505 1106 1103 1378 3672 131 113 122 114 1175 1108 1199 3187 5320 1115 1127 17163 2109 1104 1231 10182 21629 1107 153 21678 2137 4420 119 1370 1859 117 1385 1425 117 184 27655 117 1105 12556 13328 1849 1138 1151 3626 1112 2418 3187 5320 1111 1103 153 21678 2137 1231 10182 1197 118 1231 3633 119 164 4650 117 4589 166 1262 1103 126 4420 1150 4531 1231 10182 21629 1107 1103 153 21678 2137 1372 1127 1155 3860 1385 113 864 16480 1201 1385 114 1105 184 12866 1162 132 2456 117 1152 1127 1120 1344 3187 1104 1231 21754 1123 5813 2116 119 164 4335 166 113 123 114 124 1104 1103 126 4420 1125 1123 5813 1906 17906 1115 1127 3023 13793 117 1105 1142 1189 1103 6059 1167 2846 119 164 2539 166 1109 25399 17906 1156 1871 1107 7285 13467 13950 119 164 4650 117 5391 166 113 124 114 1258 1103 2425 22157 2137 6059 117 1103 8246 16694 1107 1126 14787 5954 20497 12725 14410 1156 1849 1103 2495 17379 2401 117 1105 1294 1103 1126 14787 5954 1129 1167 3253 1106 3687 11787 9199 119 164 4335 166 7457 1113 1103 3290 1107 1126 14787 5954 20497 12725 14410 117 1103 102\n",
      "INFO:tensorflow:input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      "I1208 12:27:37.088241 139883775852736 run_factoid.py:451] input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      "INFO:tensorflow:segment_ids: 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      "I1208 12:27:37.088330 139883775852736 run_factoid.py:453] segment_ids: 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      "INFO:tensorflow:*** Example ***\n",
      "I1208 12:27:37.090131 139883775852736 run_factoid.py:438] *** Example ***\n",
      "INFO:tensorflow:unique_id: 1000000030\n",
      "I1208 12:27:37.090193 139883775852736 run_factoid.py:439] unique_id: 1000000030\n",
      "INFO:tensorflow:example_index: 7\n",
      "I1208 12:27:37.090230 139883775852736 run_factoid.py:440] example_index: 7\n",
      "INFO:tensorflow:doc_span_index: 3\n",
      "I1208 12:27:37.090264 139883775852736 run_factoid.py:441] doc_span_index: 3\n",
      "INFO:tensorflow:tokens: [CLS] What did the paper find ? [SEP] re ##cu ##rrence rate ( 10 . 64 % ) than those treated with MI ##S - T ##L ##IF ( 0 . 0 % ) . [ 54 ] The authors attributed the findings to the following reasons : ( 1 ) there was some risk factors that were predict ##ive of re ##cu ##rrence in P ##EL ##D patients . For example , old age , o ##besity , and Mo ##dic change have been identified as significant risk factors for the P ##EL ##D re ##cu ##r - re ##nce . [ 58 , 59 ] And the 5 patients who experienced re ##cu ##rrence in the P ##EL ##D group were all relatively old ( ≥ ##60 years old ) and o ##bes ##e ; thus , they were at high risk of re ##current her ##nia ##tion . [ 54 ] ( 2 ) 3 of the 5 patients had her ##nia ##ted fragment that were highly migrated , and this made the surgery more difficult . [ 60 ] The residual fragment would result in unsuccessful surgical outcomes . [ 58 , 61 ] ( 3 ) After the primary ME ##D surgery , the artificial cracks in an ##nu ##lus fi ##bro ##sus would change the la ##minate structure , and make the an ##nu ##lus be more easily to del ##ami ##nation . [ 54 ] Based on the damage in an ##nu ##lus fi ##bro ##sus , the re ##current her ##nia ##tion easily occurred . [ 62 ] Therefore , it is unable for P ##EL ##D to solve this problem thoroughly , and a through inter ##body fusion ( MI ##S - T ##L ##IF ) might be a better choice . [ 54 ] The success rate in the P ##EL ##D group and other surgical intervention group were 7 . 2 % and 4 . 1 % , respectively . Although patients treated with P ##EL ##D achieved a significantly higher success rate than those with other surge ##ries , the difference between them was not significant . Lee SH , et al [ 46 ] performed a matched co ##hor ##t study evaluation of 60 consecutive patients with L ##D ##H [SEP]\n",
      "I1208 12:27:37.090381 139883775852736 run_factoid.py:443] tokens: [CLS] What did the paper find ? [SEP] re ##cu ##rrence rate ( 10 . 64 % ) than those treated with MI ##S - T ##L ##IF ( 0 . 0 % ) . [ 54 ] The authors attributed the findings to the following reasons : ( 1 ) there was some risk factors that were predict ##ive of re ##cu ##rrence in P ##EL ##D patients . For example , old age , o ##besity , and Mo ##dic change have been identified as significant risk factors for the P ##EL ##D re ##cu ##r - re ##nce . [ 58 , 59 ] And the 5 patients who experienced re ##cu ##rrence in the P ##EL ##D group were all relatively old ( ≥ ##60 years old ) and o ##bes ##e ; thus , they were at high risk of re ##current her ##nia ##tion . [ 54 ] ( 2 ) 3 of the 5 patients had her ##nia ##ted fragment that were highly migrated , and this made the surgery more difficult . [ 60 ] The residual fragment would result in unsuccessful surgical outcomes . [ 58 , 61 ] ( 3 ) After the primary ME ##D surgery , the artificial cracks in an ##nu ##lus fi ##bro ##sus would change the la ##minate structure , and make the an ##nu ##lus be more easily to del ##ami ##nation . [ 54 ] Based on the damage in an ##nu ##lus fi ##bro ##sus , the re ##current her ##nia ##tion easily occurred . [ 62 ] Therefore , it is unable for P ##EL ##D to solve this problem thoroughly , and a through inter ##body fusion ( MI ##S - T ##L ##IF ) might be a better choice . [ 54 ] The success rate in the P ##EL ##D group and other surgical intervention group were 7 . 2 % and 4 . 1 % , respectively . Although patients treated with P ##EL ##D achieved a significantly higher success rate than those with other surge ##ries , the difference between them was not significant . Lee SH , et al [ 46 ] performed a matched co ##hor ##t study evaluation of 60 consecutive patients with L ##D ##H [SEP]\n",
      "INFO:tensorflow:token_to_orig_map: 8:228 9:228 10:228 11:229 12:230 13:230 14:230 15:230 16:230 17:230 18:231 19:232 20:233 21:234 22:235 23:235 24:235 25:235 26:235 27:235 28:236 29:236 30:236 31:236 32:236 33:236 34:236 35:236 36:236 37:236 38:237 39:238 40:239 41:240 42:241 43:242 44:243 45:244 46:245 47:245 48:246 49:246 50:246 51:247 52:248 53:249 54:250 55:251 56:252 57:253 58:254 59:254 60:255 61:256 62:256 63:256 64:257 65:258 66:258 67:258 68:259 69:259 70:260 71:261 72:261 73:262 74:263 75:263 76:264 77:264 78:264 79:265 80:266 81:266 82:267 83:268 84:269 85:270 86:271 87:272 88:273 89:274 90:275 91:276 92:277 93:277 94:277 95:278 96:278 97:278 98:278 99:279 100:279 101:279 102:279 103:279 104:279 105:279 106:279 107:280 108:281 109:282 110:283 111:284 112:285 113:286 114:286 115:286 116:287 117:288 118:289 119:289 120:289 121:290 122:291 123:292 124:293 125:294 126:295 127:295 128:295 129:296 130:297 131:297 132:298 133:299 134:299 135:299 136:299 137:300 138:300 139:301 140:302 141:303 142:304 143:305 144:306 145:307 146:307 147:308 148:308 149:308 150:308 151:308 152:308 153:308 154:309 155:309 156:309 157:310 158:311 159:312 160:313 161:314 162:315 163:316 164:316 165:316 166:317 167:318 168:319 169:320 170:321 171:321 172:322 173:323 174:324 175:325 176:326 177:327 178:328 179:328 180:328 181:328 182:328 183:329 184:330 185:331 186:332 187:333 188:334 189:335 190:336 191:337 192:337 193:337 194:337 195:337 196:337 197:337 198:338 199:338 200:338 201:339 202:340 203:341 204:342 205:342 206:343 207:343 208:344 209:345 210:346 211:347 212:348 213:348 214:348 215:349 216:349 217:349 218:350 219:351 220:352 221:353 222:353 223:354 224:354 225:355 226:356 227:357 228:358 229:358 230:358 231:359 232:360 233:361 234:362 235:363 236:363 237:363 238:363 239:363 240:363 241:363 242:364 243:365 244:366 245:367 246:368 247:369 248:369 249:369 250:370 251:370 252:370 253:370 254:371 255:372 256:372 257:373 258:373 259:373 260:374 261:375 262:375 263:375 264:375 265:375 266:376 267:376 268:377 269:378 270:379 271:380 272:381 273:381 274:381 275:382 276:383 277:384 278:385 279:386 280:386 281:387 282:388 283:389 284:390 285:390 286:391 287:392 288:392 289:392 290:392 291:392 292:392 293:392 294:392 295:393 296:394 297:395 298:396 299:397 300:397 301:397 302:397 303:397 304:398 305:399 306:400 307:401 308:402 309:403 310:403 311:403 312:404 313:405 314:406 315:407 316:408 317:409 318:410 319:411 320:411 321:411 322:411 323:412 324:413 325:413 326:413 327:413 328:413 329:414 330:414 331:415 332:416 333:417 334:418 335:419 336:419 337:419 338:420 339:421 340:422 341:423 342:424 343:425 344:426 345:427 346:428 347:429 348:430 349:430 350:430 351:431 352:432 353:433 354:434 355:435 356:436 357:437 358:437 359:438 360:439 361:439 362:440 363:441 364:441 365:441 366:441 367:442 368:443 369:444 370:445 371:445 372:445 373:446 374:447 375:448 376:449 377:450 378:451 379:452 380:453 381:453 382:453\n",
      "I1208 12:27:37.090499 139883775852736 run_factoid.py:445] token_to_orig_map: 8:228 9:228 10:228 11:229 12:230 13:230 14:230 15:230 16:230 17:230 18:231 19:232 20:233 21:234 22:235 23:235 24:235 25:235 26:235 27:235 28:236 29:236 30:236 31:236 32:236 33:236 34:236 35:236 36:236 37:236 38:237 39:238 40:239 41:240 42:241 43:242 44:243 45:244 46:245 47:245 48:246 49:246 50:246 51:247 52:248 53:249 54:250 55:251 56:252 57:253 58:254 59:254 60:255 61:256 62:256 63:256 64:257 65:258 66:258 67:258 68:259 69:259 70:260 71:261 72:261 73:262 74:263 75:263 76:264 77:264 78:264 79:265 80:266 81:266 82:267 83:268 84:269 85:270 86:271 87:272 88:273 89:274 90:275 91:276 92:277 93:277 94:277 95:278 96:278 97:278 98:278 99:279 100:279 101:279 102:279 103:279 104:279 105:279 106:279 107:280 108:281 109:282 110:283 111:284 112:285 113:286 114:286 115:286 116:287 117:288 118:289 119:289 120:289 121:290 122:291 123:292 124:293 125:294 126:295 127:295 128:295 129:296 130:297 131:297 132:298 133:299 134:299 135:299 136:299 137:300 138:300 139:301 140:302 141:303 142:304 143:305 144:306 145:307 146:307 147:308 148:308 149:308 150:308 151:308 152:308 153:308 154:309 155:309 156:309 157:310 158:311 159:312 160:313 161:314 162:315 163:316 164:316 165:316 166:317 167:318 168:319 169:320 170:321 171:321 172:322 173:323 174:324 175:325 176:326 177:327 178:328 179:328 180:328 181:328 182:328 183:329 184:330 185:331 186:332 187:333 188:334 189:335 190:336 191:337 192:337 193:337 194:337 195:337 196:337 197:337 198:338 199:338 200:338 201:339 202:340 203:341 204:342 205:342 206:343 207:343 208:344 209:345 210:346 211:347 212:348 213:348 214:348 215:349 216:349 217:349 218:350 219:351 220:352 221:353 222:353 223:354 224:354 225:355 226:356 227:357 228:358 229:358 230:358 231:359 232:360 233:361 234:362 235:363 236:363 237:363 238:363 239:363 240:363 241:363 242:364 243:365 244:366 245:367 246:368 247:369 248:369 249:369 250:370 251:370 252:370 253:370 254:371 255:372 256:372 257:373 258:373 259:373 260:374 261:375 262:375 263:375 264:375 265:375 266:376 267:376 268:377 269:378 270:379 271:380 272:381 273:381 274:381 275:382 276:383 277:384 278:385 279:386 280:386 281:387 282:388 283:389 284:390 285:390 286:391 287:392 288:392 289:392 290:392 291:392 292:392 293:392 294:392 295:393 296:394 297:395 298:396 299:397 300:397 301:397 302:397 303:397 304:398 305:399 306:400 307:401 308:402 309:403 310:403 311:403 312:404 313:405 314:406 315:407 316:408 317:409 318:410 319:411 320:411 321:411 322:411 323:412 324:413 325:413 326:413 327:413 328:413 329:414 330:414 331:415 332:416 333:417 334:418 335:419 336:419 337:419 338:420 339:421 340:422 341:423 342:424 343:425 344:426 345:427 346:428 347:429 348:430 349:430 350:430 351:431 352:432 353:433 354:434 355:435 356:436 357:437 358:437 359:438 360:439 361:439 362:440 363:441 364:441 365:441 366:441 367:442 368:443 369:444 370:445 371:445 372:445 373:446 374:447 375:448 376:449 377:450 378:451 379:452 380:453 381:453 382:453\n",
      "INFO:tensorflow:token_is_max_context: 8:False 9:False 10:False 11:False 12:False 13:False 14:False 15:False 16:False 17:False 18:False 19:False 20:False 21:False 22:False 23:False 24:False 25:False 26:False 27:False 28:False 29:False 30:False 31:False 32:False 33:False 34:False 35:False 36:False 37:False 38:False 39:False 40:False 41:False 42:False 43:False 44:False 45:False 46:False 47:False 48:False 49:False 50:False 51:False 52:False 53:False 54:False 55:False 56:False 57:False 58:False 59:False 60:False 61:False 62:False 63:False 64:False 65:False 66:False 67:False 68:False 69:False 70:False 71:False 72:False 73:False 74:False 75:False 76:False 77:False 78:False 79:False 80:False 81:False 82:False 83:False 84:False 85:False 86:False 87:False 88:False 89:False 90:False 91:False 92:False 93:False 94:False 95:False 96:False 97:False 98:False 99:False 100:False 101:False 102:False 103:False 104:False 105:False 106:False 107:False 108:False 109:False 110:False 111:False 112:False 113:False 114:False 115:False 116:False 117:False 118:False 119:False 120:False 121:False 122:False 123:False 124:False 125:False 126:False 127:False 128:False 129:False 130:False 131:False 132:True 133:True 134:True 135:True 136:True 137:True 138:True 139:True 140:True 141:True 142:True 143:True 144:True 145:True 146:True 147:True 148:True 149:True 150:True 151:True 152:True 153:True 154:True 155:True 156:True 157:True 158:True 159:True 160:True 161:True 162:True 163:True 164:True 165:True 166:True 167:True 168:True 169:True 170:True 171:True 172:True 173:True 174:True 175:True 176:True 177:True 178:True 179:True 180:True 181:True 182:True 183:True 184:True 185:True 186:True 187:True 188:True 189:True 190:True 191:True 192:True 193:True 194:True 195:True 196:True 197:True 198:True 199:True 200:True 201:True 202:True 203:True 204:True 205:True 206:True 207:True 208:True 209:True 210:True 211:True 212:True 213:True 214:True 215:True 216:True 217:True 218:True 219:True 220:True 221:True 222:True 223:True 224:True 225:True 226:True 227:True 228:True 229:True 230:True 231:True 232:True 233:True 234:True 235:True 236:True 237:True 238:True 239:True 240:True 241:True 242:True 243:True 244:True 245:True 246:True 247:True 248:True 249:True 250:True 251:True 252:True 253:True 254:True 255:True 256:True 257:True 258:True 259:True 260:False 261:False 262:False 263:False 264:False 265:False 266:False 267:False 268:False 269:False 270:False 271:False 272:False 273:False 274:False 275:False 276:False 277:False 278:False 279:False 280:False 281:False 282:False 283:False 284:False 285:False 286:False 287:False 288:False 289:False 290:False 291:False 292:False 293:False 294:False 295:False 296:False 297:False 298:False 299:False 300:False 301:False 302:False 303:False 304:False 305:False 306:False 307:False 308:False 309:False 310:False 311:False 312:False 313:False 314:False 315:False 316:False 317:False 318:False 319:False 320:False 321:False 322:False 323:False 324:False 325:False 326:False 327:False 328:False 329:False 330:False 331:False 332:False 333:False 334:False 335:False 336:False 337:False 338:False 339:False 340:False 341:False 342:False 343:False 344:False 345:False 346:False 347:False 348:False 349:False 350:False 351:False 352:False 353:False 354:False 355:False 356:False 357:False 358:False 359:False 360:False 361:False 362:False 363:False 364:False 365:False 366:False 367:False 368:False 369:False 370:False 371:False 372:False 373:False 374:False 375:False 376:False 377:False 378:False 379:False 380:False 381:False 382:False\n",
      "I1208 12:27:37.090607 139883775852736 run_factoid.py:447] token_is_max_context: 8:False 9:False 10:False 11:False 12:False 13:False 14:False 15:False 16:False 17:False 18:False 19:False 20:False 21:False 22:False 23:False 24:False 25:False 26:False 27:False 28:False 29:False 30:False 31:False 32:False 33:False 34:False 35:False 36:False 37:False 38:False 39:False 40:False 41:False 42:False 43:False 44:False 45:False 46:False 47:False 48:False 49:False 50:False 51:False 52:False 53:False 54:False 55:False 56:False 57:False 58:False 59:False 60:False 61:False 62:False 63:False 64:False 65:False 66:False 67:False 68:False 69:False 70:False 71:False 72:False 73:False 74:False 75:False 76:False 77:False 78:False 79:False 80:False 81:False 82:False 83:False 84:False 85:False 86:False 87:False 88:False 89:False 90:False 91:False 92:False 93:False 94:False 95:False 96:False 97:False 98:False 99:False 100:False 101:False 102:False 103:False 104:False 105:False 106:False 107:False 108:False 109:False 110:False 111:False 112:False 113:False 114:False 115:False 116:False 117:False 118:False 119:False 120:False 121:False 122:False 123:False 124:False 125:False 126:False 127:False 128:False 129:False 130:False 131:False 132:True 133:True 134:True 135:True 136:True 137:True 138:True 139:True 140:True 141:True 142:True 143:True 144:True 145:True 146:True 147:True 148:True 149:True 150:True 151:True 152:True 153:True 154:True 155:True 156:True 157:True 158:True 159:True 160:True 161:True 162:True 163:True 164:True 165:True 166:True 167:True 168:True 169:True 170:True 171:True 172:True 173:True 174:True 175:True 176:True 177:True 178:True 179:True 180:True 181:True 182:True 183:True 184:True 185:True 186:True 187:True 188:True 189:True 190:True 191:True 192:True 193:True 194:True 195:True 196:True 197:True 198:True 199:True 200:True 201:True 202:True 203:True 204:True 205:True 206:True 207:True 208:True 209:True 210:True 211:True 212:True 213:True 214:True 215:True 216:True 217:True 218:True 219:True 220:True 221:True 222:True 223:True 224:True 225:True 226:True 227:True 228:True 229:True 230:True 231:True 232:True 233:True 234:True 235:True 236:True 237:True 238:True 239:True 240:True 241:True 242:True 243:True 244:True 245:True 246:True 247:True 248:True 249:True 250:True 251:True 252:True 253:True 254:True 255:True 256:True 257:True 258:True 259:True 260:False 261:False 262:False 263:False 264:False 265:False 266:False 267:False 268:False 269:False 270:False 271:False 272:False 273:False 274:False 275:False 276:False 277:False 278:False 279:False 280:False 281:False 282:False 283:False 284:False 285:False 286:False 287:False 288:False 289:False 290:False 291:False 292:False 293:False 294:False 295:False 296:False 297:False 298:False 299:False 300:False 301:False 302:False 303:False 304:False 305:False 306:False 307:False 308:False 309:False 310:False 311:False 312:False 313:False 314:False 315:False 316:False 317:False 318:False 319:False 320:False 321:False 322:False 323:False 324:False 325:False 326:False 327:False 328:False 329:False 330:False 331:False 332:False 333:False 334:False 335:False 336:False 337:False 338:False 339:False 340:False 341:False 342:False 343:False 344:False 345:False 346:False 347:False 348:False 349:False 350:False 351:False 352:False 353:False 354:False 355:False 356:False 357:False 358:False 359:False 360:False 361:False 362:False 363:False 364:False 365:False 366:False 367:False 368:False 369:False 370:False 371:False 372:False 373:False 374:False 375:False 376:False 377:False 378:False 379:False 380:False 381:False 382:False\n",
      "INFO:tensorflow:input_ids: 101 1327 1225 1103 2526 1525 136 102 1231 10182 21629 2603 113 1275 119 3324 110 114 1190 1343 5165 1114 26574 1708 118 157 2162 15499 113 121 119 121 110 114 119 164 4335 166 1109 5752 6547 1103 9505 1106 1103 1378 3672 131 113 122 114 1175 1108 1199 3187 5320 1115 1127 17163 2109 1104 1231 10182 21629 1107 153 21678 2137 4420 119 1370 1859 117 1385 1425 117 184 27655 117 1105 12556 13328 1849 1138 1151 3626 1112 2418 3187 5320 1111 1103 153 21678 2137 1231 10182 1197 118 1231 3633 119 164 4650 117 4589 166 1262 1103 126 4420 1150 4531 1231 10182 21629 1107 1103 153 21678 2137 1372 1127 1155 3860 1385 113 864 16480 1201 1385 114 1105 184 12866 1162 132 2456 117 1152 1127 1120 1344 3187 1104 1231 21754 1123 5813 2116 119 164 4335 166 113 123 114 124 1104 1103 126 4420 1125 1123 5813 1906 17906 1115 1127 3023 13793 117 1105 1142 1189 1103 6059 1167 2846 119 164 2539 166 1109 25399 17906 1156 1871 1107 7285 13467 13950 119 164 4650 117 5391 166 113 124 114 1258 1103 2425 22157 2137 6059 117 1103 8246 16694 1107 1126 14787 5954 20497 12725 14410 1156 1849 1103 2495 17379 2401 117 1105 1294 1103 1126 14787 5954 1129 1167 3253 1106 3687 11787 9199 119 164 4335 166 7457 1113 1103 3290 1107 1126 14787 5954 20497 12725 14410 117 1103 1231 21754 1123 5813 2116 3253 3296 119 164 5073 166 6589 117 1122 1110 3372 1111 153 21678 2137 1106 9474 1142 2463 12678 117 1105 170 1194 9455 14637 11970 113 26574 1708 118 157 2162 15499 114 1547 1129 170 1618 3026 119 164 4335 166 1109 2244 2603 1107 1103 153 21678 2137 1372 1105 1168 13467 9108 1372 1127 128 119 123 110 1105 125 119 122 110 117 3569 119 1966 4420 5165 1114 153 21678 2137 3890 170 5409 2299 2244 2603 1190 1343 1114 1168 12814 3377 117 1103 3719 1206 1172 1108 1136 2418 119 2499 17730 117 3084 2393 164 3993 166 1982 170 10260 1884 13252 1204 2025 10540 1104 2539 4776 4420 1114 149 2137 3048 102\n",
      "I1208 12:27:37.090709 139883775852736 run_factoid.py:449] input_ids: 101 1327 1225 1103 2526 1525 136 102 1231 10182 21629 2603 113 1275 119 3324 110 114 1190 1343 5165 1114 26574 1708 118 157 2162 15499 113 121 119 121 110 114 119 164 4335 166 1109 5752 6547 1103 9505 1106 1103 1378 3672 131 113 122 114 1175 1108 1199 3187 5320 1115 1127 17163 2109 1104 1231 10182 21629 1107 153 21678 2137 4420 119 1370 1859 117 1385 1425 117 184 27655 117 1105 12556 13328 1849 1138 1151 3626 1112 2418 3187 5320 1111 1103 153 21678 2137 1231 10182 1197 118 1231 3633 119 164 4650 117 4589 166 1262 1103 126 4420 1150 4531 1231 10182 21629 1107 1103 153 21678 2137 1372 1127 1155 3860 1385 113 864 16480 1201 1385 114 1105 184 12866 1162 132 2456 117 1152 1127 1120 1344 3187 1104 1231 21754 1123 5813 2116 119 164 4335 166 113 123 114 124 1104 1103 126 4420 1125 1123 5813 1906 17906 1115 1127 3023 13793 117 1105 1142 1189 1103 6059 1167 2846 119 164 2539 166 1109 25399 17906 1156 1871 1107 7285 13467 13950 119 164 4650 117 5391 166 113 124 114 1258 1103 2425 22157 2137 6059 117 1103 8246 16694 1107 1126 14787 5954 20497 12725 14410 1156 1849 1103 2495 17379 2401 117 1105 1294 1103 1126 14787 5954 1129 1167 3253 1106 3687 11787 9199 119 164 4335 166 7457 1113 1103 3290 1107 1126 14787 5954 20497 12725 14410 117 1103 1231 21754 1123 5813 2116 3253 3296 119 164 5073 166 6589 117 1122 1110 3372 1111 153 21678 2137 1106 9474 1142 2463 12678 117 1105 170 1194 9455 14637 11970 113 26574 1708 118 157 2162 15499 114 1547 1129 170 1618 3026 119 164 4335 166 1109 2244 2603 1107 1103 153 21678 2137 1372 1105 1168 13467 9108 1372 1127 128 119 123 110 1105 125 119 122 110 117 3569 119 1966 4420 5165 1114 153 21678 2137 3890 170 5409 2299 2244 2603 1190 1343 1114 1168 12814 3377 117 1103 3719 1206 1172 1108 1136 2418 119 2499 17730 117 3084 2393 164 3993 166 1982 170 10260 1884 13252 1204 2025 10540 1104 2539 4776 4420 1114 149 2137 3048 102\n",
      "INFO:tensorflow:input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      "I1208 12:27:37.090801 139883775852736 run_factoid.py:451] input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      "INFO:tensorflow:segment_ids: 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      "I1208 12:27:37.090890 139883775852736 run_factoid.py:453] segment_ids: 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      "INFO:tensorflow:*** Example ***\n",
      "I1208 12:27:37.092775 139883775852736 run_factoid.py:438] *** Example ***\n",
      "INFO:tensorflow:unique_id: 1000000031\n",
      "I1208 12:27:37.092845 139883775852736 run_factoid.py:439] unique_id: 1000000031\n",
      "INFO:tensorflow:example_index: 7\n",
      "I1208 12:27:37.092883 139883775852736 run_factoid.py:440] example_index: 7\n",
      "INFO:tensorflow:doc_span_index: 4\n",
      "I1208 12:27:37.092917 139883775852736 run_factoid.py:441] doc_span_index: 4\n",
      "INFO:tensorflow:tokens: [CLS] What did the paper find ? [SEP] ; thus , they were at high risk of re ##current her ##nia ##tion . [ 54 ] ( 2 ) 3 of the 5 patients had her ##nia ##ted fragment that were highly migrated , and this made the surgery more difficult . [ 60 ] The residual fragment would result in unsuccessful surgical outcomes . [ 58 , 61 ] ( 3 ) After the primary ME ##D surgery , the artificial cracks in an ##nu ##lus fi ##bro ##sus would change the la ##minate structure , and make the an ##nu ##lus be more easily to del ##ami ##nation . [ 54 ] Based on the damage in an ##nu ##lus fi ##bro ##sus , the re ##current her ##nia ##tion easily occurred . [ 62 ] Therefore , it is unable for P ##EL ##D to solve this problem thoroughly , and a through inter ##body fusion ( MI ##S - T ##L ##IF ) might be a better choice . [ 54 ] The success rate in the P ##EL ##D group and other surgical intervention group were 7 . 2 % and 4 . 1 % , respectively . Although patients treated with P ##EL ##D achieved a significantly higher success rate than those with other surge ##ries , the difference between them was not significant . Lee SH , et al [ 46 ] performed a matched co ##hor ##t study evaluation of 60 consecutive patients with L ##D ##H . Of them , 30 patients were underwent P ##EL ##D , and 30 were treated with O ##LM . [ 46 ] At the follow - up duration of 36 ##mont ##hs , 96 . 7 % of patients in the P ##EL ##D group and 93 . 3 % of patients in the O ##LM group achieved good or excellent results . [ 46 ] For micro ##su ##rg ##ical disc ##ec ##tom ##y , our result also showed a similar success rate with P ##EL ##D . R ##utt ##en S , et al [ 48 ] performed a prospective random ##ized study to compare the clinical outcomes of P ##EL ##D with micro ##su ##rg ##ical technique . In that study , 95 % [SEP]\n",
      "I1208 12:27:37.093029 139883775852736 run_factoid.py:443] tokens: [CLS] What did the paper find ? [SEP] ; thus , they were at high risk of re ##current her ##nia ##tion . [ 54 ] ( 2 ) 3 of the 5 patients had her ##nia ##ted fragment that were highly migrated , and this made the surgery more difficult . [ 60 ] The residual fragment would result in unsuccessful surgical outcomes . [ 58 , 61 ] ( 3 ) After the primary ME ##D surgery , the artificial cracks in an ##nu ##lus fi ##bro ##sus would change the la ##minate structure , and make the an ##nu ##lus be more easily to del ##ami ##nation . [ 54 ] Based on the damage in an ##nu ##lus fi ##bro ##sus , the re ##current her ##nia ##tion easily occurred . [ 62 ] Therefore , it is unable for P ##EL ##D to solve this problem thoroughly , and a through inter ##body fusion ( MI ##S - T ##L ##IF ) might be a better choice . [ 54 ] The success rate in the P ##EL ##D group and other surgical intervention group were 7 . 2 % and 4 . 1 % , respectively . Although patients treated with P ##EL ##D achieved a significantly higher success rate than those with other surge ##ries , the difference between them was not significant . Lee SH , et al [ 46 ] performed a matched co ##hor ##t study evaluation of 60 consecutive patients with L ##D ##H . Of them , 30 patients were underwent P ##EL ##D , and 30 were treated with O ##LM . [ 46 ] At the follow - up duration of 36 ##mont ##hs , 96 . 7 % of patients in the P ##EL ##D group and 93 . 3 % of patients in the O ##LM group achieved good or excellent results . [ 46 ] For micro ##su ##rg ##ical disc ##ec ##tom ##y , our result also showed a similar success rate with P ##EL ##D . R ##utt ##en S , et al [ 48 ] performed a prospective random ##ized study to compare the clinical outcomes of P ##EL ##D with micro ##su ##rg ##ical technique . In that study , 95 % [SEP]\n",
      "INFO:tensorflow:token_to_orig_map: 8:299 9:300 10:300 11:301 12:302 13:303 14:304 15:305 16:306 17:307 18:307 19:308 20:308 21:308 22:308 23:308 24:308 25:308 26:309 27:309 28:309 29:310 30:311 31:312 32:313 33:314 34:315 35:316 36:316 37:316 38:317 39:318 40:319 41:320 42:321 43:321 44:322 45:323 46:324 47:325 48:326 49:327 50:328 51:328 52:328 53:328 54:328 55:329 56:330 57:331 58:332 59:333 60:334 61:335 62:336 63:337 64:337 65:337 66:337 67:337 68:337 69:337 70:338 71:338 72:338 73:339 74:340 75:341 76:342 77:342 78:343 79:343 80:344 81:345 82:346 83:347 84:348 85:348 86:348 87:349 88:349 89:349 90:350 91:351 92:352 93:353 94:353 95:354 96:354 97:355 98:356 99:357 100:358 101:358 102:358 103:359 104:360 105:361 106:362 107:363 108:363 109:363 110:363 111:363 112:363 113:363 114:364 115:365 116:366 117:367 118:368 119:369 120:369 121:369 122:370 123:370 124:370 125:370 126:371 127:372 128:372 129:373 130:373 131:373 132:374 133:375 134:375 135:375 136:375 137:375 138:376 139:376 140:377 141:378 142:379 143:380 144:381 145:381 146:381 147:382 148:383 149:384 150:385 151:386 152:386 153:387 154:388 155:389 156:390 157:390 158:391 159:392 160:392 161:392 162:392 163:392 164:392 165:392 166:392 167:393 168:394 169:395 170:396 171:397 172:397 173:397 174:397 175:397 176:398 177:399 178:400 179:401 180:402 181:403 182:403 183:403 184:404 185:405 186:406 187:407 188:408 189:409 190:410 191:411 192:411 193:411 194:411 195:412 196:413 197:413 198:413 199:413 200:413 201:414 202:414 203:415 204:416 205:417 206:418 207:419 208:419 209:419 210:420 211:421 212:422 213:423 214:424 215:425 216:426 217:427 218:428 219:429 220:430 221:430 222:430 223:431 224:432 225:433 226:434 227:435 228:436 229:437 230:437 231:438 232:439 233:439 234:440 235:441 236:441 237:441 238:441 239:442 240:443 241:444 242:445 243:445 244:445 245:446 246:447 247:448 248:449 249:450 250:451 251:452 252:453 253:453 254:453 255:453 256:454 257:455 258:455 259:456 260:457 261:458 262:459 263:460 264:460 265:460 266:460 267:461 268:462 269:463 270:464 271:465 272:466 273:466 274:466 275:466 276:466 277:466 278:467 279:468 280:469 281:469 282:469 283:470 284:471 285:472 286:472 287:472 288:472 289:473 290:473 291:473 292:473 293:474 294:475 295:476 296:477 297:478 298:478 299:478 300:479 301:480 302:481 303:481 304:481 305:481 306:482 307:483 308:484 309:485 310:486 311:486 312:487 313:488 314:489 315:490 316:491 317:492 318:492 319:492 320:492 321:492 322:493 323:494 324:494 325:494 326:494 327:495 328:495 329:495 330:495 331:495 332:496 333:497 334:498 335:499 336:500 337:501 338:502 339:503 340:504 341:505 342:505 343:505 344:505 345:506 346:506 347:506 348:507 349:507 350:508 351:509 352:509 353:509 354:509 355:510 356:511 357:512 358:513 359:513 360:514 361:515 362:516 363:517 364:518 365:519 366:520 367:521 368:521 369:521 370:522 371:523 372:523 373:523 374:523 375:524 376:524 377:525 378:526 379:527 380:527 381:528 382:528\n",
      "I1208 12:27:37.093144 139883775852736 run_factoid.py:445] token_to_orig_map: 8:299 9:300 10:300 11:301 12:302 13:303 14:304 15:305 16:306 17:307 18:307 19:308 20:308 21:308 22:308 23:308 24:308 25:308 26:309 27:309 28:309 29:310 30:311 31:312 32:313 33:314 34:315 35:316 36:316 37:316 38:317 39:318 40:319 41:320 42:321 43:321 44:322 45:323 46:324 47:325 48:326 49:327 50:328 51:328 52:328 53:328 54:328 55:329 56:330 57:331 58:332 59:333 60:334 61:335 62:336 63:337 64:337 65:337 66:337 67:337 68:337 69:337 70:338 71:338 72:338 73:339 74:340 75:341 76:342 77:342 78:343 79:343 80:344 81:345 82:346 83:347 84:348 85:348 86:348 87:349 88:349 89:349 90:350 91:351 92:352 93:353 94:353 95:354 96:354 97:355 98:356 99:357 100:358 101:358 102:358 103:359 104:360 105:361 106:362 107:363 108:363 109:363 110:363 111:363 112:363 113:363 114:364 115:365 116:366 117:367 118:368 119:369 120:369 121:369 122:370 123:370 124:370 125:370 126:371 127:372 128:372 129:373 130:373 131:373 132:374 133:375 134:375 135:375 136:375 137:375 138:376 139:376 140:377 141:378 142:379 143:380 144:381 145:381 146:381 147:382 148:383 149:384 150:385 151:386 152:386 153:387 154:388 155:389 156:390 157:390 158:391 159:392 160:392 161:392 162:392 163:392 164:392 165:392 166:392 167:393 168:394 169:395 170:396 171:397 172:397 173:397 174:397 175:397 176:398 177:399 178:400 179:401 180:402 181:403 182:403 183:403 184:404 185:405 186:406 187:407 188:408 189:409 190:410 191:411 192:411 193:411 194:411 195:412 196:413 197:413 198:413 199:413 200:413 201:414 202:414 203:415 204:416 205:417 206:418 207:419 208:419 209:419 210:420 211:421 212:422 213:423 214:424 215:425 216:426 217:427 218:428 219:429 220:430 221:430 222:430 223:431 224:432 225:433 226:434 227:435 228:436 229:437 230:437 231:438 232:439 233:439 234:440 235:441 236:441 237:441 238:441 239:442 240:443 241:444 242:445 243:445 244:445 245:446 246:447 247:448 248:449 249:450 250:451 251:452 252:453 253:453 254:453 255:453 256:454 257:455 258:455 259:456 260:457 261:458 262:459 263:460 264:460 265:460 266:460 267:461 268:462 269:463 270:464 271:465 272:466 273:466 274:466 275:466 276:466 277:466 278:467 279:468 280:469 281:469 282:469 283:470 284:471 285:472 286:472 287:472 288:472 289:473 290:473 291:473 292:473 293:474 294:475 295:476 296:477 297:478 298:478 299:478 300:479 301:480 302:481 303:481 304:481 305:481 306:482 307:483 308:484 309:485 310:486 311:486 312:487 313:488 314:489 315:490 316:491 317:492 318:492 319:492 320:492 321:492 322:493 323:494 324:494 325:494 326:494 327:495 328:495 329:495 330:495 331:495 332:496 333:497 334:498 335:499 336:500 337:501 338:502 339:503 340:504 341:505 342:505 343:505 344:505 345:506 346:506 347:506 348:507 349:507 350:508 351:509 352:509 353:509 354:509 355:510 356:511 357:512 358:513 359:513 360:514 361:515 362:516 363:517 364:518 365:519 366:520 367:521 368:521 369:521 370:522 371:523 372:523 373:523 374:523 375:524 376:524 377:525 378:526 379:527 380:527 381:528 382:528\n",
      "INFO:tensorflow:token_is_max_context: 8:False 9:False 10:False 11:False 12:False 13:False 14:False 15:False 16:False 17:False 18:False 19:False 20:False 21:False 22:False 23:False 24:False 25:False 26:False 27:False 28:False 29:False 30:False 31:False 32:False 33:False 34:False 35:False 36:False 37:False 38:False 39:False 40:False 41:False 42:False 43:False 44:False 45:False 46:False 47:False 48:False 49:False 50:False 51:False 52:False 53:False 54:False 55:False 56:False 57:False 58:False 59:False 60:False 61:False 62:False 63:False 64:False 65:False 66:False 67:False 68:False 69:False 70:False 71:False 72:False 73:False 74:False 75:False 76:False 77:False 78:False 79:False 80:False 81:False 82:False 83:False 84:False 85:False 86:False 87:False 88:False 89:False 90:False 91:False 92:False 93:False 94:False 95:False 96:False 97:False 98:False 99:False 100:False 101:False 102:False 103:False 104:False 105:False 106:False 107:False 108:False 109:False 110:False 111:False 112:False 113:False 114:False 115:False 116:False 117:False 118:False 119:False 120:False 121:False 122:False 123:False 124:False 125:False 126:False 127:False 128:False 129:False 130:False 131:False 132:True 133:True 134:True 135:True 136:True 137:True 138:True 139:True 140:True 141:True 142:True 143:True 144:True 145:True 146:True 147:True 148:True 149:True 150:True 151:True 152:True 153:True 154:True 155:True 156:True 157:True 158:True 159:True 160:True 161:True 162:True 163:True 164:True 165:True 166:True 167:True 168:True 169:True 170:True 171:True 172:True 173:True 174:True 175:True 176:True 177:True 178:True 179:True 180:True 181:True 182:True 183:True 184:True 185:True 186:True 187:True 188:True 189:True 190:True 191:True 192:True 193:True 194:True 195:True 196:True 197:True 198:True 199:True 200:True 201:True 202:True 203:True 204:True 205:True 206:True 207:True 208:True 209:True 210:True 211:True 212:True 213:True 214:True 215:True 216:True 217:True 218:True 219:True 220:True 221:True 222:True 223:True 224:True 225:True 226:True 227:True 228:True 229:True 230:True 231:True 232:True 233:True 234:True 235:True 236:True 237:True 238:True 239:True 240:True 241:True 242:True 243:True 244:True 245:True 246:True 247:True 248:True 249:True 250:True 251:True 252:True 253:True 254:True 255:True 256:True 257:True 258:True 259:True 260:False 261:False 262:False 263:False 264:False 265:False 266:False 267:False 268:False 269:False 270:False 271:False 272:False 273:False 274:False 275:False 276:False 277:False 278:False 279:False 280:False 281:False 282:False 283:False 284:False 285:False 286:False 287:False 288:False 289:False 290:False 291:False 292:False 293:False 294:False 295:False 296:False 297:False 298:False 299:False 300:False 301:False 302:False 303:False 304:False 305:False 306:False 307:False 308:False 309:False 310:False 311:False 312:False 313:False 314:False 315:False 316:False 317:False 318:False 319:False 320:False 321:False 322:False 323:False 324:False 325:False 326:False 327:False 328:False 329:False 330:False 331:False 332:False 333:False 334:False 335:False 336:False 337:False 338:False 339:False 340:False 341:False 342:False 343:False 344:False 345:False 346:False 347:False 348:False 349:False 350:False 351:False 352:False 353:False 354:False 355:False 356:False 357:False 358:False 359:False 360:False 361:False 362:False 363:False 364:False 365:False 366:False 367:False 368:False 369:False 370:False 371:False 372:False 373:False 374:False 375:False 376:False 377:False 378:False 379:False 380:False 381:False 382:False\n",
      "I1208 12:27:37.093254 139883775852736 run_factoid.py:447] token_is_max_context: 8:False 9:False 10:False 11:False 12:False 13:False 14:False 15:False 16:False 17:False 18:False 19:False 20:False 21:False 22:False 23:False 24:False 25:False 26:False 27:False 28:False 29:False 30:False 31:False 32:False 33:False 34:False 35:False 36:False 37:False 38:False 39:False 40:False 41:False 42:False 43:False 44:False 45:False 46:False 47:False 48:False 49:False 50:False 51:False 52:False 53:False 54:False 55:False 56:False 57:False 58:False 59:False 60:False 61:False 62:False 63:False 64:False 65:False 66:False 67:False 68:False 69:False 70:False 71:False 72:False 73:False 74:False 75:False 76:False 77:False 78:False 79:False 80:False 81:False 82:False 83:False 84:False 85:False 86:False 87:False 88:False 89:False 90:False 91:False 92:False 93:False 94:False 95:False 96:False 97:False 98:False 99:False 100:False 101:False 102:False 103:False 104:False 105:False 106:False 107:False 108:False 109:False 110:False 111:False 112:False 113:False 114:False 115:False 116:False 117:False 118:False 119:False 120:False 121:False 122:False 123:False 124:False 125:False 126:False 127:False 128:False 129:False 130:False 131:False 132:True 133:True 134:True 135:True 136:True 137:True 138:True 139:True 140:True 141:True 142:True 143:True 144:True 145:True 146:True 147:True 148:True 149:True 150:True 151:True 152:True 153:True 154:True 155:True 156:True 157:True 158:True 159:True 160:True 161:True 162:True 163:True 164:True 165:True 166:True 167:True 168:True 169:True 170:True 171:True 172:True 173:True 174:True 175:True 176:True 177:True 178:True 179:True 180:True 181:True 182:True 183:True 184:True 185:True 186:True 187:True 188:True 189:True 190:True 191:True 192:True 193:True 194:True 195:True 196:True 197:True 198:True 199:True 200:True 201:True 202:True 203:True 204:True 205:True 206:True 207:True 208:True 209:True 210:True 211:True 212:True 213:True 214:True 215:True 216:True 217:True 218:True 219:True 220:True 221:True 222:True 223:True 224:True 225:True 226:True 227:True 228:True 229:True 230:True 231:True 232:True 233:True 234:True 235:True 236:True 237:True 238:True 239:True 240:True 241:True 242:True 243:True 244:True 245:True 246:True 247:True 248:True 249:True 250:True 251:True 252:True 253:True 254:True 255:True 256:True 257:True 258:True 259:True 260:False 261:False 262:False 263:False 264:False 265:False 266:False 267:False 268:False 269:False 270:False 271:False 272:False 273:False 274:False 275:False 276:False 277:False 278:False 279:False 280:False 281:False 282:False 283:False 284:False 285:False 286:False 287:False 288:False 289:False 290:False 291:False 292:False 293:False 294:False 295:False 296:False 297:False 298:False 299:False 300:False 301:False 302:False 303:False 304:False 305:False 306:False 307:False 308:False 309:False 310:False 311:False 312:False 313:False 314:False 315:False 316:False 317:False 318:False 319:False 320:False 321:False 322:False 323:False 324:False 325:False 326:False 327:False 328:False 329:False 330:False 331:False 332:False 333:False 334:False 335:False 336:False 337:False 338:False 339:False 340:False 341:False 342:False 343:False 344:False 345:False 346:False 347:False 348:False 349:False 350:False 351:False 352:False 353:False 354:False 355:False 356:False 357:False 358:False 359:False 360:False 361:False 362:False 363:False 364:False 365:False 366:False 367:False 368:False 369:False 370:False 371:False 372:False 373:False 374:False 375:False 376:False 377:False 378:False 379:False 380:False 381:False 382:False\n",
      "INFO:tensorflow:input_ids: 101 1327 1225 1103 2526 1525 136 102 132 2456 117 1152 1127 1120 1344 3187 1104 1231 21754 1123 5813 2116 119 164 4335 166 113 123 114 124 1104 1103 126 4420 1125 1123 5813 1906 17906 1115 1127 3023 13793 117 1105 1142 1189 1103 6059 1167 2846 119 164 2539 166 1109 25399 17906 1156 1871 1107 7285 13467 13950 119 164 4650 117 5391 166 113 124 114 1258 1103 2425 22157 2137 6059 117 1103 8246 16694 1107 1126 14787 5954 20497 12725 14410 1156 1849 1103 2495 17379 2401 117 1105 1294 1103 1126 14787 5954 1129 1167 3253 1106 3687 11787 9199 119 164 4335 166 7457 1113 1103 3290 1107 1126 14787 5954 20497 12725 14410 117 1103 1231 21754 1123 5813 2116 3253 3296 119 164 5073 166 6589 117 1122 1110 3372 1111 153 21678 2137 1106 9474 1142 2463 12678 117 1105 170 1194 9455 14637 11970 113 26574 1708 118 157 2162 15499 114 1547 1129 170 1618 3026 119 164 4335 166 1109 2244 2603 1107 1103 153 21678 2137 1372 1105 1168 13467 9108 1372 1127 128 119 123 110 1105 125 119 122 110 117 3569 119 1966 4420 5165 1114 153 21678 2137 3890 170 5409 2299 2244 2603 1190 1343 1114 1168 12814 3377 117 1103 3719 1206 1172 1108 1136 2418 119 2499 17730 117 3084 2393 164 3993 166 1982 170 10260 1884 13252 1204 2025 10540 1104 2539 4776 4420 1114 149 2137 3048 119 2096 1172 117 1476 4420 1127 9315 153 21678 2137 117 1105 1476 1127 5165 1114 152 22074 119 164 3993 166 1335 1103 2812 118 1146 9355 1104 3164 7578 9524 117 5306 119 128 110 1104 4420 1107 1103 153 21678 2137 1372 1105 5429 119 124 110 1104 4420 1107 1103 152 22074 1372 3890 1363 1137 6548 2686 119 164 3993 166 1370 17599 6385 10805 4571 6187 10294 18778 1183 117 1412 1871 1145 2799 170 1861 2244 2603 1114 153 21678 2137 119 155 25131 1424 156 117 3084 2393 164 3615 166 1982 170 19916 7091 2200 2025 1106 14133 1103 7300 13950 1104 153 21678 2137 1114 17599 6385 10805 4571 5531 119 1130 1115 2025 117 4573 110 102\n",
      "I1208 12:27:37.093356 139883775852736 run_factoid.py:449] input_ids: 101 1327 1225 1103 2526 1525 136 102 132 2456 117 1152 1127 1120 1344 3187 1104 1231 21754 1123 5813 2116 119 164 4335 166 113 123 114 124 1104 1103 126 4420 1125 1123 5813 1906 17906 1115 1127 3023 13793 117 1105 1142 1189 1103 6059 1167 2846 119 164 2539 166 1109 25399 17906 1156 1871 1107 7285 13467 13950 119 164 4650 117 5391 166 113 124 114 1258 1103 2425 22157 2137 6059 117 1103 8246 16694 1107 1126 14787 5954 20497 12725 14410 1156 1849 1103 2495 17379 2401 117 1105 1294 1103 1126 14787 5954 1129 1167 3253 1106 3687 11787 9199 119 164 4335 166 7457 1113 1103 3290 1107 1126 14787 5954 20497 12725 14410 117 1103 1231 21754 1123 5813 2116 3253 3296 119 164 5073 166 6589 117 1122 1110 3372 1111 153 21678 2137 1106 9474 1142 2463 12678 117 1105 170 1194 9455 14637 11970 113 26574 1708 118 157 2162 15499 114 1547 1129 170 1618 3026 119 164 4335 166 1109 2244 2603 1107 1103 153 21678 2137 1372 1105 1168 13467 9108 1372 1127 128 119 123 110 1105 125 119 122 110 117 3569 119 1966 4420 5165 1114 153 21678 2137 3890 170 5409 2299 2244 2603 1190 1343 1114 1168 12814 3377 117 1103 3719 1206 1172 1108 1136 2418 119 2499 17730 117 3084 2393 164 3993 166 1982 170 10260 1884 13252 1204 2025 10540 1104 2539 4776 4420 1114 149 2137 3048 119 2096 1172 117 1476 4420 1127 9315 153 21678 2137 117 1105 1476 1127 5165 1114 152 22074 119 164 3993 166 1335 1103 2812 118 1146 9355 1104 3164 7578 9524 117 5306 119 128 110 1104 4420 1107 1103 153 21678 2137 1372 1105 5429 119 124 110 1104 4420 1107 1103 152 22074 1372 3890 1363 1137 6548 2686 119 164 3993 166 1370 17599 6385 10805 4571 6187 10294 18778 1183 117 1412 1871 1145 2799 170 1861 2244 2603 1114 153 21678 2137 119 155 25131 1424 156 117 3084 2393 164 3615 166 1982 170 19916 7091 2200 2025 1106 14133 1103 7300 13950 1104 153 21678 2137 1114 17599 6385 10805 4571 5531 119 1130 1115 2025 117 4573 110 102\n",
      "INFO:tensorflow:input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      "I1208 12:27:37.093446 139883775852736 run_factoid.py:451] input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      "INFO:tensorflow:segment_ids: 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      "I1208 12:27:37.093535 139883775852736 run_factoid.py:453] segment_ids: 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      "INFO:tensorflow:*** Example ***\n",
      "I1208 12:27:37.095364 139883775852736 run_factoid.py:438] *** Example ***\n",
      "INFO:tensorflow:unique_id: 1000000032\n",
      "I1208 12:27:37.095425 139883775852736 run_factoid.py:439] unique_id: 1000000032\n",
      "INFO:tensorflow:example_index: 7\n",
      "I1208 12:27:37.095463 139883775852736 run_factoid.py:440] example_index: 7\n",
      "INFO:tensorflow:doc_span_index: 5\n",
      "I1208 12:27:37.095497 139883775852736 run_factoid.py:441] doc_span_index: 5\n",
      "INFO:tensorflow:tokens: [CLS] What did the paper find ? [SEP] 62 ] Therefore , it is unable for P ##EL ##D to solve this problem thoroughly , and a through inter ##body fusion ( MI ##S - T ##L ##IF ) might be a better choice . [ 54 ] The success rate in the P ##EL ##D group and other surgical intervention group were 7 . 2 % and 4 . 1 % , respectively . Although patients treated with P ##EL ##D achieved a significantly higher success rate than those with other surge ##ries , the difference between them was not significant . Lee SH , et al [ 46 ] performed a matched co ##hor ##t study evaluation of 60 consecutive patients with L ##D ##H . Of them , 30 patients were underwent P ##EL ##D , and 30 were treated with O ##LM . [ 46 ] At the follow - up duration of 36 ##mont ##hs , 96 . 7 % of patients in the P ##EL ##D group and 93 . 3 % of patients in the O ##LM group achieved good or excellent results . [ 46 ] For micro ##su ##rg ##ical disc ##ec ##tom ##y , our result also showed a similar success rate with P ##EL ##D . R ##utt ##en S , et al [ 48 ] performed a prospective random ##ized study to compare the clinical outcomes of P ##EL ##D with micro ##su ##rg ##ical technique . In that study , 95 % of patients with P ##EL ##D reported subjective satisfaction as compared with 86 % of patients with micro ##su ##rg ##ical technique . However , the difference between them was not significant . In contrast to the lower success rates of O ##LM and micro ##su ##rg ##ical disc ##ec ##tom ##y , MI ##S - T ##L ##IF seemed to have a higher success rate than P ##EL ##D . Liu C , et al [ 52 ] reported a prospective co ##hor ##t study of 401 patients with re ##current L ##D ##H who were treated with P ##EL ##D ( n = 209 ) or MI ##S - T ##L ##IF ( n = 192 ) . At the mean duration follow - up of [SEP]\n",
      "I1208 12:27:37.095609 139883775852736 run_factoid.py:443] tokens: [CLS] What did the paper find ? [SEP] 62 ] Therefore , it is unable for P ##EL ##D to solve this problem thoroughly , and a through inter ##body fusion ( MI ##S - T ##L ##IF ) might be a better choice . [ 54 ] The success rate in the P ##EL ##D group and other surgical intervention group were 7 . 2 % and 4 . 1 % , respectively . Although patients treated with P ##EL ##D achieved a significantly higher success rate than those with other surge ##ries , the difference between them was not significant . Lee SH , et al [ 46 ] performed a matched co ##hor ##t study evaluation of 60 consecutive patients with L ##D ##H . Of them , 30 patients were underwent P ##EL ##D , and 30 were treated with O ##LM . [ 46 ] At the follow - up duration of 36 ##mont ##hs , 96 . 7 % of patients in the P ##EL ##D group and 93 . 3 % of patients in the O ##LM group achieved good or excellent results . [ 46 ] For micro ##su ##rg ##ical disc ##ec ##tom ##y , our result also showed a similar success rate with P ##EL ##D . R ##utt ##en S , et al [ 48 ] performed a prospective random ##ized study to compare the clinical outcomes of P ##EL ##D with micro ##su ##rg ##ical technique . In that study , 95 % of patients with P ##EL ##D reported subjective satisfaction as compared with 86 % of patients with micro ##su ##rg ##ical technique . However , the difference between them was not significant . In contrast to the lower success rates of O ##LM and micro ##su ##rg ##ical disc ##ec ##tom ##y , MI ##S - T ##L ##IF seemed to have a higher success rate than P ##EL ##D . Liu C , et al [ 52 ] reported a prospective co ##hor ##t study of 401 patients with re ##current L ##D ##H who were treated with P ##EL ##D ( n = 209 ) or MI ##S - T ##L ##IF ( n = 192 ) . At the mean duration follow - up of [SEP]\n",
      "INFO:tensorflow:token_to_orig_map: 8:375 9:375 10:376 11:376 12:377 13:378 14:379 15:380 16:381 17:381 18:381 19:382 20:383 21:384 22:385 23:386 24:386 25:387 26:388 27:389 28:390 29:390 30:391 31:392 32:392 33:392 34:392 35:392 36:392 37:392 38:392 39:393 40:394 41:395 42:396 43:397 44:397 45:397 46:397 47:397 48:398 49:399 50:400 51:401 52:402 53:403 54:403 55:403 56:404 57:405 58:406 59:407 60:408 61:409 62:410 63:411 64:411 65:411 66:411 67:412 68:413 69:413 70:413 71:413 72:413 73:414 74:414 75:415 76:416 77:417 78:418 79:419 80:419 81:419 82:420 83:421 84:422 85:423 86:424 87:425 88:426 89:427 90:428 91:429 92:430 93:430 94:430 95:431 96:432 97:433 98:434 99:435 100:436 101:437 102:437 103:438 104:439 105:439 106:440 107:441 108:441 109:441 110:441 111:442 112:443 113:444 114:445 115:445 116:445 117:446 118:447 119:448 120:449 121:450 122:451 123:452 124:453 125:453 126:453 127:453 128:454 129:455 130:455 131:456 132:457 133:458 134:459 135:460 136:460 137:460 138:460 139:461 140:462 141:463 142:464 143:465 144:466 145:466 146:466 147:466 148:466 149:466 150:467 151:468 152:469 153:469 154:469 155:470 156:471 157:472 158:472 159:472 160:472 161:473 162:473 163:473 164:473 165:474 166:475 167:476 168:477 169:478 170:478 171:478 172:479 173:480 174:481 175:481 176:481 177:481 178:482 179:483 180:484 181:485 182:486 183:486 184:487 185:488 186:489 187:490 188:491 189:492 190:492 191:492 192:492 193:492 194:493 195:494 196:494 197:494 198:494 199:495 200:495 201:495 202:495 203:495 204:496 205:497 206:498 207:499 208:500 209:501 210:502 211:503 212:504 213:505 214:505 215:505 216:505 217:506 218:506 219:506 220:507 221:507 222:508 223:509 224:509 225:509 226:509 227:510 228:511 229:512 230:513 231:513 232:514 233:515 234:516 235:517 236:518 237:519 238:520 239:521 240:521 241:521 242:522 243:523 244:523 245:523 246:523 247:524 248:524 249:525 250:526 251:527 252:527 253:528 254:528 255:529 256:530 257:531 258:532 259:532 260:532 261:533 262:534 263:535 264:536 265:537 266:538 267:539 268:539 269:540 270:541 271:542 272:543 273:543 274:543 275:543 276:544 277:544 278:545 279:545 280:546 281:547 282:548 283:549 284:550 285:551 286:552 287:552 288:553 289:554 290:555 291:556 292:557 293:558 294:559 295:560 296:561 297:561 298:562 299:563 300:563 301:563 302:563 303:564 304:564 305:564 306:564 307:564 308:565 309:565 310:565 311:565 312:565 313:565 314:566 315:567 316:568 317:569 318:570 319:571 320:572 321:573 322:574 323:574 324:574 325:574 326:575 327:576 328:576 329:577 330:578 331:578 332:578 333:578 334:579 335:580 336:581 337:582 338:582 339:582 340:583 341:584 342:585 343:586 344:587 345:588 346:588 347:589 348:589 349:589 350:590 351:591 352:592 353:593 354:594 355:594 356:594 357:595 358:595 359:596 360:597 361:597 362:598 363:599 364:599 365:599 366:599 367:599 368:599 369:600 370:600 371:601 372:602 373:602 374:602 375:603 376:604 377:605 378:606 379:607 380:607 381:607 382:608\n",
      "I1208 12:27:37.095725 139883775852736 run_factoid.py:445] token_to_orig_map: 8:375 9:375 10:376 11:376 12:377 13:378 14:379 15:380 16:381 17:381 18:381 19:382 20:383 21:384 22:385 23:386 24:386 25:387 26:388 27:389 28:390 29:390 30:391 31:392 32:392 33:392 34:392 35:392 36:392 37:392 38:392 39:393 40:394 41:395 42:396 43:397 44:397 45:397 46:397 47:397 48:398 49:399 50:400 51:401 52:402 53:403 54:403 55:403 56:404 57:405 58:406 59:407 60:408 61:409 62:410 63:411 64:411 65:411 66:411 67:412 68:413 69:413 70:413 71:413 72:413 73:414 74:414 75:415 76:416 77:417 78:418 79:419 80:419 81:419 82:420 83:421 84:422 85:423 86:424 87:425 88:426 89:427 90:428 91:429 92:430 93:430 94:430 95:431 96:432 97:433 98:434 99:435 100:436 101:437 102:437 103:438 104:439 105:439 106:440 107:441 108:441 109:441 110:441 111:442 112:443 113:444 114:445 115:445 116:445 117:446 118:447 119:448 120:449 121:450 122:451 123:452 124:453 125:453 126:453 127:453 128:454 129:455 130:455 131:456 132:457 133:458 134:459 135:460 136:460 137:460 138:460 139:461 140:462 141:463 142:464 143:465 144:466 145:466 146:466 147:466 148:466 149:466 150:467 151:468 152:469 153:469 154:469 155:470 156:471 157:472 158:472 159:472 160:472 161:473 162:473 163:473 164:473 165:474 166:475 167:476 168:477 169:478 170:478 171:478 172:479 173:480 174:481 175:481 176:481 177:481 178:482 179:483 180:484 181:485 182:486 183:486 184:487 185:488 186:489 187:490 188:491 189:492 190:492 191:492 192:492 193:492 194:493 195:494 196:494 197:494 198:494 199:495 200:495 201:495 202:495 203:495 204:496 205:497 206:498 207:499 208:500 209:501 210:502 211:503 212:504 213:505 214:505 215:505 216:505 217:506 218:506 219:506 220:507 221:507 222:508 223:509 224:509 225:509 226:509 227:510 228:511 229:512 230:513 231:513 232:514 233:515 234:516 235:517 236:518 237:519 238:520 239:521 240:521 241:521 242:522 243:523 244:523 245:523 246:523 247:524 248:524 249:525 250:526 251:527 252:527 253:528 254:528 255:529 256:530 257:531 258:532 259:532 260:532 261:533 262:534 263:535 264:536 265:537 266:538 267:539 268:539 269:540 270:541 271:542 272:543 273:543 274:543 275:543 276:544 277:544 278:545 279:545 280:546 281:547 282:548 283:549 284:550 285:551 286:552 287:552 288:553 289:554 290:555 291:556 292:557 293:558 294:559 295:560 296:561 297:561 298:562 299:563 300:563 301:563 302:563 303:564 304:564 305:564 306:564 307:564 308:565 309:565 310:565 311:565 312:565 313:565 314:566 315:567 316:568 317:569 318:570 319:571 320:572 321:573 322:574 323:574 324:574 325:574 326:575 327:576 328:576 329:577 330:578 331:578 332:578 333:578 334:579 335:580 336:581 337:582 338:582 339:582 340:583 341:584 342:585 343:586 344:587 345:588 346:588 347:589 348:589 349:589 350:590 351:591 352:592 353:593 354:594 355:594 356:594 357:595 358:595 359:596 360:597 361:597 362:598 363:599 364:599 365:599 366:599 367:599 368:599 369:600 370:600 371:601 372:602 373:602 374:602 375:603 376:604 377:605 378:606 379:607 380:607 381:607 382:608\n",
      "INFO:tensorflow:token_is_max_context: 8:False 9:False 10:False 11:False 12:False 13:False 14:False 15:False 16:False 17:False 18:False 19:False 20:False 21:False 22:False 23:False 24:False 25:False 26:False 27:False 28:False 29:False 30:False 31:False 32:False 33:False 34:False 35:False 36:False 37:False 38:False 39:False 40:False 41:False 42:False 43:False 44:False 45:False 46:False 47:False 48:False 49:False 50:False 51:False 52:False 53:False 54:False 55:False 56:False 57:False 58:False 59:False 60:False 61:False 62:False 63:False 64:False 65:False 66:False 67:False 68:False 69:False 70:False 71:False 72:False 73:False 74:False 75:False 76:False 77:False 78:False 79:False 80:False 81:False 82:False 83:False 84:False 85:False 86:False 87:False 88:False 89:False 90:False 91:False 92:False 93:False 94:False 95:False 96:False 97:False 98:False 99:False 100:False 101:False 102:False 103:False 104:False 105:False 106:False 107:False 108:False 109:False 110:False 111:False 112:False 113:False 114:False 115:False 116:False 117:False 118:False 119:False 120:False 121:False 122:False 123:False 124:False 125:False 126:False 127:False 128:False 129:False 130:False 131:False 132:True 133:True 134:True 135:True 136:True 137:True 138:True 139:True 140:True 141:True 142:True 143:True 144:True 145:True 146:True 147:True 148:True 149:True 150:True 151:True 152:True 153:True 154:True 155:True 156:True 157:True 158:True 159:True 160:True 161:True 162:True 163:True 164:True 165:True 166:True 167:True 168:True 169:True 170:True 171:True 172:True 173:True 174:True 175:True 176:True 177:True 178:True 179:True 180:True 181:True 182:True 183:True 184:True 185:True 186:True 187:True 188:True 189:True 190:True 191:True 192:True 193:True 194:True 195:True 196:True 197:True 198:True 199:True 200:True 201:True 202:True 203:True 204:True 205:True 206:True 207:True 208:True 209:True 210:True 211:True 212:True 213:True 214:True 215:True 216:True 217:True 218:True 219:True 220:True 221:True 222:True 223:True 224:True 225:True 226:True 227:True 228:True 229:True 230:True 231:True 232:True 233:True 234:True 235:True 236:True 237:True 238:True 239:True 240:True 241:True 242:True 243:True 244:True 245:True 246:True 247:True 248:True 249:True 250:True 251:True 252:True 253:True 254:True 255:True 256:True 257:True 258:True 259:True 260:False 261:False 262:False 263:False 264:False 265:False 266:False 267:False 268:False 269:False 270:False 271:False 272:False 273:False 274:False 275:False 276:False 277:False 278:False 279:False 280:False 281:False 282:False 283:False 284:False 285:False 286:False 287:False 288:False 289:False 290:False 291:False 292:False 293:False 294:False 295:False 296:False 297:False 298:False 299:False 300:False 301:False 302:False 303:False 304:False 305:False 306:False 307:False 308:False 309:False 310:False 311:False 312:False 313:False 314:False 315:False 316:False 317:False 318:False 319:False 320:False 321:False 322:False 323:False 324:False 325:False 326:False 327:False 328:False 329:False 330:False 331:False 332:False 333:False 334:False 335:False 336:False 337:False 338:False 339:False 340:False 341:False 342:False 343:False 344:False 345:False 346:False 347:False 348:False 349:False 350:False 351:False 352:False 353:False 354:False 355:False 356:False 357:False 358:False 359:False 360:False 361:False 362:False 363:False 364:False 365:False 366:False 367:False 368:False 369:False 370:False 371:False 372:False 373:False 374:False 375:False 376:False 377:False 378:False 379:False 380:False 381:False 382:False\n",
      "I1208 12:27:37.095835 139883775852736 run_factoid.py:447] token_is_max_context: 8:False 9:False 10:False 11:False 12:False 13:False 14:False 15:False 16:False 17:False 18:False 19:False 20:False 21:False 22:False 23:False 24:False 25:False 26:False 27:False 28:False 29:False 30:False 31:False 32:False 33:False 34:False 35:False 36:False 37:False 38:False 39:False 40:False 41:False 42:False 43:False 44:False 45:False 46:False 47:False 48:False 49:False 50:False 51:False 52:False 53:False 54:False 55:False 56:False 57:False 58:False 59:False 60:False 61:False 62:False 63:False 64:False 65:False 66:False 67:False 68:False 69:False 70:False 71:False 72:False 73:False 74:False 75:False 76:False 77:False 78:False 79:False 80:False 81:False 82:False 83:False 84:False 85:False 86:False 87:False 88:False 89:False 90:False 91:False 92:False 93:False 94:False 95:False 96:False 97:False 98:False 99:False 100:False 101:False 102:False 103:False 104:False 105:False 106:False 107:False 108:False 109:False 110:False 111:False 112:False 113:False 114:False 115:False 116:False 117:False 118:False 119:False 120:False 121:False 122:False 123:False 124:False 125:False 126:False 127:False 128:False 129:False 130:False 131:False 132:True 133:True 134:True 135:True 136:True 137:True 138:True 139:True 140:True 141:True 142:True 143:True 144:True 145:True 146:True 147:True 148:True 149:True 150:True 151:True 152:True 153:True 154:True 155:True 156:True 157:True 158:True 159:True 160:True 161:True 162:True 163:True 164:True 165:True 166:True 167:True 168:True 169:True 170:True 171:True 172:True 173:True 174:True 175:True 176:True 177:True 178:True 179:True 180:True 181:True 182:True 183:True 184:True 185:True 186:True 187:True 188:True 189:True 190:True 191:True 192:True 193:True 194:True 195:True 196:True 197:True 198:True 199:True 200:True 201:True 202:True 203:True 204:True 205:True 206:True 207:True 208:True 209:True 210:True 211:True 212:True 213:True 214:True 215:True 216:True 217:True 218:True 219:True 220:True 221:True 222:True 223:True 224:True 225:True 226:True 227:True 228:True 229:True 230:True 231:True 232:True 233:True 234:True 235:True 236:True 237:True 238:True 239:True 240:True 241:True 242:True 243:True 244:True 245:True 246:True 247:True 248:True 249:True 250:True 251:True 252:True 253:True 254:True 255:True 256:True 257:True 258:True 259:True 260:False 261:False 262:False 263:False 264:False 265:False 266:False 267:False 268:False 269:False 270:False 271:False 272:False 273:False 274:False 275:False 276:False 277:False 278:False 279:False 280:False 281:False 282:False 283:False 284:False 285:False 286:False 287:False 288:False 289:False 290:False 291:False 292:False 293:False 294:False 295:False 296:False 297:False 298:False 299:False 300:False 301:False 302:False 303:False 304:False 305:False 306:False 307:False 308:False 309:False 310:False 311:False 312:False 313:False 314:False 315:False 316:False 317:False 318:False 319:False 320:False 321:False 322:False 323:False 324:False 325:False 326:False 327:False 328:False 329:False 330:False 331:False 332:False 333:False 334:False 335:False 336:False 337:False 338:False 339:False 340:False 341:False 342:False 343:False 344:False 345:False 346:False 347:False 348:False 349:False 350:False 351:False 352:False 353:False 354:False 355:False 356:False 357:False 358:False 359:False 360:False 361:False 362:False 363:False 364:False 365:False 366:False 367:False 368:False 369:False 370:False 371:False 372:False 373:False 374:False 375:False 376:False 377:False 378:False 379:False 380:False 381:False 382:False\n",
      "INFO:tensorflow:input_ids: 101 1327 1225 1103 2526 1525 136 102 5073 166 6589 117 1122 1110 3372 1111 153 21678 2137 1106 9474 1142 2463 12678 117 1105 170 1194 9455 14637 11970 113 26574 1708 118 157 2162 15499 114 1547 1129 170 1618 3026 119 164 4335 166 1109 2244 2603 1107 1103 153 21678 2137 1372 1105 1168 13467 9108 1372 1127 128 119 123 110 1105 125 119 122 110 117 3569 119 1966 4420 5165 1114 153 21678 2137 3890 170 5409 2299 2244 2603 1190 1343 1114 1168 12814 3377 117 1103 3719 1206 1172 1108 1136 2418 119 2499 17730 117 3084 2393 164 3993 166 1982 170 10260 1884 13252 1204 2025 10540 1104 2539 4776 4420 1114 149 2137 3048 119 2096 1172 117 1476 4420 1127 9315 153 21678 2137 117 1105 1476 1127 5165 1114 152 22074 119 164 3993 166 1335 1103 2812 118 1146 9355 1104 3164 7578 9524 117 5306 119 128 110 1104 4420 1107 1103 153 21678 2137 1372 1105 5429 119 124 110 1104 4420 1107 1103 152 22074 1372 3890 1363 1137 6548 2686 119 164 3993 166 1370 17599 6385 10805 4571 6187 10294 18778 1183 117 1412 1871 1145 2799 170 1861 2244 2603 1114 153 21678 2137 119 155 25131 1424 156 117 3084 2393 164 3615 166 1982 170 19916 7091 2200 2025 1106 14133 1103 7300 13950 1104 153 21678 2137 1114 17599 6385 10805 4571 5531 119 1130 1115 2025 117 4573 110 1104 4420 1114 153 21678 2137 2103 23481 10241 1112 3402 1114 5942 110 1104 4420 1114 17599 6385 10805 4571 5531 119 1438 117 1103 3719 1206 1172 1108 1136 2418 119 1130 5014 1106 1103 2211 2244 5600 1104 152 22074 1105 17599 6385 10805 4571 6187 10294 18778 1183 117 26574 1708 118 157 2162 15499 1882 1106 1138 170 2299 2244 2603 1190 153 21678 2137 119 8411 140 117 3084 2393 164 3882 166 2103 170 19916 1884 13252 1204 2025 1104 25182 4420 1114 1231 21754 149 2137 3048 1150 1127 5165 1114 153 21678 2137 113 183 134 21040 114 1137 26574 1708 118 157 2162 15499 113 183 134 18868 114 119 1335 1103 1928 9355 2812 118 1146 1104 102\n",
      "I1208 12:27:37.095938 139883775852736 run_factoid.py:449] input_ids: 101 1327 1225 1103 2526 1525 136 102 5073 166 6589 117 1122 1110 3372 1111 153 21678 2137 1106 9474 1142 2463 12678 117 1105 170 1194 9455 14637 11970 113 26574 1708 118 157 2162 15499 114 1547 1129 170 1618 3026 119 164 4335 166 1109 2244 2603 1107 1103 153 21678 2137 1372 1105 1168 13467 9108 1372 1127 128 119 123 110 1105 125 119 122 110 117 3569 119 1966 4420 5165 1114 153 21678 2137 3890 170 5409 2299 2244 2603 1190 1343 1114 1168 12814 3377 117 1103 3719 1206 1172 1108 1136 2418 119 2499 17730 117 3084 2393 164 3993 166 1982 170 10260 1884 13252 1204 2025 10540 1104 2539 4776 4420 1114 149 2137 3048 119 2096 1172 117 1476 4420 1127 9315 153 21678 2137 117 1105 1476 1127 5165 1114 152 22074 119 164 3993 166 1335 1103 2812 118 1146 9355 1104 3164 7578 9524 117 5306 119 128 110 1104 4420 1107 1103 153 21678 2137 1372 1105 5429 119 124 110 1104 4420 1107 1103 152 22074 1372 3890 1363 1137 6548 2686 119 164 3993 166 1370 17599 6385 10805 4571 6187 10294 18778 1183 117 1412 1871 1145 2799 170 1861 2244 2603 1114 153 21678 2137 119 155 25131 1424 156 117 3084 2393 164 3615 166 1982 170 19916 7091 2200 2025 1106 14133 1103 7300 13950 1104 153 21678 2137 1114 17599 6385 10805 4571 5531 119 1130 1115 2025 117 4573 110 1104 4420 1114 153 21678 2137 2103 23481 10241 1112 3402 1114 5942 110 1104 4420 1114 17599 6385 10805 4571 5531 119 1438 117 1103 3719 1206 1172 1108 1136 2418 119 1130 5014 1106 1103 2211 2244 5600 1104 152 22074 1105 17599 6385 10805 4571 6187 10294 18778 1183 117 26574 1708 118 157 2162 15499 1882 1106 1138 170 2299 2244 2603 1190 153 21678 2137 119 8411 140 117 3084 2393 164 3882 166 2103 170 19916 1884 13252 1204 2025 1104 25182 4420 1114 1231 21754 149 2137 3048 1150 1127 5165 1114 153 21678 2137 113 183 134 21040 114 1137 26574 1708 118 157 2162 15499 113 183 134 18868 114 119 1335 1103 1928 9355 2812 118 1146 1104 102\n",
      "INFO:tensorflow:input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      "I1208 12:27:37.096029 139883775852736 run_factoid.py:451] input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      "INFO:tensorflow:segment_ids: 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      "I1208 12:27:37.096118 139883775852736 run_factoid.py:453] segment_ids: 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      "INFO:tensorflow:*** Example ***\n",
      "I1208 12:27:37.098021 139883775852736 run_factoid.py:438] *** Example ***\n",
      "INFO:tensorflow:unique_id: 1000000033\n",
      "I1208 12:27:37.098086 139883775852736 run_factoid.py:439] unique_id: 1000000033\n",
      "INFO:tensorflow:example_index: 7\n",
      "I1208 12:27:37.098124 139883775852736 run_factoid.py:440] example_index: 7\n",
      "INFO:tensorflow:doc_span_index: 6\n",
      "I1208 12:27:37.098159 139883775852736 run_factoid.py:441] doc_span_index: 6\n",
      "INFO:tensorflow:tokens: [CLS] What did the paper find ? [SEP] ##EL ##D , and 30 were treated with O ##LM . [ 46 ] At the follow - up duration of 36 ##mont ##hs , 96 . 7 % of patients in the P ##EL ##D group and 93 . 3 % of patients in the O ##LM group achieved good or excellent results . [ 46 ] For micro ##su ##rg ##ical disc ##ec ##tom ##y , our result also showed a similar success rate with P ##EL ##D . R ##utt ##en S , et al [ 48 ] performed a prospective random ##ized study to compare the clinical outcomes of P ##EL ##D with micro ##su ##rg ##ical technique . In that study , 95 % of patients with P ##EL ##D reported subjective satisfaction as compared with 86 % of patients with micro ##su ##rg ##ical technique . However , the difference between them was not significant . In contrast to the lower success rates of O ##LM and micro ##su ##rg ##ical disc ##ec ##tom ##y , MI ##S - T ##L ##IF seemed to have a higher success rate than P ##EL ##D . Liu C , et al [ 52 ] reported a prospective co ##hor ##t study of 401 patients with re ##current L ##D ##H who were treated with P ##EL ##D ( n = 209 ) or MI ##S - T ##L ##IF ( n = 192 ) . At the mean duration follow - up of 46 . 5 months , the success rate in the two groups was 91 . 3 % and 95 . 2 % , respectively . [ 52 ] MI ##S - T ##L ##IF resulted in a higher success rate than P ##EL ##D , however , there was no significant difference between them . Regarding the operation time , the present study demonstrated that patients treated with P ##EL ##D had 18 . 14 minutes less of operation time than those with other surgical interventions . However , the reduced operation time of P ##EL ##D was only observed in the comparison with O ##LM , MI ##S - T ##L ##IF , micro ##su ##rg ##ical disc ##ec ##tom ##y and micro ##dis ##ce ##ct ##omy [SEP]\n",
      "I1208 12:27:37.098269 139883775852736 run_factoid.py:443] tokens: [CLS] What did the paper find ? [SEP] ##EL ##D , and 30 were treated with O ##LM . [ 46 ] At the follow - up duration of 36 ##mont ##hs , 96 . 7 % of patients in the P ##EL ##D group and 93 . 3 % of patients in the O ##LM group achieved good or excellent results . [ 46 ] For micro ##su ##rg ##ical disc ##ec ##tom ##y , our result also showed a similar success rate with P ##EL ##D . R ##utt ##en S , et al [ 48 ] performed a prospective random ##ized study to compare the clinical outcomes of P ##EL ##D with micro ##su ##rg ##ical technique . In that study , 95 % of patients with P ##EL ##D reported subjective satisfaction as compared with 86 % of patients with micro ##su ##rg ##ical technique . However , the difference between them was not significant . In contrast to the lower success rates of O ##LM and micro ##su ##rg ##ical disc ##ec ##tom ##y , MI ##S - T ##L ##IF seemed to have a higher success rate than P ##EL ##D . Liu C , et al [ 52 ] reported a prospective co ##hor ##t study of 401 patients with re ##current L ##D ##H who were treated with P ##EL ##D ( n = 209 ) or MI ##S - T ##L ##IF ( n = 192 ) . At the mean duration follow - up of 46 . 5 months , the success rate in the two groups was 91 . 3 % and 95 . 2 % , respectively . [ 52 ] MI ##S - T ##L ##IF resulted in a higher success rate than P ##EL ##D , however , there was no significant difference between them . Regarding the operation time , the present study demonstrated that patients treated with P ##EL ##D had 18 . 14 minutes less of operation time than those with other surgical interventions . However , the reduced operation time of P ##EL ##D was only observed in the comparison with O ##LM , MI ##S - T ##L ##IF , micro ##su ##rg ##ical disc ##ec ##tom ##y and micro ##dis ##ce ##ct ##omy [SEP]\n",
      "INFO:tensorflow:token_to_orig_map: 8:460 9:460 10:460 11:461 12:462 13:463 14:464 15:465 16:466 17:466 18:466 19:466 20:466 21:466 22:467 23:468 24:469 25:469 26:469 27:470 28:471 29:472 30:472 31:472 32:472 33:473 34:473 35:473 36:473 37:474 38:475 39:476 40:477 41:478 42:478 43:478 44:479 45:480 46:481 47:481 48:481 49:481 50:482 51:483 52:484 53:485 54:486 55:486 56:487 57:488 58:489 59:490 60:491 61:492 62:492 63:492 64:492 65:492 66:493 67:494 68:494 69:494 70:494 71:495 72:495 73:495 74:495 75:495 76:496 77:497 78:498 79:499 80:500 81:501 82:502 83:503 84:504 85:505 86:505 87:505 88:505 89:506 90:506 91:506 92:507 93:507 94:508 95:509 96:509 97:509 98:509 99:510 100:511 101:512 102:513 103:513 104:514 105:515 106:516 107:517 108:518 109:519 110:520 111:521 112:521 113:521 114:522 115:523 116:523 117:523 118:523 119:524 120:524 121:525 122:526 123:527 124:527 125:528 126:528 127:529 128:530 129:531 130:532 131:532 132:532 133:533 134:534 135:535 136:536 137:537 138:538 139:539 140:539 141:540 142:541 143:542 144:543 145:543 146:543 147:543 148:544 149:544 150:545 151:545 152:546 153:547 154:548 155:549 156:550 157:551 158:552 159:552 160:553 161:554 162:555 163:556 164:557 165:558 166:559 167:560 168:561 169:561 170:562 171:563 172:563 173:563 174:563 175:564 176:564 177:564 178:564 179:564 180:565 181:565 182:565 183:565 184:565 185:565 186:566 187:567 188:568 189:569 190:570 191:571 192:572 193:573 194:574 195:574 196:574 197:574 198:575 199:576 200:576 201:577 202:578 203:578 204:578 205:578 206:579 207:580 208:581 209:582 210:582 211:582 212:583 213:584 214:585 215:586 216:587 217:588 218:588 219:589 220:589 221:589 222:590 223:591 224:592 225:593 226:594 227:594 228:594 229:595 230:595 231:596 232:597 233:597 234:598 235:599 236:599 237:599 238:599 239:599 240:599 241:600 242:600 243:601 244:602 245:602 246:602 247:603 248:604 249:605 250:606 251:607 252:607 253:607 254:608 255:609 256:609 257:609 258:610 259:610 260:611 261:612 262:613 263:614 264:615 265:616 266:617 267:618 268:619 269:619 270:619 271:619 272:620 273:621 274:621 275:621 276:621 277:621 278:622 279:622 280:622 281:622 282:622 283:623 284:623 285:623 286:623 287:623 288:623 289:624 290:625 291:626 292:627 293:628 294:629 295:630 296:631 297:631 298:631 299:631 300:632 301:632 302:633 303:634 304:635 305:636 306:637 307:638 308:639 309:639 310:640 311:641 312:642 313:643 314:643 315:644 316:645 317:646 318:647 319:648 320:649 321:650 322:651 323:652 324:652 325:652 326:653 327:654 328:654 329:654 330:655 331:656 332:657 333:658 334:659 335:660 336:661 337:662 338:663 339:664 340:665 341:665 342:666 343:666 344:667 345:668 346:669 347:670 348:671 349:672 350:672 351:672 352:673 353:674 354:675 355:676 356:677 357:678 358:679 359:680 360:680 361:680 362:681 363:681 364:681 365:681 366:681 367:681 368:681 369:682 370:682 371:682 372:682 373:683 374:683 375:683 376:683 377:684 378:685 379:685 380:685 381:685 382:685\n",
      "I1208 12:27:37.098386 139883775852736 run_factoid.py:445] token_to_orig_map: 8:460 9:460 10:460 11:461 12:462 13:463 14:464 15:465 16:466 17:466 18:466 19:466 20:466 21:466 22:467 23:468 24:469 25:469 26:469 27:470 28:471 29:472 30:472 31:472 32:472 33:473 34:473 35:473 36:473 37:474 38:475 39:476 40:477 41:478 42:478 43:478 44:479 45:480 46:481 47:481 48:481 49:481 50:482 51:483 52:484 53:485 54:486 55:486 56:487 57:488 58:489 59:490 60:491 61:492 62:492 63:492 64:492 65:492 66:493 67:494 68:494 69:494 70:494 71:495 72:495 73:495 74:495 75:495 76:496 77:497 78:498 79:499 80:500 81:501 82:502 83:503 84:504 85:505 86:505 87:505 88:505 89:506 90:506 91:506 92:507 93:507 94:508 95:509 96:509 97:509 98:509 99:510 100:511 101:512 102:513 103:513 104:514 105:515 106:516 107:517 108:518 109:519 110:520 111:521 112:521 113:521 114:522 115:523 116:523 117:523 118:523 119:524 120:524 121:525 122:526 123:527 124:527 125:528 126:528 127:529 128:530 129:531 130:532 131:532 132:532 133:533 134:534 135:535 136:536 137:537 138:538 139:539 140:539 141:540 142:541 143:542 144:543 145:543 146:543 147:543 148:544 149:544 150:545 151:545 152:546 153:547 154:548 155:549 156:550 157:551 158:552 159:552 160:553 161:554 162:555 163:556 164:557 165:558 166:559 167:560 168:561 169:561 170:562 171:563 172:563 173:563 174:563 175:564 176:564 177:564 178:564 179:564 180:565 181:565 182:565 183:565 184:565 185:565 186:566 187:567 188:568 189:569 190:570 191:571 192:572 193:573 194:574 195:574 196:574 197:574 198:575 199:576 200:576 201:577 202:578 203:578 204:578 205:578 206:579 207:580 208:581 209:582 210:582 211:582 212:583 213:584 214:585 215:586 216:587 217:588 218:588 219:589 220:589 221:589 222:590 223:591 224:592 225:593 226:594 227:594 228:594 229:595 230:595 231:596 232:597 233:597 234:598 235:599 236:599 237:599 238:599 239:599 240:599 241:600 242:600 243:601 244:602 245:602 246:602 247:603 248:604 249:605 250:606 251:607 252:607 253:607 254:608 255:609 256:609 257:609 258:610 259:610 260:611 261:612 262:613 263:614 264:615 265:616 266:617 267:618 268:619 269:619 270:619 271:619 272:620 273:621 274:621 275:621 276:621 277:621 278:622 279:622 280:622 281:622 282:622 283:623 284:623 285:623 286:623 287:623 288:623 289:624 290:625 291:626 292:627 293:628 294:629 295:630 296:631 297:631 298:631 299:631 300:632 301:632 302:633 303:634 304:635 305:636 306:637 307:638 308:639 309:639 310:640 311:641 312:642 313:643 314:643 315:644 316:645 317:646 318:647 319:648 320:649 321:650 322:651 323:652 324:652 325:652 326:653 327:654 328:654 329:654 330:655 331:656 332:657 333:658 334:659 335:660 336:661 337:662 338:663 339:664 340:665 341:665 342:666 343:666 344:667 345:668 346:669 347:670 348:671 349:672 350:672 351:672 352:673 353:674 354:675 355:676 356:677 357:678 358:679 359:680 360:680 361:680 362:681 363:681 364:681 365:681 366:681 367:681 368:681 369:682 370:682 371:682 372:682 373:683 374:683 375:683 376:683 377:684 378:685 379:685 380:685 381:685 382:685\n",
      "INFO:tensorflow:token_is_max_context: 8:False 9:False 10:False 11:False 12:False 13:False 14:False 15:False 16:False 17:False 18:False 19:False 20:False 21:False 22:False 23:False 24:False 25:False 26:False 27:False 28:False 29:False 30:False 31:False 32:False 33:False 34:False 35:False 36:False 37:False 38:False 39:False 40:False 41:False 42:False 43:False 44:False 45:False 46:False 47:False 48:False 49:False 50:False 51:False 52:False 53:False 54:False 55:False 56:False 57:False 58:False 59:False 60:False 61:False 62:False 63:False 64:False 65:False 66:False 67:False 68:False 69:False 70:False 71:False 72:False 73:False 74:False 75:False 76:False 77:False 78:False 79:False 80:False 81:False 82:False 83:False 84:False 85:False 86:False 87:False 88:False 89:False 90:False 91:False 92:False 93:False 94:False 95:False 96:False 97:False 98:False 99:False 100:False 101:False 102:False 103:False 104:False 105:False 106:False 107:False 108:False 109:False 110:False 111:False 112:False 113:False 114:False 115:False 116:False 117:False 118:False 119:False 120:False 121:False 122:False 123:False 124:False 125:False 126:False 127:False 128:False 129:False 130:False 131:False 132:True 133:True 134:True 135:True 136:True 137:True 138:True 139:True 140:True 141:True 142:True 143:True 144:True 145:True 146:True 147:True 148:True 149:True 150:True 151:True 152:True 153:True 154:True 155:True 156:True 157:True 158:True 159:True 160:True 161:True 162:True 163:True 164:True 165:True 166:True 167:True 168:True 169:True 170:True 171:True 172:True 173:True 174:True 175:True 176:True 177:True 178:True 179:True 180:True 181:True 182:True 183:True 184:True 185:True 186:True 187:True 188:True 189:True 190:True 191:True 192:True 193:True 194:True 195:True 196:True 197:True 198:True 199:True 200:True 201:True 202:True 203:True 204:True 205:True 206:True 207:True 208:True 209:True 210:True 211:True 212:True 213:True 214:True 215:True 216:True 217:True 218:True 219:True 220:True 221:True 222:True 223:True 224:True 225:True 226:True 227:True 228:True 229:True 230:True 231:True 232:True 233:True 234:True 235:True 236:True 237:True 238:True 239:True 240:True 241:True 242:True 243:True 244:True 245:True 246:True 247:True 248:True 249:True 250:True 251:True 252:True 253:True 254:True 255:True 256:True 257:True 258:True 259:True 260:False 261:False 262:False 263:False 264:False 265:False 266:False 267:False 268:False 269:False 270:False 271:False 272:False 273:False 274:False 275:False 276:False 277:False 278:False 279:False 280:False 281:False 282:False 283:False 284:False 285:False 286:False 287:False 288:False 289:False 290:False 291:False 292:False 293:False 294:False 295:False 296:False 297:False 298:False 299:False 300:False 301:False 302:False 303:False 304:False 305:False 306:False 307:False 308:False 309:False 310:False 311:False 312:False 313:False 314:False 315:False 316:False 317:False 318:False 319:False 320:False 321:False 322:False 323:False 324:False 325:False 326:False 327:False 328:False 329:False 330:False 331:False 332:False 333:False 334:False 335:False 336:False 337:False 338:False 339:False 340:False 341:False 342:False 343:False 344:False 345:False 346:False 347:False 348:False 349:False 350:False 351:False 352:False 353:False 354:False 355:False 356:False 357:False 358:False 359:False 360:False 361:False 362:False 363:False 364:False 365:False 366:False 367:False 368:False 369:False 370:False 371:False 372:False 373:False 374:False 375:False 376:False 377:False 378:False 379:False 380:False 381:False 382:False\n",
      "I1208 12:27:37.098495 139883775852736 run_factoid.py:447] token_is_max_context: 8:False 9:False 10:False 11:False 12:False 13:False 14:False 15:False 16:False 17:False 18:False 19:False 20:False 21:False 22:False 23:False 24:False 25:False 26:False 27:False 28:False 29:False 30:False 31:False 32:False 33:False 34:False 35:False 36:False 37:False 38:False 39:False 40:False 41:False 42:False 43:False 44:False 45:False 46:False 47:False 48:False 49:False 50:False 51:False 52:False 53:False 54:False 55:False 56:False 57:False 58:False 59:False 60:False 61:False 62:False 63:False 64:False 65:False 66:False 67:False 68:False 69:False 70:False 71:False 72:False 73:False 74:False 75:False 76:False 77:False 78:False 79:False 80:False 81:False 82:False 83:False 84:False 85:False 86:False 87:False 88:False 89:False 90:False 91:False 92:False 93:False 94:False 95:False 96:False 97:False 98:False 99:False 100:False 101:False 102:False 103:False 104:False 105:False 106:False 107:False 108:False 109:False 110:False 111:False 112:False 113:False 114:False 115:False 116:False 117:False 118:False 119:False 120:False 121:False 122:False 123:False 124:False 125:False 126:False 127:False 128:False 129:False 130:False 131:False 132:True 133:True 134:True 135:True 136:True 137:True 138:True 139:True 140:True 141:True 142:True 143:True 144:True 145:True 146:True 147:True 148:True 149:True 150:True 151:True 152:True 153:True 154:True 155:True 156:True 157:True 158:True 159:True 160:True 161:True 162:True 163:True 164:True 165:True 166:True 167:True 168:True 169:True 170:True 171:True 172:True 173:True 174:True 175:True 176:True 177:True 178:True 179:True 180:True 181:True 182:True 183:True 184:True 185:True 186:True 187:True 188:True 189:True 190:True 191:True 192:True 193:True 194:True 195:True 196:True 197:True 198:True 199:True 200:True 201:True 202:True 203:True 204:True 205:True 206:True 207:True 208:True 209:True 210:True 211:True 212:True 213:True 214:True 215:True 216:True 217:True 218:True 219:True 220:True 221:True 222:True 223:True 224:True 225:True 226:True 227:True 228:True 229:True 230:True 231:True 232:True 233:True 234:True 235:True 236:True 237:True 238:True 239:True 240:True 241:True 242:True 243:True 244:True 245:True 246:True 247:True 248:True 249:True 250:True 251:True 252:True 253:True 254:True 255:True 256:True 257:True 258:True 259:True 260:False 261:False 262:False 263:False 264:False 265:False 266:False 267:False 268:False 269:False 270:False 271:False 272:False 273:False 274:False 275:False 276:False 277:False 278:False 279:False 280:False 281:False 282:False 283:False 284:False 285:False 286:False 287:False 288:False 289:False 290:False 291:False 292:False 293:False 294:False 295:False 296:False 297:False 298:False 299:False 300:False 301:False 302:False 303:False 304:False 305:False 306:False 307:False 308:False 309:False 310:False 311:False 312:False 313:False 314:False 315:False 316:False 317:False 318:False 319:False 320:False 321:False 322:False 323:False 324:False 325:False 326:False 327:False 328:False 329:False 330:False 331:False 332:False 333:False 334:False 335:False 336:False 337:False 338:False 339:False 340:False 341:False 342:False 343:False 344:False 345:False 346:False 347:False 348:False 349:False 350:False 351:False 352:False 353:False 354:False 355:False 356:False 357:False 358:False 359:False 360:False 361:False 362:False 363:False 364:False 365:False 366:False 367:False 368:False 369:False 370:False 371:False 372:False 373:False 374:False 375:False 376:False 377:False 378:False 379:False 380:False 381:False 382:False\n",
      "INFO:tensorflow:input_ids: 101 1327 1225 1103 2526 1525 136 102 21678 2137 117 1105 1476 1127 5165 1114 152 22074 119 164 3993 166 1335 1103 2812 118 1146 9355 1104 3164 7578 9524 117 5306 119 128 110 1104 4420 1107 1103 153 21678 2137 1372 1105 5429 119 124 110 1104 4420 1107 1103 152 22074 1372 3890 1363 1137 6548 2686 119 164 3993 166 1370 17599 6385 10805 4571 6187 10294 18778 1183 117 1412 1871 1145 2799 170 1861 2244 2603 1114 153 21678 2137 119 155 25131 1424 156 117 3084 2393 164 3615 166 1982 170 19916 7091 2200 2025 1106 14133 1103 7300 13950 1104 153 21678 2137 1114 17599 6385 10805 4571 5531 119 1130 1115 2025 117 4573 110 1104 4420 1114 153 21678 2137 2103 23481 10241 1112 3402 1114 5942 110 1104 4420 1114 17599 6385 10805 4571 5531 119 1438 117 1103 3719 1206 1172 1108 1136 2418 119 1130 5014 1106 1103 2211 2244 5600 1104 152 22074 1105 17599 6385 10805 4571 6187 10294 18778 1183 117 26574 1708 118 157 2162 15499 1882 1106 1138 170 2299 2244 2603 1190 153 21678 2137 119 8411 140 117 3084 2393 164 3882 166 2103 170 19916 1884 13252 1204 2025 1104 25182 4420 1114 1231 21754 149 2137 3048 1150 1127 5165 1114 153 21678 2137 113 183 134 21040 114 1137 26574 1708 118 157 2162 15499 113 183 134 18868 114 119 1335 1103 1928 9355 2812 118 1146 1104 3993 119 126 1808 117 1103 2244 2603 1107 1103 1160 2114 1108 5539 119 124 110 1105 4573 119 123 110 117 3569 119 164 3882 166 26574 1708 118 157 2162 15499 3657 1107 170 2299 2244 2603 1190 153 21678 2137 117 1649 117 1175 1108 1185 2418 3719 1206 1172 119 23840 1103 2805 1159 117 1103 1675 2025 7160 1115 4420 5165 1114 153 21678 2137 1125 1407 119 1489 1904 1750 1104 2805 1159 1190 1343 1114 1168 13467 22496 119 1438 117 1103 3549 2805 1159 1104 153 21678 2137 1108 1178 4379 1107 1103 7577 1114 152 22074 117 26574 1708 118 157 2162 15499 117 17599 6385 10805 4571 6187 10294 18778 1183 1105 17599 10396 2093 5822 18574 102\n",
      "I1208 12:27:37.098596 139883775852736 run_factoid.py:449] input_ids: 101 1327 1225 1103 2526 1525 136 102 21678 2137 117 1105 1476 1127 5165 1114 152 22074 119 164 3993 166 1335 1103 2812 118 1146 9355 1104 3164 7578 9524 117 5306 119 128 110 1104 4420 1107 1103 153 21678 2137 1372 1105 5429 119 124 110 1104 4420 1107 1103 152 22074 1372 3890 1363 1137 6548 2686 119 164 3993 166 1370 17599 6385 10805 4571 6187 10294 18778 1183 117 1412 1871 1145 2799 170 1861 2244 2603 1114 153 21678 2137 119 155 25131 1424 156 117 3084 2393 164 3615 166 1982 170 19916 7091 2200 2025 1106 14133 1103 7300 13950 1104 153 21678 2137 1114 17599 6385 10805 4571 5531 119 1130 1115 2025 117 4573 110 1104 4420 1114 153 21678 2137 2103 23481 10241 1112 3402 1114 5942 110 1104 4420 1114 17599 6385 10805 4571 5531 119 1438 117 1103 3719 1206 1172 1108 1136 2418 119 1130 5014 1106 1103 2211 2244 5600 1104 152 22074 1105 17599 6385 10805 4571 6187 10294 18778 1183 117 26574 1708 118 157 2162 15499 1882 1106 1138 170 2299 2244 2603 1190 153 21678 2137 119 8411 140 117 3084 2393 164 3882 166 2103 170 19916 1884 13252 1204 2025 1104 25182 4420 1114 1231 21754 149 2137 3048 1150 1127 5165 1114 153 21678 2137 113 183 134 21040 114 1137 26574 1708 118 157 2162 15499 113 183 134 18868 114 119 1335 1103 1928 9355 2812 118 1146 1104 3993 119 126 1808 117 1103 2244 2603 1107 1103 1160 2114 1108 5539 119 124 110 1105 4573 119 123 110 117 3569 119 164 3882 166 26574 1708 118 157 2162 15499 3657 1107 170 2299 2244 2603 1190 153 21678 2137 117 1649 117 1175 1108 1185 2418 3719 1206 1172 119 23840 1103 2805 1159 117 1103 1675 2025 7160 1115 4420 5165 1114 153 21678 2137 1125 1407 119 1489 1904 1750 1104 2805 1159 1190 1343 1114 1168 13467 22496 119 1438 117 1103 3549 2805 1159 1104 153 21678 2137 1108 1178 4379 1107 1103 7577 1114 152 22074 117 26574 1708 118 157 2162 15499 117 17599 6385 10805 4571 6187 10294 18778 1183 1105 17599 10396 2093 5822 18574 102\n",
      "INFO:tensorflow:input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      "I1208 12:27:37.098686 139883775852736 run_factoid.py:451] input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      "INFO:tensorflow:segment_ids: 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      "I1208 12:27:37.098775 139883775852736 run_factoid.py:453] segment_ids: 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      "INFO:tensorflow:*** Example ***\n",
      "I1208 12:27:37.100605 139883775852736 run_factoid.py:438] *** Example ***\n",
      "INFO:tensorflow:unique_id: 1000000034\n",
      "I1208 12:27:37.100668 139883775852736 run_factoid.py:439] unique_id: 1000000034\n",
      "INFO:tensorflow:example_index: 7\n",
      "I1208 12:27:37.100707 139883775852736 run_factoid.py:440] example_index: 7\n",
      "INFO:tensorflow:doc_span_index: 7\n",
      "I1208 12:27:37.100740 139883775852736 run_factoid.py:441] doc_span_index: 7\n",
      "INFO:tensorflow:tokens: [CLS] What did the paper find ? [SEP] as compared with 86 % of patients with micro ##su ##rg ##ical technique . However , the difference between them was not significant . In contrast to the lower success rates of O ##LM and micro ##su ##rg ##ical disc ##ec ##tom ##y , MI ##S - T ##L ##IF seemed to have a higher success rate than P ##EL ##D . Liu C , et al [ 52 ] reported a prospective co ##hor ##t study of 401 patients with re ##current L ##D ##H who were treated with P ##EL ##D ( n = 209 ) or MI ##S - T ##L ##IF ( n = 192 ) . At the mean duration follow - up of 46 . 5 months , the success rate in the two groups was 91 . 3 % and 95 . 2 % , respectively . [ 52 ] MI ##S - T ##L ##IF resulted in a higher success rate than P ##EL ##D , however , there was no significant difference between them . Regarding the operation time , the present study demonstrated that patients treated with P ##EL ##D had 18 . 14 minutes less of operation time than those with other surgical interventions . However , the reduced operation time of P ##EL ##D was only observed in the comparison with O ##LM , MI ##S - T ##L ##IF , micro ##su ##rg ##ical disc ##ec ##tom ##y and micro ##dis ##ce ##ct ##omy . Compared with these surgical approaches , P ##EL ##D had 11 . 66 minutes , 75 . 23 minutes , 23 . 21 minutes , and 17 minutes less of operation time , respectively . Kim M ##J , et al . [ 44 ] compared the clinical outcomes of P ##EL ##D with O ##LM , and they found the operation time in these two groups was 53 . 0 ± 13 . 0 minutes and 64 . 6 ± 28 . 7 minutes , respectively ( P < 0 . 00 ##1 ) . Yao Y , et al . [ 45 ] assessed the three minimal ##ly invasive spine surgical approaches ( P ##EL ##D , MI ##S - T ##L ##IF , and [SEP]\n",
      "I1208 12:27:37.100853 139883775852736 run_factoid.py:443] tokens: [CLS] What did the paper find ? [SEP] as compared with 86 % of patients with micro ##su ##rg ##ical technique . However , the difference between them was not significant . In contrast to the lower success rates of O ##LM and micro ##su ##rg ##ical disc ##ec ##tom ##y , MI ##S - T ##L ##IF seemed to have a higher success rate than P ##EL ##D . Liu C , et al [ 52 ] reported a prospective co ##hor ##t study of 401 patients with re ##current L ##D ##H who were treated with P ##EL ##D ( n = 209 ) or MI ##S - T ##L ##IF ( n = 192 ) . At the mean duration follow - up of 46 . 5 months , the success rate in the two groups was 91 . 3 % and 95 . 2 % , respectively . [ 52 ] MI ##S - T ##L ##IF resulted in a higher success rate than P ##EL ##D , however , there was no significant difference between them . Regarding the operation time , the present study demonstrated that patients treated with P ##EL ##D had 18 . 14 minutes less of operation time than those with other surgical interventions . However , the reduced operation time of P ##EL ##D was only observed in the comparison with O ##LM , MI ##S - T ##L ##IF , micro ##su ##rg ##ical disc ##ec ##tom ##y and micro ##dis ##ce ##ct ##omy . Compared with these surgical approaches , P ##EL ##D had 11 . 66 minutes , 75 . 23 minutes , 23 . 21 minutes , and 17 minutes less of operation time , respectively . Kim M ##J , et al . [ 44 ] compared the clinical outcomes of P ##EL ##D with O ##LM , and they found the operation time in these two groups was 53 . 0 ± 13 . 0 minutes and 64 . 6 ± 28 . 7 minutes , respectively ( P < 0 . 00 ##1 ) . Yao Y , et al . [ 45 ] assessed the three minimal ##ly invasive spine surgical approaches ( P ##EL ##D , MI ##S - T ##L ##IF , and [SEP]\n",
      "INFO:tensorflow:token_to_orig_map: 8:536 9:537 10:538 11:539 12:539 13:540 14:541 15:542 16:543 17:543 18:543 19:543 20:544 21:544 22:545 23:545 24:546 25:547 26:548 27:549 28:550 29:551 30:552 31:552 32:553 33:554 34:555 35:556 36:557 37:558 38:559 39:560 40:561 41:561 42:562 43:563 44:563 45:563 46:563 47:564 48:564 49:564 50:564 51:564 52:565 53:565 54:565 55:565 56:565 57:565 58:566 59:567 60:568 61:569 62:570 63:571 64:572 65:573 66:574 67:574 68:574 69:574 70:575 71:576 72:576 73:577 74:578 75:578 76:578 77:578 78:579 79:580 80:581 81:582 82:582 83:582 84:583 85:584 86:585 87:586 88:587 89:588 90:588 91:589 92:589 93:589 94:590 95:591 96:592 97:593 98:594 99:594 100:594 101:595 102:595 103:596 104:597 105:597 106:598 107:599 108:599 109:599 110:599 111:599 112:599 113:600 114:600 115:601 116:602 117:602 118:602 119:603 120:604 121:605 122:606 123:607 124:607 125:607 126:608 127:609 128:609 129:609 130:610 131:610 132:611 133:612 134:613 135:614 136:615 137:616 138:617 139:618 140:619 141:619 142:619 143:619 144:620 145:621 146:621 147:621 148:621 149:621 150:622 151:622 152:622 153:622 154:622 155:623 156:623 157:623 158:623 159:623 160:623 161:624 162:625 163:626 164:627 165:628 166:629 167:630 168:631 169:631 170:631 171:631 172:632 173:632 174:633 175:634 176:635 177:636 178:637 179:638 180:639 181:639 182:640 183:641 184:642 185:643 186:643 187:644 188:645 189:646 190:647 191:648 192:649 193:650 194:651 195:652 196:652 197:652 198:653 199:654 200:654 201:654 202:655 203:656 204:657 205:658 206:659 207:660 208:661 209:662 210:663 211:664 212:665 213:665 214:666 215:666 216:667 217:668 218:669 219:670 220:671 221:672 222:672 223:672 224:673 225:674 226:675 227:676 228:677 229:678 230:679 231:680 232:680 233:680 234:681 235:681 236:681 237:681 238:681 239:681 240:681 241:682 242:682 243:682 244:682 245:683 246:683 247:683 248:683 249:684 250:685 251:685 252:685 253:685 254:685 255:685 256:686 257:687 258:688 259:689 260:690 261:690 262:691 263:691 264:691 265:692 266:693 267:693 268:693 269:694 270:694 271:695 272:695 273:695 274:696 275:696 276:697 277:697 278:697 279:698 280:698 281:699 282:700 283:701 284:702 285:703 286:704 287:705 288:705 289:706 290:706 291:707 292:708 293:708 294:708 295:709 296:710 297:710 298:710 299:710 300:710 301:711 302:712 303:713 304:714 305:715 306:716 307:716 308:716 309:717 310:718 311:718 312:718 313:719 314:720 315:721 316:722 317:723 318:724 319:725 320:726 321:727 322:728 323:729 324:730 325:730 326:730 327:731 328:732 329:732 330:732 331:733 332:734 333:735 334:735 335:735 336:736 337:737 338:737 339:737 340:738 341:738 342:739 343:740 344:740 345:741 346:742 347:742 348:742 349:742 350:742 351:742 352:743 353:744 354:744 355:745 356:746 357:746 358:746 359:746 360:746 361:747 362:748 363:749 364:750 365:750 366:751 367:752 368:753 369:754 370:755 371:755 372:755 373:755 374:755 375:756 376:756 377:756 378:756 379:756 380:756 381:756 382:757\n",
      "I1208 12:27:37.100979 139883775852736 run_factoid.py:445] token_to_orig_map: 8:536 9:537 10:538 11:539 12:539 13:540 14:541 15:542 16:543 17:543 18:543 19:543 20:544 21:544 22:545 23:545 24:546 25:547 26:548 27:549 28:550 29:551 30:552 31:552 32:553 33:554 34:555 35:556 36:557 37:558 38:559 39:560 40:561 41:561 42:562 43:563 44:563 45:563 46:563 47:564 48:564 49:564 50:564 51:564 52:565 53:565 54:565 55:565 56:565 57:565 58:566 59:567 60:568 61:569 62:570 63:571 64:572 65:573 66:574 67:574 68:574 69:574 70:575 71:576 72:576 73:577 74:578 75:578 76:578 77:578 78:579 79:580 80:581 81:582 82:582 83:582 84:583 85:584 86:585 87:586 88:587 89:588 90:588 91:589 92:589 93:589 94:590 95:591 96:592 97:593 98:594 99:594 100:594 101:595 102:595 103:596 104:597 105:597 106:598 107:599 108:599 109:599 110:599 111:599 112:599 113:600 114:600 115:601 116:602 117:602 118:602 119:603 120:604 121:605 122:606 123:607 124:607 125:607 126:608 127:609 128:609 129:609 130:610 131:610 132:611 133:612 134:613 135:614 136:615 137:616 138:617 139:618 140:619 141:619 142:619 143:619 144:620 145:621 146:621 147:621 148:621 149:621 150:622 151:622 152:622 153:622 154:622 155:623 156:623 157:623 158:623 159:623 160:623 161:624 162:625 163:626 164:627 165:628 166:629 167:630 168:631 169:631 170:631 171:631 172:632 173:632 174:633 175:634 176:635 177:636 178:637 179:638 180:639 181:639 182:640 183:641 184:642 185:643 186:643 187:644 188:645 189:646 190:647 191:648 192:649 193:650 194:651 195:652 196:652 197:652 198:653 199:654 200:654 201:654 202:655 203:656 204:657 205:658 206:659 207:660 208:661 209:662 210:663 211:664 212:665 213:665 214:666 215:666 216:667 217:668 218:669 219:670 220:671 221:672 222:672 223:672 224:673 225:674 226:675 227:676 228:677 229:678 230:679 231:680 232:680 233:680 234:681 235:681 236:681 237:681 238:681 239:681 240:681 241:682 242:682 243:682 244:682 245:683 246:683 247:683 248:683 249:684 250:685 251:685 252:685 253:685 254:685 255:685 256:686 257:687 258:688 259:689 260:690 261:690 262:691 263:691 264:691 265:692 266:693 267:693 268:693 269:694 270:694 271:695 272:695 273:695 274:696 275:696 276:697 277:697 278:697 279:698 280:698 281:699 282:700 283:701 284:702 285:703 286:704 287:705 288:705 289:706 290:706 291:707 292:708 293:708 294:708 295:709 296:710 297:710 298:710 299:710 300:710 301:711 302:712 303:713 304:714 305:715 306:716 307:716 308:716 309:717 310:718 311:718 312:718 313:719 314:720 315:721 316:722 317:723 318:724 319:725 320:726 321:727 322:728 323:729 324:730 325:730 326:730 327:731 328:732 329:732 330:732 331:733 332:734 333:735 334:735 335:735 336:736 337:737 338:737 339:737 340:738 341:738 342:739 343:740 344:740 345:741 346:742 347:742 348:742 349:742 350:742 351:742 352:743 353:744 354:744 355:745 356:746 357:746 358:746 359:746 360:746 361:747 362:748 363:749 364:750 365:750 366:751 367:752 368:753 369:754 370:755 371:755 372:755 373:755 374:755 375:756 376:756 377:756 378:756 379:756 380:756 381:756 382:757\n",
      "INFO:tensorflow:token_is_max_context: 8:False 9:False 10:False 11:False 12:False 13:False 14:False 15:False 16:False 17:False 18:False 19:False 20:False 21:False 22:False 23:False 24:False 25:False 26:False 27:False 28:False 29:False 30:False 31:False 32:False 33:False 34:False 35:False 36:False 37:False 38:False 39:False 40:False 41:False 42:False 43:False 44:False 45:False 46:False 47:False 48:False 49:False 50:False 51:False 52:False 53:False 54:False 55:False 56:False 57:False 58:False 59:False 60:False 61:False 62:False 63:False 64:False 65:False 66:False 67:False 68:False 69:False 70:False 71:False 72:False 73:False 74:False 75:False 76:False 77:False 78:False 79:False 80:False 81:False 82:False 83:False 84:False 85:False 86:False 87:False 88:False 89:False 90:False 91:False 92:False 93:False 94:False 95:False 96:False 97:False 98:False 99:False 100:False 101:False 102:False 103:False 104:False 105:False 106:False 107:False 108:False 109:False 110:False 111:False 112:False 113:False 114:False 115:False 116:False 117:False 118:False 119:False 120:False 121:False 122:False 123:False 124:False 125:False 126:False 127:False 128:False 129:False 130:False 131:False 132:True 133:True 134:True 135:True 136:True 137:True 138:True 139:True 140:True 141:True 142:True 143:True 144:True 145:True 146:True 147:True 148:True 149:True 150:True 151:True 152:True 153:True 154:True 155:True 156:True 157:True 158:True 159:True 160:True 161:True 162:True 163:True 164:True 165:True 166:True 167:True 168:True 169:True 170:True 171:True 172:True 173:True 174:True 175:True 176:True 177:True 178:True 179:True 180:True 181:True 182:True 183:True 184:True 185:True 186:True 187:True 188:True 189:True 190:True 191:True 192:True 193:True 194:True 195:True 196:True 197:True 198:True 199:True 200:True 201:True 202:True 203:True 204:True 205:True 206:True 207:True 208:True 209:True 210:True 211:True 212:True 213:True 214:True 215:True 216:True 217:True 218:True 219:True 220:True 221:True 222:True 223:True 224:True 225:True 226:True 227:True 228:True 229:True 230:True 231:True 232:True 233:True 234:True 235:True 236:True 237:True 238:True 239:True 240:True 241:True 242:True 243:True 244:True 245:True 246:True 247:True 248:True 249:True 250:True 251:True 252:True 253:True 254:True 255:True 256:True 257:True 258:True 259:True 260:False 261:False 262:False 263:False 264:False 265:False 266:False 267:False 268:False 269:False 270:False 271:False 272:False 273:False 274:False 275:False 276:False 277:False 278:False 279:False 280:False 281:False 282:False 283:False 284:False 285:False 286:False 287:False 288:False 289:False 290:False 291:False 292:False 293:False 294:False 295:False 296:False 297:False 298:False 299:False 300:False 301:False 302:False 303:False 304:False 305:False 306:False 307:False 308:False 309:False 310:False 311:False 312:False 313:False 314:False 315:False 316:False 317:False 318:False 319:False 320:False 321:False 322:False 323:False 324:False 325:False 326:False 327:False 328:False 329:False 330:False 331:False 332:False 333:False 334:False 335:False 336:False 337:False 338:False 339:False 340:False 341:False 342:False 343:False 344:False 345:False 346:False 347:False 348:False 349:False 350:False 351:False 352:False 353:False 354:False 355:False 356:False 357:False 358:False 359:False 360:False 361:False 362:False 363:False 364:False 365:False 366:False 367:False 368:False 369:False 370:False 371:False 372:False 373:False 374:False 375:False 376:False 377:False 378:False 379:False 380:False 381:False 382:False\n",
      "I1208 12:27:37.101092 139883775852736 run_factoid.py:447] token_is_max_context: 8:False 9:False 10:False 11:False 12:False 13:False 14:False 15:False 16:False 17:False 18:False 19:False 20:False 21:False 22:False 23:False 24:False 25:False 26:False 27:False 28:False 29:False 30:False 31:False 32:False 33:False 34:False 35:False 36:False 37:False 38:False 39:False 40:False 41:False 42:False 43:False 44:False 45:False 46:False 47:False 48:False 49:False 50:False 51:False 52:False 53:False 54:False 55:False 56:False 57:False 58:False 59:False 60:False 61:False 62:False 63:False 64:False 65:False 66:False 67:False 68:False 69:False 70:False 71:False 72:False 73:False 74:False 75:False 76:False 77:False 78:False 79:False 80:False 81:False 82:False 83:False 84:False 85:False 86:False 87:False 88:False 89:False 90:False 91:False 92:False 93:False 94:False 95:False 96:False 97:False 98:False 99:False 100:False 101:False 102:False 103:False 104:False 105:False 106:False 107:False 108:False 109:False 110:False 111:False 112:False 113:False 114:False 115:False 116:False 117:False 118:False 119:False 120:False 121:False 122:False 123:False 124:False 125:False 126:False 127:False 128:False 129:False 130:False 131:False 132:True 133:True 134:True 135:True 136:True 137:True 138:True 139:True 140:True 141:True 142:True 143:True 144:True 145:True 146:True 147:True 148:True 149:True 150:True 151:True 152:True 153:True 154:True 155:True 156:True 157:True 158:True 159:True 160:True 161:True 162:True 163:True 164:True 165:True 166:True 167:True 168:True 169:True 170:True 171:True 172:True 173:True 174:True 175:True 176:True 177:True 178:True 179:True 180:True 181:True 182:True 183:True 184:True 185:True 186:True 187:True 188:True 189:True 190:True 191:True 192:True 193:True 194:True 195:True 196:True 197:True 198:True 199:True 200:True 201:True 202:True 203:True 204:True 205:True 206:True 207:True 208:True 209:True 210:True 211:True 212:True 213:True 214:True 215:True 216:True 217:True 218:True 219:True 220:True 221:True 222:True 223:True 224:True 225:True 226:True 227:True 228:True 229:True 230:True 231:True 232:True 233:True 234:True 235:True 236:True 237:True 238:True 239:True 240:True 241:True 242:True 243:True 244:True 245:True 246:True 247:True 248:True 249:True 250:True 251:True 252:True 253:True 254:True 255:True 256:True 257:True 258:True 259:True 260:False 261:False 262:False 263:False 264:False 265:False 266:False 267:False 268:False 269:False 270:False 271:False 272:False 273:False 274:False 275:False 276:False 277:False 278:False 279:False 280:False 281:False 282:False 283:False 284:False 285:False 286:False 287:False 288:False 289:False 290:False 291:False 292:False 293:False 294:False 295:False 296:False 297:False 298:False 299:False 300:False 301:False 302:False 303:False 304:False 305:False 306:False 307:False 308:False 309:False 310:False 311:False 312:False 313:False 314:False 315:False 316:False 317:False 318:False 319:False 320:False 321:False 322:False 323:False 324:False 325:False 326:False 327:False 328:False 329:False 330:False 331:False 332:False 333:False 334:False 335:False 336:False 337:False 338:False 339:False 340:False 341:False 342:False 343:False 344:False 345:False 346:False 347:False 348:False 349:False 350:False 351:False 352:False 353:False 354:False 355:False 356:False 357:False 358:False 359:False 360:False 361:False 362:False 363:False 364:False 365:False 366:False 367:False 368:False 369:False 370:False 371:False 372:False 373:False 374:False 375:False 376:False 377:False 378:False 379:False 380:False 381:False 382:False\n",
      "INFO:tensorflow:input_ids: 101 1327 1225 1103 2526 1525 136 102 1112 3402 1114 5942 110 1104 4420 1114 17599 6385 10805 4571 5531 119 1438 117 1103 3719 1206 1172 1108 1136 2418 119 1130 5014 1106 1103 2211 2244 5600 1104 152 22074 1105 17599 6385 10805 4571 6187 10294 18778 1183 117 26574 1708 118 157 2162 15499 1882 1106 1138 170 2299 2244 2603 1190 153 21678 2137 119 8411 140 117 3084 2393 164 3882 166 2103 170 19916 1884 13252 1204 2025 1104 25182 4420 1114 1231 21754 149 2137 3048 1150 1127 5165 1114 153 21678 2137 113 183 134 21040 114 1137 26574 1708 118 157 2162 15499 113 183 134 18868 114 119 1335 1103 1928 9355 2812 118 1146 1104 3993 119 126 1808 117 1103 2244 2603 1107 1103 1160 2114 1108 5539 119 124 110 1105 4573 119 123 110 117 3569 119 164 3882 166 26574 1708 118 157 2162 15499 3657 1107 170 2299 2244 2603 1190 153 21678 2137 117 1649 117 1175 1108 1185 2418 3719 1206 1172 119 23840 1103 2805 1159 117 1103 1675 2025 7160 1115 4420 5165 1114 153 21678 2137 1125 1407 119 1489 1904 1750 1104 2805 1159 1190 1343 1114 1168 13467 22496 119 1438 117 1103 3549 2805 1159 1104 153 21678 2137 1108 1178 4379 1107 1103 7577 1114 152 22074 117 26574 1708 118 157 2162 15499 117 17599 6385 10805 4571 6187 10294 18778 1183 1105 17599 10396 2093 5822 18574 119 22439 1114 1292 13467 8015 117 153 21678 2137 1125 1429 119 5046 1904 117 3453 119 1695 1904 117 1695 119 1626 1904 117 1105 1542 1904 1750 1104 2805 1159 117 3569 119 4246 150 4538 117 3084 2393 119 164 3140 166 3402 1103 7300 13950 1104 153 21678 2137 1114 152 22074 117 1105 1152 1276 1103 2805 1159 1107 1292 1160 2114 1108 4389 119 121 212 1492 119 121 1904 1105 3324 119 127 212 1743 119 128 1904 117 3569 113 153 133 121 119 3135 1475 114 119 27762 162 117 3084 2393 119 164 2532 166 14758 1103 1210 10298 1193 19849 8340 13467 8015 113 153 21678 2137 117 26574 1708 118 157 2162 15499 117 1105 102\n",
      "I1208 12:27:37.101192 139883775852736 run_factoid.py:449] input_ids: 101 1327 1225 1103 2526 1525 136 102 1112 3402 1114 5942 110 1104 4420 1114 17599 6385 10805 4571 5531 119 1438 117 1103 3719 1206 1172 1108 1136 2418 119 1130 5014 1106 1103 2211 2244 5600 1104 152 22074 1105 17599 6385 10805 4571 6187 10294 18778 1183 117 26574 1708 118 157 2162 15499 1882 1106 1138 170 2299 2244 2603 1190 153 21678 2137 119 8411 140 117 3084 2393 164 3882 166 2103 170 19916 1884 13252 1204 2025 1104 25182 4420 1114 1231 21754 149 2137 3048 1150 1127 5165 1114 153 21678 2137 113 183 134 21040 114 1137 26574 1708 118 157 2162 15499 113 183 134 18868 114 119 1335 1103 1928 9355 2812 118 1146 1104 3993 119 126 1808 117 1103 2244 2603 1107 1103 1160 2114 1108 5539 119 124 110 1105 4573 119 123 110 117 3569 119 164 3882 166 26574 1708 118 157 2162 15499 3657 1107 170 2299 2244 2603 1190 153 21678 2137 117 1649 117 1175 1108 1185 2418 3719 1206 1172 119 23840 1103 2805 1159 117 1103 1675 2025 7160 1115 4420 5165 1114 153 21678 2137 1125 1407 119 1489 1904 1750 1104 2805 1159 1190 1343 1114 1168 13467 22496 119 1438 117 1103 3549 2805 1159 1104 153 21678 2137 1108 1178 4379 1107 1103 7577 1114 152 22074 117 26574 1708 118 157 2162 15499 117 17599 6385 10805 4571 6187 10294 18778 1183 1105 17599 10396 2093 5822 18574 119 22439 1114 1292 13467 8015 117 153 21678 2137 1125 1429 119 5046 1904 117 3453 119 1695 1904 117 1695 119 1626 1904 117 1105 1542 1904 1750 1104 2805 1159 117 3569 119 4246 150 4538 117 3084 2393 119 164 3140 166 3402 1103 7300 13950 1104 153 21678 2137 1114 152 22074 117 1105 1152 1276 1103 2805 1159 1107 1292 1160 2114 1108 4389 119 121 212 1492 119 121 1904 1105 3324 119 127 212 1743 119 128 1904 117 3569 113 153 133 121 119 3135 1475 114 119 27762 162 117 3084 2393 119 164 2532 166 14758 1103 1210 10298 1193 19849 8340 13467 8015 113 153 21678 2137 117 26574 1708 118 157 2162 15499 117 1105 102\n",
      "INFO:tensorflow:input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      "I1208 12:27:37.101284 139883775852736 run_factoid.py:451] input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      "INFO:tensorflow:segment_ids: 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      "I1208 12:27:37.101373 139883775852736 run_factoid.py:453] segment_ids: 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      "INFO:tensorflow:*** Example ***\n",
      "I1208 12:27:37.103215 139883775852736 run_factoid.py:438] *** Example ***\n",
      "INFO:tensorflow:unique_id: 1000000035\n",
      "I1208 12:27:37.103274 139883775852736 run_factoid.py:439] unique_id: 1000000035\n",
      "INFO:tensorflow:example_index: 7\n",
      "I1208 12:27:37.103314 139883775852736 run_factoid.py:440] example_index: 7\n",
      "INFO:tensorflow:doc_span_index: 8\n",
      "I1208 12:27:37.103346 139883775852736 run_factoid.py:441] doc_span_index: 8\n",
      "INFO:tensorflow:tokens: [CLS] What did the paper find ? [SEP] the two groups was 91 . 3 % and 95 . 2 % , respectively . [ 52 ] MI ##S - T ##L ##IF resulted in a higher success rate than P ##EL ##D , however , there was no significant difference between them . Regarding the operation time , the present study demonstrated that patients treated with P ##EL ##D had 18 . 14 minutes less of operation time than those with other surgical interventions . However , the reduced operation time of P ##EL ##D was only observed in the comparison with O ##LM , MI ##S - T ##L ##IF , micro ##su ##rg ##ical disc ##ec ##tom ##y and micro ##dis ##ce ##ct ##omy . Compared with these surgical approaches , P ##EL ##D had 11 . 66 minutes , 75 . 23 minutes , 23 . 21 minutes , and 17 minutes less of operation time , respectively . Kim M ##J , et al . [ 44 ] compared the clinical outcomes of P ##EL ##D with O ##LM , and they found the operation time in these two groups was 53 . 0 ± 13 . 0 minutes and 64 . 6 ± 28 . 7 minutes , respectively ( P < 0 . 00 ##1 ) . Yao Y , et al . [ 45 ] assessed the three minimal ##ly invasive spine surgical approaches ( P ##EL ##D , MI ##S - T ##L ##IF , and ME ##D ) for re ##current her ##nia ##tion , and the mean operation time between them was 75 . 0 ± 31 . 56 minutes , 146 . 54 ± 38 . 07 minutes , and 85 . 25 ± 41 . 60 minutes , respectively . P ##EL ##D had a significantly less operation time than MI ##S - T ##L ##IF , but a comparable operation time with ME ##D . The functional outcomes were assessed by the VA ##S scores for back pain and leg pain . Our results suggested that patients treated with P ##EL ##D had comparable post ##oper ##ation VA ##S scores for back pain and leg pain with those treated with other surge ##ries . Our result was in consistent [SEP]\n",
      "I1208 12:27:37.103456 139883775852736 run_factoid.py:443] tokens: [CLS] What did the paper find ? [SEP] the two groups was 91 . 3 % and 95 . 2 % , respectively . [ 52 ] MI ##S - T ##L ##IF resulted in a higher success rate than P ##EL ##D , however , there was no significant difference between them . Regarding the operation time , the present study demonstrated that patients treated with P ##EL ##D had 18 . 14 minutes less of operation time than those with other surgical interventions . However , the reduced operation time of P ##EL ##D was only observed in the comparison with O ##LM , MI ##S - T ##L ##IF , micro ##su ##rg ##ical disc ##ec ##tom ##y and micro ##dis ##ce ##ct ##omy . Compared with these surgical approaches , P ##EL ##D had 11 . 66 minutes , 75 . 23 minutes , 23 . 21 minutes , and 17 minutes less of operation time , respectively . Kim M ##J , et al . [ 44 ] compared the clinical outcomes of P ##EL ##D with O ##LM , and they found the operation time in these two groups was 53 . 0 ± 13 . 0 minutes and 64 . 6 ± 28 . 7 minutes , respectively ( P < 0 . 00 ##1 ) . Yao Y , et al . [ 45 ] assessed the three minimal ##ly invasive spine surgical approaches ( P ##EL ##D , MI ##S - T ##L ##IF , and ME ##D ) for re ##current her ##nia ##tion , and the mean operation time between them was 75 . 0 ± 31 . 56 minutes , 146 . 54 ± 38 . 07 minutes , and 85 . 25 ± 41 . 60 minutes , respectively . P ##EL ##D had a significantly less operation time than MI ##S - T ##L ##IF , but a comparable operation time with ME ##D . The functional outcomes were assessed by the VA ##S scores for back pain and leg pain . Our results suggested that patients treated with P ##EL ##D had comparable post ##oper ##ation VA ##S scores for back pain and leg pain with those treated with other surge ##ries . Our result was in consistent [SEP]\n",
      "INFO:tensorflow:token_to_orig_map: 8:615 9:616 10:617 11:618 12:619 13:619 14:619 15:619 16:620 17:621 18:621 19:621 20:621 21:621 22:622 23:622 24:622 25:622 26:622 27:623 28:623 29:623 30:623 31:623 32:623 33:624 34:625 35:626 36:627 37:628 38:629 39:630 40:631 41:631 42:631 43:631 44:632 45:632 46:633 47:634 48:635 49:636 50:637 51:638 52:639 53:639 54:640 55:641 56:642 57:643 58:643 59:644 60:645 61:646 62:647 63:648 64:649 65:650 66:651 67:652 68:652 69:652 70:653 71:654 72:654 73:654 74:655 75:656 76:657 77:658 78:659 79:660 80:661 81:662 82:663 83:664 84:665 85:665 86:666 87:666 88:667 89:668 90:669 91:670 92:671 93:672 94:672 95:672 96:673 97:674 98:675 99:676 100:677 101:678 102:679 103:680 104:680 105:680 106:681 107:681 108:681 109:681 110:681 111:681 112:681 113:682 114:682 115:682 116:682 117:683 118:683 119:683 120:683 121:684 122:685 123:685 124:685 125:685 126:685 127:685 128:686 129:687 130:688 131:689 132:690 133:690 134:691 135:691 136:691 137:692 138:693 139:693 140:693 141:694 142:694 143:695 144:695 145:695 146:696 147:696 148:697 149:697 150:697 151:698 152:698 153:699 154:700 155:701 156:702 157:703 158:704 159:705 160:705 161:706 162:706 163:707 164:708 165:708 166:708 167:709 168:710 169:710 170:710 171:710 172:710 173:711 174:712 175:713 176:714 177:715 178:716 179:716 180:716 181:717 182:718 183:718 184:718 185:719 186:720 187:721 188:722 189:723 190:724 191:725 192:726 193:727 194:728 195:729 196:730 197:730 198:730 199:731 200:732 201:732 202:732 203:733 204:734 205:735 206:735 207:735 208:736 209:737 210:737 211:737 212:738 213:738 214:739 215:740 216:740 217:741 218:742 219:742 220:742 221:742 222:742 223:742 224:743 225:744 226:744 227:745 228:746 229:746 230:746 231:746 232:746 233:747 234:748 235:749 236:750 237:750 238:751 239:752 240:753 241:754 242:755 243:755 244:755 245:755 246:755 247:756 248:756 249:756 250:756 251:756 252:756 253:756 254:757 255:758 256:758 257:758 258:759 259:760 260:760 261:761 262:761 263:761 264:761 265:762 266:763 267:764 268:765 269:766 270:767 271:768 272:769 273:770 274:770 275:770 276:771 277:772 278:772 279:772 280:773 281:773 282:774 283:774 284:774 285:775 286:776 287:776 288:776 289:777 290:777 291:778 292:779 293:779 294:779 295:780 296:781 297:781 298:781 299:782 300:782 301:783 302:783 303:784 304:784 305:784 306:785 307:786 308:787 309:788 310:789 311:790 312:791 313:792 314:792 315:792 316:792 317:792 318:792 319:792 320:793 321:794 322:795 323:796 324:797 325:798 326:799 327:799 328:799 329:800 330:801 331:802 332:803 333:804 334:805 335:806 336:807 337:807 338:808 339:809 340:810 341:811 342:812 343:813 344:814 345:814 346:815 347:816 348:817 349:818 350:819 351:820 352:821 353:822 354:822 355:822 356:823 357:824 358:825 359:825 360:825 361:826 362:826 363:827 364:828 365:829 366:830 367:831 368:832 369:833 370:834 371:835 372:836 373:837 374:838 375:839 376:839 377:839 378:840 379:841 380:842 381:843 382:844\n",
      "I1208 12:27:37.103574 139883775852736 run_factoid.py:445] token_to_orig_map: 8:615 9:616 10:617 11:618 12:619 13:619 14:619 15:619 16:620 17:621 18:621 19:621 20:621 21:621 22:622 23:622 24:622 25:622 26:622 27:623 28:623 29:623 30:623 31:623 32:623 33:624 34:625 35:626 36:627 37:628 38:629 39:630 40:631 41:631 42:631 43:631 44:632 45:632 46:633 47:634 48:635 49:636 50:637 51:638 52:639 53:639 54:640 55:641 56:642 57:643 58:643 59:644 60:645 61:646 62:647 63:648 64:649 65:650 66:651 67:652 68:652 69:652 70:653 71:654 72:654 73:654 74:655 75:656 76:657 77:658 78:659 79:660 80:661 81:662 82:663 83:664 84:665 85:665 86:666 87:666 88:667 89:668 90:669 91:670 92:671 93:672 94:672 95:672 96:673 97:674 98:675 99:676 100:677 101:678 102:679 103:680 104:680 105:680 106:681 107:681 108:681 109:681 110:681 111:681 112:681 113:682 114:682 115:682 116:682 117:683 118:683 119:683 120:683 121:684 122:685 123:685 124:685 125:685 126:685 127:685 128:686 129:687 130:688 131:689 132:690 133:690 134:691 135:691 136:691 137:692 138:693 139:693 140:693 141:694 142:694 143:695 144:695 145:695 146:696 147:696 148:697 149:697 150:697 151:698 152:698 153:699 154:700 155:701 156:702 157:703 158:704 159:705 160:705 161:706 162:706 163:707 164:708 165:708 166:708 167:709 168:710 169:710 170:710 171:710 172:710 173:711 174:712 175:713 176:714 177:715 178:716 179:716 180:716 181:717 182:718 183:718 184:718 185:719 186:720 187:721 188:722 189:723 190:724 191:725 192:726 193:727 194:728 195:729 196:730 197:730 198:730 199:731 200:732 201:732 202:732 203:733 204:734 205:735 206:735 207:735 208:736 209:737 210:737 211:737 212:738 213:738 214:739 215:740 216:740 217:741 218:742 219:742 220:742 221:742 222:742 223:742 224:743 225:744 226:744 227:745 228:746 229:746 230:746 231:746 232:746 233:747 234:748 235:749 236:750 237:750 238:751 239:752 240:753 241:754 242:755 243:755 244:755 245:755 246:755 247:756 248:756 249:756 250:756 251:756 252:756 253:756 254:757 255:758 256:758 257:758 258:759 259:760 260:760 261:761 262:761 263:761 264:761 265:762 266:763 267:764 268:765 269:766 270:767 271:768 272:769 273:770 274:770 275:770 276:771 277:772 278:772 279:772 280:773 281:773 282:774 283:774 284:774 285:775 286:776 287:776 288:776 289:777 290:777 291:778 292:779 293:779 294:779 295:780 296:781 297:781 298:781 299:782 300:782 301:783 302:783 303:784 304:784 305:784 306:785 307:786 308:787 309:788 310:789 311:790 312:791 313:792 314:792 315:792 316:792 317:792 318:792 319:792 320:793 321:794 322:795 323:796 324:797 325:798 326:799 327:799 328:799 329:800 330:801 331:802 332:803 333:804 334:805 335:806 336:807 337:807 338:808 339:809 340:810 341:811 342:812 343:813 344:814 345:814 346:815 347:816 348:817 349:818 350:819 351:820 352:821 353:822 354:822 355:822 356:823 357:824 358:825 359:825 360:825 361:826 362:826 363:827 364:828 365:829 366:830 367:831 368:832 369:833 370:834 371:835 372:836 373:837 374:838 375:839 376:839 377:839 378:840 379:841 380:842 381:843 382:844\n",
      "INFO:tensorflow:token_is_max_context: 8:False 9:False 10:False 11:False 12:False 13:False 14:False 15:False 16:False 17:False 18:False 19:False 20:False 21:False 22:False 23:False 24:False 25:False 26:False 27:False 28:False 29:False 30:False 31:False 32:False 33:False 34:False 35:False 36:False 37:False 38:False 39:False 40:False 41:False 42:False 43:False 44:False 45:False 46:False 47:False 48:False 49:False 50:False 51:False 52:False 53:False 54:False 55:False 56:False 57:False 58:False 59:False 60:False 61:False 62:False 63:False 64:False 65:False 66:False 67:False 68:False 69:False 70:False 71:False 72:False 73:False 74:False 75:False 76:False 77:False 78:False 79:False 80:False 81:False 82:False 83:False 84:False 85:False 86:False 87:False 88:False 89:False 90:False 91:False 92:False 93:False 94:False 95:False 96:False 97:False 98:False 99:False 100:False 101:False 102:False 103:False 104:False 105:False 106:False 107:False 108:False 109:False 110:False 111:False 112:False 113:False 114:False 115:False 116:False 117:False 118:False 119:False 120:False 121:False 122:False 123:False 124:False 125:False 126:False 127:False 128:False 129:False 130:False 131:False 132:True 133:True 134:True 135:True 136:True 137:True 138:True 139:True 140:True 141:True 142:True 143:True 144:True 145:True 146:True 147:True 148:True 149:True 150:True 151:True 152:True 153:True 154:True 155:True 156:True 157:True 158:True 159:True 160:True 161:True 162:True 163:True 164:True 165:True 166:True 167:True 168:True 169:True 170:True 171:True 172:True 173:True 174:True 175:True 176:True 177:True 178:True 179:True 180:True 181:True 182:True 183:True 184:True 185:True 186:True 187:True 188:True 189:True 190:True 191:True 192:True 193:True 194:True 195:True 196:True 197:True 198:True 199:True 200:True 201:True 202:True 203:True 204:True 205:True 206:True 207:True 208:True 209:True 210:True 211:True 212:True 213:True 214:True 215:True 216:True 217:True 218:True 219:True 220:True 221:True 222:True 223:True 224:True 225:True 226:True 227:True 228:True 229:True 230:True 231:True 232:True 233:True 234:True 235:True 236:True 237:True 238:True 239:True 240:True 241:True 242:True 243:True 244:True 245:True 246:True 247:True 248:True 249:True 250:True 251:True 252:True 253:True 254:True 255:True 256:True 257:True 258:True 259:True 260:False 261:False 262:False 263:False 264:False 265:False 266:False 267:False 268:False 269:False 270:False 271:False 272:False 273:False 274:False 275:False 276:False 277:False 278:False 279:False 280:False 281:False 282:False 283:False 284:False 285:False 286:False 287:False 288:False 289:False 290:False 291:False 292:False 293:False 294:False 295:False 296:False 297:False 298:False 299:False 300:False 301:False 302:False 303:False 304:False 305:False 306:False 307:False 308:False 309:False 310:False 311:False 312:False 313:False 314:False 315:False 316:False 317:False 318:False 319:False 320:False 321:False 322:False 323:False 324:False 325:False 326:False 327:False 328:False 329:False 330:False 331:False 332:False 333:False 334:False 335:False 336:False 337:False 338:False 339:False 340:False 341:False 342:False 343:False 344:False 345:False 346:False 347:False 348:False 349:False 350:False 351:False 352:False 353:False 354:False 355:False 356:False 357:False 358:False 359:False 360:False 361:False 362:False 363:False 364:False 365:False 366:False 367:False 368:False 369:False 370:False 371:False 372:False 373:False 374:False 375:False 376:False 377:False 378:False 379:False 380:False 381:False 382:False\n",
      "I1208 12:27:37.103684 139883775852736 run_factoid.py:447] token_is_max_context: 8:False 9:False 10:False 11:False 12:False 13:False 14:False 15:False 16:False 17:False 18:False 19:False 20:False 21:False 22:False 23:False 24:False 25:False 26:False 27:False 28:False 29:False 30:False 31:False 32:False 33:False 34:False 35:False 36:False 37:False 38:False 39:False 40:False 41:False 42:False 43:False 44:False 45:False 46:False 47:False 48:False 49:False 50:False 51:False 52:False 53:False 54:False 55:False 56:False 57:False 58:False 59:False 60:False 61:False 62:False 63:False 64:False 65:False 66:False 67:False 68:False 69:False 70:False 71:False 72:False 73:False 74:False 75:False 76:False 77:False 78:False 79:False 80:False 81:False 82:False 83:False 84:False 85:False 86:False 87:False 88:False 89:False 90:False 91:False 92:False 93:False 94:False 95:False 96:False 97:False 98:False 99:False 100:False 101:False 102:False 103:False 104:False 105:False 106:False 107:False 108:False 109:False 110:False 111:False 112:False 113:False 114:False 115:False 116:False 117:False 118:False 119:False 120:False 121:False 122:False 123:False 124:False 125:False 126:False 127:False 128:False 129:False 130:False 131:False 132:True 133:True 134:True 135:True 136:True 137:True 138:True 139:True 140:True 141:True 142:True 143:True 144:True 145:True 146:True 147:True 148:True 149:True 150:True 151:True 152:True 153:True 154:True 155:True 156:True 157:True 158:True 159:True 160:True 161:True 162:True 163:True 164:True 165:True 166:True 167:True 168:True 169:True 170:True 171:True 172:True 173:True 174:True 175:True 176:True 177:True 178:True 179:True 180:True 181:True 182:True 183:True 184:True 185:True 186:True 187:True 188:True 189:True 190:True 191:True 192:True 193:True 194:True 195:True 196:True 197:True 198:True 199:True 200:True 201:True 202:True 203:True 204:True 205:True 206:True 207:True 208:True 209:True 210:True 211:True 212:True 213:True 214:True 215:True 216:True 217:True 218:True 219:True 220:True 221:True 222:True 223:True 224:True 225:True 226:True 227:True 228:True 229:True 230:True 231:True 232:True 233:True 234:True 235:True 236:True 237:True 238:True 239:True 240:True 241:True 242:True 243:True 244:True 245:True 246:True 247:True 248:True 249:True 250:True 251:True 252:True 253:True 254:True 255:True 256:True 257:True 258:True 259:True 260:False 261:False 262:False 263:False 264:False 265:False 266:False 267:False 268:False 269:False 270:False 271:False 272:False 273:False 274:False 275:False 276:False 277:False 278:False 279:False 280:False 281:False 282:False 283:False 284:False 285:False 286:False 287:False 288:False 289:False 290:False 291:False 292:False 293:False 294:False 295:False 296:False 297:False 298:False 299:False 300:False 301:False 302:False 303:False 304:False 305:False 306:False 307:False 308:False 309:False 310:False 311:False 312:False 313:False 314:False 315:False 316:False 317:False 318:False 319:False 320:False 321:False 322:False 323:False 324:False 325:False 326:False 327:False 328:False 329:False 330:False 331:False 332:False 333:False 334:False 335:False 336:False 337:False 338:False 339:False 340:False 341:False 342:False 343:False 344:False 345:False 346:False 347:False 348:False 349:False 350:False 351:False 352:False 353:False 354:False 355:False 356:False 357:False 358:False 359:False 360:False 361:False 362:False 363:False 364:False 365:False 366:False 367:False 368:False 369:False 370:False 371:False 372:False 373:False 374:False 375:False 376:False 377:False 378:False 379:False 380:False 381:False 382:False\n",
      "INFO:tensorflow:input_ids: 101 1327 1225 1103 2526 1525 136 102 1103 1160 2114 1108 5539 119 124 110 1105 4573 119 123 110 117 3569 119 164 3882 166 26574 1708 118 157 2162 15499 3657 1107 170 2299 2244 2603 1190 153 21678 2137 117 1649 117 1175 1108 1185 2418 3719 1206 1172 119 23840 1103 2805 1159 117 1103 1675 2025 7160 1115 4420 5165 1114 153 21678 2137 1125 1407 119 1489 1904 1750 1104 2805 1159 1190 1343 1114 1168 13467 22496 119 1438 117 1103 3549 2805 1159 1104 153 21678 2137 1108 1178 4379 1107 1103 7577 1114 152 22074 117 26574 1708 118 157 2162 15499 117 17599 6385 10805 4571 6187 10294 18778 1183 1105 17599 10396 2093 5822 18574 119 22439 1114 1292 13467 8015 117 153 21678 2137 1125 1429 119 5046 1904 117 3453 119 1695 1904 117 1695 119 1626 1904 117 1105 1542 1904 1750 1104 2805 1159 117 3569 119 4246 150 4538 117 3084 2393 119 164 3140 166 3402 1103 7300 13950 1104 153 21678 2137 1114 152 22074 117 1105 1152 1276 1103 2805 1159 1107 1292 1160 2114 1108 4389 119 121 212 1492 119 121 1904 1105 3324 119 127 212 1743 119 128 1904 117 3569 113 153 133 121 119 3135 1475 114 119 27762 162 117 3084 2393 119 164 2532 166 14758 1103 1210 10298 1193 19849 8340 13467 8015 113 153 21678 2137 117 26574 1708 118 157 2162 15499 117 1105 22157 2137 114 1111 1231 21754 1123 5813 2116 117 1105 1103 1928 2805 1159 1206 1172 1108 3453 119 121 212 1955 119 4376 1904 117 17350 119 4335 212 3383 119 5004 1904 117 1105 4859 119 1512 212 3746 119 2539 1904 117 3569 119 153 21678 2137 1125 170 5409 1750 2805 1159 1190 26574 1708 118 157 2162 15499 117 1133 170 12763 2805 1159 1114 22157 2137 119 1109 8458 13950 1127 14758 1118 1103 19497 1708 7432 1111 1171 2489 1105 3420 2489 119 3458 2686 3228 1115 4420 5165 1114 153 21678 2137 1125 12763 2112 19807 1891 19497 1708 7432 1111 1171 2489 1105 3420 2489 1114 1343 5165 1114 1168 12814 3377 119 3458 1871 1108 1107 8080 102\n",
      "I1208 12:27:37.103786 139883775852736 run_factoid.py:449] input_ids: 101 1327 1225 1103 2526 1525 136 102 1103 1160 2114 1108 5539 119 124 110 1105 4573 119 123 110 117 3569 119 164 3882 166 26574 1708 118 157 2162 15499 3657 1107 170 2299 2244 2603 1190 153 21678 2137 117 1649 117 1175 1108 1185 2418 3719 1206 1172 119 23840 1103 2805 1159 117 1103 1675 2025 7160 1115 4420 5165 1114 153 21678 2137 1125 1407 119 1489 1904 1750 1104 2805 1159 1190 1343 1114 1168 13467 22496 119 1438 117 1103 3549 2805 1159 1104 153 21678 2137 1108 1178 4379 1107 1103 7577 1114 152 22074 117 26574 1708 118 157 2162 15499 117 17599 6385 10805 4571 6187 10294 18778 1183 1105 17599 10396 2093 5822 18574 119 22439 1114 1292 13467 8015 117 153 21678 2137 1125 1429 119 5046 1904 117 3453 119 1695 1904 117 1695 119 1626 1904 117 1105 1542 1904 1750 1104 2805 1159 117 3569 119 4246 150 4538 117 3084 2393 119 164 3140 166 3402 1103 7300 13950 1104 153 21678 2137 1114 152 22074 117 1105 1152 1276 1103 2805 1159 1107 1292 1160 2114 1108 4389 119 121 212 1492 119 121 1904 1105 3324 119 127 212 1743 119 128 1904 117 3569 113 153 133 121 119 3135 1475 114 119 27762 162 117 3084 2393 119 164 2532 166 14758 1103 1210 10298 1193 19849 8340 13467 8015 113 153 21678 2137 117 26574 1708 118 157 2162 15499 117 1105 22157 2137 114 1111 1231 21754 1123 5813 2116 117 1105 1103 1928 2805 1159 1206 1172 1108 3453 119 121 212 1955 119 4376 1904 117 17350 119 4335 212 3383 119 5004 1904 117 1105 4859 119 1512 212 3746 119 2539 1904 117 3569 119 153 21678 2137 1125 170 5409 1750 2805 1159 1190 26574 1708 118 157 2162 15499 117 1133 170 12763 2805 1159 1114 22157 2137 119 1109 8458 13950 1127 14758 1118 1103 19497 1708 7432 1111 1171 2489 1105 3420 2489 119 3458 2686 3228 1115 4420 5165 1114 153 21678 2137 1125 12763 2112 19807 1891 19497 1708 7432 1111 1171 2489 1105 3420 2489 1114 1343 5165 1114 1168 12814 3377 119 3458 1871 1108 1107 8080 102\n",
      "INFO:tensorflow:input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      "I1208 12:27:37.103878 139883775852736 run_factoid.py:451] input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      "INFO:tensorflow:segment_ids: 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      "I1208 12:27:37.103967 139883775852736 run_factoid.py:453] segment_ids: 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      "INFO:tensorflow:*** Example ***\n",
      "I1208 12:27:37.105859 139883775852736 run_factoid.py:438] *** Example ***\n",
      "INFO:tensorflow:unique_id: 1000000036\n",
      "I1208 12:27:37.105925 139883775852736 run_factoid.py:439] unique_id: 1000000036\n",
      "INFO:tensorflow:example_index: 7\n",
      "I1208 12:27:37.105963 139883775852736 run_factoid.py:440] example_index: 7\n",
      "INFO:tensorflow:doc_span_index: 9\n",
      "I1208 12:27:37.105997 139883775852736 run_factoid.py:441] doc_span_index: 9\n",
      "INFO:tensorflow:tokens: [CLS] What did the paper find ? [SEP] ##D had 11 . 66 minutes , 75 . 23 minutes , 23 . 21 minutes , and 17 minutes less of operation time , respectively . Kim M ##J , et al . [ 44 ] compared the clinical outcomes of P ##EL ##D with O ##LM , and they found the operation time in these two groups was 53 . 0 ± 13 . 0 minutes and 64 . 6 ± 28 . 7 minutes , respectively ( P < 0 . 00 ##1 ) . Yao Y , et al . [ 45 ] assessed the three minimal ##ly invasive spine surgical approaches ( P ##EL ##D , MI ##S - T ##L ##IF , and ME ##D ) for re ##current her ##nia ##tion , and the mean operation time between them was 75 . 0 ± 31 . 56 minutes , 146 . 54 ± 38 . 07 minutes , and 85 . 25 ± 41 . 60 minutes , respectively . P ##EL ##D had a significantly less operation time than MI ##S - T ##L ##IF , but a comparable operation time with ME ##D . The functional outcomes were assessed by the VA ##S scores for back pain and leg pain . Our results suggested that patients treated with P ##EL ##D had comparable post ##oper ##ation VA ##S scores for back pain and leg pain with those treated with other surge ##ries . Our result was in consistent with the previous findings . [ 50 , 52 , 54 ] Yao Y , et al [ 54 ] reported that the pre ##oper ##ative VA ##S scores for back pain and leg pain were 5 . 88 ± 1 . 24 and 7 . 05 ± 1 . 08 in the MI ##S - T ##L ##IF group , 5 . 92 ± 1 . 33 and 7 . 13 ± 1 . 09 respectively in the P ##EL ##D group ( P = . 88 ##8 ) . [ 54 ] At the follow - up duration of 12 months , the VA ##S scores significantly reduced in the two groups as compared with pre ##oper ##ative values . However , there was no significant [SEP]\n",
      "I1208 12:27:37.106109 139883775852736 run_factoid.py:443] tokens: [CLS] What did the paper find ? [SEP] ##D had 11 . 66 minutes , 75 . 23 minutes , 23 . 21 minutes , and 17 minutes less of operation time , respectively . Kim M ##J , et al . [ 44 ] compared the clinical outcomes of P ##EL ##D with O ##LM , and they found the operation time in these two groups was 53 . 0 ± 13 . 0 minutes and 64 . 6 ± 28 . 7 minutes , respectively ( P < 0 . 00 ##1 ) . Yao Y , et al . [ 45 ] assessed the three minimal ##ly invasive spine surgical approaches ( P ##EL ##D , MI ##S - T ##L ##IF , and ME ##D ) for re ##current her ##nia ##tion , and the mean operation time between them was 75 . 0 ± 31 . 56 minutes , 146 . 54 ± 38 . 07 minutes , and 85 . 25 ± 41 . 60 minutes , respectively . P ##EL ##D had a significantly less operation time than MI ##S - T ##L ##IF , but a comparable operation time with ME ##D . The functional outcomes were assessed by the VA ##S scores for back pain and leg pain . Our results suggested that patients treated with P ##EL ##D had comparable post ##oper ##ation VA ##S scores for back pain and leg pain with those treated with other surge ##ries . Our result was in consistent with the previous findings . [ 50 , 52 , 54 ] Yao Y , et al [ 54 ] reported that the pre ##oper ##ative VA ##S scores for back pain and leg pain were 5 . 88 ± 1 . 24 and 7 . 05 ± 1 . 08 in the MI ##S - T ##L ##IF group , 5 . 92 ± 1 . 33 and 7 . 13 ± 1 . 09 respectively in the P ##EL ##D group ( P = . 88 ##8 ) . [ 54 ] At the follow - up duration of 12 months , the VA ##S scores significantly reduced in the two groups as compared with pre ##oper ##ative values . However , there was no significant [SEP]\n",
      "INFO:tensorflow:token_to_orig_map: 8:691 9:692 10:693 11:693 12:693 13:694 14:694 15:695 16:695 17:695 18:696 19:696 20:697 21:697 22:697 23:698 24:698 25:699 26:700 27:701 28:702 29:703 30:704 31:705 32:705 33:706 34:706 35:707 36:708 37:708 38:708 39:709 40:710 41:710 42:710 43:710 44:710 45:711 46:712 47:713 48:714 49:715 50:716 51:716 52:716 53:717 54:718 55:718 56:718 57:719 58:720 59:721 60:722 61:723 62:724 63:725 64:726 65:727 66:728 67:729 68:730 69:730 70:730 71:731 72:732 73:732 74:732 75:733 76:734 77:735 78:735 79:735 80:736 81:737 82:737 83:737 84:738 85:738 86:739 87:740 88:740 89:741 90:742 91:742 92:742 93:742 94:742 95:742 96:743 97:744 98:744 99:745 100:746 101:746 102:746 103:746 104:746 105:747 106:748 107:749 108:750 109:750 110:751 111:752 112:753 113:754 114:755 115:755 116:755 117:755 118:755 119:756 120:756 121:756 122:756 123:756 124:756 125:756 126:757 127:758 128:758 129:758 130:759 131:760 132:760 133:761 134:761 135:761 136:761 137:762 138:763 139:764 140:765 141:766 142:767 143:768 144:769 145:770 146:770 147:770 148:771 149:772 150:772 151:772 152:773 153:773 154:774 155:774 156:774 157:775 158:776 159:776 160:776 161:777 162:777 163:778 164:779 165:779 166:779 167:780 168:781 169:781 170:781 171:782 172:782 173:783 174:783 175:784 176:784 177:784 178:785 179:786 180:787 181:788 182:789 183:790 184:791 185:792 186:792 187:792 188:792 189:792 190:792 191:792 192:793 193:794 194:795 195:796 196:797 197:798 198:799 199:799 200:799 201:800 202:801 203:802 204:803 205:804 206:805 207:806 208:807 209:807 210:808 211:809 212:810 213:811 214:812 215:813 216:814 217:814 218:815 219:816 220:817 221:818 222:819 223:820 224:821 225:822 226:822 227:822 228:823 229:824 230:825 231:825 232:825 233:826 234:826 235:827 236:828 237:829 238:830 239:831 240:832 241:833 242:834 243:835 244:836 245:837 246:838 247:839 248:839 249:839 250:840 251:841 252:842 253:843 254:844 255:845 256:846 257:847 258:848 259:848 260:848 261:848 262:848 263:848 264:848 265:848 266:848 267:849 268:850 269:850 270:851 271:852 272:852 273:852 274:852 275:853 276:854 277:855 278:856 279:856 280:856 281:857 282:857 283:858 284:859 285:860 286:861 287:862 288:863 289:864 290:865 291:866 292:866 293:866 294:867 295:868 296:868 297:868 298:869 299:870 300:870 301:870 302:871 303:872 304:872 305:872 306:873 307:874 308:875 309:875 310:875 311:876 312:876 313:876 314:877 315:877 316:878 317:878 318:878 319:879 320:880 321:880 322:880 323:881 324:882 325:882 326:882 327:883 328:884 329:884 330:884 331:885 332:886 333:887 334:888 335:888 336:888 337:889 338:890 339:890 340:891 341:892 342:892 343:892 344:892 345:892 346:892 347:892 348:892 349:893 350:894 351:895 352:895 353:895 354:896 355:897 356:898 357:899 358:899 359:900 360:901 361:901 362:902 363:903 364:904 365:905 366:906 367:907 368:908 369:909 370:910 371:911 372:912 373:912 374:912 375:913 376:913 377:914 378:914 379:915 380:916 381:917 382:918\n",
      "I1208 12:27:37.106229 139883775852736 run_factoid.py:445] token_to_orig_map: 8:691 9:692 10:693 11:693 12:693 13:694 14:694 15:695 16:695 17:695 18:696 19:696 20:697 21:697 22:697 23:698 24:698 25:699 26:700 27:701 28:702 29:703 30:704 31:705 32:705 33:706 34:706 35:707 36:708 37:708 38:708 39:709 40:710 41:710 42:710 43:710 44:710 45:711 46:712 47:713 48:714 49:715 50:716 51:716 52:716 53:717 54:718 55:718 56:718 57:719 58:720 59:721 60:722 61:723 62:724 63:725 64:726 65:727 66:728 67:729 68:730 69:730 70:730 71:731 72:732 73:732 74:732 75:733 76:734 77:735 78:735 79:735 80:736 81:737 82:737 83:737 84:738 85:738 86:739 87:740 88:740 89:741 90:742 91:742 92:742 93:742 94:742 95:742 96:743 97:744 98:744 99:745 100:746 101:746 102:746 103:746 104:746 105:747 106:748 107:749 108:750 109:750 110:751 111:752 112:753 113:754 114:755 115:755 116:755 117:755 118:755 119:756 120:756 121:756 122:756 123:756 124:756 125:756 126:757 127:758 128:758 129:758 130:759 131:760 132:760 133:761 134:761 135:761 136:761 137:762 138:763 139:764 140:765 141:766 142:767 143:768 144:769 145:770 146:770 147:770 148:771 149:772 150:772 151:772 152:773 153:773 154:774 155:774 156:774 157:775 158:776 159:776 160:776 161:777 162:777 163:778 164:779 165:779 166:779 167:780 168:781 169:781 170:781 171:782 172:782 173:783 174:783 175:784 176:784 177:784 178:785 179:786 180:787 181:788 182:789 183:790 184:791 185:792 186:792 187:792 188:792 189:792 190:792 191:792 192:793 193:794 194:795 195:796 196:797 197:798 198:799 199:799 200:799 201:800 202:801 203:802 204:803 205:804 206:805 207:806 208:807 209:807 210:808 211:809 212:810 213:811 214:812 215:813 216:814 217:814 218:815 219:816 220:817 221:818 222:819 223:820 224:821 225:822 226:822 227:822 228:823 229:824 230:825 231:825 232:825 233:826 234:826 235:827 236:828 237:829 238:830 239:831 240:832 241:833 242:834 243:835 244:836 245:837 246:838 247:839 248:839 249:839 250:840 251:841 252:842 253:843 254:844 255:845 256:846 257:847 258:848 259:848 260:848 261:848 262:848 263:848 264:848 265:848 266:848 267:849 268:850 269:850 270:851 271:852 272:852 273:852 274:852 275:853 276:854 277:855 278:856 279:856 280:856 281:857 282:857 283:858 284:859 285:860 286:861 287:862 288:863 289:864 290:865 291:866 292:866 293:866 294:867 295:868 296:868 297:868 298:869 299:870 300:870 301:870 302:871 303:872 304:872 305:872 306:873 307:874 308:875 309:875 310:875 311:876 312:876 313:876 314:877 315:877 316:878 317:878 318:878 319:879 320:880 321:880 322:880 323:881 324:882 325:882 326:882 327:883 328:884 329:884 330:884 331:885 332:886 333:887 334:888 335:888 336:888 337:889 338:890 339:890 340:891 341:892 342:892 343:892 344:892 345:892 346:892 347:892 348:892 349:893 350:894 351:895 352:895 353:895 354:896 355:897 356:898 357:899 358:899 359:900 360:901 361:901 362:902 363:903 364:904 365:905 366:906 367:907 368:908 369:909 370:910 371:911 372:912 373:912 374:912 375:913 376:913 377:914 378:914 379:915 380:916 381:917 382:918\n",
      "INFO:tensorflow:token_is_max_context: 8:False 9:False 10:False 11:False 12:False 13:False 14:False 15:False 16:False 17:False 18:False 19:False 20:False 21:False 22:False 23:False 24:False 25:False 26:False 27:False 28:False 29:False 30:False 31:False 32:False 33:False 34:False 35:False 36:False 37:False 38:False 39:False 40:False 41:False 42:False 43:False 44:False 45:False 46:False 47:False 48:False 49:False 50:False 51:False 52:False 53:False 54:False 55:False 56:False 57:False 58:False 59:False 60:False 61:False 62:False 63:False 64:False 65:False 66:False 67:False 68:False 69:False 70:False 71:False 72:False 73:False 74:False 75:False 76:False 77:False 78:False 79:False 80:False 81:False 82:False 83:False 84:False 85:False 86:False 87:False 88:False 89:False 90:False 91:False 92:False 93:False 94:False 95:False 96:False 97:False 98:False 99:False 100:False 101:False 102:False 103:False 104:False 105:False 106:False 107:False 108:False 109:False 110:False 111:False 112:False 113:False 114:False 115:False 116:False 117:False 118:False 119:False 120:False 121:False 122:False 123:False 124:False 125:False 126:False 127:False 128:False 129:False 130:False 131:False 132:True 133:True 134:True 135:True 136:True 137:True 138:True 139:True 140:True 141:True 142:True 143:True 144:True 145:True 146:True 147:True 148:True 149:True 150:True 151:True 152:True 153:True 154:True 155:True 156:True 157:True 158:True 159:True 160:True 161:True 162:True 163:True 164:True 165:True 166:True 167:True 168:True 169:True 170:True 171:True 172:True 173:True 174:True 175:True 176:True 177:True 178:True 179:True 180:True 181:True 182:True 183:True 184:True 185:True 186:True 187:True 188:True 189:True 190:True 191:True 192:True 193:True 194:True 195:True 196:True 197:True 198:True 199:True 200:True 201:True 202:True 203:True 204:True 205:True 206:True 207:True 208:True 209:True 210:True 211:True 212:True 213:True 214:True 215:True 216:True 217:True 218:True 219:True 220:True 221:True 222:True 223:True 224:True 225:True 226:True 227:True 228:True 229:True 230:True 231:True 232:True 233:True 234:True 235:True 236:True 237:True 238:True 239:True 240:True 241:True 242:True 243:True 244:True 245:True 246:True 247:True 248:True 249:True 250:True 251:True 252:True 253:True 254:True 255:True 256:True 257:True 258:True 259:True 260:False 261:False 262:False 263:False 264:False 265:False 266:False 267:False 268:False 269:False 270:False 271:False 272:False 273:False 274:False 275:False 276:False 277:False 278:False 279:False 280:False 281:False 282:False 283:False 284:False 285:False 286:False 287:False 288:False 289:False 290:False 291:False 292:False 293:False 294:False 295:False 296:False 297:False 298:False 299:False 300:False 301:False 302:False 303:False 304:False 305:False 306:False 307:False 308:False 309:False 310:False 311:False 312:False 313:False 314:False 315:False 316:False 317:False 318:False 319:False 320:False 321:False 322:False 323:False 324:False 325:False 326:False 327:False 328:False 329:False 330:False 331:False 332:False 333:False 334:False 335:False 336:False 337:False 338:False 339:False 340:False 341:False 342:False 343:False 344:False 345:False 346:False 347:False 348:False 349:False 350:False 351:False 352:False 353:False 354:False 355:False 356:False 357:False 358:False 359:False 360:False 361:False 362:False 363:False 364:False 365:False 366:False 367:False 368:False 369:False 370:False 371:False 372:False 373:False 374:False 375:False 376:False 377:False 378:False 379:False 380:False 381:False 382:False\n",
      "I1208 12:27:37.106338 139883775852736 run_factoid.py:447] token_is_max_context: 8:False 9:False 10:False 11:False 12:False 13:False 14:False 15:False 16:False 17:False 18:False 19:False 20:False 21:False 22:False 23:False 24:False 25:False 26:False 27:False 28:False 29:False 30:False 31:False 32:False 33:False 34:False 35:False 36:False 37:False 38:False 39:False 40:False 41:False 42:False 43:False 44:False 45:False 46:False 47:False 48:False 49:False 50:False 51:False 52:False 53:False 54:False 55:False 56:False 57:False 58:False 59:False 60:False 61:False 62:False 63:False 64:False 65:False 66:False 67:False 68:False 69:False 70:False 71:False 72:False 73:False 74:False 75:False 76:False 77:False 78:False 79:False 80:False 81:False 82:False 83:False 84:False 85:False 86:False 87:False 88:False 89:False 90:False 91:False 92:False 93:False 94:False 95:False 96:False 97:False 98:False 99:False 100:False 101:False 102:False 103:False 104:False 105:False 106:False 107:False 108:False 109:False 110:False 111:False 112:False 113:False 114:False 115:False 116:False 117:False 118:False 119:False 120:False 121:False 122:False 123:False 124:False 125:False 126:False 127:False 128:False 129:False 130:False 131:False 132:True 133:True 134:True 135:True 136:True 137:True 138:True 139:True 140:True 141:True 142:True 143:True 144:True 145:True 146:True 147:True 148:True 149:True 150:True 151:True 152:True 153:True 154:True 155:True 156:True 157:True 158:True 159:True 160:True 161:True 162:True 163:True 164:True 165:True 166:True 167:True 168:True 169:True 170:True 171:True 172:True 173:True 174:True 175:True 176:True 177:True 178:True 179:True 180:True 181:True 182:True 183:True 184:True 185:True 186:True 187:True 188:True 189:True 190:True 191:True 192:True 193:True 194:True 195:True 196:True 197:True 198:True 199:True 200:True 201:True 202:True 203:True 204:True 205:True 206:True 207:True 208:True 209:True 210:True 211:True 212:True 213:True 214:True 215:True 216:True 217:True 218:True 219:True 220:True 221:True 222:True 223:True 224:True 225:True 226:True 227:True 228:True 229:True 230:True 231:True 232:True 233:True 234:True 235:True 236:True 237:True 238:True 239:True 240:True 241:True 242:True 243:True 244:True 245:True 246:True 247:True 248:True 249:True 250:True 251:True 252:True 253:True 254:True 255:True 256:True 257:True 258:True 259:True 260:False 261:False 262:False 263:False 264:False 265:False 266:False 267:False 268:False 269:False 270:False 271:False 272:False 273:False 274:False 275:False 276:False 277:False 278:False 279:False 280:False 281:False 282:False 283:False 284:False 285:False 286:False 287:False 288:False 289:False 290:False 291:False 292:False 293:False 294:False 295:False 296:False 297:False 298:False 299:False 300:False 301:False 302:False 303:False 304:False 305:False 306:False 307:False 308:False 309:False 310:False 311:False 312:False 313:False 314:False 315:False 316:False 317:False 318:False 319:False 320:False 321:False 322:False 323:False 324:False 325:False 326:False 327:False 328:False 329:False 330:False 331:False 332:False 333:False 334:False 335:False 336:False 337:False 338:False 339:False 340:False 341:False 342:False 343:False 344:False 345:False 346:False 347:False 348:False 349:False 350:False 351:False 352:False 353:False 354:False 355:False 356:False 357:False 358:False 359:False 360:False 361:False 362:False 363:False 364:False 365:False 366:False 367:False 368:False 369:False 370:False 371:False 372:False 373:False 374:False 375:False 376:False 377:False 378:False 379:False 380:False 381:False 382:False\n",
      "INFO:tensorflow:input_ids: 101 1327 1225 1103 2526 1525 136 102 2137 1125 1429 119 5046 1904 117 3453 119 1695 1904 117 1695 119 1626 1904 117 1105 1542 1904 1750 1104 2805 1159 117 3569 119 4246 150 4538 117 3084 2393 119 164 3140 166 3402 1103 7300 13950 1104 153 21678 2137 1114 152 22074 117 1105 1152 1276 1103 2805 1159 1107 1292 1160 2114 1108 4389 119 121 212 1492 119 121 1904 1105 3324 119 127 212 1743 119 128 1904 117 3569 113 153 133 121 119 3135 1475 114 119 27762 162 117 3084 2393 119 164 2532 166 14758 1103 1210 10298 1193 19849 8340 13467 8015 113 153 21678 2137 117 26574 1708 118 157 2162 15499 117 1105 22157 2137 114 1111 1231 21754 1123 5813 2116 117 1105 1103 1928 2805 1159 1206 1172 1108 3453 119 121 212 1955 119 4376 1904 117 17350 119 4335 212 3383 119 5004 1904 117 1105 4859 119 1512 212 3746 119 2539 1904 117 3569 119 153 21678 2137 1125 170 5409 1750 2805 1159 1190 26574 1708 118 157 2162 15499 117 1133 170 12763 2805 1159 1114 22157 2137 119 1109 8458 13950 1127 14758 1118 1103 19497 1708 7432 1111 1171 2489 1105 3420 2489 119 3458 2686 3228 1115 4420 5165 1114 153 21678 2137 1125 12763 2112 19807 1891 19497 1708 7432 1111 1171 2489 1105 3420 2489 1114 1343 5165 1114 1168 12814 3377 119 3458 1871 1108 1107 8080 1114 1103 2166 9505 119 164 1851 117 3882 117 4335 166 27762 162 117 3084 2393 164 4335 166 2103 1115 1103 3073 19807 5838 19497 1708 7432 1111 1171 2489 1105 3420 2489 1127 126 119 5385 212 122 119 1572 1105 128 119 4991 212 122 119 4775 1107 1103 26574 1708 118 157 2162 15499 1372 117 126 119 5556 212 122 119 3081 1105 128 119 1492 212 122 119 4925 3569 1107 1103 153 21678 2137 1372 113 153 134 119 5385 1604 114 119 164 4335 166 1335 1103 2812 118 1146 9355 1104 1367 1808 117 1103 19497 1708 7432 5409 3549 1107 1103 1160 2114 1112 3402 1114 3073 19807 5838 4718 119 1438 117 1175 1108 1185 2418 102\n",
      "I1208 12:27:37.106438 139883775852736 run_factoid.py:449] input_ids: 101 1327 1225 1103 2526 1525 136 102 2137 1125 1429 119 5046 1904 117 3453 119 1695 1904 117 1695 119 1626 1904 117 1105 1542 1904 1750 1104 2805 1159 117 3569 119 4246 150 4538 117 3084 2393 119 164 3140 166 3402 1103 7300 13950 1104 153 21678 2137 1114 152 22074 117 1105 1152 1276 1103 2805 1159 1107 1292 1160 2114 1108 4389 119 121 212 1492 119 121 1904 1105 3324 119 127 212 1743 119 128 1904 117 3569 113 153 133 121 119 3135 1475 114 119 27762 162 117 3084 2393 119 164 2532 166 14758 1103 1210 10298 1193 19849 8340 13467 8015 113 153 21678 2137 117 26574 1708 118 157 2162 15499 117 1105 22157 2137 114 1111 1231 21754 1123 5813 2116 117 1105 1103 1928 2805 1159 1206 1172 1108 3453 119 121 212 1955 119 4376 1904 117 17350 119 4335 212 3383 119 5004 1904 117 1105 4859 119 1512 212 3746 119 2539 1904 117 3569 119 153 21678 2137 1125 170 5409 1750 2805 1159 1190 26574 1708 118 157 2162 15499 117 1133 170 12763 2805 1159 1114 22157 2137 119 1109 8458 13950 1127 14758 1118 1103 19497 1708 7432 1111 1171 2489 1105 3420 2489 119 3458 2686 3228 1115 4420 5165 1114 153 21678 2137 1125 12763 2112 19807 1891 19497 1708 7432 1111 1171 2489 1105 3420 2489 1114 1343 5165 1114 1168 12814 3377 119 3458 1871 1108 1107 8080 1114 1103 2166 9505 119 164 1851 117 3882 117 4335 166 27762 162 117 3084 2393 164 4335 166 2103 1115 1103 3073 19807 5838 19497 1708 7432 1111 1171 2489 1105 3420 2489 1127 126 119 5385 212 122 119 1572 1105 128 119 4991 212 122 119 4775 1107 1103 26574 1708 118 157 2162 15499 1372 117 126 119 5556 212 122 119 3081 1105 128 119 1492 212 122 119 4925 3569 1107 1103 153 21678 2137 1372 113 153 134 119 5385 1604 114 119 164 4335 166 1335 1103 2812 118 1146 9355 1104 1367 1808 117 1103 19497 1708 7432 5409 3549 1107 1103 1160 2114 1112 3402 1114 3073 19807 5838 4718 119 1438 117 1175 1108 1185 2418 102\n",
      "INFO:tensorflow:input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      "I1208 12:27:37.106530 139883775852736 run_factoid.py:451] input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      "INFO:tensorflow:segment_ids: 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      "I1208 12:27:37.106619 139883775852736 run_factoid.py:453] segment_ids: 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      "INFO:tensorflow:*** Example ***\n",
      "I1208 12:27:37.108495 139883775852736 run_factoid.py:438] *** Example ***\n",
      "INFO:tensorflow:unique_id: 1000000037\n",
      "I1208 12:27:37.108559 139883775852736 run_factoid.py:439] unique_id: 1000000037\n",
      "INFO:tensorflow:example_index: 7\n",
      "I1208 12:27:37.108595 139883775852736 run_factoid.py:440] example_index: 7\n",
      "INFO:tensorflow:doc_span_index: 10\n",
      "I1208 12:27:37.108629 139883775852736 run_factoid.py:441] doc_span_index: 10\n",
      "INFO:tensorflow:tokens: [CLS] What did the paper find ? [SEP] , and the mean operation time between them was 75 . 0 ± 31 . 56 minutes , 146 . 54 ± 38 . 07 minutes , and 85 . 25 ± 41 . 60 minutes , respectively . P ##EL ##D had a significantly less operation time than MI ##S - T ##L ##IF , but a comparable operation time with ME ##D . The functional outcomes were assessed by the VA ##S scores for back pain and leg pain . Our results suggested that patients treated with P ##EL ##D had comparable post ##oper ##ation VA ##S scores for back pain and leg pain with those treated with other surge ##ries . Our result was in consistent with the previous findings . [ 50 , 52 , 54 ] Yao Y , et al [ 54 ] reported that the pre ##oper ##ative VA ##S scores for back pain and leg pain were 5 . 88 ± 1 . 24 and 7 . 05 ± 1 . 08 in the MI ##S - T ##L ##IF group , 5 . 92 ± 1 . 33 and 7 . 13 ± 1 . 09 respectively in the P ##EL ##D group ( P = . 88 ##8 ) . [ 54 ] At the follow - up duration of 12 months , the VA ##S scores significantly reduced in the two groups as compared with pre ##oper ##ative values . However , there was no significant differences between the them in the post ##oper ##ation VA ##S scores for back pain and leg pain . [ 54 ] The authors attributed the results to the relatively larger injury of soft tissue and disruption of spinal stability , which were caused by the inter ##body fusion than disc ##ec ##tom ##y . [ 54 ] There were several potential limitations in this meta - analysis . First , for some outcomes , the data analysis was based on relatively small number of included studies and sample size ; thus , the conclusions about the outcomes should be interpreted with caution . Second , most of the included studies were retrospective co ##hor ##t study , and the grade evidence was inferior to that of RC [SEP]\n",
      "I1208 12:27:37.108746 139883775852736 run_factoid.py:443] tokens: [CLS] What did the paper find ? [SEP] , and the mean operation time between them was 75 . 0 ± 31 . 56 minutes , 146 . 54 ± 38 . 07 minutes , and 85 . 25 ± 41 . 60 minutes , respectively . P ##EL ##D had a significantly less operation time than MI ##S - T ##L ##IF , but a comparable operation time with ME ##D . The functional outcomes were assessed by the VA ##S scores for back pain and leg pain . Our results suggested that patients treated with P ##EL ##D had comparable post ##oper ##ation VA ##S scores for back pain and leg pain with those treated with other surge ##ries . Our result was in consistent with the previous findings . [ 50 , 52 , 54 ] Yao Y , et al [ 54 ] reported that the pre ##oper ##ative VA ##S scores for back pain and leg pain were 5 . 88 ± 1 . 24 and 7 . 05 ± 1 . 08 in the MI ##S - T ##L ##IF group , 5 . 92 ± 1 . 33 and 7 . 13 ± 1 . 09 respectively in the P ##EL ##D group ( P = . 88 ##8 ) . [ 54 ] At the follow - up duration of 12 months , the VA ##S scores significantly reduced in the two groups as compared with pre ##oper ##ative values . However , there was no significant differences between the them in the post ##oper ##ation VA ##S scores for back pain and leg pain . [ 54 ] The authors attributed the results to the relatively larger injury of soft tissue and disruption of spinal stability , which were caused by the inter ##body fusion than disc ##ec ##tom ##y . [ 54 ] There were several potential limitations in this meta - analysis . First , for some outcomes , the data analysis was based on relatively small number of included studies and sample size ; thus , the conclusions about the outcomes should be interpreted with caution . Second , most of the included studies were retrospective co ##hor ##t study , and the grade evidence was inferior to that of RC [SEP]\n",
      "INFO:tensorflow:token_to_orig_map: 8:761 9:762 10:763 11:764 12:765 13:766 14:767 15:768 16:769 17:770 18:770 19:770 20:771 21:772 22:772 23:772 24:773 25:773 26:774 27:774 28:774 29:775 30:776 31:776 32:776 33:777 34:777 35:778 36:779 37:779 38:779 39:780 40:781 41:781 42:781 43:782 44:782 45:783 46:783 47:784 48:784 49:784 50:785 51:786 52:787 53:788 54:789 55:790 56:791 57:792 58:792 59:792 60:792 61:792 62:792 63:792 64:793 65:794 66:795 67:796 68:797 69:798 70:799 71:799 72:799 73:800 74:801 75:802 76:803 77:804 78:805 79:806 80:807 81:807 82:808 83:809 84:810 85:811 86:812 87:813 88:814 89:814 90:815 91:816 92:817 93:818 94:819 95:820 96:821 97:822 98:822 99:822 100:823 101:824 102:825 103:825 104:825 105:826 106:826 107:827 108:828 109:829 110:830 111:831 112:832 113:833 114:834 115:835 116:836 117:837 118:838 119:839 120:839 121:839 122:840 123:841 124:842 125:843 126:844 127:845 128:846 129:847 130:848 131:848 132:848 133:848 134:848 135:848 136:848 137:848 138:848 139:849 140:850 141:850 142:851 143:852 144:852 145:852 146:852 147:853 148:854 149:855 150:856 151:856 152:856 153:857 154:857 155:858 156:859 157:860 158:861 159:862 160:863 161:864 162:865 163:866 164:866 165:866 166:867 167:868 168:868 169:868 170:869 171:870 172:870 173:870 174:871 175:872 176:872 177:872 178:873 179:874 180:875 181:875 182:875 183:876 184:876 185:876 186:877 187:877 188:878 189:878 190:878 191:879 192:880 193:880 194:880 195:881 196:882 197:882 198:882 199:883 200:884 201:884 202:884 203:885 204:886 205:887 206:888 207:888 208:888 209:889 210:890 211:890 212:891 213:892 214:892 215:892 216:892 217:892 218:892 219:892 220:892 221:893 222:894 223:895 224:895 225:895 226:896 227:897 228:898 229:899 230:899 231:900 232:901 233:901 234:902 235:903 236:904 237:905 238:906 239:907 240:908 241:909 242:910 243:911 244:912 245:912 246:912 247:913 248:913 249:914 250:914 251:915 252:916 253:917 254:918 255:919 256:920 257:921 258:922 259:923 260:924 261:925 262:925 263:925 264:926 265:926 266:927 267:928 268:929 269:930 270:931 271:932 272:933 273:933 274:933 275:933 276:933 277:934 278:935 279:936 280:937 281:938 282:939 283:940 284:941 285:942 286:943 287:944 288:945 289:946 290:947 291:948 292:949 293:950 294:951 295:951 296:952 297:953 298:954 299:955 300:956 301:957 302:957 303:958 304:959 305:960 306:960 307:960 308:960 309:960 310:960 311:960 312:960 313:961 314:962 315:963 316:964 317:965 318:966 319:967 320:968 321:968 322:968 323:968 324:969 325:969 326:970 327:971 328:972 329:972 330:973 331:974 332:975 333:976 334:977 335:978 336:979 337:980 338:981 339:982 340:983 341:984 342:985 343:986 344:987 345:987 346:988 347:988 348:989 349:990 350:991 351:992 352:993 353:994 354:995 355:996 356:997 357:998 358:998 359:999 360:999 361:1000 362:1001 363:1002 364:1003 365:1004 366:1005 367:1006 368:1007 369:1007 370:1007 371:1008 372:1008 373:1009 374:1010 375:1011 376:1012 377:1013 378:1014 379:1015 380:1016 381:1017 382:1018\n",
      "I1208 12:27:37.108866 139883775852736 run_factoid.py:445] token_to_orig_map: 8:761 9:762 10:763 11:764 12:765 13:766 14:767 15:768 16:769 17:770 18:770 19:770 20:771 21:772 22:772 23:772 24:773 25:773 26:774 27:774 28:774 29:775 30:776 31:776 32:776 33:777 34:777 35:778 36:779 37:779 38:779 39:780 40:781 41:781 42:781 43:782 44:782 45:783 46:783 47:784 48:784 49:784 50:785 51:786 52:787 53:788 54:789 55:790 56:791 57:792 58:792 59:792 60:792 61:792 62:792 63:792 64:793 65:794 66:795 67:796 68:797 69:798 70:799 71:799 72:799 73:800 74:801 75:802 76:803 77:804 78:805 79:806 80:807 81:807 82:808 83:809 84:810 85:811 86:812 87:813 88:814 89:814 90:815 91:816 92:817 93:818 94:819 95:820 96:821 97:822 98:822 99:822 100:823 101:824 102:825 103:825 104:825 105:826 106:826 107:827 108:828 109:829 110:830 111:831 112:832 113:833 114:834 115:835 116:836 117:837 118:838 119:839 120:839 121:839 122:840 123:841 124:842 125:843 126:844 127:845 128:846 129:847 130:848 131:848 132:848 133:848 134:848 135:848 136:848 137:848 138:848 139:849 140:850 141:850 142:851 143:852 144:852 145:852 146:852 147:853 148:854 149:855 150:856 151:856 152:856 153:857 154:857 155:858 156:859 157:860 158:861 159:862 160:863 161:864 162:865 163:866 164:866 165:866 166:867 167:868 168:868 169:868 170:869 171:870 172:870 173:870 174:871 175:872 176:872 177:872 178:873 179:874 180:875 181:875 182:875 183:876 184:876 185:876 186:877 187:877 188:878 189:878 190:878 191:879 192:880 193:880 194:880 195:881 196:882 197:882 198:882 199:883 200:884 201:884 202:884 203:885 204:886 205:887 206:888 207:888 208:888 209:889 210:890 211:890 212:891 213:892 214:892 215:892 216:892 217:892 218:892 219:892 220:892 221:893 222:894 223:895 224:895 225:895 226:896 227:897 228:898 229:899 230:899 231:900 232:901 233:901 234:902 235:903 236:904 237:905 238:906 239:907 240:908 241:909 242:910 243:911 244:912 245:912 246:912 247:913 248:913 249:914 250:914 251:915 252:916 253:917 254:918 255:919 256:920 257:921 258:922 259:923 260:924 261:925 262:925 263:925 264:926 265:926 266:927 267:928 268:929 269:930 270:931 271:932 272:933 273:933 274:933 275:933 276:933 277:934 278:935 279:936 280:937 281:938 282:939 283:940 284:941 285:942 286:943 287:944 288:945 289:946 290:947 291:948 292:949 293:950 294:951 295:951 296:952 297:953 298:954 299:955 300:956 301:957 302:957 303:958 304:959 305:960 306:960 307:960 308:960 309:960 310:960 311:960 312:960 313:961 314:962 315:963 316:964 317:965 318:966 319:967 320:968 321:968 322:968 323:968 324:969 325:969 326:970 327:971 328:972 329:972 330:973 331:974 332:975 333:976 334:977 335:978 336:979 337:980 338:981 339:982 340:983 341:984 342:985 343:986 344:987 345:987 346:988 347:988 348:989 349:990 350:991 351:992 352:993 353:994 354:995 355:996 356:997 357:998 358:998 359:999 360:999 361:1000 362:1001 363:1002 364:1003 365:1004 366:1005 367:1006 368:1007 369:1007 370:1007 371:1008 372:1008 373:1009 374:1010 375:1011 376:1012 377:1013 378:1014 379:1015 380:1016 381:1017 382:1018\n",
      "INFO:tensorflow:token_is_max_context: 8:False 9:False 10:False 11:False 12:False 13:False 14:False 15:False 16:False 17:False 18:False 19:False 20:False 21:False 22:False 23:False 24:False 25:False 26:False 27:False 28:False 29:False 30:False 31:False 32:False 33:False 34:False 35:False 36:False 37:False 38:False 39:False 40:False 41:False 42:False 43:False 44:False 45:False 46:False 47:False 48:False 49:False 50:False 51:False 52:False 53:False 54:False 55:False 56:False 57:False 58:False 59:False 60:False 61:False 62:False 63:False 64:False 65:False 66:False 67:False 68:False 69:False 70:False 71:False 72:False 73:False 74:False 75:False 76:False 77:False 78:False 79:False 80:False 81:False 82:False 83:False 84:False 85:False 86:False 87:False 88:False 89:False 90:False 91:False 92:False 93:False 94:False 95:False 96:False 97:False 98:False 99:False 100:False 101:False 102:False 103:False 104:False 105:False 106:False 107:False 108:False 109:False 110:False 111:False 112:False 113:False 114:False 115:False 116:False 117:False 118:False 119:False 120:False 121:False 122:False 123:False 124:False 125:False 126:False 127:False 128:False 129:False 130:False 131:False 132:True 133:True 134:True 135:True 136:True 137:True 138:True 139:True 140:True 141:True 142:True 143:True 144:True 145:True 146:True 147:True 148:True 149:True 150:True 151:True 152:True 153:True 154:True 155:True 156:True 157:True 158:True 159:True 160:True 161:True 162:True 163:True 164:True 165:True 166:True 167:True 168:True 169:True 170:True 171:True 172:True 173:True 174:True 175:True 176:True 177:True 178:True 179:True 180:True 181:True 182:True 183:True 184:True 185:True 186:True 187:True 188:True 189:True 190:True 191:True 192:True 193:True 194:True 195:True 196:True 197:True 198:True 199:True 200:True 201:True 202:True 203:True 204:True 205:True 206:True 207:True 208:True 209:True 210:True 211:True 212:True 213:True 214:True 215:True 216:True 217:True 218:True 219:True 220:True 221:True 222:True 223:True 224:True 225:True 226:True 227:True 228:True 229:True 230:True 231:True 232:True 233:True 234:True 235:True 236:True 237:True 238:True 239:True 240:True 241:True 242:True 243:True 244:True 245:True 246:True 247:True 248:True 249:True 250:True 251:True 252:True 253:True 254:True 255:True 256:True 257:True 258:True 259:True 260:False 261:False 262:False 263:False 264:False 265:False 266:False 267:False 268:False 269:False 270:False 271:False 272:False 273:False 274:False 275:False 276:False 277:False 278:False 279:False 280:False 281:False 282:False 283:False 284:False 285:False 286:False 287:False 288:False 289:False 290:False 291:False 292:False 293:False 294:False 295:False 296:False 297:False 298:False 299:False 300:False 301:False 302:False 303:False 304:False 305:False 306:False 307:False 308:False 309:False 310:False 311:False 312:False 313:False 314:False 315:False 316:False 317:False 318:False 319:False 320:False 321:False 322:False 323:False 324:False 325:False 326:False 327:False 328:False 329:False 330:False 331:False 332:False 333:False 334:False 335:False 336:False 337:False 338:False 339:False 340:False 341:False 342:False 343:False 344:False 345:False 346:False 347:False 348:False 349:False 350:False 351:False 352:False 353:False 354:False 355:False 356:False 357:False 358:False 359:False 360:False 361:False 362:False 363:False 364:False 365:False 366:False 367:False 368:False 369:False 370:False 371:False 372:False 373:False 374:False 375:False 376:False 377:False 378:False 379:False 380:False 381:False 382:False\n",
      "I1208 12:27:37.108996 139883775852736 run_factoid.py:447] token_is_max_context: 8:False 9:False 10:False 11:False 12:False 13:False 14:False 15:False 16:False 17:False 18:False 19:False 20:False 21:False 22:False 23:False 24:False 25:False 26:False 27:False 28:False 29:False 30:False 31:False 32:False 33:False 34:False 35:False 36:False 37:False 38:False 39:False 40:False 41:False 42:False 43:False 44:False 45:False 46:False 47:False 48:False 49:False 50:False 51:False 52:False 53:False 54:False 55:False 56:False 57:False 58:False 59:False 60:False 61:False 62:False 63:False 64:False 65:False 66:False 67:False 68:False 69:False 70:False 71:False 72:False 73:False 74:False 75:False 76:False 77:False 78:False 79:False 80:False 81:False 82:False 83:False 84:False 85:False 86:False 87:False 88:False 89:False 90:False 91:False 92:False 93:False 94:False 95:False 96:False 97:False 98:False 99:False 100:False 101:False 102:False 103:False 104:False 105:False 106:False 107:False 108:False 109:False 110:False 111:False 112:False 113:False 114:False 115:False 116:False 117:False 118:False 119:False 120:False 121:False 122:False 123:False 124:False 125:False 126:False 127:False 128:False 129:False 130:False 131:False 132:True 133:True 134:True 135:True 136:True 137:True 138:True 139:True 140:True 141:True 142:True 143:True 144:True 145:True 146:True 147:True 148:True 149:True 150:True 151:True 152:True 153:True 154:True 155:True 156:True 157:True 158:True 159:True 160:True 161:True 162:True 163:True 164:True 165:True 166:True 167:True 168:True 169:True 170:True 171:True 172:True 173:True 174:True 175:True 176:True 177:True 178:True 179:True 180:True 181:True 182:True 183:True 184:True 185:True 186:True 187:True 188:True 189:True 190:True 191:True 192:True 193:True 194:True 195:True 196:True 197:True 198:True 199:True 200:True 201:True 202:True 203:True 204:True 205:True 206:True 207:True 208:True 209:True 210:True 211:True 212:True 213:True 214:True 215:True 216:True 217:True 218:True 219:True 220:True 221:True 222:True 223:True 224:True 225:True 226:True 227:True 228:True 229:True 230:True 231:True 232:True 233:True 234:True 235:True 236:True 237:True 238:True 239:True 240:True 241:True 242:True 243:True 244:True 245:True 246:True 247:True 248:True 249:True 250:True 251:True 252:True 253:True 254:True 255:True 256:True 257:True 258:True 259:True 260:False 261:False 262:False 263:False 264:False 265:False 266:False 267:False 268:False 269:False 270:False 271:False 272:False 273:False 274:False 275:False 276:False 277:False 278:False 279:False 280:False 281:False 282:False 283:False 284:False 285:False 286:False 287:False 288:False 289:False 290:False 291:False 292:False 293:False 294:False 295:False 296:False 297:False 298:False 299:False 300:False 301:False 302:False 303:False 304:False 305:False 306:False 307:False 308:False 309:False 310:False 311:False 312:False 313:False 314:False 315:False 316:False 317:False 318:False 319:False 320:False 321:False 322:False 323:False 324:False 325:False 326:False 327:False 328:False 329:False 330:False 331:False 332:False 333:False 334:False 335:False 336:False 337:False 338:False 339:False 340:False 341:False 342:False 343:False 344:False 345:False 346:False 347:False 348:False 349:False 350:False 351:False 352:False 353:False 354:False 355:False 356:False 357:False 358:False 359:False 360:False 361:False 362:False 363:False 364:False 365:False 366:False 367:False 368:False 369:False 370:False 371:False 372:False 373:False 374:False 375:False 376:False 377:False 378:False 379:False 380:False 381:False 382:False\n",
      "INFO:tensorflow:input_ids: 101 1327 1225 1103 2526 1525 136 102 117 1105 1103 1928 2805 1159 1206 1172 1108 3453 119 121 212 1955 119 4376 1904 117 17350 119 4335 212 3383 119 5004 1904 117 1105 4859 119 1512 212 3746 119 2539 1904 117 3569 119 153 21678 2137 1125 170 5409 1750 2805 1159 1190 26574 1708 118 157 2162 15499 117 1133 170 12763 2805 1159 1114 22157 2137 119 1109 8458 13950 1127 14758 1118 1103 19497 1708 7432 1111 1171 2489 1105 3420 2489 119 3458 2686 3228 1115 4420 5165 1114 153 21678 2137 1125 12763 2112 19807 1891 19497 1708 7432 1111 1171 2489 1105 3420 2489 1114 1343 5165 1114 1168 12814 3377 119 3458 1871 1108 1107 8080 1114 1103 2166 9505 119 164 1851 117 3882 117 4335 166 27762 162 117 3084 2393 164 4335 166 2103 1115 1103 3073 19807 5838 19497 1708 7432 1111 1171 2489 1105 3420 2489 1127 126 119 5385 212 122 119 1572 1105 128 119 4991 212 122 119 4775 1107 1103 26574 1708 118 157 2162 15499 1372 117 126 119 5556 212 122 119 3081 1105 128 119 1492 212 122 119 4925 3569 1107 1103 153 21678 2137 1372 113 153 134 119 5385 1604 114 119 164 4335 166 1335 1103 2812 118 1146 9355 1104 1367 1808 117 1103 19497 1708 7432 5409 3549 1107 1103 1160 2114 1112 3402 1114 3073 19807 5838 4718 119 1438 117 1175 1108 1185 2418 5408 1206 1103 1172 1107 1103 2112 19807 1891 19497 1708 7432 1111 1171 2489 1105 3420 2489 119 164 4335 166 1109 5752 6547 1103 2686 1106 1103 3860 2610 3773 1104 2991 7918 1105 23730 1104 19245 9397 117 1134 1127 2416 1118 1103 9455 14637 11970 1190 6187 10294 18778 1183 119 164 4335 166 1247 1127 1317 3209 13004 1107 1142 27154 118 3622 119 1752 117 1111 1199 13950 117 1103 2233 3622 1108 1359 1113 3860 1353 1295 1104 1529 2527 1105 6876 2060 132 2456 117 1103 16421 1164 1103 13950 1431 1129 9829 1114 15597 119 2307 117 1211 1104 1103 1529 2527 1127 18675 1884 13252 1204 2025 117 1105 1103 3654 2554 1108 15543 1106 1115 1104 25157 102\n",
      "I1208 12:27:37.109126 139883775852736 run_factoid.py:449] input_ids: 101 1327 1225 1103 2526 1525 136 102 117 1105 1103 1928 2805 1159 1206 1172 1108 3453 119 121 212 1955 119 4376 1904 117 17350 119 4335 212 3383 119 5004 1904 117 1105 4859 119 1512 212 3746 119 2539 1904 117 3569 119 153 21678 2137 1125 170 5409 1750 2805 1159 1190 26574 1708 118 157 2162 15499 117 1133 170 12763 2805 1159 1114 22157 2137 119 1109 8458 13950 1127 14758 1118 1103 19497 1708 7432 1111 1171 2489 1105 3420 2489 119 3458 2686 3228 1115 4420 5165 1114 153 21678 2137 1125 12763 2112 19807 1891 19497 1708 7432 1111 1171 2489 1105 3420 2489 1114 1343 5165 1114 1168 12814 3377 119 3458 1871 1108 1107 8080 1114 1103 2166 9505 119 164 1851 117 3882 117 4335 166 27762 162 117 3084 2393 164 4335 166 2103 1115 1103 3073 19807 5838 19497 1708 7432 1111 1171 2489 1105 3420 2489 1127 126 119 5385 212 122 119 1572 1105 128 119 4991 212 122 119 4775 1107 1103 26574 1708 118 157 2162 15499 1372 117 126 119 5556 212 122 119 3081 1105 128 119 1492 212 122 119 4925 3569 1107 1103 153 21678 2137 1372 113 153 134 119 5385 1604 114 119 164 4335 166 1335 1103 2812 118 1146 9355 1104 1367 1808 117 1103 19497 1708 7432 5409 3549 1107 1103 1160 2114 1112 3402 1114 3073 19807 5838 4718 119 1438 117 1175 1108 1185 2418 5408 1206 1103 1172 1107 1103 2112 19807 1891 19497 1708 7432 1111 1171 2489 1105 3420 2489 119 164 4335 166 1109 5752 6547 1103 2686 1106 1103 3860 2610 3773 1104 2991 7918 1105 23730 1104 19245 9397 117 1134 1127 2416 1118 1103 9455 14637 11970 1190 6187 10294 18778 1183 119 164 4335 166 1247 1127 1317 3209 13004 1107 1142 27154 118 3622 119 1752 117 1111 1199 13950 117 1103 2233 3622 1108 1359 1113 3860 1353 1295 1104 1529 2527 1105 6876 2060 132 2456 117 1103 16421 1164 1103 13950 1431 1129 9829 1114 15597 119 2307 117 1211 1104 1103 1529 2527 1127 18675 1884 13252 1204 2025 117 1105 1103 3654 2554 1108 15543 1106 1115 1104 25157 102\n",
      "INFO:tensorflow:input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      "I1208 12:27:37.109225 139883775852736 run_factoid.py:451] input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      "INFO:tensorflow:segment_ids: 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      "I1208 12:27:37.109323 139883775852736 run_factoid.py:453] segment_ids: 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      "INFO:tensorflow:*** Example ***\n",
      "I1208 12:27:37.111219 139883775852736 run_factoid.py:438] *** Example ***\n",
      "INFO:tensorflow:unique_id: 1000000038\n",
      "I1208 12:27:37.111279 139883775852736 run_factoid.py:439] unique_id: 1000000038\n",
      "INFO:tensorflow:example_index: 7\n",
      "I1208 12:27:37.111315 139883775852736 run_factoid.py:440] example_index: 7\n",
      "INFO:tensorflow:doc_span_index: 11\n",
      "I1208 12:27:37.111350 139883775852736 run_factoid.py:441] doc_span_index: 11\n",
      "INFO:tensorflow:tokens: [CLS] What did the paper find ? [SEP] , 54 ] Yao Y , et al [ 54 ] reported that the pre ##oper ##ative VA ##S scores for back pain and leg pain were 5 . 88 ± 1 . 24 and 7 . 05 ± 1 . 08 in the MI ##S - T ##L ##IF group , 5 . 92 ± 1 . 33 and 7 . 13 ± 1 . 09 respectively in the P ##EL ##D group ( P = . 88 ##8 ) . [ 54 ] At the follow - up duration of 12 months , the VA ##S scores significantly reduced in the two groups as compared with pre ##oper ##ative values . However , there was no significant differences between the them in the post ##oper ##ation VA ##S scores for back pain and leg pain . [ 54 ] The authors attributed the results to the relatively larger injury of soft tissue and disruption of spinal stability , which were caused by the inter ##body fusion than disc ##ec ##tom ##y . [ 54 ] There were several potential limitations in this meta - analysis . First , for some outcomes , the data analysis was based on relatively small number of included studies and sample size ; thus , the conclusions about the outcomes should be interpreted with caution . Second , most of the included studies were retrospective co ##hor ##t study , and the grade evidence was inferior to that of RC ##T ##s . Third , despite we performed sensitivity analysis and subgroup analysis to explore the der ##ivation of he ##tero ##gene ##ity , no valuable information was found . We thought that some potential reasons may account for the great he ##tero ##gene ##ity , including patients ’ characteristics ( age , sex , B ##MI , type of disc her ##nia ##tion , and surgical segment ) , duration of follow - up , case definition , and surgical approaches . These factors may have an impact on our results . thus , considering these limitations , caution is advised when interpret ##ing our findings and applying them into the clinical practice . In conclusion , the present meta - analysis of 14 studies suggested that [SEP]\n",
      "I1208 12:27:37.111467 139883775852736 run_factoid.py:443] tokens: [CLS] What did the paper find ? [SEP] , 54 ] Yao Y , et al [ 54 ] reported that the pre ##oper ##ative VA ##S scores for back pain and leg pain were 5 . 88 ± 1 . 24 and 7 . 05 ± 1 . 08 in the MI ##S - T ##L ##IF group , 5 . 92 ± 1 . 33 and 7 . 13 ± 1 . 09 respectively in the P ##EL ##D group ( P = . 88 ##8 ) . [ 54 ] At the follow - up duration of 12 months , the VA ##S scores significantly reduced in the two groups as compared with pre ##oper ##ative values . However , there was no significant differences between the them in the post ##oper ##ation VA ##S scores for back pain and leg pain . [ 54 ] The authors attributed the results to the relatively larger injury of soft tissue and disruption of spinal stability , which were caused by the inter ##body fusion than disc ##ec ##tom ##y . [ 54 ] There were several potential limitations in this meta - analysis . First , for some outcomes , the data analysis was based on relatively small number of included studies and sample size ; thus , the conclusions about the outcomes should be interpreted with caution . Second , most of the included studies were retrospective co ##hor ##t study , and the grade evidence was inferior to that of RC ##T ##s . Third , despite we performed sensitivity analysis and subgroup analysis to explore the der ##ivation of he ##tero ##gene ##ity , no valuable information was found . We thought that some potential reasons may account for the great he ##tero ##gene ##ity , including patients ’ characteristics ( age , sex , B ##MI , type of disc her ##nia ##tion , and surgical segment ) , duration of follow - up , case definition , and surgical approaches . These factors may have an impact on our results . thus , considering these limitations , caution is advised when interpret ##ing our findings and applying them into the clinical practice . In conclusion , the present meta - analysis of 14 studies suggested that [SEP]\n",
      "INFO:tensorflow:token_to_orig_map: 8:848 9:848 10:848 11:849 12:850 13:850 14:851 15:852 16:852 17:852 18:852 19:853 20:854 21:855 22:856 23:856 24:856 25:857 26:857 27:858 28:859 29:860 30:861 31:862 32:863 33:864 34:865 35:866 36:866 37:866 38:867 39:868 40:868 41:868 42:869 43:870 44:870 45:870 46:871 47:872 48:872 49:872 50:873 51:874 52:875 53:875 54:875 55:876 56:876 57:876 58:877 59:877 60:878 61:878 62:878 63:879 64:880 65:880 66:880 67:881 68:882 69:882 70:882 71:883 72:884 73:884 74:884 75:885 76:886 77:887 78:888 79:888 80:888 81:889 82:890 83:890 84:891 85:892 86:892 87:892 88:892 89:892 90:892 91:892 92:892 93:893 94:894 95:895 96:895 97:895 98:896 99:897 100:898 101:899 102:899 103:900 104:901 105:901 106:902 107:903 108:904 109:905 110:906 111:907 112:908 113:909 114:910 115:911 116:912 117:912 118:912 119:913 120:913 121:914 122:914 123:915 124:916 125:917 126:918 127:919 128:920 129:921 130:922 131:923 132:924 133:925 134:925 135:925 136:926 137:926 138:927 139:928 140:929 141:930 142:931 143:932 144:933 145:933 146:933 147:933 148:933 149:934 150:935 151:936 152:937 153:938 154:939 155:940 156:941 157:942 158:943 159:944 160:945 161:946 162:947 163:948 164:949 165:950 166:951 167:951 168:952 169:953 170:954 171:955 172:956 173:957 174:957 175:958 176:959 177:960 178:960 179:960 180:960 181:960 182:960 183:960 184:960 185:961 186:962 187:963 188:964 189:965 190:966 191:967 192:968 193:968 194:968 195:968 196:969 197:969 198:970 199:971 200:972 201:972 202:973 203:974 204:975 205:976 206:977 207:978 208:979 209:980 210:981 211:982 212:983 213:984 214:985 215:986 216:987 217:987 218:988 219:988 220:989 221:990 222:991 223:992 224:993 225:994 226:995 227:996 228:997 229:998 230:998 231:999 232:999 233:1000 234:1001 235:1002 236:1003 237:1004 238:1005 239:1006 240:1007 241:1007 242:1007 243:1008 244:1008 245:1009 246:1010 247:1011 248:1012 249:1013 250:1014 251:1015 252:1016 253:1017 254:1018 255:1018 256:1018 257:1018 258:1019 259:1019 260:1020 261:1021 262:1022 263:1023 264:1024 265:1025 266:1026 267:1027 268:1028 269:1029 270:1030 271:1031 272:1031 273:1032 274:1033 275:1033 276:1033 277:1033 278:1033 279:1034 280:1035 281:1036 282:1037 283:1038 284:1038 285:1039 286:1040 287:1041 288:1042 289:1043 290:1044 291:1045 292:1046 293:1047 294:1048 295:1049 296:1050 297:1050 298:1050 299:1050 300:1050 301:1051 302:1052 303:1052 304:1053 305:1054 306:1054 307:1054 308:1055 309:1055 310:1056 311:1056 312:1056 313:1057 314:1058 315:1059 316:1060 317:1060 318:1060 319:1060 320:1061 321:1062 322:1063 323:1063 324:1063 325:1064 326:1065 327:1066 328:1066 329:1066 330:1066 331:1067 332:1068 333:1068 334:1069 335:1070 336:1071 337:1071 338:1072 339:1073 340:1074 341:1075 342:1076 343:1077 344:1078 345:1079 346:1080 347:1080 348:1081 349:1081 350:1082 351:1083 352:1084 353:1084 354:1085 355:1086 356:1087 357:1088 358:1089 359:1089 360:1090 361:1091 362:1092 363:1093 364:1094 365:1095 366:1096 367:1097 368:1098 369:1098 370:1099 371:1100 372:1100 373:1101 374:1102 375:1103 376:1103 377:1103 378:1104 379:1105 380:1106 381:1107 382:1108\n",
      "I1208 12:27:37.111602 139883775852736 run_factoid.py:445] token_to_orig_map: 8:848 9:848 10:848 11:849 12:850 13:850 14:851 15:852 16:852 17:852 18:852 19:853 20:854 21:855 22:856 23:856 24:856 25:857 26:857 27:858 28:859 29:860 30:861 31:862 32:863 33:864 34:865 35:866 36:866 37:866 38:867 39:868 40:868 41:868 42:869 43:870 44:870 45:870 46:871 47:872 48:872 49:872 50:873 51:874 52:875 53:875 54:875 55:876 56:876 57:876 58:877 59:877 60:878 61:878 62:878 63:879 64:880 65:880 66:880 67:881 68:882 69:882 70:882 71:883 72:884 73:884 74:884 75:885 76:886 77:887 78:888 79:888 80:888 81:889 82:890 83:890 84:891 85:892 86:892 87:892 88:892 89:892 90:892 91:892 92:892 93:893 94:894 95:895 96:895 97:895 98:896 99:897 100:898 101:899 102:899 103:900 104:901 105:901 106:902 107:903 108:904 109:905 110:906 111:907 112:908 113:909 114:910 115:911 116:912 117:912 118:912 119:913 120:913 121:914 122:914 123:915 124:916 125:917 126:918 127:919 128:920 129:921 130:922 131:923 132:924 133:925 134:925 135:925 136:926 137:926 138:927 139:928 140:929 141:930 142:931 143:932 144:933 145:933 146:933 147:933 148:933 149:934 150:935 151:936 152:937 153:938 154:939 155:940 156:941 157:942 158:943 159:944 160:945 161:946 162:947 163:948 164:949 165:950 166:951 167:951 168:952 169:953 170:954 171:955 172:956 173:957 174:957 175:958 176:959 177:960 178:960 179:960 180:960 181:960 182:960 183:960 184:960 185:961 186:962 187:963 188:964 189:965 190:966 191:967 192:968 193:968 194:968 195:968 196:969 197:969 198:970 199:971 200:972 201:972 202:973 203:974 204:975 205:976 206:977 207:978 208:979 209:980 210:981 211:982 212:983 213:984 214:985 215:986 216:987 217:987 218:988 219:988 220:989 221:990 222:991 223:992 224:993 225:994 226:995 227:996 228:997 229:998 230:998 231:999 232:999 233:1000 234:1001 235:1002 236:1003 237:1004 238:1005 239:1006 240:1007 241:1007 242:1007 243:1008 244:1008 245:1009 246:1010 247:1011 248:1012 249:1013 250:1014 251:1015 252:1016 253:1017 254:1018 255:1018 256:1018 257:1018 258:1019 259:1019 260:1020 261:1021 262:1022 263:1023 264:1024 265:1025 266:1026 267:1027 268:1028 269:1029 270:1030 271:1031 272:1031 273:1032 274:1033 275:1033 276:1033 277:1033 278:1033 279:1034 280:1035 281:1036 282:1037 283:1038 284:1038 285:1039 286:1040 287:1041 288:1042 289:1043 290:1044 291:1045 292:1046 293:1047 294:1048 295:1049 296:1050 297:1050 298:1050 299:1050 300:1050 301:1051 302:1052 303:1052 304:1053 305:1054 306:1054 307:1054 308:1055 309:1055 310:1056 311:1056 312:1056 313:1057 314:1058 315:1059 316:1060 317:1060 318:1060 319:1060 320:1061 321:1062 322:1063 323:1063 324:1063 325:1064 326:1065 327:1066 328:1066 329:1066 330:1066 331:1067 332:1068 333:1068 334:1069 335:1070 336:1071 337:1071 338:1072 339:1073 340:1074 341:1075 342:1076 343:1077 344:1078 345:1079 346:1080 347:1080 348:1081 349:1081 350:1082 351:1083 352:1084 353:1084 354:1085 355:1086 356:1087 357:1088 358:1089 359:1089 360:1090 361:1091 362:1092 363:1093 364:1094 365:1095 366:1096 367:1097 368:1098 369:1098 370:1099 371:1100 372:1100 373:1101 374:1102 375:1103 376:1103 377:1103 378:1104 379:1105 380:1106 381:1107 382:1108\n",
      "INFO:tensorflow:token_is_max_context: 8:False 9:False 10:False 11:False 12:False 13:False 14:False 15:False 16:False 17:False 18:False 19:False 20:False 21:False 22:False 23:False 24:False 25:False 26:False 27:False 28:False 29:False 30:False 31:False 32:False 33:False 34:False 35:False 36:False 37:False 38:False 39:False 40:False 41:False 42:False 43:False 44:False 45:False 46:False 47:False 48:False 49:False 50:False 51:False 52:False 53:False 54:False 55:False 56:False 57:False 58:False 59:False 60:False 61:False 62:False 63:False 64:False 65:False 66:False 67:False 68:False 69:False 70:False 71:False 72:False 73:False 74:False 75:False 76:False 77:False 78:False 79:False 80:False 81:False 82:False 83:False 84:False 85:False 86:False 87:False 88:False 89:False 90:False 91:False 92:False 93:False 94:False 95:False 96:False 97:False 98:False 99:False 100:False 101:False 102:False 103:False 104:False 105:False 106:False 107:False 108:False 109:False 110:False 111:False 112:False 113:False 114:False 115:False 116:False 117:False 118:False 119:False 120:False 121:False 122:False 123:False 124:False 125:False 126:False 127:False 128:False 129:False 130:False 131:False 132:True 133:True 134:True 135:True 136:True 137:True 138:True 139:True 140:True 141:True 142:True 143:True 144:True 145:True 146:True 147:True 148:True 149:True 150:True 151:True 152:True 153:True 154:True 155:True 156:True 157:True 158:True 159:True 160:True 161:True 162:True 163:True 164:True 165:True 166:True 167:True 168:True 169:True 170:True 171:True 172:True 173:True 174:True 175:True 176:True 177:True 178:True 179:True 180:True 181:True 182:True 183:True 184:True 185:True 186:True 187:True 188:True 189:True 190:True 191:True 192:True 193:True 194:True 195:True 196:True 197:True 198:True 199:True 200:True 201:True 202:True 203:True 204:True 205:True 206:True 207:True 208:True 209:True 210:True 211:True 212:True 213:True 214:True 215:True 216:True 217:True 218:True 219:True 220:True 221:True 222:True 223:True 224:True 225:True 226:True 227:True 228:True 229:True 230:True 231:True 232:True 233:True 234:True 235:True 236:True 237:True 238:True 239:True 240:True 241:True 242:True 243:True 244:True 245:True 246:True 247:True 248:True 249:True 250:True 251:True 252:True 253:True 254:True 255:True 256:True 257:True 258:True 259:True 260:False 261:False 262:False 263:False 264:False 265:False 266:False 267:False 268:False 269:False 270:False 271:False 272:False 273:False 274:False 275:False 276:False 277:False 278:False 279:False 280:False 281:False 282:False 283:False 284:False 285:False 286:False 287:False 288:False 289:False 290:False 291:False 292:False 293:False 294:False 295:False 296:False 297:False 298:False 299:False 300:False 301:False 302:False 303:False 304:False 305:False 306:False 307:False 308:False 309:False 310:False 311:False 312:False 313:False 314:False 315:False 316:False 317:False 318:False 319:False 320:False 321:False 322:False 323:False 324:False 325:False 326:False 327:False 328:False 329:False 330:False 331:False 332:False 333:False 334:False 335:False 336:False 337:False 338:False 339:False 340:False 341:False 342:False 343:False 344:False 345:False 346:False 347:False 348:False 349:False 350:False 351:False 352:False 353:False 354:False 355:False 356:False 357:False 358:False 359:False 360:False 361:False 362:False 363:False 364:False 365:False 366:False 367:False 368:False 369:False 370:False 371:False 372:False 373:False 374:False 375:False 376:False 377:False 378:False 379:False 380:False 381:False 382:False\n",
      "I1208 12:27:37.111718 139883775852736 run_factoid.py:447] token_is_max_context: 8:False 9:False 10:False 11:False 12:False 13:False 14:False 15:False 16:False 17:False 18:False 19:False 20:False 21:False 22:False 23:False 24:False 25:False 26:False 27:False 28:False 29:False 30:False 31:False 32:False 33:False 34:False 35:False 36:False 37:False 38:False 39:False 40:False 41:False 42:False 43:False 44:False 45:False 46:False 47:False 48:False 49:False 50:False 51:False 52:False 53:False 54:False 55:False 56:False 57:False 58:False 59:False 60:False 61:False 62:False 63:False 64:False 65:False 66:False 67:False 68:False 69:False 70:False 71:False 72:False 73:False 74:False 75:False 76:False 77:False 78:False 79:False 80:False 81:False 82:False 83:False 84:False 85:False 86:False 87:False 88:False 89:False 90:False 91:False 92:False 93:False 94:False 95:False 96:False 97:False 98:False 99:False 100:False 101:False 102:False 103:False 104:False 105:False 106:False 107:False 108:False 109:False 110:False 111:False 112:False 113:False 114:False 115:False 116:False 117:False 118:False 119:False 120:False 121:False 122:False 123:False 124:False 125:False 126:False 127:False 128:False 129:False 130:False 131:False 132:True 133:True 134:True 135:True 136:True 137:True 138:True 139:True 140:True 141:True 142:True 143:True 144:True 145:True 146:True 147:True 148:True 149:True 150:True 151:True 152:True 153:True 154:True 155:True 156:True 157:True 158:True 159:True 160:True 161:True 162:True 163:True 164:True 165:True 166:True 167:True 168:True 169:True 170:True 171:True 172:True 173:True 174:True 175:True 176:True 177:True 178:True 179:True 180:True 181:True 182:True 183:True 184:True 185:True 186:True 187:True 188:True 189:True 190:True 191:True 192:True 193:True 194:True 195:True 196:True 197:True 198:True 199:True 200:True 201:True 202:True 203:True 204:True 205:True 206:True 207:True 208:True 209:True 210:True 211:True 212:True 213:True 214:True 215:True 216:True 217:True 218:True 219:True 220:True 221:True 222:True 223:True 224:True 225:True 226:True 227:True 228:True 229:True 230:True 231:True 232:True 233:True 234:True 235:True 236:True 237:True 238:True 239:True 240:True 241:True 242:True 243:True 244:True 245:True 246:True 247:True 248:True 249:True 250:True 251:True 252:True 253:True 254:True 255:True 256:True 257:True 258:True 259:True 260:False 261:False 262:False 263:False 264:False 265:False 266:False 267:False 268:False 269:False 270:False 271:False 272:False 273:False 274:False 275:False 276:False 277:False 278:False 279:False 280:False 281:False 282:False 283:False 284:False 285:False 286:False 287:False 288:False 289:False 290:False 291:False 292:False 293:False 294:False 295:False 296:False 297:False 298:False 299:False 300:False 301:False 302:False 303:False 304:False 305:False 306:False 307:False 308:False 309:False 310:False 311:False 312:False 313:False 314:False 315:False 316:False 317:False 318:False 319:False 320:False 321:False 322:False 323:False 324:False 325:False 326:False 327:False 328:False 329:False 330:False 331:False 332:False 333:False 334:False 335:False 336:False 337:False 338:False 339:False 340:False 341:False 342:False 343:False 344:False 345:False 346:False 347:False 348:False 349:False 350:False 351:False 352:False 353:False 354:False 355:False 356:False 357:False 358:False 359:False 360:False 361:False 362:False 363:False 364:False 365:False 366:False 367:False 368:False 369:False 370:False 371:False 372:False 373:False 374:False 375:False 376:False 377:False 378:False 379:False 380:False 381:False 382:False\n",
      "INFO:tensorflow:input_ids: 101 1327 1225 1103 2526 1525 136 102 117 4335 166 27762 162 117 3084 2393 164 4335 166 2103 1115 1103 3073 19807 5838 19497 1708 7432 1111 1171 2489 1105 3420 2489 1127 126 119 5385 212 122 119 1572 1105 128 119 4991 212 122 119 4775 1107 1103 26574 1708 118 157 2162 15499 1372 117 126 119 5556 212 122 119 3081 1105 128 119 1492 212 122 119 4925 3569 1107 1103 153 21678 2137 1372 113 153 134 119 5385 1604 114 119 164 4335 166 1335 1103 2812 118 1146 9355 1104 1367 1808 117 1103 19497 1708 7432 5409 3549 1107 1103 1160 2114 1112 3402 1114 3073 19807 5838 4718 119 1438 117 1175 1108 1185 2418 5408 1206 1103 1172 1107 1103 2112 19807 1891 19497 1708 7432 1111 1171 2489 1105 3420 2489 119 164 4335 166 1109 5752 6547 1103 2686 1106 1103 3860 2610 3773 1104 2991 7918 1105 23730 1104 19245 9397 117 1134 1127 2416 1118 1103 9455 14637 11970 1190 6187 10294 18778 1183 119 164 4335 166 1247 1127 1317 3209 13004 1107 1142 27154 118 3622 119 1752 117 1111 1199 13950 117 1103 2233 3622 1108 1359 1113 3860 1353 1295 1104 1529 2527 1105 6876 2060 132 2456 117 1103 16421 1164 1103 13950 1431 1129 9829 1114 15597 119 2307 117 1211 1104 1103 1529 2527 1127 18675 1884 13252 1204 2025 117 1105 1103 3654 2554 1108 15543 1106 1115 1104 25157 1942 1116 119 4180 117 2693 1195 1982 15750 3622 1105 23470 3622 1106 8664 1103 4167 16617 1104 1119 25710 27054 1785 117 1185 7468 1869 1108 1276 119 1284 1354 1115 1199 3209 3672 1336 3300 1111 1103 1632 1119 25710 27054 1785 117 1259 4420 787 5924 113 1425 117 2673 117 139 14038 117 2076 1104 6187 1123 5813 2116 117 1105 13467 6441 114 117 9355 1104 2812 118 1146 117 1692 5754 117 1105 13467 8015 119 1636 5320 1336 1138 1126 3772 1113 1412 2686 119 2456 117 6103 1292 13004 117 15597 1110 9213 1165 19348 1158 1412 9505 1105 11892 1172 1154 1103 7300 2415 119 1130 6593 117 1103 1675 27154 118 3622 1104 1489 2527 3228 1115 102\n",
      "I1208 12:27:37.111828 139883775852736 run_factoid.py:449] input_ids: 101 1327 1225 1103 2526 1525 136 102 117 4335 166 27762 162 117 3084 2393 164 4335 166 2103 1115 1103 3073 19807 5838 19497 1708 7432 1111 1171 2489 1105 3420 2489 1127 126 119 5385 212 122 119 1572 1105 128 119 4991 212 122 119 4775 1107 1103 26574 1708 118 157 2162 15499 1372 117 126 119 5556 212 122 119 3081 1105 128 119 1492 212 122 119 4925 3569 1107 1103 153 21678 2137 1372 113 153 134 119 5385 1604 114 119 164 4335 166 1335 1103 2812 118 1146 9355 1104 1367 1808 117 1103 19497 1708 7432 5409 3549 1107 1103 1160 2114 1112 3402 1114 3073 19807 5838 4718 119 1438 117 1175 1108 1185 2418 5408 1206 1103 1172 1107 1103 2112 19807 1891 19497 1708 7432 1111 1171 2489 1105 3420 2489 119 164 4335 166 1109 5752 6547 1103 2686 1106 1103 3860 2610 3773 1104 2991 7918 1105 23730 1104 19245 9397 117 1134 1127 2416 1118 1103 9455 14637 11970 1190 6187 10294 18778 1183 119 164 4335 166 1247 1127 1317 3209 13004 1107 1142 27154 118 3622 119 1752 117 1111 1199 13950 117 1103 2233 3622 1108 1359 1113 3860 1353 1295 1104 1529 2527 1105 6876 2060 132 2456 117 1103 16421 1164 1103 13950 1431 1129 9829 1114 15597 119 2307 117 1211 1104 1103 1529 2527 1127 18675 1884 13252 1204 2025 117 1105 1103 3654 2554 1108 15543 1106 1115 1104 25157 1942 1116 119 4180 117 2693 1195 1982 15750 3622 1105 23470 3622 1106 8664 1103 4167 16617 1104 1119 25710 27054 1785 117 1185 7468 1869 1108 1276 119 1284 1354 1115 1199 3209 3672 1336 3300 1111 1103 1632 1119 25710 27054 1785 117 1259 4420 787 5924 113 1425 117 2673 117 139 14038 117 2076 1104 6187 1123 5813 2116 117 1105 13467 6441 114 117 9355 1104 2812 118 1146 117 1692 5754 117 1105 13467 8015 119 1636 5320 1336 1138 1126 3772 1113 1412 2686 119 2456 117 6103 1292 13004 117 15597 1110 9213 1165 19348 1158 1412 9505 1105 11892 1172 1154 1103 7300 2415 119 1130 6593 117 1103 1675 27154 118 3622 1104 1489 2527 3228 1115 102\n",
      "INFO:tensorflow:input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      "I1208 12:27:37.111925 139883775852736 run_factoid.py:451] input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      "INFO:tensorflow:segment_ids: 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      "I1208 12:27:37.112019 139883775852736 run_factoid.py:453] segment_ids: 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      "INFO:tensorflow:*** Example ***\n",
      "I1208 12:27:37.113548 139883775852736 run_factoid.py:438] *** Example ***\n",
      "INFO:tensorflow:unique_id: 1000000039\n",
      "I1208 12:27:37.113611 139883775852736 run_factoid.py:439] unique_id: 1000000039\n",
      "INFO:tensorflow:example_index: 7\n",
      "I1208 12:27:37.113649 139883775852736 run_factoid.py:440] example_index: 7\n",
      "INFO:tensorflow:doc_span_index: 12\n",
      "I1208 12:27:37.113684 139883775852736 run_factoid.py:441] doc_span_index: 12\n",
      "INFO:tensorflow:tokens: [CLS] What did the paper find ? [SEP] VA ##S scores for back pain and leg pain . [ 54 ] The authors attributed the results to the relatively larger injury of soft tissue and disruption of spinal stability , which were caused by the inter ##body fusion than disc ##ec ##tom ##y . [ 54 ] There were several potential limitations in this meta - analysis . First , for some outcomes , the data analysis was based on relatively small number of included studies and sample size ; thus , the conclusions about the outcomes should be interpreted with caution . Second , most of the included studies were retrospective co ##hor ##t study , and the grade evidence was inferior to that of RC ##T ##s . Third , despite we performed sensitivity analysis and subgroup analysis to explore the der ##ivation of he ##tero ##gene ##ity , no valuable information was found . We thought that some potential reasons may account for the great he ##tero ##gene ##ity , including patients ’ characteristics ( age , sex , B ##MI , type of disc her ##nia ##tion , and surgical segment ) , duration of follow - up , case definition , and surgical approaches . These factors may have an impact on our results . thus , considering these limitations , caution is advised when interpret ##ing our findings and applying them into the clinical practice . In conclusion , the present meta - analysis of 14 studies suggested that , P ##EL ##D was associated with better effects and similar complications with other surge ##ries in the treatment of L ##D ##H . However , it also resulted in a higher re ##cu ##rrence rate . Considering the potential limitations in the present study , further large - scale , well - performed random ##ized trials are needed to verify our findings . [SEP]\n",
      "I1208 12:27:37.113787 139883775852736 run_factoid.py:443] tokens: [CLS] What did the paper find ? [SEP] VA ##S scores for back pain and leg pain . [ 54 ] The authors attributed the results to the relatively larger injury of soft tissue and disruption of spinal stability , which were caused by the inter ##body fusion than disc ##ec ##tom ##y . [ 54 ] There were several potential limitations in this meta - analysis . First , for some outcomes , the data analysis was based on relatively small number of included studies and sample size ; thus , the conclusions about the outcomes should be interpreted with caution . Second , most of the included studies were retrospective co ##hor ##t study , and the grade evidence was inferior to that of RC ##T ##s . Third , despite we performed sensitivity analysis and subgroup analysis to explore the der ##ivation of he ##tero ##gene ##ity , no valuable information was found . We thought that some potential reasons may account for the great he ##tero ##gene ##ity , including patients ’ characteristics ( age , sex , B ##MI , type of disc her ##nia ##tion , and surgical segment ) , duration of follow - up , case definition , and surgical approaches . These factors may have an impact on our results . thus , considering these limitations , caution is advised when interpret ##ing our findings and applying them into the clinical practice . In conclusion , the present meta - analysis of 14 studies suggested that , P ##EL ##D was associated with better effects and similar complications with other surge ##ries in the treatment of L ##D ##H . However , it also resulted in a higher re ##cu ##rrence rate . Considering the potential limitations in the present study , further large - scale , well - performed random ##ized trials are needed to verify our findings . [SEP]\n",
      "INFO:tensorflow:token_to_orig_map: 8:926 9:926 10:927 11:928 12:929 13:930 14:931 15:932 16:933 17:933 18:933 19:933 20:933 21:934 22:935 23:936 24:937 25:938 26:939 27:940 28:941 29:942 30:943 31:944 32:945 33:946 34:947 35:948 36:949 37:950 38:951 39:951 40:952 41:953 42:954 43:955 44:956 45:957 46:957 47:958 48:959 49:960 50:960 51:960 52:960 53:960 54:960 55:960 56:960 57:961 58:962 59:963 60:964 61:965 62:966 63:967 64:968 65:968 66:968 67:968 68:969 69:969 70:970 71:971 72:972 73:972 74:973 75:974 76:975 77:976 78:977 79:978 80:979 81:980 82:981 83:982 84:983 85:984 86:985 87:986 88:987 89:987 90:988 91:988 92:989 93:990 94:991 95:992 96:993 97:994 98:995 99:996 100:997 101:998 102:998 103:999 104:999 105:1000 106:1001 107:1002 108:1003 109:1004 110:1005 111:1006 112:1007 113:1007 114:1007 115:1008 116:1008 117:1009 118:1010 119:1011 120:1012 121:1013 122:1014 123:1015 124:1016 125:1017 126:1018 127:1018 128:1018 129:1018 130:1019 131:1019 132:1020 133:1021 134:1022 135:1023 136:1024 137:1025 138:1026 139:1027 140:1028 141:1029 142:1030 143:1031 144:1031 145:1032 146:1033 147:1033 148:1033 149:1033 150:1033 151:1034 152:1035 153:1036 154:1037 155:1038 156:1038 157:1039 158:1040 159:1041 160:1042 161:1043 162:1044 163:1045 164:1046 165:1047 166:1048 167:1049 168:1050 169:1050 170:1050 171:1050 172:1050 173:1051 174:1052 175:1052 176:1053 177:1054 178:1054 179:1054 180:1055 181:1055 182:1056 183:1056 184:1056 185:1057 186:1058 187:1059 188:1060 189:1060 190:1060 191:1060 192:1061 193:1062 194:1063 195:1063 196:1063 197:1064 198:1065 199:1066 200:1066 201:1066 202:1066 203:1067 204:1068 205:1068 206:1069 207:1070 208:1071 209:1071 210:1072 211:1073 212:1074 213:1075 214:1076 215:1077 216:1078 217:1079 218:1080 219:1080 220:1081 221:1081 222:1082 223:1083 224:1084 225:1084 226:1085 227:1086 228:1087 229:1088 230:1089 231:1089 232:1090 233:1091 234:1092 235:1093 236:1094 237:1095 238:1096 239:1097 240:1098 241:1098 242:1099 243:1100 244:1100 245:1101 246:1102 247:1103 248:1103 249:1103 250:1104 251:1105 252:1106 253:1107 254:1108 255:1108 256:1109 257:1109 258:1109 259:1110 260:1111 261:1112 262:1113 263:1114 264:1115 265:1116 266:1117 267:1118 268:1119 269:1120 270:1120 271:1121 272:1122 273:1123 274:1124 275:1125 276:1125 277:1125 278:1125 279:1126 280:1126 281:1127 282:1128 283:1129 284:1130 285:1131 286:1132 287:1133 288:1133 289:1133 290:1134 291:1134 292:1135 293:1136 294:1137 295:1138 296:1139 297:1140 298:1141 299:1142 300:1142 301:1143 302:1144 303:1144 304:1144 305:1144 306:1145 307:1145 308:1145 309:1146 310:1146 311:1147 312:1148 313:1149 314:1150 315:1151 316:1152 317:1153 318:1153\n",
      "I1208 12:27:37.113909 139883775852736 run_factoid.py:445] token_to_orig_map: 8:926 9:926 10:927 11:928 12:929 13:930 14:931 15:932 16:933 17:933 18:933 19:933 20:933 21:934 22:935 23:936 24:937 25:938 26:939 27:940 28:941 29:942 30:943 31:944 32:945 33:946 34:947 35:948 36:949 37:950 38:951 39:951 40:952 41:953 42:954 43:955 44:956 45:957 46:957 47:958 48:959 49:960 50:960 51:960 52:960 53:960 54:960 55:960 56:960 57:961 58:962 59:963 60:964 61:965 62:966 63:967 64:968 65:968 66:968 67:968 68:969 69:969 70:970 71:971 72:972 73:972 74:973 75:974 76:975 77:976 78:977 79:978 80:979 81:980 82:981 83:982 84:983 85:984 86:985 87:986 88:987 89:987 90:988 91:988 92:989 93:990 94:991 95:992 96:993 97:994 98:995 99:996 100:997 101:998 102:998 103:999 104:999 105:1000 106:1001 107:1002 108:1003 109:1004 110:1005 111:1006 112:1007 113:1007 114:1007 115:1008 116:1008 117:1009 118:1010 119:1011 120:1012 121:1013 122:1014 123:1015 124:1016 125:1017 126:1018 127:1018 128:1018 129:1018 130:1019 131:1019 132:1020 133:1021 134:1022 135:1023 136:1024 137:1025 138:1026 139:1027 140:1028 141:1029 142:1030 143:1031 144:1031 145:1032 146:1033 147:1033 148:1033 149:1033 150:1033 151:1034 152:1035 153:1036 154:1037 155:1038 156:1038 157:1039 158:1040 159:1041 160:1042 161:1043 162:1044 163:1045 164:1046 165:1047 166:1048 167:1049 168:1050 169:1050 170:1050 171:1050 172:1050 173:1051 174:1052 175:1052 176:1053 177:1054 178:1054 179:1054 180:1055 181:1055 182:1056 183:1056 184:1056 185:1057 186:1058 187:1059 188:1060 189:1060 190:1060 191:1060 192:1061 193:1062 194:1063 195:1063 196:1063 197:1064 198:1065 199:1066 200:1066 201:1066 202:1066 203:1067 204:1068 205:1068 206:1069 207:1070 208:1071 209:1071 210:1072 211:1073 212:1074 213:1075 214:1076 215:1077 216:1078 217:1079 218:1080 219:1080 220:1081 221:1081 222:1082 223:1083 224:1084 225:1084 226:1085 227:1086 228:1087 229:1088 230:1089 231:1089 232:1090 233:1091 234:1092 235:1093 236:1094 237:1095 238:1096 239:1097 240:1098 241:1098 242:1099 243:1100 244:1100 245:1101 246:1102 247:1103 248:1103 249:1103 250:1104 251:1105 252:1106 253:1107 254:1108 255:1108 256:1109 257:1109 258:1109 259:1110 260:1111 261:1112 262:1113 263:1114 264:1115 265:1116 266:1117 267:1118 268:1119 269:1120 270:1120 271:1121 272:1122 273:1123 274:1124 275:1125 276:1125 277:1125 278:1125 279:1126 280:1126 281:1127 282:1128 283:1129 284:1130 285:1131 286:1132 287:1133 288:1133 289:1133 290:1134 291:1134 292:1135 293:1136 294:1137 295:1138 296:1139 297:1140 298:1141 299:1142 300:1142 301:1143 302:1144 303:1144 304:1144 305:1144 306:1145 307:1145 308:1145 309:1146 310:1146 311:1147 312:1148 313:1149 314:1150 315:1151 316:1152 317:1153 318:1153\n",
      "INFO:tensorflow:token_is_max_context: 8:False 9:False 10:False 11:False 12:False 13:False 14:False 15:False 16:False 17:False 18:False 19:False 20:False 21:False 22:False 23:False 24:False 25:False 26:False 27:False 28:False 29:False 30:False 31:False 32:False 33:False 34:False 35:False 36:False 37:False 38:False 39:False 40:False 41:False 42:False 43:False 44:False 45:False 46:False 47:False 48:False 49:False 50:False 51:False 52:False 53:False 54:False 55:False 56:False 57:False 58:False 59:False 60:False 61:False 62:False 63:False 64:False 65:False 66:False 67:False 68:False 69:False 70:False 71:False 72:False 73:False 74:False 75:False 76:False 77:False 78:False 79:False 80:False 81:False 82:False 83:False 84:False 85:False 86:False 87:False 88:False 89:False 90:False 91:False 92:False 93:False 94:False 95:False 96:False 97:False 98:False 99:False 100:False 101:False 102:False 103:False 104:False 105:False 106:False 107:False 108:False 109:False 110:False 111:False 112:False 113:False 114:False 115:False 116:False 117:False 118:False 119:False 120:False 121:False 122:False 123:False 124:False 125:False 126:False 127:False 128:False 129:False 130:False 131:False 132:True 133:True 134:True 135:True 136:True 137:True 138:True 139:True 140:True 141:True 142:True 143:True 144:True 145:True 146:True 147:True 148:True 149:True 150:True 151:True 152:True 153:True 154:True 155:True 156:True 157:True 158:True 159:True 160:True 161:True 162:True 163:True 164:True 165:True 166:True 167:True 168:True 169:True 170:True 171:True 172:True 173:True 174:True 175:True 176:True 177:True 178:True 179:True 180:True 181:True 182:True 183:True 184:True 185:True 186:True 187:True 188:True 189:True 190:True 191:True 192:True 193:True 194:True 195:True 196:True 197:True 198:True 199:True 200:True 201:True 202:True 203:True 204:True 205:True 206:True 207:True 208:True 209:True 210:True 211:True 212:True 213:True 214:True 215:True 216:True 217:True 218:True 219:True 220:True 221:True 222:True 223:True 224:True 225:True 226:True 227:True 228:True 229:True 230:True 231:True 232:True 233:True 234:True 235:True 236:True 237:True 238:True 239:True 240:True 241:True 242:True 243:True 244:True 245:True 246:True 247:True 248:True 249:True 250:True 251:True 252:True 253:True 254:True 255:True 256:True 257:True 258:True 259:True 260:True 261:True 262:True 263:True 264:True 265:True 266:True 267:True 268:True 269:True 270:True 271:True 272:True 273:True 274:True 275:True 276:True 277:True 278:True 279:True 280:True 281:True 282:True 283:True 284:True 285:True 286:True 287:True 288:True 289:True 290:True 291:True 292:True 293:True 294:True 295:True 296:True 297:True 298:True 299:True 300:True 301:True 302:True 303:True 304:True 305:True 306:True 307:True 308:True 309:True 310:True 311:True 312:True 313:True 314:True 315:True 316:True 317:True 318:True\n",
      "I1208 12:27:37.114014 139883775852736 run_factoid.py:447] token_is_max_context: 8:False 9:False 10:False 11:False 12:False 13:False 14:False 15:False 16:False 17:False 18:False 19:False 20:False 21:False 22:False 23:False 24:False 25:False 26:False 27:False 28:False 29:False 30:False 31:False 32:False 33:False 34:False 35:False 36:False 37:False 38:False 39:False 40:False 41:False 42:False 43:False 44:False 45:False 46:False 47:False 48:False 49:False 50:False 51:False 52:False 53:False 54:False 55:False 56:False 57:False 58:False 59:False 60:False 61:False 62:False 63:False 64:False 65:False 66:False 67:False 68:False 69:False 70:False 71:False 72:False 73:False 74:False 75:False 76:False 77:False 78:False 79:False 80:False 81:False 82:False 83:False 84:False 85:False 86:False 87:False 88:False 89:False 90:False 91:False 92:False 93:False 94:False 95:False 96:False 97:False 98:False 99:False 100:False 101:False 102:False 103:False 104:False 105:False 106:False 107:False 108:False 109:False 110:False 111:False 112:False 113:False 114:False 115:False 116:False 117:False 118:False 119:False 120:False 121:False 122:False 123:False 124:False 125:False 126:False 127:False 128:False 129:False 130:False 131:False 132:True 133:True 134:True 135:True 136:True 137:True 138:True 139:True 140:True 141:True 142:True 143:True 144:True 145:True 146:True 147:True 148:True 149:True 150:True 151:True 152:True 153:True 154:True 155:True 156:True 157:True 158:True 159:True 160:True 161:True 162:True 163:True 164:True 165:True 166:True 167:True 168:True 169:True 170:True 171:True 172:True 173:True 174:True 175:True 176:True 177:True 178:True 179:True 180:True 181:True 182:True 183:True 184:True 185:True 186:True 187:True 188:True 189:True 190:True 191:True 192:True 193:True 194:True 195:True 196:True 197:True 198:True 199:True 200:True 201:True 202:True 203:True 204:True 205:True 206:True 207:True 208:True 209:True 210:True 211:True 212:True 213:True 214:True 215:True 216:True 217:True 218:True 219:True 220:True 221:True 222:True 223:True 224:True 225:True 226:True 227:True 228:True 229:True 230:True 231:True 232:True 233:True 234:True 235:True 236:True 237:True 238:True 239:True 240:True 241:True 242:True 243:True 244:True 245:True 246:True 247:True 248:True 249:True 250:True 251:True 252:True 253:True 254:True 255:True 256:True 257:True 258:True 259:True 260:True 261:True 262:True 263:True 264:True 265:True 266:True 267:True 268:True 269:True 270:True 271:True 272:True 273:True 274:True 275:True 276:True 277:True 278:True 279:True 280:True 281:True 282:True 283:True 284:True 285:True 286:True 287:True 288:True 289:True 290:True 291:True 292:True 293:True 294:True 295:True 296:True 297:True 298:True 299:True 300:True 301:True 302:True 303:True 304:True 305:True 306:True 307:True 308:True 309:True 310:True 311:True 312:True 313:True 314:True 315:True 316:True 317:True 318:True\n",
      "INFO:tensorflow:input_ids: 101 1327 1225 1103 2526 1525 136 102 19497 1708 7432 1111 1171 2489 1105 3420 2489 119 164 4335 166 1109 5752 6547 1103 2686 1106 1103 3860 2610 3773 1104 2991 7918 1105 23730 1104 19245 9397 117 1134 1127 2416 1118 1103 9455 14637 11970 1190 6187 10294 18778 1183 119 164 4335 166 1247 1127 1317 3209 13004 1107 1142 27154 118 3622 119 1752 117 1111 1199 13950 117 1103 2233 3622 1108 1359 1113 3860 1353 1295 1104 1529 2527 1105 6876 2060 132 2456 117 1103 16421 1164 1103 13950 1431 1129 9829 1114 15597 119 2307 117 1211 1104 1103 1529 2527 1127 18675 1884 13252 1204 2025 117 1105 1103 3654 2554 1108 15543 1106 1115 1104 25157 1942 1116 119 4180 117 2693 1195 1982 15750 3622 1105 23470 3622 1106 8664 1103 4167 16617 1104 1119 25710 27054 1785 117 1185 7468 1869 1108 1276 119 1284 1354 1115 1199 3209 3672 1336 3300 1111 1103 1632 1119 25710 27054 1785 117 1259 4420 787 5924 113 1425 117 2673 117 139 14038 117 2076 1104 6187 1123 5813 2116 117 1105 13467 6441 114 117 9355 1104 2812 118 1146 117 1692 5754 117 1105 13467 8015 119 1636 5320 1336 1138 1126 3772 1113 1412 2686 119 2456 117 6103 1292 13004 117 15597 1110 9213 1165 19348 1158 1412 9505 1105 11892 1172 1154 1103 7300 2415 119 1130 6593 117 1103 1675 27154 118 3622 1104 1489 2527 3228 1115 117 153 21678 2137 1108 2628 1114 1618 3154 1105 1861 13522 1114 1168 12814 3377 1107 1103 3252 1104 149 2137 3048 119 1438 117 1122 1145 3657 1107 170 2299 1231 10182 21629 2603 119 23243 1103 3209 13004 1107 1103 1675 2025 117 1748 1415 118 3418 117 1218 118 1982 7091 2200 7356 1132 1834 1106 23073 1412 9505 119 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "I1208 12:27:37.114122 139883775852736 run_factoid.py:449] input_ids: 101 1327 1225 1103 2526 1525 136 102 19497 1708 7432 1111 1171 2489 1105 3420 2489 119 164 4335 166 1109 5752 6547 1103 2686 1106 1103 3860 2610 3773 1104 2991 7918 1105 23730 1104 19245 9397 117 1134 1127 2416 1118 1103 9455 14637 11970 1190 6187 10294 18778 1183 119 164 4335 166 1247 1127 1317 3209 13004 1107 1142 27154 118 3622 119 1752 117 1111 1199 13950 117 1103 2233 3622 1108 1359 1113 3860 1353 1295 1104 1529 2527 1105 6876 2060 132 2456 117 1103 16421 1164 1103 13950 1431 1129 9829 1114 15597 119 2307 117 1211 1104 1103 1529 2527 1127 18675 1884 13252 1204 2025 117 1105 1103 3654 2554 1108 15543 1106 1115 1104 25157 1942 1116 119 4180 117 2693 1195 1982 15750 3622 1105 23470 3622 1106 8664 1103 4167 16617 1104 1119 25710 27054 1785 117 1185 7468 1869 1108 1276 119 1284 1354 1115 1199 3209 3672 1336 3300 1111 1103 1632 1119 25710 27054 1785 117 1259 4420 787 5924 113 1425 117 2673 117 139 14038 117 2076 1104 6187 1123 5813 2116 117 1105 13467 6441 114 117 9355 1104 2812 118 1146 117 1692 5754 117 1105 13467 8015 119 1636 5320 1336 1138 1126 3772 1113 1412 2686 119 2456 117 6103 1292 13004 117 15597 1110 9213 1165 19348 1158 1412 9505 1105 11892 1172 1154 1103 7300 2415 119 1130 6593 117 1103 1675 27154 118 3622 1104 1489 2527 3228 1115 117 153 21678 2137 1108 2628 1114 1618 3154 1105 1861 13522 1114 1168 12814 3377 1107 1103 3252 1104 149 2137 3048 119 1438 117 1122 1145 3657 1107 170 2299 1231 10182 21629 2603 119 23243 1103 3209 13004 1107 1103 1675 2025 117 1748 1415 118 3418 117 1218 118 1982 7091 2200 7356 1132 1834 1106 23073 1412 9505 119 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "INFO:tensorflow:input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "I1208 12:27:37.114221 139883775852736 run_factoid.py:451] input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "INFO:tensorflow:segment_ids: 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "I1208 12:27:37.114317 139883775852736 run_factoid.py:453] segment_ids: 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "INFO:tensorflow:*** Example ***\n",
      "I1208 12:27:37.133069 139883775852736 run_factoid.py:438] *** Example ***\n",
      "INFO:tensorflow:unique_id: 1000000040\n",
      "I1208 12:27:37.133144 139883775852736 run_factoid.py:439] unique_id: 1000000040\n",
      "INFO:tensorflow:example_index: 8\n",
      "I1208 12:27:37.133185 139883775852736 run_factoid.py:440] example_index: 8\n",
      "INFO:tensorflow:doc_span_index: 0\n",
      "I1208 12:27:37.133221 139883775852736 run_factoid.py:441] doc_span_index: 0\n",
      "INFO:tensorflow:tokens: [CLS] Do the findings depend on patient demographic ##s ? [SEP] The present meta - analysis of 14 trials involving 2 , 52 ##8 patients provided evidence that P ##EL ##D had favorable clinical outcomes for L ##DF , including shorter operation time and hospital stay , less blood loss , and improved SF ##12 - MC ##S and SF ##12 - PC ##S score . However , it also was associated with a significantly higher rate of re ##current disc her ##nia ##tion . In the present study , we found that patients who underwent P ##EL ##D had a significantly higher re ##cu ##rrence rate than those treated with other surgical interventions . However , in the subgroup analysis based on the com ##par ##ators , the higher rate of re ##current di ##s her ##nia ##tion was only observed in the comparison with MI ##S - T ##L ##IF . Yao Y , et al . [ 45 ] performed a retrospective co ##hor ##t study to compare the outcomes of three minimal ##ly invasive spine surge ##ries ( MI ##S - T ##L ##IF , ME ##D , and P ##EL ##D ) in the treatment of re ##current her ##nia ##tion . At the follow - up duration of 12 ##mont ##hs , no patients ( 0 . 0 % ) in the MI ##S - T ##L ##IF group , 3 patients ( 15 . 0 % ) in the ME ##D group , and 7 patients ( 25 . 0 % ) in the P ##EL ##D group developed re ##cu ##rrence . [ 45 ] The re ##cu ##rrence rate in the P ##EL ##D group was significantly higher than that in the MI ##S - T ##L ##IF group . Similarly , in their another recently published trial , [ 54 ] they also reported a higher re ##cu ##rrence rate of P ##EL ##D than MI ##S - T ##L ##IF . In that study , the authors enrolled 105 patients who underwent either P ##EL ##D ( n = 47 ) or MI ##S - T ##L ##IF ( n = 58 ) for revision of ME ##D re ##cu ##rrence . [ 54 ] At the 12 - month follow - [SEP]\n",
      "I1208 12:27:37.133334 139883775852736 run_factoid.py:443] tokens: [CLS] Do the findings depend on patient demographic ##s ? [SEP] The present meta - analysis of 14 trials involving 2 , 52 ##8 patients provided evidence that P ##EL ##D had favorable clinical outcomes for L ##DF , including shorter operation time and hospital stay , less blood loss , and improved SF ##12 - MC ##S and SF ##12 - PC ##S score . However , it also was associated with a significantly higher rate of re ##current disc her ##nia ##tion . In the present study , we found that patients who underwent P ##EL ##D had a significantly higher re ##cu ##rrence rate than those treated with other surgical interventions . However , in the subgroup analysis based on the com ##par ##ators , the higher rate of re ##current di ##s her ##nia ##tion was only observed in the comparison with MI ##S - T ##L ##IF . Yao Y , et al . [ 45 ] performed a retrospective co ##hor ##t study to compare the outcomes of three minimal ##ly invasive spine surge ##ries ( MI ##S - T ##L ##IF , ME ##D , and P ##EL ##D ) in the treatment of re ##current her ##nia ##tion . At the follow - up duration of 12 ##mont ##hs , no patients ( 0 . 0 % ) in the MI ##S - T ##L ##IF group , 3 patients ( 15 . 0 % ) in the ME ##D group , and 7 patients ( 25 . 0 % ) in the P ##EL ##D group developed re ##cu ##rrence . [ 45 ] The re ##cu ##rrence rate in the P ##EL ##D group was significantly higher than that in the MI ##S - T ##L ##IF group . Similarly , in their another recently published trial , [ 54 ] they also reported a higher re ##cu ##rrence rate of P ##EL ##D than MI ##S - T ##L ##IF . In that study , the authors enrolled 105 patients who underwent either P ##EL ##D ( n = 47 ) or MI ##S - T ##L ##IF ( n = 58 ) for revision of ME ##D re ##cu ##rrence . [ 54 ] At the 12 - month follow - [SEP]\n",
      "INFO:tensorflow:token_to_orig_map: 11:0 12:1 13:2 14:2 15:2 16:3 17:4 18:5 19:6 20:7 21:7 22:7 23:7 24:8 25:9 26:10 27:11 28:12 29:12 30:12 31:13 32:14 33:15 34:16 35:17 36:18 37:18 38:18 39:19 40:20 41:21 42:22 43:23 44:24 45:25 46:25 47:26 48:27 49:28 50:28 51:29 52:30 53:31 54:31 55:31 56:31 57:31 58:32 59:33 60:33 61:33 62:33 63:33 64:34 65:34 66:35 67:35 68:36 69:37 70:38 71:39 72:40 73:41 74:42 75:43 76:44 77:45 78:46 79:46 80:47 81:48 82:48 83:48 84:48 85:49 86:50 87:51 88:52 89:52 90:53 91:54 92:55 93:56 94:57 95:58 96:59 97:59 98:59 99:60 100:61 101:62 102:63 103:64 104:64 105:64 106:65 107:66 108:67 109:68 110:69 111:70 112:71 113:72 114:72 115:73 116:73 117:74 118:75 119:76 120:77 121:78 122:79 123:80 124:81 125:81 126:81 127:81 128:82 129:83 130:84 131:85 132:86 133:86 134:87 135:87 136:88 137:88 138:88 139:89 140:90 141:91 142:92 143:93 144:94 145:95 146:96 147:96 148:96 149:96 150:96 151:96 152:96 153:97 154:98 155:98 156:99 157:100 158:100 159:100 160:100 161:100 162:101 163:102 164:103 165:104 166:104 167:104 168:105 169:106 170:107 171:108 172:109 173:110 174:111 175:112 176:112 177:113 178:114 179:115 180:115 181:116 182:116 183:116 184:116 185:117 186:117 187:117 188:117 189:118 190:118 191:118 192:119 193:120 194:120 195:120 196:120 197:121 198:122 199:123 200:124 201:125 202:125 203:126 204:126 205:126 206:126 207:127 208:128 209:129 210:129 211:129 212:130 213:131 214:132 215:132 216:132 217:132 218:133 219:134 220:135 221:135 222:135 223:135 224:135 225:135 226:136 227:137 228:138 229:138 230:138 231:138 232:138 233:138 234:139 235:139 236:140 237:141 238:142 239:142 240:142 241:142 242:142 243:142 244:143 245:144 246:145 247:145 248:146 249:146 250:147 251:148 252:149 253:150 254:150 255:150 256:150 257:150 258:150 259:151 260:152 261:153 262:153 263:153 264:154 265:155 266:156 267:156 268:156 269:156 270:156 271:156 272:156 273:157 274:158 275:158 276:158 277:159 278:160 279:161 280:162 281:162 282:162 283:163 284:164 285:165 286:166 287:167 288:168 289:169 290:170 291:171 292:171 293:171 294:171 295:171 296:171 297:172 298:172 299:173 300:173 301:174 302:175 303:176 304:177 305:178 306:179 307:179 308:179 309:179 310:179 311:180 312:181 313:182 314:183 315:184 316:185 317:185 318:185 319:186 320:187 321:188 322:188 323:188 324:189 325:190 326:190 327:190 328:190 329:190 330:190 331:190 332:191 333:192 334:193 335:193 336:194 337:195 338:196 339:197 340:198 341:199 342:200 343:201 344:202 345:202 346:202 347:203 348:203 349:204 350:205 351:205 352:206 353:207 354:207 355:207 356:207 357:207 358:207 359:208 360:208 361:209 362:210 363:210 364:211 365:212 366:213 367:214 368:214 369:215 370:215 371:215 372:215 373:215 374:215 375:215 376:216 377:217 378:218 379:218 380:218 381:219 382:219\n",
      "I1208 12:27:37.133450 139883775852736 run_factoid.py:445] token_to_orig_map: 11:0 12:1 13:2 14:2 15:2 16:3 17:4 18:5 19:6 20:7 21:7 22:7 23:7 24:8 25:9 26:10 27:11 28:12 29:12 30:12 31:13 32:14 33:15 34:16 35:17 36:18 37:18 38:18 39:19 40:20 41:21 42:22 43:23 44:24 45:25 46:25 47:26 48:27 49:28 50:28 51:29 52:30 53:31 54:31 55:31 56:31 57:31 58:32 59:33 60:33 61:33 62:33 63:33 64:34 65:34 66:35 67:35 68:36 69:37 70:38 71:39 72:40 73:41 74:42 75:43 76:44 77:45 78:46 79:46 80:47 81:48 82:48 83:48 84:48 85:49 86:50 87:51 88:52 89:52 90:53 91:54 92:55 93:56 94:57 95:58 96:59 97:59 98:59 99:60 100:61 101:62 102:63 103:64 104:64 105:64 106:65 107:66 108:67 109:68 110:69 111:70 112:71 113:72 114:72 115:73 116:73 117:74 118:75 119:76 120:77 121:78 122:79 123:80 124:81 125:81 126:81 127:81 128:82 129:83 130:84 131:85 132:86 133:86 134:87 135:87 136:88 137:88 138:88 139:89 140:90 141:91 142:92 143:93 144:94 145:95 146:96 147:96 148:96 149:96 150:96 151:96 152:96 153:97 154:98 155:98 156:99 157:100 158:100 159:100 160:100 161:100 162:101 163:102 164:103 165:104 166:104 167:104 168:105 169:106 170:107 171:108 172:109 173:110 174:111 175:112 176:112 177:113 178:114 179:115 180:115 181:116 182:116 183:116 184:116 185:117 186:117 187:117 188:117 189:118 190:118 191:118 192:119 193:120 194:120 195:120 196:120 197:121 198:122 199:123 200:124 201:125 202:125 203:126 204:126 205:126 206:126 207:127 208:128 209:129 210:129 211:129 212:130 213:131 214:132 215:132 216:132 217:132 218:133 219:134 220:135 221:135 222:135 223:135 224:135 225:135 226:136 227:137 228:138 229:138 230:138 231:138 232:138 233:138 234:139 235:139 236:140 237:141 238:142 239:142 240:142 241:142 242:142 243:142 244:143 245:144 246:145 247:145 248:146 249:146 250:147 251:148 252:149 253:150 254:150 255:150 256:150 257:150 258:150 259:151 260:152 261:153 262:153 263:153 264:154 265:155 266:156 267:156 268:156 269:156 270:156 271:156 272:156 273:157 274:158 275:158 276:158 277:159 278:160 279:161 280:162 281:162 282:162 283:163 284:164 285:165 286:166 287:167 288:168 289:169 290:170 291:171 292:171 293:171 294:171 295:171 296:171 297:172 298:172 299:173 300:173 301:174 302:175 303:176 304:177 305:178 306:179 307:179 308:179 309:179 310:179 311:180 312:181 313:182 314:183 315:184 316:185 317:185 318:185 319:186 320:187 321:188 322:188 323:188 324:189 325:190 326:190 327:190 328:190 329:190 330:190 331:190 332:191 333:192 334:193 335:193 336:194 337:195 338:196 339:197 340:198 341:199 342:200 343:201 344:202 345:202 346:202 347:203 348:203 349:204 350:205 351:205 352:206 353:207 354:207 355:207 356:207 357:207 358:207 359:208 360:208 361:209 362:210 363:210 364:211 365:212 366:213 367:214 368:214 369:215 370:215 371:215 372:215 373:215 374:215 375:215 376:216 377:217 378:218 379:218 380:218 381:219 382:219\n",
      "INFO:tensorflow:token_is_max_context: 11:True 12:True 13:True 14:True 15:True 16:True 17:True 18:True 19:True 20:True 21:True 22:True 23:True 24:True 25:True 26:True 27:True 28:True 29:True 30:True 31:True 32:True 33:True 34:True 35:True 36:True 37:True 38:True 39:True 40:True 41:True 42:True 43:True 44:True 45:True 46:True 47:True 48:True 49:True 50:True 51:True 52:True 53:True 54:True 55:True 56:True 57:True 58:True 59:True 60:True 61:True 62:True 63:True 64:True 65:True 66:True 67:True 68:True 69:True 70:True 71:True 72:True 73:True 74:True 75:True 76:True 77:True 78:True 79:True 80:True 81:True 82:True 83:True 84:True 85:True 86:True 87:True 88:True 89:True 90:True 91:True 92:True 93:True 94:True 95:True 96:True 97:True 98:True 99:True 100:True 101:True 102:True 103:True 104:True 105:True 106:True 107:True 108:True 109:True 110:True 111:True 112:True 113:True 114:True 115:True 116:True 117:True 118:True 119:True 120:True 121:True 122:True 123:True 124:True 125:True 126:True 127:True 128:True 129:True 130:True 131:True 132:True 133:True 134:True 135:True 136:True 137:True 138:True 139:True 140:True 141:True 142:True 143:True 144:True 145:True 146:True 147:True 148:True 149:True 150:True 151:True 152:True 153:True 154:True 155:True 156:True 157:True 158:True 159:True 160:True 161:True 162:True 163:True 164:True 165:True 166:True 167:True 168:True 169:True 170:True 171:True 172:True 173:True 174:True 175:True 176:True 177:True 178:True 179:True 180:True 181:True 182:True 183:True 184:True 185:True 186:True 187:True 188:True 189:True 190:True 191:True 192:True 193:True 194:True 195:True 196:True 197:True 198:True 199:True 200:True 201:True 202:True 203:True 204:True 205:True 206:True 207:True 208:True 209:True 210:True 211:True 212:True 213:True 214:True 215:True 216:True 217:True 218:True 219:True 220:True 221:True 222:True 223:True 224:True 225:True 226:True 227:True 228:True 229:True 230:True 231:True 232:True 233:True 234:True 235:True 236:True 237:True 238:True 239:True 240:True 241:True 242:True 243:True 244:True 245:True 246:True 247:True 248:True 249:True 250:True 251:True 252:True 253:True 254:True 255:True 256:True 257:True 258:True 259:True 260:True 261:False 262:False 263:False 264:False 265:False 266:False 267:False 268:False 269:False 270:False 271:False 272:False 273:False 274:False 275:False 276:False 277:False 278:False 279:False 280:False 281:False 282:False 283:False 284:False 285:False 286:False 287:False 288:False 289:False 290:False 291:False 292:False 293:False 294:False 295:False 296:False 297:False 298:False 299:False 300:False 301:False 302:False 303:False 304:False 305:False 306:False 307:False 308:False 309:False 310:False 311:False 312:False 313:False 314:False 315:False 316:False 317:False 318:False 319:False 320:False 321:False 322:False 323:False 324:False 325:False 326:False 327:False 328:False 329:False 330:False 331:False 332:False 333:False 334:False 335:False 336:False 337:False 338:False 339:False 340:False 341:False 342:False 343:False 344:False 345:False 346:False 347:False 348:False 349:False 350:False 351:False 352:False 353:False 354:False 355:False 356:False 357:False 358:False 359:False 360:False 361:False 362:False 363:False 364:False 365:False 366:False 367:False 368:False 369:False 370:False 371:False 372:False 373:False 374:False 375:False 376:False 377:False 378:False 379:False 380:False 381:False 382:False\n",
      "I1208 12:27:37.133559 139883775852736 run_factoid.py:447] token_is_max_context: 11:True 12:True 13:True 14:True 15:True 16:True 17:True 18:True 19:True 20:True 21:True 22:True 23:True 24:True 25:True 26:True 27:True 28:True 29:True 30:True 31:True 32:True 33:True 34:True 35:True 36:True 37:True 38:True 39:True 40:True 41:True 42:True 43:True 44:True 45:True 46:True 47:True 48:True 49:True 50:True 51:True 52:True 53:True 54:True 55:True 56:True 57:True 58:True 59:True 60:True 61:True 62:True 63:True 64:True 65:True 66:True 67:True 68:True 69:True 70:True 71:True 72:True 73:True 74:True 75:True 76:True 77:True 78:True 79:True 80:True 81:True 82:True 83:True 84:True 85:True 86:True 87:True 88:True 89:True 90:True 91:True 92:True 93:True 94:True 95:True 96:True 97:True 98:True 99:True 100:True 101:True 102:True 103:True 104:True 105:True 106:True 107:True 108:True 109:True 110:True 111:True 112:True 113:True 114:True 115:True 116:True 117:True 118:True 119:True 120:True 121:True 122:True 123:True 124:True 125:True 126:True 127:True 128:True 129:True 130:True 131:True 132:True 133:True 134:True 135:True 136:True 137:True 138:True 139:True 140:True 141:True 142:True 143:True 144:True 145:True 146:True 147:True 148:True 149:True 150:True 151:True 152:True 153:True 154:True 155:True 156:True 157:True 158:True 159:True 160:True 161:True 162:True 163:True 164:True 165:True 166:True 167:True 168:True 169:True 170:True 171:True 172:True 173:True 174:True 175:True 176:True 177:True 178:True 179:True 180:True 181:True 182:True 183:True 184:True 185:True 186:True 187:True 188:True 189:True 190:True 191:True 192:True 193:True 194:True 195:True 196:True 197:True 198:True 199:True 200:True 201:True 202:True 203:True 204:True 205:True 206:True 207:True 208:True 209:True 210:True 211:True 212:True 213:True 214:True 215:True 216:True 217:True 218:True 219:True 220:True 221:True 222:True 223:True 224:True 225:True 226:True 227:True 228:True 229:True 230:True 231:True 232:True 233:True 234:True 235:True 236:True 237:True 238:True 239:True 240:True 241:True 242:True 243:True 244:True 245:True 246:True 247:True 248:True 249:True 250:True 251:True 252:True 253:True 254:True 255:True 256:True 257:True 258:True 259:True 260:True 261:False 262:False 263:False 264:False 265:False 266:False 267:False 268:False 269:False 270:False 271:False 272:False 273:False 274:False 275:False 276:False 277:False 278:False 279:False 280:False 281:False 282:False 283:False 284:False 285:False 286:False 287:False 288:False 289:False 290:False 291:False 292:False 293:False 294:False 295:False 296:False 297:False 298:False 299:False 300:False 301:False 302:False 303:False 304:False 305:False 306:False 307:False 308:False 309:False 310:False 311:False 312:False 313:False 314:False 315:False 316:False 317:False 318:False 319:False 320:False 321:False 322:False 323:False 324:False 325:False 326:False 327:False 328:False 329:False 330:False 331:False 332:False 333:False 334:False 335:False 336:False 337:False 338:False 339:False 340:False 341:False 342:False 343:False 344:False 345:False 346:False 347:False 348:False 349:False 350:False 351:False 352:False 353:False 354:False 355:False 356:False 357:False 358:False 359:False 360:False 361:False 362:False 363:False 364:False 365:False 366:False 367:False 368:False 369:False 370:False 371:False 372:False 373:False 374:False 375:False 376:False 377:False 378:False 379:False 380:False 381:False 382:False\n",
      "INFO:tensorflow:input_ids: 101 2091 1103 9505 12864 1113 5351 17898 1116 136 102 1109 1675 27154 118 3622 1104 1489 7356 5336 123 117 3882 1604 4420 2136 2554 1115 153 21678 2137 1125 11169 7300 13950 1111 149 16395 117 1259 7681 2805 1159 1105 2704 2215 117 1750 1892 2445 117 1105 4725 18659 11964 118 12029 1708 1105 18659 11964 118 7054 1708 2794 119 1438 117 1122 1145 1108 2628 1114 170 5409 2299 2603 1104 1231 21754 6187 1123 5813 2116 119 1130 1103 1675 2025 117 1195 1276 1115 4420 1150 9315 153 21678 2137 1125 170 5409 2299 1231 10182 21629 2603 1190 1343 5165 1114 1168 13467 22496 119 1438 117 1107 1103 23470 3622 1359 1113 1103 3254 17482 11664 117 1103 2299 2603 1104 1231 21754 4267 1116 1123 5813 2116 1108 1178 4379 1107 1103 7577 1114 26574 1708 118 157 2162 15499 119 27762 162 117 3084 2393 119 164 2532 166 1982 170 18675 1884 13252 1204 2025 1106 14133 1103 13950 1104 1210 10298 1193 19849 8340 12814 3377 113 26574 1708 118 157 2162 15499 117 22157 2137 117 1105 153 21678 2137 114 1107 1103 3252 1104 1231 21754 1123 5813 2116 119 1335 1103 2812 118 1146 9355 1104 1367 7578 9524 117 1185 4420 113 121 119 121 110 114 1107 1103 26574 1708 118 157 2162 15499 1372 117 124 4420 113 1405 119 121 110 114 1107 1103 22157 2137 1372 117 1105 128 4420 113 1512 119 121 110 114 1107 1103 153 21678 2137 1372 1872 1231 10182 21629 119 164 2532 166 1109 1231 10182 21629 2603 1107 1103 153 21678 2137 1372 1108 5409 2299 1190 1115 1107 1103 26574 1708 118 157 2162 15499 1372 119 10321 117 1107 1147 1330 3055 1502 3443 117 164 4335 166 1152 1145 2103 170 2299 1231 10182 21629 2603 1104 153 21678 2137 1190 26574 1708 118 157 2162 15499 119 1130 1115 2025 117 1103 5752 7945 8359 4420 1150 9315 1719 153 21678 2137 113 183 134 3862 114 1137 26574 1708 118 157 2162 15499 113 183 134 4650 114 1111 16547 1104 22157 2137 1231 10182 21629 119 164 4335 166 1335 1103 1367 118 2370 2812 118 102\n",
      "I1208 12:27:37.133662 139883775852736 run_factoid.py:449] input_ids: 101 2091 1103 9505 12864 1113 5351 17898 1116 136 102 1109 1675 27154 118 3622 1104 1489 7356 5336 123 117 3882 1604 4420 2136 2554 1115 153 21678 2137 1125 11169 7300 13950 1111 149 16395 117 1259 7681 2805 1159 1105 2704 2215 117 1750 1892 2445 117 1105 4725 18659 11964 118 12029 1708 1105 18659 11964 118 7054 1708 2794 119 1438 117 1122 1145 1108 2628 1114 170 5409 2299 2603 1104 1231 21754 6187 1123 5813 2116 119 1130 1103 1675 2025 117 1195 1276 1115 4420 1150 9315 153 21678 2137 1125 170 5409 2299 1231 10182 21629 2603 1190 1343 5165 1114 1168 13467 22496 119 1438 117 1107 1103 23470 3622 1359 1113 1103 3254 17482 11664 117 1103 2299 2603 1104 1231 21754 4267 1116 1123 5813 2116 1108 1178 4379 1107 1103 7577 1114 26574 1708 118 157 2162 15499 119 27762 162 117 3084 2393 119 164 2532 166 1982 170 18675 1884 13252 1204 2025 1106 14133 1103 13950 1104 1210 10298 1193 19849 8340 12814 3377 113 26574 1708 118 157 2162 15499 117 22157 2137 117 1105 153 21678 2137 114 1107 1103 3252 1104 1231 21754 1123 5813 2116 119 1335 1103 2812 118 1146 9355 1104 1367 7578 9524 117 1185 4420 113 121 119 121 110 114 1107 1103 26574 1708 118 157 2162 15499 1372 117 124 4420 113 1405 119 121 110 114 1107 1103 22157 2137 1372 117 1105 128 4420 113 1512 119 121 110 114 1107 1103 153 21678 2137 1372 1872 1231 10182 21629 119 164 2532 166 1109 1231 10182 21629 2603 1107 1103 153 21678 2137 1372 1108 5409 2299 1190 1115 1107 1103 26574 1708 118 157 2162 15499 1372 119 10321 117 1107 1147 1330 3055 1502 3443 117 164 4335 166 1152 1145 2103 170 2299 1231 10182 21629 2603 1104 153 21678 2137 1190 26574 1708 118 157 2162 15499 119 1130 1115 2025 117 1103 5752 7945 8359 4420 1150 9315 1719 153 21678 2137 113 183 134 3862 114 1137 26574 1708 118 157 2162 15499 113 183 134 4650 114 1111 16547 1104 22157 2137 1231 10182 21629 119 164 4335 166 1335 1103 1367 118 2370 2812 118 102\n",
      "INFO:tensorflow:input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      "I1208 12:27:37.133753 139883775852736 run_factoid.py:451] input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      "INFO:tensorflow:segment_ids: 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      "I1208 12:27:37.133844 139883775852736 run_factoid.py:453] segment_ids: 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      "INFO:tensorflow:*** Example ***\n",
      "I1208 12:27:37.135557 139883775852736 run_factoid.py:438] *** Example ***\n",
      "INFO:tensorflow:unique_id: 1000000041\n",
      "I1208 12:27:37.135617 139883775852736 run_factoid.py:439] unique_id: 1000000041\n",
      "INFO:tensorflow:example_index: 8\n",
      "I1208 12:27:37.135655 139883775852736 run_factoid.py:440] example_index: 8\n",
      "INFO:tensorflow:doc_span_index: 1\n",
      "I1208 12:27:37.135689 139883775852736 run_factoid.py:441] doc_span_index: 1\n",
      "INFO:tensorflow:tokens: [CLS] Do the findings depend on patient demographic ##s ? [SEP] was only observed in the comparison with MI ##S - T ##L ##IF . Yao Y , et al . [ 45 ] performed a retrospective co ##hor ##t study to compare the outcomes of three minimal ##ly invasive spine surge ##ries ( MI ##S - T ##L ##IF , ME ##D , and P ##EL ##D ) in the treatment of re ##current her ##nia ##tion . At the follow - up duration of 12 ##mont ##hs , no patients ( 0 . 0 % ) in the MI ##S - T ##L ##IF group , 3 patients ( 15 . 0 % ) in the ME ##D group , and 7 patients ( 25 . 0 % ) in the P ##EL ##D group developed re ##cu ##rrence . [ 45 ] The re ##cu ##rrence rate in the P ##EL ##D group was significantly higher than that in the MI ##S - T ##L ##IF group . Similarly , in their another recently published trial , [ 54 ] they also reported a higher re ##cu ##rrence rate of P ##EL ##D than MI ##S - T ##L ##IF . In that study , the authors enrolled 105 patients who underwent either P ##EL ##D ( n = 47 ) or MI ##S - T ##L ##IF ( n = 58 ) for revision of ME ##D re ##cu ##rrence . [ 54 ] At the 12 - month follow - up , patients who underwent P ##EL ##D had a significantly higher re ##cu ##rrence rate ( 10 . 64 % ) than those treated with MI ##S - T ##L ##IF ( 0 . 0 % ) . [ 54 ] The authors attributed the findings to the following reasons : ( 1 ) there was some risk factors that were predict ##ive of re ##cu ##rrence in P ##EL ##D patients . For example , old age , o ##besity , and Mo ##dic change have been identified as significant risk factors for the P ##EL ##D re ##cu ##r - re ##nce . [ 58 , 59 ] And the 5 patients who experienced re ##cu ##rrence in the P ##EL ##D group were all [SEP]\n",
      "I1208 12:27:37.135803 139883775852736 run_factoid.py:443] tokens: [CLS] Do the findings depend on patient demographic ##s ? [SEP] was only observed in the comparison with MI ##S - T ##L ##IF . Yao Y , et al . [ 45 ] performed a retrospective co ##hor ##t study to compare the outcomes of three minimal ##ly invasive spine surge ##ries ( MI ##S - T ##L ##IF , ME ##D , and P ##EL ##D ) in the treatment of re ##current her ##nia ##tion . At the follow - up duration of 12 ##mont ##hs , no patients ( 0 . 0 % ) in the MI ##S - T ##L ##IF group , 3 patients ( 15 . 0 % ) in the ME ##D group , and 7 patients ( 25 . 0 % ) in the P ##EL ##D group developed re ##cu ##rrence . [ 45 ] The re ##cu ##rrence rate in the P ##EL ##D group was significantly higher than that in the MI ##S - T ##L ##IF group . Similarly , in their another recently published trial , [ 54 ] they also reported a higher re ##cu ##rrence rate of P ##EL ##D than MI ##S - T ##L ##IF . In that study , the authors enrolled 105 patients who underwent either P ##EL ##D ( n = 47 ) or MI ##S - T ##L ##IF ( n = 58 ) for revision of ME ##D re ##cu ##rrence . [ 54 ] At the 12 - month follow - up , patients who underwent P ##EL ##D had a significantly higher re ##cu ##rrence rate ( 10 . 64 % ) than those treated with MI ##S - T ##L ##IF ( 0 . 0 % ) . [ 54 ] The authors attributed the findings to the following reasons : ( 1 ) there was some risk factors that were predict ##ive of re ##cu ##rrence in P ##EL ##D patients . For example , old age , o ##besity , and Mo ##dic change have been identified as significant risk factors for the P ##EL ##D re ##cu ##r - re ##nce . [ 58 , 59 ] And the 5 patients who experienced re ##cu ##rrence in the P ##EL ##D group were all [SEP]\n",
      "INFO:tensorflow:token_to_orig_map: 11:89 12:90 13:91 14:92 15:93 16:94 17:95 18:96 19:96 20:96 21:96 22:96 23:96 24:96 25:97 26:98 27:98 28:99 29:100 30:100 31:100 32:100 33:100 34:101 35:102 36:103 37:104 38:104 39:104 40:105 41:106 42:107 43:108 44:109 45:110 46:111 47:112 48:112 49:113 50:114 51:115 52:115 53:116 54:116 55:116 56:116 57:117 58:117 59:117 60:117 61:118 62:118 63:118 64:119 65:120 66:120 67:120 68:120 69:121 70:122 71:123 72:124 73:125 74:125 75:126 76:126 77:126 78:126 79:127 80:128 81:129 82:129 83:129 84:130 85:131 86:132 87:132 88:132 89:132 90:133 91:134 92:135 93:135 94:135 95:135 96:135 97:135 98:136 99:137 100:138 101:138 102:138 103:138 104:138 105:138 106:139 107:139 108:140 109:141 110:142 111:142 112:142 113:142 114:142 115:142 116:143 117:144 118:145 119:145 120:146 121:146 122:147 123:148 124:149 125:150 126:150 127:150 128:150 129:150 130:150 131:151 132:152 133:153 134:153 135:153 136:154 137:155 138:156 139:156 140:156 141:156 142:156 143:156 144:156 145:157 146:158 147:158 148:158 149:159 150:160 151:161 152:162 153:162 154:162 155:163 156:164 157:165 158:166 159:167 160:168 161:169 162:170 163:171 164:171 165:171 166:171 167:171 168:171 169:172 170:172 171:173 172:173 173:174 174:175 175:176 176:177 177:178 178:179 179:179 180:179 181:179 182:179 183:180 184:181 185:182 186:183 187:184 188:185 189:185 190:185 191:186 192:187 193:188 194:188 195:188 196:189 197:190 198:190 199:190 200:190 201:190 202:190 203:190 204:191 205:192 206:193 207:193 208:194 209:195 210:196 211:197 212:198 213:199 214:200 215:201 216:202 217:202 218:202 219:203 220:203 221:204 222:205 223:205 224:206 225:207 226:207 227:207 228:207 229:207 230:207 231:208 232:208 233:209 234:210 235:210 236:211 237:212 238:213 239:214 240:214 241:215 242:215 243:215 244:215 245:215 246:215 247:215 248:216 249:217 250:218 251:218 252:218 253:219 254:219 255:219 256:219 257:220 258:221 259:222 260:223 261:223 262:223 263:224 264:225 265:226 266:227 267:228 268:228 269:228 270:229 271:230 272:230 273:230 274:230 275:230 276:230 277:231 278:232 279:233 280:234 281:235 282:235 283:235 284:235 285:235 286:235 287:236 288:236 289:236 290:236 291:236 292:236 293:236 294:236 295:236 296:236 297:237 298:238 299:239 300:240 301:241 302:242 303:243 304:244 305:245 306:245 307:246 308:246 309:246 310:247 311:248 312:249 313:250 314:251 315:252 316:253 317:254 318:254 319:255 320:256 321:256 322:256 323:257 324:258 325:258 326:258 327:259 328:259 329:260 330:261 331:261 332:262 333:263 334:263 335:264 336:264 337:264 338:265 339:266 340:266 341:267 342:268 343:269 344:270 345:271 346:272 347:273 348:274 349:275 350:276 351:277 352:277 353:277 354:278 355:278 356:278 357:278 358:279 359:279 360:279 361:279 362:279 363:279 364:279 365:279 366:280 367:281 368:282 369:283 370:284 371:285 372:286 373:286 374:286 375:287 376:288 377:289 378:289 379:289 380:290 381:291 382:292\n",
      "I1208 12:27:37.135917 139883775852736 run_factoid.py:445] token_to_orig_map: 11:89 12:90 13:91 14:92 15:93 16:94 17:95 18:96 19:96 20:96 21:96 22:96 23:96 24:96 25:97 26:98 27:98 28:99 29:100 30:100 31:100 32:100 33:100 34:101 35:102 36:103 37:104 38:104 39:104 40:105 41:106 42:107 43:108 44:109 45:110 46:111 47:112 48:112 49:113 50:114 51:115 52:115 53:116 54:116 55:116 56:116 57:117 58:117 59:117 60:117 61:118 62:118 63:118 64:119 65:120 66:120 67:120 68:120 69:121 70:122 71:123 72:124 73:125 74:125 75:126 76:126 77:126 78:126 79:127 80:128 81:129 82:129 83:129 84:130 85:131 86:132 87:132 88:132 89:132 90:133 91:134 92:135 93:135 94:135 95:135 96:135 97:135 98:136 99:137 100:138 101:138 102:138 103:138 104:138 105:138 106:139 107:139 108:140 109:141 110:142 111:142 112:142 113:142 114:142 115:142 116:143 117:144 118:145 119:145 120:146 121:146 122:147 123:148 124:149 125:150 126:150 127:150 128:150 129:150 130:150 131:151 132:152 133:153 134:153 135:153 136:154 137:155 138:156 139:156 140:156 141:156 142:156 143:156 144:156 145:157 146:158 147:158 148:158 149:159 150:160 151:161 152:162 153:162 154:162 155:163 156:164 157:165 158:166 159:167 160:168 161:169 162:170 163:171 164:171 165:171 166:171 167:171 168:171 169:172 170:172 171:173 172:173 173:174 174:175 175:176 176:177 177:178 178:179 179:179 180:179 181:179 182:179 183:180 184:181 185:182 186:183 187:184 188:185 189:185 190:185 191:186 192:187 193:188 194:188 195:188 196:189 197:190 198:190 199:190 200:190 201:190 202:190 203:190 204:191 205:192 206:193 207:193 208:194 209:195 210:196 211:197 212:198 213:199 214:200 215:201 216:202 217:202 218:202 219:203 220:203 221:204 222:205 223:205 224:206 225:207 226:207 227:207 228:207 229:207 230:207 231:208 232:208 233:209 234:210 235:210 236:211 237:212 238:213 239:214 240:214 241:215 242:215 243:215 244:215 245:215 246:215 247:215 248:216 249:217 250:218 251:218 252:218 253:219 254:219 255:219 256:219 257:220 258:221 259:222 260:223 261:223 262:223 263:224 264:225 265:226 266:227 267:228 268:228 269:228 270:229 271:230 272:230 273:230 274:230 275:230 276:230 277:231 278:232 279:233 280:234 281:235 282:235 283:235 284:235 285:235 286:235 287:236 288:236 289:236 290:236 291:236 292:236 293:236 294:236 295:236 296:236 297:237 298:238 299:239 300:240 301:241 302:242 303:243 304:244 305:245 306:245 307:246 308:246 309:246 310:247 311:248 312:249 313:250 314:251 315:252 316:253 317:254 318:254 319:255 320:256 321:256 322:256 323:257 324:258 325:258 326:258 327:259 328:259 329:260 330:261 331:261 332:262 333:263 334:263 335:264 336:264 337:264 338:265 339:266 340:266 341:267 342:268 343:269 344:270 345:271 346:272 347:273 348:274 349:275 350:276 351:277 352:277 353:277 354:278 355:278 356:278 357:278 358:279 359:279 360:279 361:279 362:279 363:279 364:279 365:279 366:280 367:281 368:282 369:283 370:284 371:285 372:286 373:286 374:286 375:287 376:288 377:289 378:289 379:289 380:290 381:291 382:292\n",
      "INFO:tensorflow:token_is_max_context: 11:False 12:False 13:False 14:False 15:False 16:False 17:False 18:False 19:False 20:False 21:False 22:False 23:False 24:False 25:False 26:False 27:False 28:False 29:False 30:False 31:False 32:False 33:False 34:False 35:False 36:False 37:False 38:False 39:False 40:False 41:False 42:False 43:False 44:False 45:False 46:False 47:False 48:False 49:False 50:False 51:False 52:False 53:False 54:False 55:False 56:False 57:False 58:False 59:False 60:False 61:False 62:False 63:False 64:False 65:False 66:False 67:False 68:False 69:False 70:False 71:False 72:False 73:False 74:False 75:False 76:False 77:False 78:False 79:False 80:False 81:False 82:False 83:False 84:False 85:False 86:False 87:False 88:False 89:False 90:False 91:False 92:False 93:False 94:False 95:False 96:False 97:False 98:False 99:False 100:False 101:False 102:False 103:False 104:False 105:False 106:False 107:False 108:False 109:False 110:False 111:False 112:False 113:False 114:False 115:False 116:False 117:False 118:False 119:False 120:False 121:False 122:False 123:False 124:False 125:False 126:False 127:False 128:False 129:False 130:False 131:False 132:False 133:True 134:True 135:True 136:True 137:True 138:True 139:True 140:True 141:True 142:True 143:True 144:True 145:True 146:True 147:True 148:True 149:True 150:True 151:True 152:True 153:True 154:True 155:True 156:True 157:True 158:True 159:True 160:True 161:True 162:True 163:True 164:True 165:True 166:True 167:True 168:True 169:True 170:True 171:True 172:True 173:True 174:True 175:True 176:True 177:True 178:True 179:True 180:True 181:True 182:True 183:True 184:True 185:True 186:True 187:True 188:True 189:True 190:True 191:True 192:True 193:True 194:True 195:True 196:True 197:True 198:True 199:True 200:True 201:True 202:True 203:True 204:True 205:True 206:True 207:True 208:True 209:True 210:True 211:True 212:True 213:True 214:True 215:True 216:True 217:True 218:True 219:True 220:True 221:True 222:True 223:True 224:True 225:True 226:True 227:True 228:True 229:True 230:True 231:True 232:True 233:True 234:True 235:True 236:True 237:True 238:True 239:True 240:True 241:True 242:True 243:True 244:True 245:True 246:True 247:True 248:True 249:True 250:True 251:True 252:True 253:True 254:True 255:True 256:True 257:True 258:True 259:True 260:True 261:False 262:False 263:False 264:False 265:False 266:False 267:False 268:False 269:False 270:False 271:False 272:False 273:False 274:False 275:False 276:False 277:False 278:False 279:False 280:False 281:False 282:False 283:False 284:False 285:False 286:False 287:False 288:False 289:False 290:False 291:False 292:False 293:False 294:False 295:False 296:False 297:False 298:False 299:False 300:False 301:False 302:False 303:False 304:False 305:False 306:False 307:False 308:False 309:False 310:False 311:False 312:False 313:False 314:False 315:False 316:False 317:False 318:False 319:False 320:False 321:False 322:False 323:False 324:False 325:False 326:False 327:False 328:False 329:False 330:False 331:False 332:False 333:False 334:False 335:False 336:False 337:False 338:False 339:False 340:False 341:False 342:False 343:False 344:False 345:False 346:False 347:False 348:False 349:False 350:False 351:False 352:False 353:False 354:False 355:False 356:False 357:False 358:False 359:False 360:False 361:False 362:False 363:False 364:False 365:False 366:False 367:False 368:False 369:False 370:False 371:False 372:False 373:False 374:False 375:False 376:False 377:False 378:False 379:False 380:False 381:False 382:False\n",
      "I1208 12:27:37.136028 139883775852736 run_factoid.py:447] token_is_max_context: 11:False 12:False 13:False 14:False 15:False 16:False 17:False 18:False 19:False 20:False 21:False 22:False 23:False 24:False 25:False 26:False 27:False 28:False 29:False 30:False 31:False 32:False 33:False 34:False 35:False 36:False 37:False 38:False 39:False 40:False 41:False 42:False 43:False 44:False 45:False 46:False 47:False 48:False 49:False 50:False 51:False 52:False 53:False 54:False 55:False 56:False 57:False 58:False 59:False 60:False 61:False 62:False 63:False 64:False 65:False 66:False 67:False 68:False 69:False 70:False 71:False 72:False 73:False 74:False 75:False 76:False 77:False 78:False 79:False 80:False 81:False 82:False 83:False 84:False 85:False 86:False 87:False 88:False 89:False 90:False 91:False 92:False 93:False 94:False 95:False 96:False 97:False 98:False 99:False 100:False 101:False 102:False 103:False 104:False 105:False 106:False 107:False 108:False 109:False 110:False 111:False 112:False 113:False 114:False 115:False 116:False 117:False 118:False 119:False 120:False 121:False 122:False 123:False 124:False 125:False 126:False 127:False 128:False 129:False 130:False 131:False 132:False 133:True 134:True 135:True 136:True 137:True 138:True 139:True 140:True 141:True 142:True 143:True 144:True 145:True 146:True 147:True 148:True 149:True 150:True 151:True 152:True 153:True 154:True 155:True 156:True 157:True 158:True 159:True 160:True 161:True 162:True 163:True 164:True 165:True 166:True 167:True 168:True 169:True 170:True 171:True 172:True 173:True 174:True 175:True 176:True 177:True 178:True 179:True 180:True 181:True 182:True 183:True 184:True 185:True 186:True 187:True 188:True 189:True 190:True 191:True 192:True 193:True 194:True 195:True 196:True 197:True 198:True 199:True 200:True 201:True 202:True 203:True 204:True 205:True 206:True 207:True 208:True 209:True 210:True 211:True 212:True 213:True 214:True 215:True 216:True 217:True 218:True 219:True 220:True 221:True 222:True 223:True 224:True 225:True 226:True 227:True 228:True 229:True 230:True 231:True 232:True 233:True 234:True 235:True 236:True 237:True 238:True 239:True 240:True 241:True 242:True 243:True 244:True 245:True 246:True 247:True 248:True 249:True 250:True 251:True 252:True 253:True 254:True 255:True 256:True 257:True 258:True 259:True 260:True 261:False 262:False 263:False 264:False 265:False 266:False 267:False 268:False 269:False 270:False 271:False 272:False 273:False 274:False 275:False 276:False 277:False 278:False 279:False 280:False 281:False 282:False 283:False 284:False 285:False 286:False 287:False 288:False 289:False 290:False 291:False 292:False 293:False 294:False 295:False 296:False 297:False 298:False 299:False 300:False 301:False 302:False 303:False 304:False 305:False 306:False 307:False 308:False 309:False 310:False 311:False 312:False 313:False 314:False 315:False 316:False 317:False 318:False 319:False 320:False 321:False 322:False 323:False 324:False 325:False 326:False 327:False 328:False 329:False 330:False 331:False 332:False 333:False 334:False 335:False 336:False 337:False 338:False 339:False 340:False 341:False 342:False 343:False 344:False 345:False 346:False 347:False 348:False 349:False 350:False 351:False 352:False 353:False 354:False 355:False 356:False 357:False 358:False 359:False 360:False 361:False 362:False 363:False 364:False 365:False 366:False 367:False 368:False 369:False 370:False 371:False 372:False 373:False 374:False 375:False 376:False 377:False 378:False 379:False 380:False 381:False 382:False\n",
      "INFO:tensorflow:input_ids: 101 2091 1103 9505 12864 1113 5351 17898 1116 136 102 1108 1178 4379 1107 1103 7577 1114 26574 1708 118 157 2162 15499 119 27762 162 117 3084 2393 119 164 2532 166 1982 170 18675 1884 13252 1204 2025 1106 14133 1103 13950 1104 1210 10298 1193 19849 8340 12814 3377 113 26574 1708 118 157 2162 15499 117 22157 2137 117 1105 153 21678 2137 114 1107 1103 3252 1104 1231 21754 1123 5813 2116 119 1335 1103 2812 118 1146 9355 1104 1367 7578 9524 117 1185 4420 113 121 119 121 110 114 1107 1103 26574 1708 118 157 2162 15499 1372 117 124 4420 113 1405 119 121 110 114 1107 1103 22157 2137 1372 117 1105 128 4420 113 1512 119 121 110 114 1107 1103 153 21678 2137 1372 1872 1231 10182 21629 119 164 2532 166 1109 1231 10182 21629 2603 1107 1103 153 21678 2137 1372 1108 5409 2299 1190 1115 1107 1103 26574 1708 118 157 2162 15499 1372 119 10321 117 1107 1147 1330 3055 1502 3443 117 164 4335 166 1152 1145 2103 170 2299 1231 10182 21629 2603 1104 153 21678 2137 1190 26574 1708 118 157 2162 15499 119 1130 1115 2025 117 1103 5752 7945 8359 4420 1150 9315 1719 153 21678 2137 113 183 134 3862 114 1137 26574 1708 118 157 2162 15499 113 183 134 4650 114 1111 16547 1104 22157 2137 1231 10182 21629 119 164 4335 166 1335 1103 1367 118 2370 2812 118 1146 117 4420 1150 9315 153 21678 2137 1125 170 5409 2299 1231 10182 21629 2603 113 1275 119 3324 110 114 1190 1343 5165 1114 26574 1708 118 157 2162 15499 113 121 119 121 110 114 119 164 4335 166 1109 5752 6547 1103 9505 1106 1103 1378 3672 131 113 122 114 1175 1108 1199 3187 5320 1115 1127 17163 2109 1104 1231 10182 21629 1107 153 21678 2137 4420 119 1370 1859 117 1385 1425 117 184 27655 117 1105 12556 13328 1849 1138 1151 3626 1112 2418 3187 5320 1111 1103 153 21678 2137 1231 10182 1197 118 1231 3633 119 164 4650 117 4589 166 1262 1103 126 4420 1150 4531 1231 10182 21629 1107 1103 153 21678 2137 1372 1127 1155 102\n",
      "I1208 12:27:37.136132 139883775852736 run_factoid.py:449] input_ids: 101 2091 1103 9505 12864 1113 5351 17898 1116 136 102 1108 1178 4379 1107 1103 7577 1114 26574 1708 118 157 2162 15499 119 27762 162 117 3084 2393 119 164 2532 166 1982 170 18675 1884 13252 1204 2025 1106 14133 1103 13950 1104 1210 10298 1193 19849 8340 12814 3377 113 26574 1708 118 157 2162 15499 117 22157 2137 117 1105 153 21678 2137 114 1107 1103 3252 1104 1231 21754 1123 5813 2116 119 1335 1103 2812 118 1146 9355 1104 1367 7578 9524 117 1185 4420 113 121 119 121 110 114 1107 1103 26574 1708 118 157 2162 15499 1372 117 124 4420 113 1405 119 121 110 114 1107 1103 22157 2137 1372 117 1105 128 4420 113 1512 119 121 110 114 1107 1103 153 21678 2137 1372 1872 1231 10182 21629 119 164 2532 166 1109 1231 10182 21629 2603 1107 1103 153 21678 2137 1372 1108 5409 2299 1190 1115 1107 1103 26574 1708 118 157 2162 15499 1372 119 10321 117 1107 1147 1330 3055 1502 3443 117 164 4335 166 1152 1145 2103 170 2299 1231 10182 21629 2603 1104 153 21678 2137 1190 26574 1708 118 157 2162 15499 119 1130 1115 2025 117 1103 5752 7945 8359 4420 1150 9315 1719 153 21678 2137 113 183 134 3862 114 1137 26574 1708 118 157 2162 15499 113 183 134 4650 114 1111 16547 1104 22157 2137 1231 10182 21629 119 164 4335 166 1335 1103 1367 118 2370 2812 118 1146 117 4420 1150 9315 153 21678 2137 1125 170 5409 2299 1231 10182 21629 2603 113 1275 119 3324 110 114 1190 1343 5165 1114 26574 1708 118 157 2162 15499 113 121 119 121 110 114 119 164 4335 166 1109 5752 6547 1103 9505 1106 1103 1378 3672 131 113 122 114 1175 1108 1199 3187 5320 1115 1127 17163 2109 1104 1231 10182 21629 1107 153 21678 2137 4420 119 1370 1859 117 1385 1425 117 184 27655 117 1105 12556 13328 1849 1138 1151 3626 1112 2418 3187 5320 1111 1103 153 21678 2137 1231 10182 1197 118 1231 3633 119 164 4650 117 4589 166 1262 1103 126 4420 1150 4531 1231 10182 21629 1107 1103 153 21678 2137 1372 1127 1155 102\n",
      "INFO:tensorflow:input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      "I1208 12:27:37.136223 139883775852736 run_factoid.py:451] input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      "INFO:tensorflow:segment_ids: 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      "I1208 12:27:37.136312 139883775852736 run_factoid.py:453] segment_ids: 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      "INFO:tensorflow:*** Example ***\n",
      "I1208 12:27:37.138072 139883775852736 run_factoid.py:438] *** Example ***\n",
      "INFO:tensorflow:unique_id: 1000000042\n",
      "I1208 12:27:37.138133 139883775852736 run_factoid.py:439] unique_id: 1000000042\n",
      "INFO:tensorflow:example_index: 8\n",
      "I1208 12:27:37.138170 139883775852736 run_factoid.py:440] example_index: 8\n",
      "INFO:tensorflow:doc_span_index: 2\n",
      "I1208 12:27:37.138203 139883775852736 run_factoid.py:441] doc_span_index: 2\n",
      "INFO:tensorflow:tokens: [CLS] Do the findings depend on patient demographic ##s ? [SEP] ##cu ##rrence . [ 45 ] The re ##cu ##rrence rate in the P ##EL ##D group was significantly higher than that in the MI ##S - T ##L ##IF group . Similarly , in their another recently published trial , [ 54 ] they also reported a higher re ##cu ##rrence rate of P ##EL ##D than MI ##S - T ##L ##IF . In that study , the authors enrolled 105 patients who underwent either P ##EL ##D ( n = 47 ) or MI ##S - T ##L ##IF ( n = 58 ) for revision of ME ##D re ##cu ##rrence . [ 54 ] At the 12 - month follow - up , patients who underwent P ##EL ##D had a significantly higher re ##cu ##rrence rate ( 10 . 64 % ) than those treated with MI ##S - T ##L ##IF ( 0 . 0 % ) . [ 54 ] The authors attributed the findings to the following reasons : ( 1 ) there was some risk factors that were predict ##ive of re ##cu ##rrence in P ##EL ##D patients . For example , old age , o ##besity , and Mo ##dic change have been identified as significant risk factors for the P ##EL ##D re ##cu ##r - re ##nce . [ 58 , 59 ] And the 5 patients who experienced re ##cu ##rrence in the P ##EL ##D group were all relatively old ( ≥ ##60 years old ) and o ##bes ##e ; thus , they were at high risk of re ##current her ##nia ##tion . [ 54 ] ( 2 ) 3 of the 5 patients had her ##nia ##ted fragment that were highly migrated , and this made the surgery more difficult . [ 60 ] The residual fragment would result in unsuccessful surgical outcomes . [ 58 , 61 ] ( 3 ) After the primary ME ##D surgery , the artificial cracks in an ##nu ##lus fi ##bro ##sus would change the la ##minate structure , and make the an ##nu ##lus be more easily to del ##ami ##nation . [ 54 ] Based on the damage in an ##nu ##lus fi ##bro [SEP]\n",
      "I1208 12:27:37.138328 139883775852736 run_factoid.py:443] tokens: [CLS] Do the findings depend on patient demographic ##s ? [SEP] ##cu ##rrence . [ 45 ] The re ##cu ##rrence rate in the P ##EL ##D group was significantly higher than that in the MI ##S - T ##L ##IF group . Similarly , in their another recently published trial , [ 54 ] they also reported a higher re ##cu ##rrence rate of P ##EL ##D than MI ##S - T ##L ##IF . In that study , the authors enrolled 105 patients who underwent either P ##EL ##D ( n = 47 ) or MI ##S - T ##L ##IF ( n = 58 ) for revision of ME ##D re ##cu ##rrence . [ 54 ] At the 12 - month follow - up , patients who underwent P ##EL ##D had a significantly higher re ##cu ##rrence rate ( 10 . 64 % ) than those treated with MI ##S - T ##L ##IF ( 0 . 0 % ) . [ 54 ] The authors attributed the findings to the following reasons : ( 1 ) there was some risk factors that were predict ##ive of re ##cu ##rrence in P ##EL ##D patients . For example , old age , o ##besity , and Mo ##dic change have been identified as significant risk factors for the P ##EL ##D re ##cu ##r - re ##nce . [ 58 , 59 ] And the 5 patients who experienced re ##cu ##rrence in the P ##EL ##D group were all relatively old ( ≥ ##60 years old ) and o ##bes ##e ; thus , they were at high risk of re ##current her ##nia ##tion . [ 54 ] ( 2 ) 3 of the 5 patients had her ##nia ##ted fragment that were highly migrated , and this made the surgery more difficult . [ 60 ] The residual fragment would result in unsuccessful surgical outcomes . [ 58 , 61 ] ( 3 ) After the primary ME ##D surgery , the artificial cracks in an ##nu ##lus fi ##bro ##sus would change the la ##minate structure , and make the an ##nu ##lus be more easily to del ##ami ##nation . [ 54 ] Based on the damage in an ##nu ##lus fi ##bro [SEP]\n",
      "INFO:tensorflow:token_to_orig_map: 11:156 12:156 13:156 14:156 15:156 16:156 17:157 18:158 19:158 20:158 21:159 22:160 23:161 24:162 25:162 26:162 27:163 28:164 29:165 30:166 31:167 32:168 33:169 34:170 35:171 36:171 37:171 38:171 39:171 40:171 41:172 42:172 43:173 44:173 45:174 46:175 47:176 48:177 49:178 50:179 51:179 52:179 53:179 54:179 55:180 56:181 57:182 58:183 59:184 60:185 61:185 62:185 63:186 64:187 65:188 66:188 67:188 68:189 69:190 70:190 71:190 72:190 73:190 74:190 75:190 76:191 77:192 78:193 79:193 80:194 81:195 82:196 83:197 84:198 85:199 86:200 87:201 88:202 89:202 90:202 91:203 92:203 93:204 94:205 95:205 96:206 97:207 98:207 99:207 100:207 101:207 102:207 103:208 104:208 105:209 106:210 107:210 108:211 109:212 110:213 111:214 112:214 113:215 114:215 115:215 116:215 117:215 118:215 119:215 120:216 121:217 122:218 123:218 124:218 125:219 126:219 127:219 128:219 129:220 130:221 131:222 132:223 133:223 134:223 135:224 136:225 137:226 138:227 139:228 140:228 141:228 142:229 143:230 144:230 145:230 146:230 147:230 148:230 149:231 150:232 151:233 152:234 153:235 154:235 155:235 156:235 157:235 158:235 159:236 160:236 161:236 162:236 163:236 164:236 165:236 166:236 167:236 168:236 169:237 170:238 171:239 172:240 173:241 174:242 175:243 176:244 177:245 178:245 179:246 180:246 181:246 182:247 183:248 184:249 185:250 186:251 187:252 188:253 189:254 190:254 191:255 192:256 193:256 194:256 195:257 196:258 197:258 198:258 199:259 200:259 201:260 202:261 203:261 204:262 205:263 206:263 207:264 208:264 209:264 210:265 211:266 212:266 213:267 214:268 215:269 216:270 217:271 218:272 219:273 220:274 221:275 222:276 223:277 224:277 225:277 226:278 227:278 228:278 229:278 230:279 231:279 232:279 233:279 234:279 235:279 236:279 237:279 238:280 239:281 240:282 241:283 242:284 243:285 244:286 245:286 246:286 247:287 248:288 249:289 250:289 251:289 252:290 253:291 254:292 255:293 256:294 257:295 258:295 259:295 260:296 261:297 262:297 263:298 264:299 265:299 266:299 267:299 268:300 269:300 270:301 271:302 272:303 273:304 274:305 275:306 276:307 277:307 278:308 279:308 280:308 281:308 282:308 283:308 284:308 285:309 286:309 287:309 288:310 289:311 290:312 291:313 292:314 293:315 294:316 295:316 296:316 297:317 298:318 299:319 300:320 301:321 302:321 303:322 304:323 305:324 306:325 307:326 308:327 309:328 310:328 311:328 312:328 313:328 314:329 315:330 316:331 317:332 318:333 319:334 320:335 321:336 322:337 323:337 324:337 325:337 326:337 327:337 328:337 329:338 330:338 331:338 332:339 333:340 334:341 335:342 336:342 337:343 338:343 339:344 340:345 341:346 342:347 343:348 344:348 345:348 346:349 347:349 348:349 349:350 350:351 351:352 352:353 353:353 354:354 355:354 356:355 357:356 358:357 359:358 360:358 361:358 362:359 363:360 364:361 365:362 366:363 367:363 368:363 369:363 370:363 371:363 372:363 373:364 374:365 375:366 376:367 377:368 378:369 379:369 380:369 381:370 382:370\n",
      "I1208 12:27:37.138450 139883775852736 run_factoid.py:445] token_to_orig_map: 11:156 12:156 13:156 14:156 15:156 16:156 17:157 18:158 19:158 20:158 21:159 22:160 23:161 24:162 25:162 26:162 27:163 28:164 29:165 30:166 31:167 32:168 33:169 34:170 35:171 36:171 37:171 38:171 39:171 40:171 41:172 42:172 43:173 44:173 45:174 46:175 47:176 48:177 49:178 50:179 51:179 52:179 53:179 54:179 55:180 56:181 57:182 58:183 59:184 60:185 61:185 62:185 63:186 64:187 65:188 66:188 67:188 68:189 69:190 70:190 71:190 72:190 73:190 74:190 75:190 76:191 77:192 78:193 79:193 80:194 81:195 82:196 83:197 84:198 85:199 86:200 87:201 88:202 89:202 90:202 91:203 92:203 93:204 94:205 95:205 96:206 97:207 98:207 99:207 100:207 101:207 102:207 103:208 104:208 105:209 106:210 107:210 108:211 109:212 110:213 111:214 112:214 113:215 114:215 115:215 116:215 117:215 118:215 119:215 120:216 121:217 122:218 123:218 124:218 125:219 126:219 127:219 128:219 129:220 130:221 131:222 132:223 133:223 134:223 135:224 136:225 137:226 138:227 139:228 140:228 141:228 142:229 143:230 144:230 145:230 146:230 147:230 148:230 149:231 150:232 151:233 152:234 153:235 154:235 155:235 156:235 157:235 158:235 159:236 160:236 161:236 162:236 163:236 164:236 165:236 166:236 167:236 168:236 169:237 170:238 171:239 172:240 173:241 174:242 175:243 176:244 177:245 178:245 179:246 180:246 181:246 182:247 183:248 184:249 185:250 186:251 187:252 188:253 189:254 190:254 191:255 192:256 193:256 194:256 195:257 196:258 197:258 198:258 199:259 200:259 201:260 202:261 203:261 204:262 205:263 206:263 207:264 208:264 209:264 210:265 211:266 212:266 213:267 214:268 215:269 216:270 217:271 218:272 219:273 220:274 221:275 222:276 223:277 224:277 225:277 226:278 227:278 228:278 229:278 230:279 231:279 232:279 233:279 234:279 235:279 236:279 237:279 238:280 239:281 240:282 241:283 242:284 243:285 244:286 245:286 246:286 247:287 248:288 249:289 250:289 251:289 252:290 253:291 254:292 255:293 256:294 257:295 258:295 259:295 260:296 261:297 262:297 263:298 264:299 265:299 266:299 267:299 268:300 269:300 270:301 271:302 272:303 273:304 274:305 275:306 276:307 277:307 278:308 279:308 280:308 281:308 282:308 283:308 284:308 285:309 286:309 287:309 288:310 289:311 290:312 291:313 292:314 293:315 294:316 295:316 296:316 297:317 298:318 299:319 300:320 301:321 302:321 303:322 304:323 305:324 306:325 307:326 308:327 309:328 310:328 311:328 312:328 313:328 314:329 315:330 316:331 317:332 318:333 319:334 320:335 321:336 322:337 323:337 324:337 325:337 326:337 327:337 328:337 329:338 330:338 331:338 332:339 333:340 334:341 335:342 336:342 337:343 338:343 339:344 340:345 341:346 342:347 343:348 344:348 345:348 346:349 347:349 348:349 349:350 350:351 351:352 352:353 353:353 354:354 355:354 356:355 357:356 358:357 359:358 360:358 361:358 362:359 363:360 364:361 365:362 366:363 367:363 368:363 369:363 370:363 371:363 372:363 373:364 374:365 375:366 376:367 377:368 378:369 379:369 380:369 381:370 382:370\n",
      "INFO:tensorflow:token_is_max_context: 11:False 12:False 13:False 14:False 15:False 16:False 17:False 18:False 19:False 20:False 21:False 22:False 23:False 24:False 25:False 26:False 27:False 28:False 29:False 30:False 31:False 32:False 33:False 34:False 35:False 36:False 37:False 38:False 39:False 40:False 41:False 42:False 43:False 44:False 45:False 46:False 47:False 48:False 49:False 50:False 51:False 52:False 53:False 54:False 55:False 56:False 57:False 58:False 59:False 60:False 61:False 62:False 63:False 64:False 65:False 66:False 67:False 68:False 69:False 70:False 71:False 72:False 73:False 74:False 75:False 76:False 77:False 78:False 79:False 80:False 81:False 82:False 83:False 84:False 85:False 86:False 87:False 88:False 89:False 90:False 91:False 92:False 93:False 94:False 95:False 96:False 97:False 98:False 99:False 100:False 101:False 102:False 103:False 104:False 105:False 106:False 107:False 108:False 109:False 110:False 111:False 112:False 113:False 114:False 115:False 116:False 117:False 118:False 119:False 120:False 121:False 122:False 123:False 124:False 125:False 126:False 127:False 128:False 129:False 130:False 131:False 132:False 133:True 134:True 135:True 136:True 137:True 138:True 139:True 140:True 141:True 142:True 143:True 144:True 145:True 146:True 147:True 148:True 149:True 150:True 151:True 152:True 153:True 154:True 155:True 156:True 157:True 158:True 159:True 160:True 161:True 162:True 163:True 164:True 165:True 166:True 167:True 168:True 169:True 170:True 171:True 172:True 173:True 174:True 175:True 176:True 177:True 178:True 179:True 180:True 181:True 182:True 183:True 184:True 185:True 186:True 187:True 188:True 189:True 190:True 191:True 192:True 193:True 194:True 195:True 196:True 197:True 198:True 199:True 200:True 201:True 202:True 203:True 204:True 205:True 206:True 207:True 208:True 209:True 210:True 211:True 212:True 213:True 214:True 215:True 216:True 217:True 218:True 219:True 220:True 221:True 222:True 223:True 224:True 225:True 226:True 227:True 228:True 229:True 230:True 231:True 232:True 233:True 234:True 235:True 236:True 237:True 238:True 239:True 240:True 241:True 242:True 243:True 244:True 245:True 246:True 247:True 248:True 249:True 250:True 251:True 252:True 253:True 254:True 255:True 256:True 257:True 258:True 259:True 260:True 261:False 262:False 263:False 264:False 265:False 266:False 267:False 268:False 269:False 270:False 271:False 272:False 273:False 274:False 275:False 276:False 277:False 278:False 279:False 280:False 281:False 282:False 283:False 284:False 285:False 286:False 287:False 288:False 289:False 290:False 291:False 292:False 293:False 294:False 295:False 296:False 297:False 298:False 299:False 300:False 301:False 302:False 303:False 304:False 305:False 306:False 307:False 308:False 309:False 310:False 311:False 312:False 313:False 314:False 315:False 316:False 317:False 318:False 319:False 320:False 321:False 322:False 323:False 324:False 325:False 326:False 327:False 328:False 329:False 330:False 331:False 332:False 333:False 334:False 335:False 336:False 337:False 338:False 339:False 340:False 341:False 342:False 343:False 344:False 345:False 346:False 347:False 348:False 349:False 350:False 351:False 352:False 353:False 354:False 355:False 356:False 357:False 358:False 359:False 360:False 361:False 362:False 363:False 364:False 365:False 366:False 367:False 368:False 369:False 370:False 371:False 372:False 373:False 374:False 375:False 376:False 377:False 378:False 379:False 380:False 381:False 382:False\n",
      "I1208 12:27:37.138558 139883775852736 run_factoid.py:447] token_is_max_context: 11:False 12:False 13:False 14:False 15:False 16:False 17:False 18:False 19:False 20:False 21:False 22:False 23:False 24:False 25:False 26:False 27:False 28:False 29:False 30:False 31:False 32:False 33:False 34:False 35:False 36:False 37:False 38:False 39:False 40:False 41:False 42:False 43:False 44:False 45:False 46:False 47:False 48:False 49:False 50:False 51:False 52:False 53:False 54:False 55:False 56:False 57:False 58:False 59:False 60:False 61:False 62:False 63:False 64:False 65:False 66:False 67:False 68:False 69:False 70:False 71:False 72:False 73:False 74:False 75:False 76:False 77:False 78:False 79:False 80:False 81:False 82:False 83:False 84:False 85:False 86:False 87:False 88:False 89:False 90:False 91:False 92:False 93:False 94:False 95:False 96:False 97:False 98:False 99:False 100:False 101:False 102:False 103:False 104:False 105:False 106:False 107:False 108:False 109:False 110:False 111:False 112:False 113:False 114:False 115:False 116:False 117:False 118:False 119:False 120:False 121:False 122:False 123:False 124:False 125:False 126:False 127:False 128:False 129:False 130:False 131:False 132:False 133:True 134:True 135:True 136:True 137:True 138:True 139:True 140:True 141:True 142:True 143:True 144:True 145:True 146:True 147:True 148:True 149:True 150:True 151:True 152:True 153:True 154:True 155:True 156:True 157:True 158:True 159:True 160:True 161:True 162:True 163:True 164:True 165:True 166:True 167:True 168:True 169:True 170:True 171:True 172:True 173:True 174:True 175:True 176:True 177:True 178:True 179:True 180:True 181:True 182:True 183:True 184:True 185:True 186:True 187:True 188:True 189:True 190:True 191:True 192:True 193:True 194:True 195:True 196:True 197:True 198:True 199:True 200:True 201:True 202:True 203:True 204:True 205:True 206:True 207:True 208:True 209:True 210:True 211:True 212:True 213:True 214:True 215:True 216:True 217:True 218:True 219:True 220:True 221:True 222:True 223:True 224:True 225:True 226:True 227:True 228:True 229:True 230:True 231:True 232:True 233:True 234:True 235:True 236:True 237:True 238:True 239:True 240:True 241:True 242:True 243:True 244:True 245:True 246:True 247:True 248:True 249:True 250:True 251:True 252:True 253:True 254:True 255:True 256:True 257:True 258:True 259:True 260:True 261:False 262:False 263:False 264:False 265:False 266:False 267:False 268:False 269:False 270:False 271:False 272:False 273:False 274:False 275:False 276:False 277:False 278:False 279:False 280:False 281:False 282:False 283:False 284:False 285:False 286:False 287:False 288:False 289:False 290:False 291:False 292:False 293:False 294:False 295:False 296:False 297:False 298:False 299:False 300:False 301:False 302:False 303:False 304:False 305:False 306:False 307:False 308:False 309:False 310:False 311:False 312:False 313:False 314:False 315:False 316:False 317:False 318:False 319:False 320:False 321:False 322:False 323:False 324:False 325:False 326:False 327:False 328:False 329:False 330:False 331:False 332:False 333:False 334:False 335:False 336:False 337:False 338:False 339:False 340:False 341:False 342:False 343:False 344:False 345:False 346:False 347:False 348:False 349:False 350:False 351:False 352:False 353:False 354:False 355:False 356:False 357:False 358:False 359:False 360:False 361:False 362:False 363:False 364:False 365:False 366:False 367:False 368:False 369:False 370:False 371:False 372:False 373:False 374:False 375:False 376:False 377:False 378:False 379:False 380:False 381:False 382:False\n",
      "INFO:tensorflow:input_ids: 101 2091 1103 9505 12864 1113 5351 17898 1116 136 102 10182 21629 119 164 2532 166 1109 1231 10182 21629 2603 1107 1103 153 21678 2137 1372 1108 5409 2299 1190 1115 1107 1103 26574 1708 118 157 2162 15499 1372 119 10321 117 1107 1147 1330 3055 1502 3443 117 164 4335 166 1152 1145 2103 170 2299 1231 10182 21629 2603 1104 153 21678 2137 1190 26574 1708 118 157 2162 15499 119 1130 1115 2025 117 1103 5752 7945 8359 4420 1150 9315 1719 153 21678 2137 113 183 134 3862 114 1137 26574 1708 118 157 2162 15499 113 183 134 4650 114 1111 16547 1104 22157 2137 1231 10182 21629 119 164 4335 166 1335 1103 1367 118 2370 2812 118 1146 117 4420 1150 9315 153 21678 2137 1125 170 5409 2299 1231 10182 21629 2603 113 1275 119 3324 110 114 1190 1343 5165 1114 26574 1708 118 157 2162 15499 113 121 119 121 110 114 119 164 4335 166 1109 5752 6547 1103 9505 1106 1103 1378 3672 131 113 122 114 1175 1108 1199 3187 5320 1115 1127 17163 2109 1104 1231 10182 21629 1107 153 21678 2137 4420 119 1370 1859 117 1385 1425 117 184 27655 117 1105 12556 13328 1849 1138 1151 3626 1112 2418 3187 5320 1111 1103 153 21678 2137 1231 10182 1197 118 1231 3633 119 164 4650 117 4589 166 1262 1103 126 4420 1150 4531 1231 10182 21629 1107 1103 153 21678 2137 1372 1127 1155 3860 1385 113 864 16480 1201 1385 114 1105 184 12866 1162 132 2456 117 1152 1127 1120 1344 3187 1104 1231 21754 1123 5813 2116 119 164 4335 166 113 123 114 124 1104 1103 126 4420 1125 1123 5813 1906 17906 1115 1127 3023 13793 117 1105 1142 1189 1103 6059 1167 2846 119 164 2539 166 1109 25399 17906 1156 1871 1107 7285 13467 13950 119 164 4650 117 5391 166 113 124 114 1258 1103 2425 22157 2137 6059 117 1103 8246 16694 1107 1126 14787 5954 20497 12725 14410 1156 1849 1103 2495 17379 2401 117 1105 1294 1103 1126 14787 5954 1129 1167 3253 1106 3687 11787 9199 119 164 4335 166 7457 1113 1103 3290 1107 1126 14787 5954 20497 12725 102\n",
      "I1208 12:27:37.138662 139883775852736 run_factoid.py:449] input_ids: 101 2091 1103 9505 12864 1113 5351 17898 1116 136 102 10182 21629 119 164 2532 166 1109 1231 10182 21629 2603 1107 1103 153 21678 2137 1372 1108 5409 2299 1190 1115 1107 1103 26574 1708 118 157 2162 15499 1372 119 10321 117 1107 1147 1330 3055 1502 3443 117 164 4335 166 1152 1145 2103 170 2299 1231 10182 21629 2603 1104 153 21678 2137 1190 26574 1708 118 157 2162 15499 119 1130 1115 2025 117 1103 5752 7945 8359 4420 1150 9315 1719 153 21678 2137 113 183 134 3862 114 1137 26574 1708 118 157 2162 15499 113 183 134 4650 114 1111 16547 1104 22157 2137 1231 10182 21629 119 164 4335 166 1335 1103 1367 118 2370 2812 118 1146 117 4420 1150 9315 153 21678 2137 1125 170 5409 2299 1231 10182 21629 2603 113 1275 119 3324 110 114 1190 1343 5165 1114 26574 1708 118 157 2162 15499 113 121 119 121 110 114 119 164 4335 166 1109 5752 6547 1103 9505 1106 1103 1378 3672 131 113 122 114 1175 1108 1199 3187 5320 1115 1127 17163 2109 1104 1231 10182 21629 1107 153 21678 2137 4420 119 1370 1859 117 1385 1425 117 184 27655 117 1105 12556 13328 1849 1138 1151 3626 1112 2418 3187 5320 1111 1103 153 21678 2137 1231 10182 1197 118 1231 3633 119 164 4650 117 4589 166 1262 1103 126 4420 1150 4531 1231 10182 21629 1107 1103 153 21678 2137 1372 1127 1155 3860 1385 113 864 16480 1201 1385 114 1105 184 12866 1162 132 2456 117 1152 1127 1120 1344 3187 1104 1231 21754 1123 5813 2116 119 164 4335 166 113 123 114 124 1104 1103 126 4420 1125 1123 5813 1906 17906 1115 1127 3023 13793 117 1105 1142 1189 1103 6059 1167 2846 119 164 2539 166 1109 25399 17906 1156 1871 1107 7285 13467 13950 119 164 4650 117 5391 166 113 124 114 1258 1103 2425 22157 2137 6059 117 1103 8246 16694 1107 1126 14787 5954 20497 12725 14410 1156 1849 1103 2495 17379 2401 117 1105 1294 1103 1126 14787 5954 1129 1167 3253 1106 3687 11787 9199 119 164 4335 166 7457 1113 1103 3290 1107 1126 14787 5954 20497 12725 102\n",
      "INFO:tensorflow:input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      "I1208 12:27:37.138753 139883775852736 run_factoid.py:451] input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      "INFO:tensorflow:segment_ids: 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      "I1208 12:27:37.138842 139883775852736 run_factoid.py:453] segment_ids: 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      "INFO:tensorflow:*** Example ***\n",
      "I1208 12:27:37.140621 139883775852736 run_factoid.py:438] *** Example ***\n",
      "INFO:tensorflow:unique_id: 1000000043\n",
      "I1208 12:27:37.140691 139883775852736 run_factoid.py:439] unique_id: 1000000043\n",
      "INFO:tensorflow:example_index: 8\n",
      "I1208 12:27:37.140729 139883775852736 run_factoid.py:440] example_index: 8\n",
      "INFO:tensorflow:doc_span_index: 3\n",
      "I1208 12:27:37.140763 139883775852736 run_factoid.py:441] doc_span_index: 3\n",
      "INFO:tensorflow:tokens: [CLS] Do the findings depend on patient demographic ##s ? [SEP] re ##cu ##rrence rate ( 10 . 64 % ) than those treated with MI ##S - T ##L ##IF ( 0 . 0 % ) . [ 54 ] The authors attributed the findings to the following reasons : ( 1 ) there was some risk factors that were predict ##ive of re ##cu ##rrence in P ##EL ##D patients . For example , old age , o ##besity , and Mo ##dic change have been identified as significant risk factors for the P ##EL ##D re ##cu ##r - re ##nce . [ 58 , 59 ] And the 5 patients who experienced re ##cu ##rrence in the P ##EL ##D group were all relatively old ( ≥ ##60 years old ) and o ##bes ##e ; thus , they were at high risk of re ##current her ##nia ##tion . [ 54 ] ( 2 ) 3 of the 5 patients had her ##nia ##ted fragment that were highly migrated , and this made the surgery more difficult . [ 60 ] The residual fragment would result in unsuccessful surgical outcomes . [ 58 , 61 ] ( 3 ) After the primary ME ##D surgery , the artificial cracks in an ##nu ##lus fi ##bro ##sus would change the la ##minate structure , and make the an ##nu ##lus be more easily to del ##ami ##nation . [ 54 ] Based on the damage in an ##nu ##lus fi ##bro ##sus , the re ##current her ##nia ##tion easily occurred . [ 62 ] Therefore , it is unable for P ##EL ##D to solve this problem thoroughly , and a through inter ##body fusion ( MI ##S - T ##L ##IF ) might be a better choice . [ 54 ] The success rate in the P ##EL ##D group and other surgical intervention group were 7 . 2 % and 4 . 1 % , respectively . Although patients treated with P ##EL ##D achieved a significantly higher success rate than those with other surge ##ries , the difference between them was not significant . Lee SH , et al [ 46 ] performed a matched co ##hor ##t study evaluation of 60 consecutive patients with [SEP]\n",
      "I1208 12:27:37.140886 139883775852736 run_factoid.py:443] tokens: [CLS] Do the findings depend on patient demographic ##s ? [SEP] re ##cu ##rrence rate ( 10 . 64 % ) than those treated with MI ##S - T ##L ##IF ( 0 . 0 % ) . [ 54 ] The authors attributed the findings to the following reasons : ( 1 ) there was some risk factors that were predict ##ive of re ##cu ##rrence in P ##EL ##D patients . For example , old age , o ##besity , and Mo ##dic change have been identified as significant risk factors for the P ##EL ##D re ##cu ##r - re ##nce . [ 58 , 59 ] And the 5 patients who experienced re ##cu ##rrence in the P ##EL ##D group were all relatively old ( ≥ ##60 years old ) and o ##bes ##e ; thus , they were at high risk of re ##current her ##nia ##tion . [ 54 ] ( 2 ) 3 of the 5 patients had her ##nia ##ted fragment that were highly migrated , and this made the surgery more difficult . [ 60 ] The residual fragment would result in unsuccessful surgical outcomes . [ 58 , 61 ] ( 3 ) After the primary ME ##D surgery , the artificial cracks in an ##nu ##lus fi ##bro ##sus would change the la ##minate structure , and make the an ##nu ##lus be more easily to del ##ami ##nation . [ 54 ] Based on the damage in an ##nu ##lus fi ##bro ##sus , the re ##current her ##nia ##tion easily occurred . [ 62 ] Therefore , it is unable for P ##EL ##D to solve this problem thoroughly , and a through inter ##body fusion ( MI ##S - T ##L ##IF ) might be a better choice . [ 54 ] The success rate in the P ##EL ##D group and other surgical intervention group were 7 . 2 % and 4 . 1 % , respectively . Although patients treated with P ##EL ##D achieved a significantly higher success rate than those with other surge ##ries , the difference between them was not significant . Lee SH , et al [ 46 ] performed a matched co ##hor ##t study evaluation of 60 consecutive patients with [SEP]\n",
      "INFO:tensorflow:token_to_orig_map: 11:228 12:228 13:228 14:229 15:230 16:230 17:230 18:230 19:230 20:230 21:231 22:232 23:233 24:234 25:235 26:235 27:235 28:235 29:235 30:235 31:236 32:236 33:236 34:236 35:236 36:236 37:236 38:236 39:236 40:236 41:237 42:238 43:239 44:240 45:241 46:242 47:243 48:244 49:245 50:245 51:246 52:246 53:246 54:247 55:248 56:249 57:250 58:251 59:252 60:253 61:254 62:254 63:255 64:256 65:256 66:256 67:257 68:258 69:258 70:258 71:259 72:259 73:260 74:261 75:261 76:262 77:263 78:263 79:264 80:264 81:264 82:265 83:266 84:266 85:267 86:268 87:269 88:270 89:271 90:272 91:273 92:274 93:275 94:276 95:277 96:277 97:277 98:278 99:278 100:278 101:278 102:279 103:279 104:279 105:279 106:279 107:279 108:279 109:279 110:280 111:281 112:282 113:283 114:284 115:285 116:286 117:286 118:286 119:287 120:288 121:289 122:289 123:289 124:290 125:291 126:292 127:293 128:294 129:295 130:295 131:295 132:296 133:297 134:297 135:298 136:299 137:299 138:299 139:299 140:300 141:300 142:301 143:302 144:303 145:304 146:305 147:306 148:307 149:307 150:308 151:308 152:308 153:308 154:308 155:308 156:308 157:309 158:309 159:309 160:310 161:311 162:312 163:313 164:314 165:315 166:316 167:316 168:316 169:317 170:318 171:319 172:320 173:321 174:321 175:322 176:323 177:324 178:325 179:326 180:327 181:328 182:328 183:328 184:328 185:328 186:329 187:330 188:331 189:332 190:333 191:334 192:335 193:336 194:337 195:337 196:337 197:337 198:337 199:337 200:337 201:338 202:338 203:338 204:339 205:340 206:341 207:342 208:342 209:343 210:343 211:344 212:345 213:346 214:347 215:348 216:348 217:348 218:349 219:349 220:349 221:350 222:351 223:352 224:353 225:353 226:354 227:354 228:355 229:356 230:357 231:358 232:358 233:358 234:359 235:360 236:361 237:362 238:363 239:363 240:363 241:363 242:363 243:363 244:363 245:364 246:365 247:366 248:367 249:368 250:369 251:369 252:369 253:370 254:370 255:370 256:370 257:371 258:372 259:372 260:373 261:373 262:373 263:374 264:375 265:375 266:375 267:375 268:375 269:376 270:376 271:377 272:378 273:379 274:380 275:381 276:381 277:381 278:382 279:383 280:384 281:385 282:386 283:386 284:387 285:388 286:389 287:390 288:390 289:391 290:392 291:392 292:392 293:392 294:392 295:392 296:392 297:392 298:393 299:394 300:395 301:396 302:397 303:397 304:397 305:397 306:397 307:398 308:399 309:400 310:401 311:402 312:403 313:403 314:403 315:404 316:405 317:406 318:407 319:408 320:409 321:410 322:411 323:411 324:411 325:411 326:412 327:413 328:413 329:413 330:413 331:413 332:414 333:414 334:415 335:416 336:417 337:418 338:419 339:419 340:419 341:420 342:421 343:422 344:423 345:424 346:425 347:426 348:427 349:428 350:429 351:430 352:430 353:430 354:431 355:432 356:433 357:434 358:435 359:436 360:437 361:437 362:438 363:439 364:439 365:440 366:441 367:441 368:441 369:441 370:442 371:443 372:444 373:445 374:445 375:445 376:446 377:447 378:448 379:449 380:450 381:451 382:452\n",
      "I1208 12:27:37.141006 139883775852736 run_factoid.py:445] token_to_orig_map: 11:228 12:228 13:228 14:229 15:230 16:230 17:230 18:230 19:230 20:230 21:231 22:232 23:233 24:234 25:235 26:235 27:235 28:235 29:235 30:235 31:236 32:236 33:236 34:236 35:236 36:236 37:236 38:236 39:236 40:236 41:237 42:238 43:239 44:240 45:241 46:242 47:243 48:244 49:245 50:245 51:246 52:246 53:246 54:247 55:248 56:249 57:250 58:251 59:252 60:253 61:254 62:254 63:255 64:256 65:256 66:256 67:257 68:258 69:258 70:258 71:259 72:259 73:260 74:261 75:261 76:262 77:263 78:263 79:264 80:264 81:264 82:265 83:266 84:266 85:267 86:268 87:269 88:270 89:271 90:272 91:273 92:274 93:275 94:276 95:277 96:277 97:277 98:278 99:278 100:278 101:278 102:279 103:279 104:279 105:279 106:279 107:279 108:279 109:279 110:280 111:281 112:282 113:283 114:284 115:285 116:286 117:286 118:286 119:287 120:288 121:289 122:289 123:289 124:290 125:291 126:292 127:293 128:294 129:295 130:295 131:295 132:296 133:297 134:297 135:298 136:299 137:299 138:299 139:299 140:300 141:300 142:301 143:302 144:303 145:304 146:305 147:306 148:307 149:307 150:308 151:308 152:308 153:308 154:308 155:308 156:308 157:309 158:309 159:309 160:310 161:311 162:312 163:313 164:314 165:315 166:316 167:316 168:316 169:317 170:318 171:319 172:320 173:321 174:321 175:322 176:323 177:324 178:325 179:326 180:327 181:328 182:328 183:328 184:328 185:328 186:329 187:330 188:331 189:332 190:333 191:334 192:335 193:336 194:337 195:337 196:337 197:337 198:337 199:337 200:337 201:338 202:338 203:338 204:339 205:340 206:341 207:342 208:342 209:343 210:343 211:344 212:345 213:346 214:347 215:348 216:348 217:348 218:349 219:349 220:349 221:350 222:351 223:352 224:353 225:353 226:354 227:354 228:355 229:356 230:357 231:358 232:358 233:358 234:359 235:360 236:361 237:362 238:363 239:363 240:363 241:363 242:363 243:363 244:363 245:364 246:365 247:366 248:367 249:368 250:369 251:369 252:369 253:370 254:370 255:370 256:370 257:371 258:372 259:372 260:373 261:373 262:373 263:374 264:375 265:375 266:375 267:375 268:375 269:376 270:376 271:377 272:378 273:379 274:380 275:381 276:381 277:381 278:382 279:383 280:384 281:385 282:386 283:386 284:387 285:388 286:389 287:390 288:390 289:391 290:392 291:392 292:392 293:392 294:392 295:392 296:392 297:392 298:393 299:394 300:395 301:396 302:397 303:397 304:397 305:397 306:397 307:398 308:399 309:400 310:401 311:402 312:403 313:403 314:403 315:404 316:405 317:406 318:407 319:408 320:409 321:410 322:411 323:411 324:411 325:411 326:412 327:413 328:413 329:413 330:413 331:413 332:414 333:414 334:415 335:416 336:417 337:418 338:419 339:419 340:419 341:420 342:421 343:422 344:423 345:424 346:425 347:426 348:427 349:428 350:429 351:430 352:430 353:430 354:431 355:432 356:433 357:434 358:435 359:436 360:437 361:437 362:438 363:439 364:439 365:440 366:441 367:441 368:441 369:441 370:442 371:443 372:444 373:445 374:445 375:445 376:446 377:447 378:448 379:449 380:450 381:451 382:452\n",
      "INFO:tensorflow:token_is_max_context: 11:False 12:False 13:False 14:False 15:False 16:False 17:False 18:False 19:False 20:False 21:False 22:False 23:False 24:False 25:False 26:False 27:False 28:False 29:False 30:False 31:False 32:False 33:False 34:False 35:False 36:False 37:False 38:False 39:False 40:False 41:False 42:False 43:False 44:False 45:False 46:False 47:False 48:False 49:False 50:False 51:False 52:False 53:False 54:False 55:False 56:False 57:False 58:False 59:False 60:False 61:False 62:False 63:False 64:False 65:False 66:False 67:False 68:False 69:False 70:False 71:False 72:False 73:False 74:False 75:False 76:False 77:False 78:False 79:False 80:False 81:False 82:False 83:False 84:False 85:False 86:False 87:False 88:False 89:False 90:False 91:False 92:False 93:False 94:False 95:False 96:False 97:False 98:False 99:False 100:False 101:False 102:False 103:False 104:False 105:False 106:False 107:False 108:False 109:False 110:False 111:False 112:False 113:False 114:False 115:False 116:False 117:False 118:False 119:False 120:False 121:False 122:False 123:False 124:False 125:False 126:False 127:False 128:False 129:False 130:False 131:False 132:False 133:True 134:True 135:True 136:True 137:True 138:True 139:True 140:True 141:True 142:True 143:True 144:True 145:True 146:True 147:True 148:True 149:True 150:True 151:True 152:True 153:True 154:True 155:True 156:True 157:True 158:True 159:True 160:True 161:True 162:True 163:True 164:True 165:True 166:True 167:True 168:True 169:True 170:True 171:True 172:True 173:True 174:True 175:True 176:True 177:True 178:True 179:True 180:True 181:True 182:True 183:True 184:True 185:True 186:True 187:True 188:True 189:True 190:True 191:True 192:True 193:True 194:True 195:True 196:True 197:True 198:True 199:True 200:True 201:True 202:True 203:True 204:True 205:True 206:True 207:True 208:True 209:True 210:True 211:True 212:True 213:True 214:True 215:True 216:True 217:True 218:True 219:True 220:True 221:True 222:True 223:True 224:True 225:True 226:True 227:True 228:True 229:True 230:True 231:True 232:True 233:True 234:True 235:True 236:True 237:True 238:True 239:True 240:True 241:True 242:True 243:True 244:True 245:True 246:True 247:True 248:True 249:True 250:True 251:True 252:True 253:True 254:True 255:True 256:True 257:True 258:True 259:True 260:True 261:False 262:False 263:False 264:False 265:False 266:False 267:False 268:False 269:False 270:False 271:False 272:False 273:False 274:False 275:False 276:False 277:False 278:False 279:False 280:False 281:False 282:False 283:False 284:False 285:False 286:False 287:False 288:False 289:False 290:False 291:False 292:False 293:False 294:False 295:False 296:False 297:False 298:False 299:False 300:False 301:False 302:False 303:False 304:False 305:False 306:False 307:False 308:False 309:False 310:False 311:False 312:False 313:False 314:False 315:False 316:False 317:False 318:False 319:False 320:False 321:False 322:False 323:False 324:False 325:False 326:False 327:False 328:False 329:False 330:False 331:False 332:False 333:False 334:False 335:False 336:False 337:False 338:False 339:False 340:False 341:False 342:False 343:False 344:False 345:False 346:False 347:False 348:False 349:False 350:False 351:False 352:False 353:False 354:False 355:False 356:False 357:False 358:False 359:False 360:False 361:False 362:False 363:False 364:False 365:False 366:False 367:False 368:False 369:False 370:False 371:False 372:False 373:False 374:False 375:False 376:False 377:False 378:False 379:False 380:False 381:False 382:False\n",
      "I1208 12:27:37.141115 139883775852736 run_factoid.py:447] token_is_max_context: 11:False 12:False 13:False 14:False 15:False 16:False 17:False 18:False 19:False 20:False 21:False 22:False 23:False 24:False 25:False 26:False 27:False 28:False 29:False 30:False 31:False 32:False 33:False 34:False 35:False 36:False 37:False 38:False 39:False 40:False 41:False 42:False 43:False 44:False 45:False 46:False 47:False 48:False 49:False 50:False 51:False 52:False 53:False 54:False 55:False 56:False 57:False 58:False 59:False 60:False 61:False 62:False 63:False 64:False 65:False 66:False 67:False 68:False 69:False 70:False 71:False 72:False 73:False 74:False 75:False 76:False 77:False 78:False 79:False 80:False 81:False 82:False 83:False 84:False 85:False 86:False 87:False 88:False 89:False 90:False 91:False 92:False 93:False 94:False 95:False 96:False 97:False 98:False 99:False 100:False 101:False 102:False 103:False 104:False 105:False 106:False 107:False 108:False 109:False 110:False 111:False 112:False 113:False 114:False 115:False 116:False 117:False 118:False 119:False 120:False 121:False 122:False 123:False 124:False 125:False 126:False 127:False 128:False 129:False 130:False 131:False 132:False 133:True 134:True 135:True 136:True 137:True 138:True 139:True 140:True 141:True 142:True 143:True 144:True 145:True 146:True 147:True 148:True 149:True 150:True 151:True 152:True 153:True 154:True 155:True 156:True 157:True 158:True 159:True 160:True 161:True 162:True 163:True 164:True 165:True 166:True 167:True 168:True 169:True 170:True 171:True 172:True 173:True 174:True 175:True 176:True 177:True 178:True 179:True 180:True 181:True 182:True 183:True 184:True 185:True 186:True 187:True 188:True 189:True 190:True 191:True 192:True 193:True 194:True 195:True 196:True 197:True 198:True 199:True 200:True 201:True 202:True 203:True 204:True 205:True 206:True 207:True 208:True 209:True 210:True 211:True 212:True 213:True 214:True 215:True 216:True 217:True 218:True 219:True 220:True 221:True 222:True 223:True 224:True 225:True 226:True 227:True 228:True 229:True 230:True 231:True 232:True 233:True 234:True 235:True 236:True 237:True 238:True 239:True 240:True 241:True 242:True 243:True 244:True 245:True 246:True 247:True 248:True 249:True 250:True 251:True 252:True 253:True 254:True 255:True 256:True 257:True 258:True 259:True 260:True 261:False 262:False 263:False 264:False 265:False 266:False 267:False 268:False 269:False 270:False 271:False 272:False 273:False 274:False 275:False 276:False 277:False 278:False 279:False 280:False 281:False 282:False 283:False 284:False 285:False 286:False 287:False 288:False 289:False 290:False 291:False 292:False 293:False 294:False 295:False 296:False 297:False 298:False 299:False 300:False 301:False 302:False 303:False 304:False 305:False 306:False 307:False 308:False 309:False 310:False 311:False 312:False 313:False 314:False 315:False 316:False 317:False 318:False 319:False 320:False 321:False 322:False 323:False 324:False 325:False 326:False 327:False 328:False 329:False 330:False 331:False 332:False 333:False 334:False 335:False 336:False 337:False 338:False 339:False 340:False 341:False 342:False 343:False 344:False 345:False 346:False 347:False 348:False 349:False 350:False 351:False 352:False 353:False 354:False 355:False 356:False 357:False 358:False 359:False 360:False 361:False 362:False 363:False 364:False 365:False 366:False 367:False 368:False 369:False 370:False 371:False 372:False 373:False 374:False 375:False 376:False 377:False 378:False 379:False 380:False 381:False 382:False\n",
      "INFO:tensorflow:input_ids: 101 2091 1103 9505 12864 1113 5351 17898 1116 136 102 1231 10182 21629 2603 113 1275 119 3324 110 114 1190 1343 5165 1114 26574 1708 118 157 2162 15499 113 121 119 121 110 114 119 164 4335 166 1109 5752 6547 1103 9505 1106 1103 1378 3672 131 113 122 114 1175 1108 1199 3187 5320 1115 1127 17163 2109 1104 1231 10182 21629 1107 153 21678 2137 4420 119 1370 1859 117 1385 1425 117 184 27655 117 1105 12556 13328 1849 1138 1151 3626 1112 2418 3187 5320 1111 1103 153 21678 2137 1231 10182 1197 118 1231 3633 119 164 4650 117 4589 166 1262 1103 126 4420 1150 4531 1231 10182 21629 1107 1103 153 21678 2137 1372 1127 1155 3860 1385 113 864 16480 1201 1385 114 1105 184 12866 1162 132 2456 117 1152 1127 1120 1344 3187 1104 1231 21754 1123 5813 2116 119 164 4335 166 113 123 114 124 1104 1103 126 4420 1125 1123 5813 1906 17906 1115 1127 3023 13793 117 1105 1142 1189 1103 6059 1167 2846 119 164 2539 166 1109 25399 17906 1156 1871 1107 7285 13467 13950 119 164 4650 117 5391 166 113 124 114 1258 1103 2425 22157 2137 6059 117 1103 8246 16694 1107 1126 14787 5954 20497 12725 14410 1156 1849 1103 2495 17379 2401 117 1105 1294 1103 1126 14787 5954 1129 1167 3253 1106 3687 11787 9199 119 164 4335 166 7457 1113 1103 3290 1107 1126 14787 5954 20497 12725 14410 117 1103 1231 21754 1123 5813 2116 3253 3296 119 164 5073 166 6589 117 1122 1110 3372 1111 153 21678 2137 1106 9474 1142 2463 12678 117 1105 170 1194 9455 14637 11970 113 26574 1708 118 157 2162 15499 114 1547 1129 170 1618 3026 119 164 4335 166 1109 2244 2603 1107 1103 153 21678 2137 1372 1105 1168 13467 9108 1372 1127 128 119 123 110 1105 125 119 122 110 117 3569 119 1966 4420 5165 1114 153 21678 2137 3890 170 5409 2299 2244 2603 1190 1343 1114 1168 12814 3377 117 1103 3719 1206 1172 1108 1136 2418 119 2499 17730 117 3084 2393 164 3993 166 1982 170 10260 1884 13252 1204 2025 10540 1104 2539 4776 4420 1114 102\n",
      "I1208 12:27:37.141216 139883775852736 run_factoid.py:449] input_ids: 101 2091 1103 9505 12864 1113 5351 17898 1116 136 102 1231 10182 21629 2603 113 1275 119 3324 110 114 1190 1343 5165 1114 26574 1708 118 157 2162 15499 113 121 119 121 110 114 119 164 4335 166 1109 5752 6547 1103 9505 1106 1103 1378 3672 131 113 122 114 1175 1108 1199 3187 5320 1115 1127 17163 2109 1104 1231 10182 21629 1107 153 21678 2137 4420 119 1370 1859 117 1385 1425 117 184 27655 117 1105 12556 13328 1849 1138 1151 3626 1112 2418 3187 5320 1111 1103 153 21678 2137 1231 10182 1197 118 1231 3633 119 164 4650 117 4589 166 1262 1103 126 4420 1150 4531 1231 10182 21629 1107 1103 153 21678 2137 1372 1127 1155 3860 1385 113 864 16480 1201 1385 114 1105 184 12866 1162 132 2456 117 1152 1127 1120 1344 3187 1104 1231 21754 1123 5813 2116 119 164 4335 166 113 123 114 124 1104 1103 126 4420 1125 1123 5813 1906 17906 1115 1127 3023 13793 117 1105 1142 1189 1103 6059 1167 2846 119 164 2539 166 1109 25399 17906 1156 1871 1107 7285 13467 13950 119 164 4650 117 5391 166 113 124 114 1258 1103 2425 22157 2137 6059 117 1103 8246 16694 1107 1126 14787 5954 20497 12725 14410 1156 1849 1103 2495 17379 2401 117 1105 1294 1103 1126 14787 5954 1129 1167 3253 1106 3687 11787 9199 119 164 4335 166 7457 1113 1103 3290 1107 1126 14787 5954 20497 12725 14410 117 1103 1231 21754 1123 5813 2116 3253 3296 119 164 5073 166 6589 117 1122 1110 3372 1111 153 21678 2137 1106 9474 1142 2463 12678 117 1105 170 1194 9455 14637 11970 113 26574 1708 118 157 2162 15499 114 1547 1129 170 1618 3026 119 164 4335 166 1109 2244 2603 1107 1103 153 21678 2137 1372 1105 1168 13467 9108 1372 1127 128 119 123 110 1105 125 119 122 110 117 3569 119 1966 4420 5165 1114 153 21678 2137 3890 170 5409 2299 2244 2603 1190 1343 1114 1168 12814 3377 117 1103 3719 1206 1172 1108 1136 2418 119 2499 17730 117 3084 2393 164 3993 166 1982 170 10260 1884 13252 1204 2025 10540 1104 2539 4776 4420 1114 102\n",
      "INFO:tensorflow:input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      "I1208 12:27:37.141307 139883775852736 run_factoid.py:451] input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      "INFO:tensorflow:segment_ids: 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      "I1208 12:27:37.141396 139883775852736 run_factoid.py:453] segment_ids: 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      "INFO:tensorflow:*** Example ***\n",
      "I1208 12:27:37.143240 139883775852736 run_factoid.py:438] *** Example ***\n",
      "INFO:tensorflow:unique_id: 1000000044\n",
      "I1208 12:27:37.143303 139883775852736 run_factoid.py:439] unique_id: 1000000044\n",
      "INFO:tensorflow:example_index: 8\n",
      "I1208 12:27:37.143340 139883775852736 run_factoid.py:440] example_index: 8\n",
      "INFO:tensorflow:doc_span_index: 4\n",
      "I1208 12:27:37.143375 139883775852736 run_factoid.py:441] doc_span_index: 4\n",
      "INFO:tensorflow:tokens: [CLS] Do the findings depend on patient demographic ##s ? [SEP] ; thus , they were at high risk of re ##current her ##nia ##tion . [ 54 ] ( 2 ) 3 of the 5 patients had her ##nia ##ted fragment that were highly migrated , and this made the surgery more difficult . [ 60 ] The residual fragment would result in unsuccessful surgical outcomes . [ 58 , 61 ] ( 3 ) After the primary ME ##D surgery , the artificial cracks in an ##nu ##lus fi ##bro ##sus would change the la ##minate structure , and make the an ##nu ##lus be more easily to del ##ami ##nation . [ 54 ] Based on the damage in an ##nu ##lus fi ##bro ##sus , the re ##current her ##nia ##tion easily occurred . [ 62 ] Therefore , it is unable for P ##EL ##D to solve this problem thoroughly , and a through inter ##body fusion ( MI ##S - T ##L ##IF ) might be a better choice . [ 54 ] The success rate in the P ##EL ##D group and other surgical intervention group were 7 . 2 % and 4 . 1 % , respectively . Although patients treated with P ##EL ##D achieved a significantly higher success rate than those with other surge ##ries , the difference between them was not significant . Lee SH , et al [ 46 ] performed a matched co ##hor ##t study evaluation of 60 consecutive patients with L ##D ##H . Of them , 30 patients were underwent P ##EL ##D , and 30 were treated with O ##LM . [ 46 ] At the follow - up duration of 36 ##mont ##hs , 96 . 7 % of patients in the P ##EL ##D group and 93 . 3 % of patients in the O ##LM group achieved good or excellent results . [ 46 ] For micro ##su ##rg ##ical disc ##ec ##tom ##y , our result also showed a similar success rate with P ##EL ##D . R ##utt ##en S , et al [ 48 ] performed a prospective random ##ized study to compare the clinical outcomes of P ##EL ##D with micro ##su ##rg ##ical technique . In that study [SEP]\n",
      "I1208 12:27:37.143490 139883775852736 run_factoid.py:443] tokens: [CLS] Do the findings depend on patient demographic ##s ? [SEP] ; thus , they were at high risk of re ##current her ##nia ##tion . [ 54 ] ( 2 ) 3 of the 5 patients had her ##nia ##ted fragment that were highly migrated , and this made the surgery more difficult . [ 60 ] The residual fragment would result in unsuccessful surgical outcomes . [ 58 , 61 ] ( 3 ) After the primary ME ##D surgery , the artificial cracks in an ##nu ##lus fi ##bro ##sus would change the la ##minate structure , and make the an ##nu ##lus be more easily to del ##ami ##nation . [ 54 ] Based on the damage in an ##nu ##lus fi ##bro ##sus , the re ##current her ##nia ##tion easily occurred . [ 62 ] Therefore , it is unable for P ##EL ##D to solve this problem thoroughly , and a through inter ##body fusion ( MI ##S - T ##L ##IF ) might be a better choice . [ 54 ] The success rate in the P ##EL ##D group and other surgical intervention group were 7 . 2 % and 4 . 1 % , respectively . Although patients treated with P ##EL ##D achieved a significantly higher success rate than those with other surge ##ries , the difference between them was not significant . Lee SH , et al [ 46 ] performed a matched co ##hor ##t study evaluation of 60 consecutive patients with L ##D ##H . Of them , 30 patients were underwent P ##EL ##D , and 30 were treated with O ##LM . [ 46 ] At the follow - up duration of 36 ##mont ##hs , 96 . 7 % of patients in the P ##EL ##D group and 93 . 3 % of patients in the O ##LM group achieved good or excellent results . [ 46 ] For micro ##su ##rg ##ical disc ##ec ##tom ##y , our result also showed a similar success rate with P ##EL ##D . R ##utt ##en S , et al [ 48 ] performed a prospective random ##ized study to compare the clinical outcomes of P ##EL ##D with micro ##su ##rg ##ical technique . In that study [SEP]\n",
      "INFO:tensorflow:token_to_orig_map: 11:299 12:300 13:300 14:301 15:302 16:303 17:304 18:305 19:306 20:307 21:307 22:308 23:308 24:308 25:308 26:308 27:308 28:308 29:309 30:309 31:309 32:310 33:311 34:312 35:313 36:314 37:315 38:316 39:316 40:316 41:317 42:318 43:319 44:320 45:321 46:321 47:322 48:323 49:324 50:325 51:326 52:327 53:328 54:328 55:328 56:328 57:328 58:329 59:330 60:331 61:332 62:333 63:334 64:335 65:336 66:337 67:337 68:337 69:337 70:337 71:337 72:337 73:338 74:338 75:338 76:339 77:340 78:341 79:342 80:342 81:343 82:343 83:344 84:345 85:346 86:347 87:348 88:348 89:348 90:349 91:349 92:349 93:350 94:351 95:352 96:353 97:353 98:354 99:354 100:355 101:356 102:357 103:358 104:358 105:358 106:359 107:360 108:361 109:362 110:363 111:363 112:363 113:363 114:363 115:363 116:363 117:364 118:365 119:366 120:367 121:368 122:369 123:369 124:369 125:370 126:370 127:370 128:370 129:371 130:372 131:372 132:373 133:373 134:373 135:374 136:375 137:375 138:375 139:375 140:375 141:376 142:376 143:377 144:378 145:379 146:380 147:381 148:381 149:381 150:382 151:383 152:384 153:385 154:386 155:386 156:387 157:388 158:389 159:390 160:390 161:391 162:392 163:392 164:392 165:392 166:392 167:392 168:392 169:392 170:393 171:394 172:395 173:396 174:397 175:397 176:397 177:397 178:397 179:398 180:399 181:400 182:401 183:402 184:403 185:403 186:403 187:404 188:405 189:406 190:407 191:408 192:409 193:410 194:411 195:411 196:411 197:411 198:412 199:413 200:413 201:413 202:413 203:413 204:414 205:414 206:415 207:416 208:417 209:418 210:419 211:419 212:419 213:420 214:421 215:422 216:423 217:424 218:425 219:426 220:427 221:428 222:429 223:430 224:430 225:430 226:431 227:432 228:433 229:434 230:435 231:436 232:437 233:437 234:438 235:439 236:439 237:440 238:441 239:441 240:441 241:441 242:442 243:443 244:444 245:445 246:445 247:445 248:446 249:447 250:448 251:449 252:450 253:451 254:452 255:453 256:453 257:453 258:453 259:454 260:455 261:455 262:456 263:457 264:458 265:459 266:460 267:460 268:460 269:460 270:461 271:462 272:463 273:464 274:465 275:466 276:466 277:466 278:466 279:466 280:466 281:467 282:468 283:469 284:469 285:469 286:470 287:471 288:472 289:472 290:472 291:472 292:473 293:473 294:473 295:473 296:474 297:475 298:476 299:477 300:478 301:478 302:478 303:479 304:480 305:481 306:481 307:481 308:481 309:482 310:483 311:484 312:485 313:486 314:486 315:487 316:488 317:489 318:490 319:491 320:492 321:492 322:492 323:492 324:492 325:493 326:494 327:494 328:494 329:494 330:495 331:495 332:495 333:495 334:495 335:496 336:497 337:498 338:499 339:500 340:501 341:502 342:503 343:504 344:505 345:505 346:505 347:505 348:506 349:506 350:506 351:507 352:507 353:508 354:509 355:509 356:509 357:509 358:510 359:511 360:512 361:513 362:513 363:514 364:515 365:516 366:517 367:518 368:519 369:520 370:521 371:521 372:521 373:522 374:523 375:523 376:523 377:523 378:524 379:524 380:525 381:526 382:527\n",
      "I1208 12:27:37.143604 139883775852736 run_factoid.py:445] token_to_orig_map: 11:299 12:300 13:300 14:301 15:302 16:303 17:304 18:305 19:306 20:307 21:307 22:308 23:308 24:308 25:308 26:308 27:308 28:308 29:309 30:309 31:309 32:310 33:311 34:312 35:313 36:314 37:315 38:316 39:316 40:316 41:317 42:318 43:319 44:320 45:321 46:321 47:322 48:323 49:324 50:325 51:326 52:327 53:328 54:328 55:328 56:328 57:328 58:329 59:330 60:331 61:332 62:333 63:334 64:335 65:336 66:337 67:337 68:337 69:337 70:337 71:337 72:337 73:338 74:338 75:338 76:339 77:340 78:341 79:342 80:342 81:343 82:343 83:344 84:345 85:346 86:347 87:348 88:348 89:348 90:349 91:349 92:349 93:350 94:351 95:352 96:353 97:353 98:354 99:354 100:355 101:356 102:357 103:358 104:358 105:358 106:359 107:360 108:361 109:362 110:363 111:363 112:363 113:363 114:363 115:363 116:363 117:364 118:365 119:366 120:367 121:368 122:369 123:369 124:369 125:370 126:370 127:370 128:370 129:371 130:372 131:372 132:373 133:373 134:373 135:374 136:375 137:375 138:375 139:375 140:375 141:376 142:376 143:377 144:378 145:379 146:380 147:381 148:381 149:381 150:382 151:383 152:384 153:385 154:386 155:386 156:387 157:388 158:389 159:390 160:390 161:391 162:392 163:392 164:392 165:392 166:392 167:392 168:392 169:392 170:393 171:394 172:395 173:396 174:397 175:397 176:397 177:397 178:397 179:398 180:399 181:400 182:401 183:402 184:403 185:403 186:403 187:404 188:405 189:406 190:407 191:408 192:409 193:410 194:411 195:411 196:411 197:411 198:412 199:413 200:413 201:413 202:413 203:413 204:414 205:414 206:415 207:416 208:417 209:418 210:419 211:419 212:419 213:420 214:421 215:422 216:423 217:424 218:425 219:426 220:427 221:428 222:429 223:430 224:430 225:430 226:431 227:432 228:433 229:434 230:435 231:436 232:437 233:437 234:438 235:439 236:439 237:440 238:441 239:441 240:441 241:441 242:442 243:443 244:444 245:445 246:445 247:445 248:446 249:447 250:448 251:449 252:450 253:451 254:452 255:453 256:453 257:453 258:453 259:454 260:455 261:455 262:456 263:457 264:458 265:459 266:460 267:460 268:460 269:460 270:461 271:462 272:463 273:464 274:465 275:466 276:466 277:466 278:466 279:466 280:466 281:467 282:468 283:469 284:469 285:469 286:470 287:471 288:472 289:472 290:472 291:472 292:473 293:473 294:473 295:473 296:474 297:475 298:476 299:477 300:478 301:478 302:478 303:479 304:480 305:481 306:481 307:481 308:481 309:482 310:483 311:484 312:485 313:486 314:486 315:487 316:488 317:489 318:490 319:491 320:492 321:492 322:492 323:492 324:492 325:493 326:494 327:494 328:494 329:494 330:495 331:495 332:495 333:495 334:495 335:496 336:497 337:498 338:499 339:500 340:501 341:502 342:503 343:504 344:505 345:505 346:505 347:505 348:506 349:506 350:506 351:507 352:507 353:508 354:509 355:509 356:509 357:509 358:510 359:511 360:512 361:513 362:513 363:514 364:515 365:516 366:517 367:518 368:519 369:520 370:521 371:521 372:521 373:522 374:523 375:523 376:523 377:523 378:524 379:524 380:525 381:526 382:527\n",
      "INFO:tensorflow:token_is_max_context: 11:False 12:False 13:False 14:False 15:False 16:False 17:False 18:False 19:False 20:False 21:False 22:False 23:False 24:False 25:False 26:False 27:False 28:False 29:False 30:False 31:False 32:False 33:False 34:False 35:False 36:False 37:False 38:False 39:False 40:False 41:False 42:False 43:False 44:False 45:False 46:False 47:False 48:False 49:False 50:False 51:False 52:False 53:False 54:False 55:False 56:False 57:False 58:False 59:False 60:False 61:False 62:False 63:False 64:False 65:False 66:False 67:False 68:False 69:False 70:False 71:False 72:False 73:False 74:False 75:False 76:False 77:False 78:False 79:False 80:False 81:False 82:False 83:False 84:False 85:False 86:False 87:False 88:False 89:False 90:False 91:False 92:False 93:False 94:False 95:False 96:False 97:False 98:False 99:False 100:False 101:False 102:False 103:False 104:False 105:False 106:False 107:False 108:False 109:False 110:False 111:False 112:False 113:False 114:False 115:False 116:False 117:False 118:False 119:False 120:False 121:False 122:False 123:False 124:False 125:False 126:False 127:False 128:False 129:False 130:False 131:False 132:False 133:True 134:True 135:True 136:True 137:True 138:True 139:True 140:True 141:True 142:True 143:True 144:True 145:True 146:True 147:True 148:True 149:True 150:True 151:True 152:True 153:True 154:True 155:True 156:True 157:True 158:True 159:True 160:True 161:True 162:True 163:True 164:True 165:True 166:True 167:True 168:True 169:True 170:True 171:True 172:True 173:True 174:True 175:True 176:True 177:True 178:True 179:True 180:True 181:True 182:True 183:True 184:True 185:True 186:True 187:True 188:True 189:True 190:True 191:True 192:True 193:True 194:True 195:True 196:True 197:True 198:True 199:True 200:True 201:True 202:True 203:True 204:True 205:True 206:True 207:True 208:True 209:True 210:True 211:True 212:True 213:True 214:True 215:True 216:True 217:True 218:True 219:True 220:True 221:True 222:True 223:True 224:True 225:True 226:True 227:True 228:True 229:True 230:True 231:True 232:True 233:True 234:True 235:True 236:True 237:True 238:True 239:True 240:True 241:True 242:True 243:True 244:True 245:True 246:True 247:True 248:True 249:True 250:True 251:True 252:True 253:True 254:True 255:True 256:True 257:True 258:True 259:True 260:True 261:False 262:False 263:False 264:False 265:False 266:False 267:False 268:False 269:False 270:False 271:False 272:False 273:False 274:False 275:False 276:False 277:False 278:False 279:False 280:False 281:False 282:False 283:False 284:False 285:False 286:False 287:False 288:False 289:False 290:False 291:False 292:False 293:False 294:False 295:False 296:False 297:False 298:False 299:False 300:False 301:False 302:False 303:False 304:False 305:False 306:False 307:False 308:False 309:False 310:False 311:False 312:False 313:False 314:False 315:False 316:False 317:False 318:False 319:False 320:False 321:False 322:False 323:False 324:False 325:False 326:False 327:False 328:False 329:False 330:False 331:False 332:False 333:False 334:False 335:False 336:False 337:False 338:False 339:False 340:False 341:False 342:False 343:False 344:False 345:False 346:False 347:False 348:False 349:False 350:False 351:False 352:False 353:False 354:False 355:False 356:False 357:False 358:False 359:False 360:False 361:False 362:False 363:False 364:False 365:False 366:False 367:False 368:False 369:False 370:False 371:False 372:False 373:False 374:False 375:False 376:False 377:False 378:False 379:False 380:False 381:False 382:False\n",
      "I1208 12:27:37.143714 139883775852736 run_factoid.py:447] token_is_max_context: 11:False 12:False 13:False 14:False 15:False 16:False 17:False 18:False 19:False 20:False 21:False 22:False 23:False 24:False 25:False 26:False 27:False 28:False 29:False 30:False 31:False 32:False 33:False 34:False 35:False 36:False 37:False 38:False 39:False 40:False 41:False 42:False 43:False 44:False 45:False 46:False 47:False 48:False 49:False 50:False 51:False 52:False 53:False 54:False 55:False 56:False 57:False 58:False 59:False 60:False 61:False 62:False 63:False 64:False 65:False 66:False 67:False 68:False 69:False 70:False 71:False 72:False 73:False 74:False 75:False 76:False 77:False 78:False 79:False 80:False 81:False 82:False 83:False 84:False 85:False 86:False 87:False 88:False 89:False 90:False 91:False 92:False 93:False 94:False 95:False 96:False 97:False 98:False 99:False 100:False 101:False 102:False 103:False 104:False 105:False 106:False 107:False 108:False 109:False 110:False 111:False 112:False 113:False 114:False 115:False 116:False 117:False 118:False 119:False 120:False 121:False 122:False 123:False 124:False 125:False 126:False 127:False 128:False 129:False 130:False 131:False 132:False 133:True 134:True 135:True 136:True 137:True 138:True 139:True 140:True 141:True 142:True 143:True 144:True 145:True 146:True 147:True 148:True 149:True 150:True 151:True 152:True 153:True 154:True 155:True 156:True 157:True 158:True 159:True 160:True 161:True 162:True 163:True 164:True 165:True 166:True 167:True 168:True 169:True 170:True 171:True 172:True 173:True 174:True 175:True 176:True 177:True 178:True 179:True 180:True 181:True 182:True 183:True 184:True 185:True 186:True 187:True 188:True 189:True 190:True 191:True 192:True 193:True 194:True 195:True 196:True 197:True 198:True 199:True 200:True 201:True 202:True 203:True 204:True 205:True 206:True 207:True 208:True 209:True 210:True 211:True 212:True 213:True 214:True 215:True 216:True 217:True 218:True 219:True 220:True 221:True 222:True 223:True 224:True 225:True 226:True 227:True 228:True 229:True 230:True 231:True 232:True 233:True 234:True 235:True 236:True 237:True 238:True 239:True 240:True 241:True 242:True 243:True 244:True 245:True 246:True 247:True 248:True 249:True 250:True 251:True 252:True 253:True 254:True 255:True 256:True 257:True 258:True 259:True 260:True 261:False 262:False 263:False 264:False 265:False 266:False 267:False 268:False 269:False 270:False 271:False 272:False 273:False 274:False 275:False 276:False 277:False 278:False 279:False 280:False 281:False 282:False 283:False 284:False 285:False 286:False 287:False 288:False 289:False 290:False 291:False 292:False 293:False 294:False 295:False 296:False 297:False 298:False 299:False 300:False 301:False 302:False 303:False 304:False 305:False 306:False 307:False 308:False 309:False 310:False 311:False 312:False 313:False 314:False 315:False 316:False 317:False 318:False 319:False 320:False 321:False 322:False 323:False 324:False 325:False 326:False 327:False 328:False 329:False 330:False 331:False 332:False 333:False 334:False 335:False 336:False 337:False 338:False 339:False 340:False 341:False 342:False 343:False 344:False 345:False 346:False 347:False 348:False 349:False 350:False 351:False 352:False 353:False 354:False 355:False 356:False 357:False 358:False 359:False 360:False 361:False 362:False 363:False 364:False 365:False 366:False 367:False 368:False 369:False 370:False 371:False 372:False 373:False 374:False 375:False 376:False 377:False 378:False 379:False 380:False 381:False 382:False\n",
      "INFO:tensorflow:input_ids: 101 2091 1103 9505 12864 1113 5351 17898 1116 136 102 132 2456 117 1152 1127 1120 1344 3187 1104 1231 21754 1123 5813 2116 119 164 4335 166 113 123 114 124 1104 1103 126 4420 1125 1123 5813 1906 17906 1115 1127 3023 13793 117 1105 1142 1189 1103 6059 1167 2846 119 164 2539 166 1109 25399 17906 1156 1871 1107 7285 13467 13950 119 164 4650 117 5391 166 113 124 114 1258 1103 2425 22157 2137 6059 117 1103 8246 16694 1107 1126 14787 5954 20497 12725 14410 1156 1849 1103 2495 17379 2401 117 1105 1294 1103 1126 14787 5954 1129 1167 3253 1106 3687 11787 9199 119 164 4335 166 7457 1113 1103 3290 1107 1126 14787 5954 20497 12725 14410 117 1103 1231 21754 1123 5813 2116 3253 3296 119 164 5073 166 6589 117 1122 1110 3372 1111 153 21678 2137 1106 9474 1142 2463 12678 117 1105 170 1194 9455 14637 11970 113 26574 1708 118 157 2162 15499 114 1547 1129 170 1618 3026 119 164 4335 166 1109 2244 2603 1107 1103 153 21678 2137 1372 1105 1168 13467 9108 1372 1127 128 119 123 110 1105 125 119 122 110 117 3569 119 1966 4420 5165 1114 153 21678 2137 3890 170 5409 2299 2244 2603 1190 1343 1114 1168 12814 3377 117 1103 3719 1206 1172 1108 1136 2418 119 2499 17730 117 3084 2393 164 3993 166 1982 170 10260 1884 13252 1204 2025 10540 1104 2539 4776 4420 1114 149 2137 3048 119 2096 1172 117 1476 4420 1127 9315 153 21678 2137 117 1105 1476 1127 5165 1114 152 22074 119 164 3993 166 1335 1103 2812 118 1146 9355 1104 3164 7578 9524 117 5306 119 128 110 1104 4420 1107 1103 153 21678 2137 1372 1105 5429 119 124 110 1104 4420 1107 1103 152 22074 1372 3890 1363 1137 6548 2686 119 164 3993 166 1370 17599 6385 10805 4571 6187 10294 18778 1183 117 1412 1871 1145 2799 170 1861 2244 2603 1114 153 21678 2137 119 155 25131 1424 156 117 3084 2393 164 3615 166 1982 170 19916 7091 2200 2025 1106 14133 1103 7300 13950 1104 153 21678 2137 1114 17599 6385 10805 4571 5531 119 1130 1115 2025 102\n",
      "I1208 12:27:37.143816 139883775852736 run_factoid.py:449] input_ids: 101 2091 1103 9505 12864 1113 5351 17898 1116 136 102 132 2456 117 1152 1127 1120 1344 3187 1104 1231 21754 1123 5813 2116 119 164 4335 166 113 123 114 124 1104 1103 126 4420 1125 1123 5813 1906 17906 1115 1127 3023 13793 117 1105 1142 1189 1103 6059 1167 2846 119 164 2539 166 1109 25399 17906 1156 1871 1107 7285 13467 13950 119 164 4650 117 5391 166 113 124 114 1258 1103 2425 22157 2137 6059 117 1103 8246 16694 1107 1126 14787 5954 20497 12725 14410 1156 1849 1103 2495 17379 2401 117 1105 1294 1103 1126 14787 5954 1129 1167 3253 1106 3687 11787 9199 119 164 4335 166 7457 1113 1103 3290 1107 1126 14787 5954 20497 12725 14410 117 1103 1231 21754 1123 5813 2116 3253 3296 119 164 5073 166 6589 117 1122 1110 3372 1111 153 21678 2137 1106 9474 1142 2463 12678 117 1105 170 1194 9455 14637 11970 113 26574 1708 118 157 2162 15499 114 1547 1129 170 1618 3026 119 164 4335 166 1109 2244 2603 1107 1103 153 21678 2137 1372 1105 1168 13467 9108 1372 1127 128 119 123 110 1105 125 119 122 110 117 3569 119 1966 4420 5165 1114 153 21678 2137 3890 170 5409 2299 2244 2603 1190 1343 1114 1168 12814 3377 117 1103 3719 1206 1172 1108 1136 2418 119 2499 17730 117 3084 2393 164 3993 166 1982 170 10260 1884 13252 1204 2025 10540 1104 2539 4776 4420 1114 149 2137 3048 119 2096 1172 117 1476 4420 1127 9315 153 21678 2137 117 1105 1476 1127 5165 1114 152 22074 119 164 3993 166 1335 1103 2812 118 1146 9355 1104 3164 7578 9524 117 5306 119 128 110 1104 4420 1107 1103 153 21678 2137 1372 1105 5429 119 124 110 1104 4420 1107 1103 152 22074 1372 3890 1363 1137 6548 2686 119 164 3993 166 1370 17599 6385 10805 4571 6187 10294 18778 1183 117 1412 1871 1145 2799 170 1861 2244 2603 1114 153 21678 2137 119 155 25131 1424 156 117 3084 2393 164 3615 166 1982 170 19916 7091 2200 2025 1106 14133 1103 7300 13950 1104 153 21678 2137 1114 17599 6385 10805 4571 5531 119 1130 1115 2025 102\n",
      "INFO:tensorflow:input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      "I1208 12:27:37.143907 139883775852736 run_factoid.py:451] input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      "INFO:tensorflow:segment_ids: 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      "I1208 12:27:37.143997 139883775852736 run_factoid.py:453] segment_ids: 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      "INFO:tensorflow:*** Example ***\n",
      "I1208 12:27:37.145828 139883775852736 run_factoid.py:438] *** Example ***\n",
      "INFO:tensorflow:unique_id: 1000000045\n",
      "I1208 12:27:37.145890 139883775852736 run_factoid.py:439] unique_id: 1000000045\n",
      "INFO:tensorflow:example_index: 8\n",
      "I1208 12:27:37.145927 139883775852736 run_factoid.py:440] example_index: 8\n",
      "INFO:tensorflow:doc_span_index: 5\n",
      "I1208 12:27:37.145961 139883775852736 run_factoid.py:441] doc_span_index: 5\n",
      "INFO:tensorflow:tokens: [CLS] Do the findings depend on patient demographic ##s ? [SEP] 62 ] Therefore , it is unable for P ##EL ##D to solve this problem thoroughly , and a through inter ##body fusion ( MI ##S - T ##L ##IF ) might be a better choice . [ 54 ] The success rate in the P ##EL ##D group and other surgical intervention group were 7 . 2 % and 4 . 1 % , respectively . Although patients treated with P ##EL ##D achieved a significantly higher success rate than those with other surge ##ries , the difference between them was not significant . Lee SH , et al [ 46 ] performed a matched co ##hor ##t study evaluation of 60 consecutive patients with L ##D ##H . Of them , 30 patients were underwent P ##EL ##D , and 30 were treated with O ##LM . [ 46 ] At the follow - up duration of 36 ##mont ##hs , 96 . 7 % of patients in the P ##EL ##D group and 93 . 3 % of patients in the O ##LM group achieved good or excellent results . [ 46 ] For micro ##su ##rg ##ical disc ##ec ##tom ##y , our result also showed a similar success rate with P ##EL ##D . R ##utt ##en S , et al [ 48 ] performed a prospective random ##ized study to compare the clinical outcomes of P ##EL ##D with micro ##su ##rg ##ical technique . In that study , 95 % of patients with P ##EL ##D reported subjective satisfaction as compared with 86 % of patients with micro ##su ##rg ##ical technique . However , the difference between them was not significant . In contrast to the lower success rates of O ##LM and micro ##su ##rg ##ical disc ##ec ##tom ##y , MI ##S - T ##L ##IF seemed to have a higher success rate than P ##EL ##D . Liu C , et al [ 52 ] reported a prospective co ##hor ##t study of 401 patients with re ##current L ##D ##H who were treated with P ##EL ##D ( n = 209 ) or MI ##S - T ##L ##IF ( n = 192 ) . At the mean duration follow [SEP]\n",
      "I1208 12:27:37.146079 139883775852736 run_factoid.py:443] tokens: [CLS] Do the findings depend on patient demographic ##s ? [SEP] 62 ] Therefore , it is unable for P ##EL ##D to solve this problem thoroughly , and a through inter ##body fusion ( MI ##S - T ##L ##IF ) might be a better choice . [ 54 ] The success rate in the P ##EL ##D group and other surgical intervention group were 7 . 2 % and 4 . 1 % , respectively . Although patients treated with P ##EL ##D achieved a significantly higher success rate than those with other surge ##ries , the difference between them was not significant . Lee SH , et al [ 46 ] performed a matched co ##hor ##t study evaluation of 60 consecutive patients with L ##D ##H . Of them , 30 patients were underwent P ##EL ##D , and 30 were treated with O ##LM . [ 46 ] At the follow - up duration of 36 ##mont ##hs , 96 . 7 % of patients in the P ##EL ##D group and 93 . 3 % of patients in the O ##LM group achieved good or excellent results . [ 46 ] For micro ##su ##rg ##ical disc ##ec ##tom ##y , our result also showed a similar success rate with P ##EL ##D . R ##utt ##en S , et al [ 48 ] performed a prospective random ##ized study to compare the clinical outcomes of P ##EL ##D with micro ##su ##rg ##ical technique . In that study , 95 % of patients with P ##EL ##D reported subjective satisfaction as compared with 86 % of patients with micro ##su ##rg ##ical technique . However , the difference between them was not significant . In contrast to the lower success rates of O ##LM and micro ##su ##rg ##ical disc ##ec ##tom ##y , MI ##S - T ##L ##IF seemed to have a higher success rate than P ##EL ##D . Liu C , et al [ 52 ] reported a prospective co ##hor ##t study of 401 patients with re ##current L ##D ##H who were treated with P ##EL ##D ( n = 209 ) or MI ##S - T ##L ##IF ( n = 192 ) . At the mean duration follow [SEP]\n",
      "INFO:tensorflow:token_to_orig_map: 11:375 12:375 13:376 14:376 15:377 16:378 17:379 18:380 19:381 20:381 21:381 22:382 23:383 24:384 25:385 26:386 27:386 28:387 29:388 30:389 31:390 32:390 33:391 34:392 35:392 36:392 37:392 38:392 39:392 40:392 41:392 42:393 43:394 44:395 45:396 46:397 47:397 48:397 49:397 50:397 51:398 52:399 53:400 54:401 55:402 56:403 57:403 58:403 59:404 60:405 61:406 62:407 63:408 64:409 65:410 66:411 67:411 68:411 69:411 70:412 71:413 72:413 73:413 74:413 75:413 76:414 77:414 78:415 79:416 80:417 81:418 82:419 83:419 84:419 85:420 86:421 87:422 88:423 89:424 90:425 91:426 92:427 93:428 94:429 95:430 96:430 97:430 98:431 99:432 100:433 101:434 102:435 103:436 104:437 105:437 106:438 107:439 108:439 109:440 110:441 111:441 112:441 113:441 114:442 115:443 116:444 117:445 118:445 119:445 120:446 121:447 122:448 123:449 124:450 125:451 126:452 127:453 128:453 129:453 130:453 131:454 132:455 133:455 134:456 135:457 136:458 137:459 138:460 139:460 140:460 141:460 142:461 143:462 144:463 145:464 146:465 147:466 148:466 149:466 150:466 151:466 152:466 153:467 154:468 155:469 156:469 157:469 158:470 159:471 160:472 161:472 162:472 163:472 164:473 165:473 166:473 167:473 168:474 169:475 170:476 171:477 172:478 173:478 174:478 175:479 176:480 177:481 178:481 179:481 180:481 181:482 182:483 183:484 184:485 185:486 186:486 187:487 188:488 189:489 190:490 191:491 192:492 193:492 194:492 195:492 196:492 197:493 198:494 199:494 200:494 201:494 202:495 203:495 204:495 205:495 206:495 207:496 208:497 209:498 210:499 211:500 212:501 213:502 214:503 215:504 216:505 217:505 218:505 219:505 220:506 221:506 222:506 223:507 224:507 225:508 226:509 227:509 228:509 229:509 230:510 231:511 232:512 233:513 234:513 235:514 236:515 237:516 238:517 239:518 240:519 241:520 242:521 243:521 244:521 245:522 246:523 247:523 248:523 249:523 250:524 251:524 252:525 253:526 254:527 255:527 256:528 257:528 258:529 259:530 260:531 261:532 262:532 263:532 264:533 265:534 266:535 267:536 268:537 269:538 270:539 271:539 272:540 273:541 274:542 275:543 276:543 277:543 278:543 279:544 280:544 281:545 282:545 283:546 284:547 285:548 286:549 287:550 288:551 289:552 290:552 291:553 292:554 293:555 294:556 295:557 296:558 297:559 298:560 299:561 300:561 301:562 302:563 303:563 304:563 305:563 306:564 307:564 308:564 309:564 310:564 311:565 312:565 313:565 314:565 315:565 316:565 317:566 318:567 319:568 320:569 321:570 322:571 323:572 324:573 325:574 326:574 327:574 328:574 329:575 330:576 331:576 332:577 333:578 334:578 335:578 336:578 337:579 338:580 339:581 340:582 341:582 342:582 343:583 344:584 345:585 346:586 347:587 348:588 349:588 350:589 351:589 352:589 353:590 354:591 355:592 356:593 357:594 358:594 359:594 360:595 361:595 362:596 363:597 364:597 365:598 366:599 367:599 368:599 369:599 370:599 371:599 372:600 373:600 374:601 375:602 376:602 377:602 378:603 379:604 380:605 381:606 382:607\n",
      "I1208 12:27:37.146197 139883775852736 run_factoid.py:445] token_to_orig_map: 11:375 12:375 13:376 14:376 15:377 16:378 17:379 18:380 19:381 20:381 21:381 22:382 23:383 24:384 25:385 26:386 27:386 28:387 29:388 30:389 31:390 32:390 33:391 34:392 35:392 36:392 37:392 38:392 39:392 40:392 41:392 42:393 43:394 44:395 45:396 46:397 47:397 48:397 49:397 50:397 51:398 52:399 53:400 54:401 55:402 56:403 57:403 58:403 59:404 60:405 61:406 62:407 63:408 64:409 65:410 66:411 67:411 68:411 69:411 70:412 71:413 72:413 73:413 74:413 75:413 76:414 77:414 78:415 79:416 80:417 81:418 82:419 83:419 84:419 85:420 86:421 87:422 88:423 89:424 90:425 91:426 92:427 93:428 94:429 95:430 96:430 97:430 98:431 99:432 100:433 101:434 102:435 103:436 104:437 105:437 106:438 107:439 108:439 109:440 110:441 111:441 112:441 113:441 114:442 115:443 116:444 117:445 118:445 119:445 120:446 121:447 122:448 123:449 124:450 125:451 126:452 127:453 128:453 129:453 130:453 131:454 132:455 133:455 134:456 135:457 136:458 137:459 138:460 139:460 140:460 141:460 142:461 143:462 144:463 145:464 146:465 147:466 148:466 149:466 150:466 151:466 152:466 153:467 154:468 155:469 156:469 157:469 158:470 159:471 160:472 161:472 162:472 163:472 164:473 165:473 166:473 167:473 168:474 169:475 170:476 171:477 172:478 173:478 174:478 175:479 176:480 177:481 178:481 179:481 180:481 181:482 182:483 183:484 184:485 185:486 186:486 187:487 188:488 189:489 190:490 191:491 192:492 193:492 194:492 195:492 196:492 197:493 198:494 199:494 200:494 201:494 202:495 203:495 204:495 205:495 206:495 207:496 208:497 209:498 210:499 211:500 212:501 213:502 214:503 215:504 216:505 217:505 218:505 219:505 220:506 221:506 222:506 223:507 224:507 225:508 226:509 227:509 228:509 229:509 230:510 231:511 232:512 233:513 234:513 235:514 236:515 237:516 238:517 239:518 240:519 241:520 242:521 243:521 244:521 245:522 246:523 247:523 248:523 249:523 250:524 251:524 252:525 253:526 254:527 255:527 256:528 257:528 258:529 259:530 260:531 261:532 262:532 263:532 264:533 265:534 266:535 267:536 268:537 269:538 270:539 271:539 272:540 273:541 274:542 275:543 276:543 277:543 278:543 279:544 280:544 281:545 282:545 283:546 284:547 285:548 286:549 287:550 288:551 289:552 290:552 291:553 292:554 293:555 294:556 295:557 296:558 297:559 298:560 299:561 300:561 301:562 302:563 303:563 304:563 305:563 306:564 307:564 308:564 309:564 310:564 311:565 312:565 313:565 314:565 315:565 316:565 317:566 318:567 319:568 320:569 321:570 322:571 323:572 324:573 325:574 326:574 327:574 328:574 329:575 330:576 331:576 332:577 333:578 334:578 335:578 336:578 337:579 338:580 339:581 340:582 341:582 342:582 343:583 344:584 345:585 346:586 347:587 348:588 349:588 350:589 351:589 352:589 353:590 354:591 355:592 356:593 357:594 358:594 359:594 360:595 361:595 362:596 363:597 364:597 365:598 366:599 367:599 368:599 369:599 370:599 371:599 372:600 373:600 374:601 375:602 376:602 377:602 378:603 379:604 380:605 381:606 382:607\n",
      "INFO:tensorflow:token_is_max_context: 11:False 12:False 13:False 14:False 15:False 16:False 17:False 18:False 19:False 20:False 21:False 22:False 23:False 24:False 25:False 26:False 27:False 28:False 29:False 30:False 31:False 32:False 33:False 34:False 35:False 36:False 37:False 38:False 39:False 40:False 41:False 42:False 43:False 44:False 45:False 46:False 47:False 48:False 49:False 50:False 51:False 52:False 53:False 54:False 55:False 56:False 57:False 58:False 59:False 60:False 61:False 62:False 63:False 64:False 65:False 66:False 67:False 68:False 69:False 70:False 71:False 72:False 73:False 74:False 75:False 76:False 77:False 78:False 79:False 80:False 81:False 82:False 83:False 84:False 85:False 86:False 87:False 88:False 89:False 90:False 91:False 92:False 93:False 94:False 95:False 96:False 97:False 98:False 99:False 100:False 101:False 102:False 103:False 104:False 105:False 106:False 107:False 108:False 109:False 110:False 111:False 112:False 113:False 114:False 115:False 116:False 117:False 118:False 119:False 120:False 121:False 122:False 123:False 124:False 125:False 126:False 127:False 128:False 129:False 130:False 131:False 132:False 133:True 134:True 135:True 136:True 137:True 138:True 139:True 140:True 141:True 142:True 143:True 144:True 145:True 146:True 147:True 148:True 149:True 150:True 151:True 152:True 153:True 154:True 155:True 156:True 157:True 158:True 159:True 160:True 161:True 162:True 163:True 164:True 165:True 166:True 167:True 168:True 169:True 170:True 171:True 172:True 173:True 174:True 175:True 176:True 177:True 178:True 179:True 180:True 181:True 182:True 183:True 184:True 185:True 186:True 187:True 188:True 189:True 190:True 191:True 192:True 193:True 194:True 195:True 196:True 197:True 198:True 199:True 200:True 201:True 202:True 203:True 204:True 205:True 206:True 207:True 208:True 209:True 210:True 211:True 212:True 213:True 214:True 215:True 216:True 217:True 218:True 219:True 220:True 221:True 222:True 223:True 224:True 225:True 226:True 227:True 228:True 229:True 230:True 231:True 232:True 233:True 234:True 235:True 236:True 237:True 238:True 239:True 240:True 241:True 242:True 243:True 244:True 245:True 246:True 247:True 248:True 249:True 250:True 251:True 252:True 253:True 254:True 255:True 256:True 257:True 258:True 259:True 260:True 261:False 262:False 263:False 264:False 265:False 266:False 267:False 268:False 269:False 270:False 271:False 272:False 273:False 274:False 275:False 276:False 277:False 278:False 279:False 280:False 281:False 282:False 283:False 284:False 285:False 286:False 287:False 288:False 289:False 290:False 291:False 292:False 293:False 294:False 295:False 296:False 297:False 298:False 299:False 300:False 301:False 302:False 303:False 304:False 305:False 306:False 307:False 308:False 309:False 310:False 311:False 312:False 313:False 314:False 315:False 316:False 317:False 318:False 319:False 320:False 321:False 322:False 323:False 324:False 325:False 326:False 327:False 328:False 329:False 330:False 331:False 332:False 333:False 334:False 335:False 336:False 337:False 338:False 339:False 340:False 341:False 342:False 343:False 344:False 345:False 346:False 347:False 348:False 349:False 350:False 351:False 352:False 353:False 354:False 355:False 356:False 357:False 358:False 359:False 360:False 361:False 362:False 363:False 364:False 365:False 366:False 367:False 368:False 369:False 370:False 371:False 372:False 373:False 374:False 375:False 376:False 377:False 378:False 379:False 380:False 381:False 382:False\n",
      "I1208 12:27:37.146308 139883775852736 run_factoid.py:447] token_is_max_context: 11:False 12:False 13:False 14:False 15:False 16:False 17:False 18:False 19:False 20:False 21:False 22:False 23:False 24:False 25:False 26:False 27:False 28:False 29:False 30:False 31:False 32:False 33:False 34:False 35:False 36:False 37:False 38:False 39:False 40:False 41:False 42:False 43:False 44:False 45:False 46:False 47:False 48:False 49:False 50:False 51:False 52:False 53:False 54:False 55:False 56:False 57:False 58:False 59:False 60:False 61:False 62:False 63:False 64:False 65:False 66:False 67:False 68:False 69:False 70:False 71:False 72:False 73:False 74:False 75:False 76:False 77:False 78:False 79:False 80:False 81:False 82:False 83:False 84:False 85:False 86:False 87:False 88:False 89:False 90:False 91:False 92:False 93:False 94:False 95:False 96:False 97:False 98:False 99:False 100:False 101:False 102:False 103:False 104:False 105:False 106:False 107:False 108:False 109:False 110:False 111:False 112:False 113:False 114:False 115:False 116:False 117:False 118:False 119:False 120:False 121:False 122:False 123:False 124:False 125:False 126:False 127:False 128:False 129:False 130:False 131:False 132:False 133:True 134:True 135:True 136:True 137:True 138:True 139:True 140:True 141:True 142:True 143:True 144:True 145:True 146:True 147:True 148:True 149:True 150:True 151:True 152:True 153:True 154:True 155:True 156:True 157:True 158:True 159:True 160:True 161:True 162:True 163:True 164:True 165:True 166:True 167:True 168:True 169:True 170:True 171:True 172:True 173:True 174:True 175:True 176:True 177:True 178:True 179:True 180:True 181:True 182:True 183:True 184:True 185:True 186:True 187:True 188:True 189:True 190:True 191:True 192:True 193:True 194:True 195:True 196:True 197:True 198:True 199:True 200:True 201:True 202:True 203:True 204:True 205:True 206:True 207:True 208:True 209:True 210:True 211:True 212:True 213:True 214:True 215:True 216:True 217:True 218:True 219:True 220:True 221:True 222:True 223:True 224:True 225:True 226:True 227:True 228:True 229:True 230:True 231:True 232:True 233:True 234:True 235:True 236:True 237:True 238:True 239:True 240:True 241:True 242:True 243:True 244:True 245:True 246:True 247:True 248:True 249:True 250:True 251:True 252:True 253:True 254:True 255:True 256:True 257:True 258:True 259:True 260:True 261:False 262:False 263:False 264:False 265:False 266:False 267:False 268:False 269:False 270:False 271:False 272:False 273:False 274:False 275:False 276:False 277:False 278:False 279:False 280:False 281:False 282:False 283:False 284:False 285:False 286:False 287:False 288:False 289:False 290:False 291:False 292:False 293:False 294:False 295:False 296:False 297:False 298:False 299:False 300:False 301:False 302:False 303:False 304:False 305:False 306:False 307:False 308:False 309:False 310:False 311:False 312:False 313:False 314:False 315:False 316:False 317:False 318:False 319:False 320:False 321:False 322:False 323:False 324:False 325:False 326:False 327:False 328:False 329:False 330:False 331:False 332:False 333:False 334:False 335:False 336:False 337:False 338:False 339:False 340:False 341:False 342:False 343:False 344:False 345:False 346:False 347:False 348:False 349:False 350:False 351:False 352:False 353:False 354:False 355:False 356:False 357:False 358:False 359:False 360:False 361:False 362:False 363:False 364:False 365:False 366:False 367:False 368:False 369:False 370:False 371:False 372:False 373:False 374:False 375:False 376:False 377:False 378:False 379:False 380:False 381:False 382:False\n",
      "INFO:tensorflow:input_ids: 101 2091 1103 9505 12864 1113 5351 17898 1116 136 102 5073 166 6589 117 1122 1110 3372 1111 153 21678 2137 1106 9474 1142 2463 12678 117 1105 170 1194 9455 14637 11970 113 26574 1708 118 157 2162 15499 114 1547 1129 170 1618 3026 119 164 4335 166 1109 2244 2603 1107 1103 153 21678 2137 1372 1105 1168 13467 9108 1372 1127 128 119 123 110 1105 125 119 122 110 117 3569 119 1966 4420 5165 1114 153 21678 2137 3890 170 5409 2299 2244 2603 1190 1343 1114 1168 12814 3377 117 1103 3719 1206 1172 1108 1136 2418 119 2499 17730 117 3084 2393 164 3993 166 1982 170 10260 1884 13252 1204 2025 10540 1104 2539 4776 4420 1114 149 2137 3048 119 2096 1172 117 1476 4420 1127 9315 153 21678 2137 117 1105 1476 1127 5165 1114 152 22074 119 164 3993 166 1335 1103 2812 118 1146 9355 1104 3164 7578 9524 117 5306 119 128 110 1104 4420 1107 1103 153 21678 2137 1372 1105 5429 119 124 110 1104 4420 1107 1103 152 22074 1372 3890 1363 1137 6548 2686 119 164 3993 166 1370 17599 6385 10805 4571 6187 10294 18778 1183 117 1412 1871 1145 2799 170 1861 2244 2603 1114 153 21678 2137 119 155 25131 1424 156 117 3084 2393 164 3615 166 1982 170 19916 7091 2200 2025 1106 14133 1103 7300 13950 1104 153 21678 2137 1114 17599 6385 10805 4571 5531 119 1130 1115 2025 117 4573 110 1104 4420 1114 153 21678 2137 2103 23481 10241 1112 3402 1114 5942 110 1104 4420 1114 17599 6385 10805 4571 5531 119 1438 117 1103 3719 1206 1172 1108 1136 2418 119 1130 5014 1106 1103 2211 2244 5600 1104 152 22074 1105 17599 6385 10805 4571 6187 10294 18778 1183 117 26574 1708 118 157 2162 15499 1882 1106 1138 170 2299 2244 2603 1190 153 21678 2137 119 8411 140 117 3084 2393 164 3882 166 2103 170 19916 1884 13252 1204 2025 1104 25182 4420 1114 1231 21754 149 2137 3048 1150 1127 5165 1114 153 21678 2137 113 183 134 21040 114 1137 26574 1708 118 157 2162 15499 113 183 134 18868 114 119 1335 1103 1928 9355 2812 102\n",
      "I1208 12:27:37.146412 139883775852736 run_factoid.py:449] input_ids: 101 2091 1103 9505 12864 1113 5351 17898 1116 136 102 5073 166 6589 117 1122 1110 3372 1111 153 21678 2137 1106 9474 1142 2463 12678 117 1105 170 1194 9455 14637 11970 113 26574 1708 118 157 2162 15499 114 1547 1129 170 1618 3026 119 164 4335 166 1109 2244 2603 1107 1103 153 21678 2137 1372 1105 1168 13467 9108 1372 1127 128 119 123 110 1105 125 119 122 110 117 3569 119 1966 4420 5165 1114 153 21678 2137 3890 170 5409 2299 2244 2603 1190 1343 1114 1168 12814 3377 117 1103 3719 1206 1172 1108 1136 2418 119 2499 17730 117 3084 2393 164 3993 166 1982 170 10260 1884 13252 1204 2025 10540 1104 2539 4776 4420 1114 149 2137 3048 119 2096 1172 117 1476 4420 1127 9315 153 21678 2137 117 1105 1476 1127 5165 1114 152 22074 119 164 3993 166 1335 1103 2812 118 1146 9355 1104 3164 7578 9524 117 5306 119 128 110 1104 4420 1107 1103 153 21678 2137 1372 1105 5429 119 124 110 1104 4420 1107 1103 152 22074 1372 3890 1363 1137 6548 2686 119 164 3993 166 1370 17599 6385 10805 4571 6187 10294 18778 1183 117 1412 1871 1145 2799 170 1861 2244 2603 1114 153 21678 2137 119 155 25131 1424 156 117 3084 2393 164 3615 166 1982 170 19916 7091 2200 2025 1106 14133 1103 7300 13950 1104 153 21678 2137 1114 17599 6385 10805 4571 5531 119 1130 1115 2025 117 4573 110 1104 4420 1114 153 21678 2137 2103 23481 10241 1112 3402 1114 5942 110 1104 4420 1114 17599 6385 10805 4571 5531 119 1438 117 1103 3719 1206 1172 1108 1136 2418 119 1130 5014 1106 1103 2211 2244 5600 1104 152 22074 1105 17599 6385 10805 4571 6187 10294 18778 1183 117 26574 1708 118 157 2162 15499 1882 1106 1138 170 2299 2244 2603 1190 153 21678 2137 119 8411 140 117 3084 2393 164 3882 166 2103 170 19916 1884 13252 1204 2025 1104 25182 4420 1114 1231 21754 149 2137 3048 1150 1127 5165 1114 153 21678 2137 113 183 134 21040 114 1137 26574 1708 118 157 2162 15499 113 183 134 18868 114 119 1335 1103 1928 9355 2812 102\n",
      "INFO:tensorflow:input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      "I1208 12:27:37.146504 139883775852736 run_factoid.py:451] input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      "INFO:tensorflow:segment_ids: 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      "I1208 12:27:37.146594 139883775852736 run_factoid.py:453] segment_ids: 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      "INFO:tensorflow:*** Example ***\n",
      "I1208 12:27:37.148456 139883775852736 run_factoid.py:438] *** Example ***\n",
      "INFO:tensorflow:unique_id: 1000000046\n",
      "I1208 12:27:37.148517 139883775852736 run_factoid.py:439] unique_id: 1000000046\n",
      "INFO:tensorflow:example_index: 8\n",
      "I1208 12:27:37.148555 139883775852736 run_factoid.py:440] example_index: 8\n",
      "INFO:tensorflow:doc_span_index: 6\n",
      "I1208 12:27:37.148589 139883775852736 run_factoid.py:441] doc_span_index: 6\n",
      "INFO:tensorflow:tokens: [CLS] Do the findings depend on patient demographic ##s ? [SEP] ##EL ##D , and 30 were treated with O ##LM . [ 46 ] At the follow - up duration of 36 ##mont ##hs , 96 . 7 % of patients in the P ##EL ##D group and 93 . 3 % of patients in the O ##LM group achieved good or excellent results . [ 46 ] For micro ##su ##rg ##ical disc ##ec ##tom ##y , our result also showed a similar success rate with P ##EL ##D . R ##utt ##en S , et al [ 48 ] performed a prospective random ##ized study to compare the clinical outcomes of P ##EL ##D with micro ##su ##rg ##ical technique . In that study , 95 % of patients with P ##EL ##D reported subjective satisfaction as compared with 86 % of patients with micro ##su ##rg ##ical technique . However , the difference between them was not significant . In contrast to the lower success rates of O ##LM and micro ##su ##rg ##ical disc ##ec ##tom ##y , MI ##S - T ##L ##IF seemed to have a higher success rate than P ##EL ##D . Liu C , et al [ 52 ] reported a prospective co ##hor ##t study of 401 patients with re ##current L ##D ##H who were treated with P ##EL ##D ( n = 209 ) or MI ##S - T ##L ##IF ( n = 192 ) . At the mean duration follow - up of 46 . 5 months , the success rate in the two groups was 91 . 3 % and 95 . 2 % , respectively . [ 52 ] MI ##S - T ##L ##IF resulted in a higher success rate than P ##EL ##D , however , there was no significant difference between them . Regarding the operation time , the present study demonstrated that patients treated with P ##EL ##D had 18 . 14 minutes less of operation time than those with other surgical interventions . However , the reduced operation time of P ##EL ##D was only observed in the comparison with O ##LM , MI ##S - T ##L ##IF , micro ##su ##rg ##ical disc ##ec ##tom ##y and micro ##dis [SEP]\n",
      "I1208 12:27:37.148705 139883775852736 run_factoid.py:443] tokens: [CLS] Do the findings depend on patient demographic ##s ? [SEP] ##EL ##D , and 30 were treated with O ##LM . [ 46 ] At the follow - up duration of 36 ##mont ##hs , 96 . 7 % of patients in the P ##EL ##D group and 93 . 3 % of patients in the O ##LM group achieved good or excellent results . [ 46 ] For micro ##su ##rg ##ical disc ##ec ##tom ##y , our result also showed a similar success rate with P ##EL ##D . R ##utt ##en S , et al [ 48 ] performed a prospective random ##ized study to compare the clinical outcomes of P ##EL ##D with micro ##su ##rg ##ical technique . In that study , 95 % of patients with P ##EL ##D reported subjective satisfaction as compared with 86 % of patients with micro ##su ##rg ##ical technique . However , the difference between them was not significant . In contrast to the lower success rates of O ##LM and micro ##su ##rg ##ical disc ##ec ##tom ##y , MI ##S - T ##L ##IF seemed to have a higher success rate than P ##EL ##D . Liu C , et al [ 52 ] reported a prospective co ##hor ##t study of 401 patients with re ##current L ##D ##H who were treated with P ##EL ##D ( n = 209 ) or MI ##S - T ##L ##IF ( n = 192 ) . At the mean duration follow - up of 46 . 5 months , the success rate in the two groups was 91 . 3 % and 95 . 2 % , respectively . [ 52 ] MI ##S - T ##L ##IF resulted in a higher success rate than P ##EL ##D , however , there was no significant difference between them . Regarding the operation time , the present study demonstrated that patients treated with P ##EL ##D had 18 . 14 minutes less of operation time than those with other surgical interventions . However , the reduced operation time of P ##EL ##D was only observed in the comparison with O ##LM , MI ##S - T ##L ##IF , micro ##su ##rg ##ical disc ##ec ##tom ##y and micro ##dis [SEP]\n",
      "INFO:tensorflow:token_to_orig_map: 11:460 12:460 13:460 14:461 15:462 16:463 17:464 18:465 19:466 20:466 21:466 22:466 23:466 24:466 25:467 26:468 27:469 28:469 29:469 30:470 31:471 32:472 33:472 34:472 35:472 36:473 37:473 38:473 39:473 40:474 41:475 42:476 43:477 44:478 45:478 46:478 47:479 48:480 49:481 50:481 51:481 52:481 53:482 54:483 55:484 56:485 57:486 58:486 59:487 60:488 61:489 62:490 63:491 64:492 65:492 66:492 67:492 68:492 69:493 70:494 71:494 72:494 73:494 74:495 75:495 76:495 77:495 78:495 79:496 80:497 81:498 82:499 83:500 84:501 85:502 86:503 87:504 88:505 89:505 90:505 91:505 92:506 93:506 94:506 95:507 96:507 97:508 98:509 99:509 100:509 101:509 102:510 103:511 104:512 105:513 106:513 107:514 108:515 109:516 110:517 111:518 112:519 113:520 114:521 115:521 116:521 117:522 118:523 119:523 120:523 121:523 122:524 123:524 124:525 125:526 126:527 127:527 128:528 129:528 130:529 131:530 132:531 133:532 134:532 135:532 136:533 137:534 138:535 139:536 140:537 141:538 142:539 143:539 144:540 145:541 146:542 147:543 148:543 149:543 150:543 151:544 152:544 153:545 154:545 155:546 156:547 157:548 158:549 159:550 160:551 161:552 162:552 163:553 164:554 165:555 166:556 167:557 168:558 169:559 170:560 171:561 172:561 173:562 174:563 175:563 176:563 177:563 178:564 179:564 180:564 181:564 182:564 183:565 184:565 185:565 186:565 187:565 188:565 189:566 190:567 191:568 192:569 193:570 194:571 195:572 196:573 197:574 198:574 199:574 200:574 201:575 202:576 203:576 204:577 205:578 206:578 207:578 208:578 209:579 210:580 211:581 212:582 213:582 214:582 215:583 216:584 217:585 218:586 219:587 220:588 221:588 222:589 223:589 224:589 225:590 226:591 227:592 228:593 229:594 230:594 231:594 232:595 233:595 234:596 235:597 236:597 237:598 238:599 239:599 240:599 241:599 242:599 243:599 244:600 245:600 246:601 247:602 248:602 249:602 250:603 251:604 252:605 253:606 254:607 255:607 256:607 257:608 258:609 259:609 260:609 261:610 262:610 263:611 264:612 265:613 266:614 267:615 268:616 269:617 270:618 271:619 272:619 273:619 274:619 275:620 276:621 277:621 278:621 279:621 280:621 281:622 282:622 283:622 284:622 285:622 286:623 287:623 288:623 289:623 290:623 291:623 292:624 293:625 294:626 295:627 296:628 297:629 298:630 299:631 300:631 301:631 302:631 303:632 304:632 305:633 306:634 307:635 308:636 309:637 310:638 311:639 312:639 313:640 314:641 315:642 316:643 317:643 318:644 319:645 320:646 321:647 322:648 323:649 324:650 325:651 326:652 327:652 328:652 329:653 330:654 331:654 332:654 333:655 334:656 335:657 336:658 337:659 338:660 339:661 340:662 341:663 342:664 343:665 344:665 345:666 346:666 347:667 348:668 349:669 350:670 351:671 352:672 353:672 354:672 355:673 356:674 357:675 358:676 359:677 360:678 361:679 362:680 363:680 364:680 365:681 366:681 367:681 368:681 369:681 370:681 371:681 372:682 373:682 374:682 375:682 376:683 377:683 378:683 379:683 380:684 381:685 382:685\n",
      "I1208 12:27:37.148823 139883775852736 run_factoid.py:445] token_to_orig_map: 11:460 12:460 13:460 14:461 15:462 16:463 17:464 18:465 19:466 20:466 21:466 22:466 23:466 24:466 25:467 26:468 27:469 28:469 29:469 30:470 31:471 32:472 33:472 34:472 35:472 36:473 37:473 38:473 39:473 40:474 41:475 42:476 43:477 44:478 45:478 46:478 47:479 48:480 49:481 50:481 51:481 52:481 53:482 54:483 55:484 56:485 57:486 58:486 59:487 60:488 61:489 62:490 63:491 64:492 65:492 66:492 67:492 68:492 69:493 70:494 71:494 72:494 73:494 74:495 75:495 76:495 77:495 78:495 79:496 80:497 81:498 82:499 83:500 84:501 85:502 86:503 87:504 88:505 89:505 90:505 91:505 92:506 93:506 94:506 95:507 96:507 97:508 98:509 99:509 100:509 101:509 102:510 103:511 104:512 105:513 106:513 107:514 108:515 109:516 110:517 111:518 112:519 113:520 114:521 115:521 116:521 117:522 118:523 119:523 120:523 121:523 122:524 123:524 124:525 125:526 126:527 127:527 128:528 129:528 130:529 131:530 132:531 133:532 134:532 135:532 136:533 137:534 138:535 139:536 140:537 141:538 142:539 143:539 144:540 145:541 146:542 147:543 148:543 149:543 150:543 151:544 152:544 153:545 154:545 155:546 156:547 157:548 158:549 159:550 160:551 161:552 162:552 163:553 164:554 165:555 166:556 167:557 168:558 169:559 170:560 171:561 172:561 173:562 174:563 175:563 176:563 177:563 178:564 179:564 180:564 181:564 182:564 183:565 184:565 185:565 186:565 187:565 188:565 189:566 190:567 191:568 192:569 193:570 194:571 195:572 196:573 197:574 198:574 199:574 200:574 201:575 202:576 203:576 204:577 205:578 206:578 207:578 208:578 209:579 210:580 211:581 212:582 213:582 214:582 215:583 216:584 217:585 218:586 219:587 220:588 221:588 222:589 223:589 224:589 225:590 226:591 227:592 228:593 229:594 230:594 231:594 232:595 233:595 234:596 235:597 236:597 237:598 238:599 239:599 240:599 241:599 242:599 243:599 244:600 245:600 246:601 247:602 248:602 249:602 250:603 251:604 252:605 253:606 254:607 255:607 256:607 257:608 258:609 259:609 260:609 261:610 262:610 263:611 264:612 265:613 266:614 267:615 268:616 269:617 270:618 271:619 272:619 273:619 274:619 275:620 276:621 277:621 278:621 279:621 280:621 281:622 282:622 283:622 284:622 285:622 286:623 287:623 288:623 289:623 290:623 291:623 292:624 293:625 294:626 295:627 296:628 297:629 298:630 299:631 300:631 301:631 302:631 303:632 304:632 305:633 306:634 307:635 308:636 309:637 310:638 311:639 312:639 313:640 314:641 315:642 316:643 317:643 318:644 319:645 320:646 321:647 322:648 323:649 324:650 325:651 326:652 327:652 328:652 329:653 330:654 331:654 332:654 333:655 334:656 335:657 336:658 337:659 338:660 339:661 340:662 341:663 342:664 343:665 344:665 345:666 346:666 347:667 348:668 349:669 350:670 351:671 352:672 353:672 354:672 355:673 356:674 357:675 358:676 359:677 360:678 361:679 362:680 363:680 364:680 365:681 366:681 367:681 368:681 369:681 370:681 371:681 372:682 373:682 374:682 375:682 376:683 377:683 378:683 379:683 380:684 381:685 382:685\n",
      "INFO:tensorflow:token_is_max_context: 11:False 12:False 13:False 14:False 15:False 16:False 17:False 18:False 19:False 20:False 21:False 22:False 23:False 24:False 25:False 26:False 27:False 28:False 29:False 30:False 31:False 32:False 33:False 34:False 35:False 36:False 37:False 38:False 39:False 40:False 41:False 42:False 43:False 44:False 45:False 46:False 47:False 48:False 49:False 50:False 51:False 52:False 53:False 54:False 55:False 56:False 57:False 58:False 59:False 60:False 61:False 62:False 63:False 64:False 65:False 66:False 67:False 68:False 69:False 70:False 71:False 72:False 73:False 74:False 75:False 76:False 77:False 78:False 79:False 80:False 81:False 82:False 83:False 84:False 85:False 86:False 87:False 88:False 89:False 90:False 91:False 92:False 93:False 94:False 95:False 96:False 97:False 98:False 99:False 100:False 101:False 102:False 103:False 104:False 105:False 106:False 107:False 108:False 109:False 110:False 111:False 112:False 113:False 114:False 115:False 116:False 117:False 118:False 119:False 120:False 121:False 122:False 123:False 124:False 125:False 126:False 127:False 128:False 129:False 130:False 131:False 132:False 133:True 134:True 135:True 136:True 137:True 138:True 139:True 140:True 141:True 142:True 143:True 144:True 145:True 146:True 147:True 148:True 149:True 150:True 151:True 152:True 153:True 154:True 155:True 156:True 157:True 158:True 159:True 160:True 161:True 162:True 163:True 164:True 165:True 166:True 167:True 168:True 169:True 170:True 171:True 172:True 173:True 174:True 175:True 176:True 177:True 178:True 179:True 180:True 181:True 182:True 183:True 184:True 185:True 186:True 187:True 188:True 189:True 190:True 191:True 192:True 193:True 194:True 195:True 196:True 197:True 198:True 199:True 200:True 201:True 202:True 203:True 204:True 205:True 206:True 207:True 208:True 209:True 210:True 211:True 212:True 213:True 214:True 215:True 216:True 217:True 218:True 219:True 220:True 221:True 222:True 223:True 224:True 225:True 226:True 227:True 228:True 229:True 230:True 231:True 232:True 233:True 234:True 235:True 236:True 237:True 238:True 239:True 240:True 241:True 242:True 243:True 244:True 245:True 246:True 247:True 248:True 249:True 250:True 251:True 252:True 253:True 254:True 255:True 256:True 257:True 258:True 259:True 260:True 261:False 262:False 263:False 264:False 265:False 266:False 267:False 268:False 269:False 270:False 271:False 272:False 273:False 274:False 275:False 276:False 277:False 278:False 279:False 280:False 281:False 282:False 283:False 284:False 285:False 286:False 287:False 288:False 289:False 290:False 291:False 292:False 293:False 294:False 295:False 296:False 297:False 298:False 299:False 300:False 301:False 302:False 303:False 304:False 305:False 306:False 307:False 308:False 309:False 310:False 311:False 312:False 313:False 314:False 315:False 316:False 317:False 318:False 319:False 320:False 321:False 322:False 323:False 324:False 325:False 326:False 327:False 328:False 329:False 330:False 331:False 332:False 333:False 334:False 335:False 336:False 337:False 338:False 339:False 340:False 341:False 342:False 343:False 344:False 345:False 346:False 347:False 348:False 349:False 350:False 351:False 352:False 353:False 354:False 355:False 356:False 357:False 358:False 359:False 360:False 361:False 362:False 363:False 364:False 365:False 366:False 367:False 368:False 369:False 370:False 371:False 372:False 373:False 374:False 375:False 376:False 377:False 378:False 379:False 380:False 381:False 382:False\n",
      "I1208 12:27:37.148937 139883775852736 run_factoid.py:447] token_is_max_context: 11:False 12:False 13:False 14:False 15:False 16:False 17:False 18:False 19:False 20:False 21:False 22:False 23:False 24:False 25:False 26:False 27:False 28:False 29:False 30:False 31:False 32:False 33:False 34:False 35:False 36:False 37:False 38:False 39:False 40:False 41:False 42:False 43:False 44:False 45:False 46:False 47:False 48:False 49:False 50:False 51:False 52:False 53:False 54:False 55:False 56:False 57:False 58:False 59:False 60:False 61:False 62:False 63:False 64:False 65:False 66:False 67:False 68:False 69:False 70:False 71:False 72:False 73:False 74:False 75:False 76:False 77:False 78:False 79:False 80:False 81:False 82:False 83:False 84:False 85:False 86:False 87:False 88:False 89:False 90:False 91:False 92:False 93:False 94:False 95:False 96:False 97:False 98:False 99:False 100:False 101:False 102:False 103:False 104:False 105:False 106:False 107:False 108:False 109:False 110:False 111:False 112:False 113:False 114:False 115:False 116:False 117:False 118:False 119:False 120:False 121:False 122:False 123:False 124:False 125:False 126:False 127:False 128:False 129:False 130:False 131:False 132:False 133:True 134:True 135:True 136:True 137:True 138:True 139:True 140:True 141:True 142:True 143:True 144:True 145:True 146:True 147:True 148:True 149:True 150:True 151:True 152:True 153:True 154:True 155:True 156:True 157:True 158:True 159:True 160:True 161:True 162:True 163:True 164:True 165:True 166:True 167:True 168:True 169:True 170:True 171:True 172:True 173:True 174:True 175:True 176:True 177:True 178:True 179:True 180:True 181:True 182:True 183:True 184:True 185:True 186:True 187:True 188:True 189:True 190:True 191:True 192:True 193:True 194:True 195:True 196:True 197:True 198:True 199:True 200:True 201:True 202:True 203:True 204:True 205:True 206:True 207:True 208:True 209:True 210:True 211:True 212:True 213:True 214:True 215:True 216:True 217:True 218:True 219:True 220:True 221:True 222:True 223:True 224:True 225:True 226:True 227:True 228:True 229:True 230:True 231:True 232:True 233:True 234:True 235:True 236:True 237:True 238:True 239:True 240:True 241:True 242:True 243:True 244:True 245:True 246:True 247:True 248:True 249:True 250:True 251:True 252:True 253:True 254:True 255:True 256:True 257:True 258:True 259:True 260:True 261:False 262:False 263:False 264:False 265:False 266:False 267:False 268:False 269:False 270:False 271:False 272:False 273:False 274:False 275:False 276:False 277:False 278:False 279:False 280:False 281:False 282:False 283:False 284:False 285:False 286:False 287:False 288:False 289:False 290:False 291:False 292:False 293:False 294:False 295:False 296:False 297:False 298:False 299:False 300:False 301:False 302:False 303:False 304:False 305:False 306:False 307:False 308:False 309:False 310:False 311:False 312:False 313:False 314:False 315:False 316:False 317:False 318:False 319:False 320:False 321:False 322:False 323:False 324:False 325:False 326:False 327:False 328:False 329:False 330:False 331:False 332:False 333:False 334:False 335:False 336:False 337:False 338:False 339:False 340:False 341:False 342:False 343:False 344:False 345:False 346:False 347:False 348:False 349:False 350:False 351:False 352:False 353:False 354:False 355:False 356:False 357:False 358:False 359:False 360:False 361:False 362:False 363:False 364:False 365:False 366:False 367:False 368:False 369:False 370:False 371:False 372:False 373:False 374:False 375:False 376:False 377:False 378:False 379:False 380:False 381:False 382:False\n",
      "INFO:tensorflow:input_ids: 101 2091 1103 9505 12864 1113 5351 17898 1116 136 102 21678 2137 117 1105 1476 1127 5165 1114 152 22074 119 164 3993 166 1335 1103 2812 118 1146 9355 1104 3164 7578 9524 117 5306 119 128 110 1104 4420 1107 1103 153 21678 2137 1372 1105 5429 119 124 110 1104 4420 1107 1103 152 22074 1372 3890 1363 1137 6548 2686 119 164 3993 166 1370 17599 6385 10805 4571 6187 10294 18778 1183 117 1412 1871 1145 2799 170 1861 2244 2603 1114 153 21678 2137 119 155 25131 1424 156 117 3084 2393 164 3615 166 1982 170 19916 7091 2200 2025 1106 14133 1103 7300 13950 1104 153 21678 2137 1114 17599 6385 10805 4571 5531 119 1130 1115 2025 117 4573 110 1104 4420 1114 153 21678 2137 2103 23481 10241 1112 3402 1114 5942 110 1104 4420 1114 17599 6385 10805 4571 5531 119 1438 117 1103 3719 1206 1172 1108 1136 2418 119 1130 5014 1106 1103 2211 2244 5600 1104 152 22074 1105 17599 6385 10805 4571 6187 10294 18778 1183 117 26574 1708 118 157 2162 15499 1882 1106 1138 170 2299 2244 2603 1190 153 21678 2137 119 8411 140 117 3084 2393 164 3882 166 2103 170 19916 1884 13252 1204 2025 1104 25182 4420 1114 1231 21754 149 2137 3048 1150 1127 5165 1114 153 21678 2137 113 183 134 21040 114 1137 26574 1708 118 157 2162 15499 113 183 134 18868 114 119 1335 1103 1928 9355 2812 118 1146 1104 3993 119 126 1808 117 1103 2244 2603 1107 1103 1160 2114 1108 5539 119 124 110 1105 4573 119 123 110 117 3569 119 164 3882 166 26574 1708 118 157 2162 15499 3657 1107 170 2299 2244 2603 1190 153 21678 2137 117 1649 117 1175 1108 1185 2418 3719 1206 1172 119 23840 1103 2805 1159 117 1103 1675 2025 7160 1115 4420 5165 1114 153 21678 2137 1125 1407 119 1489 1904 1750 1104 2805 1159 1190 1343 1114 1168 13467 22496 119 1438 117 1103 3549 2805 1159 1104 153 21678 2137 1108 1178 4379 1107 1103 7577 1114 152 22074 117 26574 1708 118 157 2162 15499 117 17599 6385 10805 4571 6187 10294 18778 1183 1105 17599 10396 102\n",
      "I1208 12:27:37.149039 139883775852736 run_factoid.py:449] input_ids: 101 2091 1103 9505 12864 1113 5351 17898 1116 136 102 21678 2137 117 1105 1476 1127 5165 1114 152 22074 119 164 3993 166 1335 1103 2812 118 1146 9355 1104 3164 7578 9524 117 5306 119 128 110 1104 4420 1107 1103 153 21678 2137 1372 1105 5429 119 124 110 1104 4420 1107 1103 152 22074 1372 3890 1363 1137 6548 2686 119 164 3993 166 1370 17599 6385 10805 4571 6187 10294 18778 1183 117 1412 1871 1145 2799 170 1861 2244 2603 1114 153 21678 2137 119 155 25131 1424 156 117 3084 2393 164 3615 166 1982 170 19916 7091 2200 2025 1106 14133 1103 7300 13950 1104 153 21678 2137 1114 17599 6385 10805 4571 5531 119 1130 1115 2025 117 4573 110 1104 4420 1114 153 21678 2137 2103 23481 10241 1112 3402 1114 5942 110 1104 4420 1114 17599 6385 10805 4571 5531 119 1438 117 1103 3719 1206 1172 1108 1136 2418 119 1130 5014 1106 1103 2211 2244 5600 1104 152 22074 1105 17599 6385 10805 4571 6187 10294 18778 1183 117 26574 1708 118 157 2162 15499 1882 1106 1138 170 2299 2244 2603 1190 153 21678 2137 119 8411 140 117 3084 2393 164 3882 166 2103 170 19916 1884 13252 1204 2025 1104 25182 4420 1114 1231 21754 149 2137 3048 1150 1127 5165 1114 153 21678 2137 113 183 134 21040 114 1137 26574 1708 118 157 2162 15499 113 183 134 18868 114 119 1335 1103 1928 9355 2812 118 1146 1104 3993 119 126 1808 117 1103 2244 2603 1107 1103 1160 2114 1108 5539 119 124 110 1105 4573 119 123 110 117 3569 119 164 3882 166 26574 1708 118 157 2162 15499 3657 1107 170 2299 2244 2603 1190 153 21678 2137 117 1649 117 1175 1108 1185 2418 3719 1206 1172 119 23840 1103 2805 1159 117 1103 1675 2025 7160 1115 4420 5165 1114 153 21678 2137 1125 1407 119 1489 1904 1750 1104 2805 1159 1190 1343 1114 1168 13467 22496 119 1438 117 1103 3549 2805 1159 1104 153 21678 2137 1108 1178 4379 1107 1103 7577 1114 152 22074 117 26574 1708 118 157 2162 15499 117 17599 6385 10805 4571 6187 10294 18778 1183 1105 17599 10396 102\n",
      "INFO:tensorflow:input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      "I1208 12:27:37.149130 139883775852736 run_factoid.py:451] input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      "INFO:tensorflow:segment_ids: 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      "I1208 12:27:37.149219 139883775852736 run_factoid.py:453] segment_ids: 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      "INFO:tensorflow:*** Example ***\n",
      "I1208 12:27:37.151022 139883775852736 run_factoid.py:438] *** Example ***\n",
      "INFO:tensorflow:unique_id: 1000000047\n",
      "I1208 12:27:37.151082 139883775852736 run_factoid.py:439] unique_id: 1000000047\n",
      "INFO:tensorflow:example_index: 8\n",
      "I1208 12:27:37.151120 139883775852736 run_factoid.py:440] example_index: 8\n",
      "INFO:tensorflow:doc_span_index: 7\n",
      "I1208 12:27:37.151154 139883775852736 run_factoid.py:441] doc_span_index: 7\n",
      "INFO:tensorflow:tokens: [CLS] Do the findings depend on patient demographic ##s ? [SEP] as compared with 86 % of patients with micro ##su ##rg ##ical technique . However , the difference between them was not significant . In contrast to the lower success rates of O ##LM and micro ##su ##rg ##ical disc ##ec ##tom ##y , MI ##S - T ##L ##IF seemed to have a higher success rate than P ##EL ##D . Liu C , et al [ 52 ] reported a prospective co ##hor ##t study of 401 patients with re ##current L ##D ##H who were treated with P ##EL ##D ( n = 209 ) or MI ##S - T ##L ##IF ( n = 192 ) . At the mean duration follow - up of 46 . 5 months , the success rate in the two groups was 91 . 3 % and 95 . 2 % , respectively . [ 52 ] MI ##S - T ##L ##IF resulted in a higher success rate than P ##EL ##D , however , there was no significant difference between them . Regarding the operation time , the present study demonstrated that patients treated with P ##EL ##D had 18 . 14 minutes less of operation time than those with other surgical interventions . However , the reduced operation time of P ##EL ##D was only observed in the comparison with O ##LM , MI ##S - T ##L ##IF , micro ##su ##rg ##ical disc ##ec ##tom ##y and micro ##dis ##ce ##ct ##omy . Compared with these surgical approaches , P ##EL ##D had 11 . 66 minutes , 75 . 23 minutes , 23 . 21 minutes , and 17 minutes less of operation time , respectively . Kim M ##J , et al . [ 44 ] compared the clinical outcomes of P ##EL ##D with O ##LM , and they found the operation time in these two groups was 53 . 0 ± 13 . 0 minutes and 64 . 6 ± 28 . 7 minutes , respectively ( P < 0 . 00 ##1 ) . Yao Y , et al . [ 45 ] assessed the three minimal ##ly invasive spine surgical approaches ( P ##EL ##D , MI ##S - T ##L [SEP]\n",
      "I1208 12:27:37.151268 139883775852736 run_factoid.py:443] tokens: [CLS] Do the findings depend on patient demographic ##s ? [SEP] as compared with 86 % of patients with micro ##su ##rg ##ical technique . However , the difference between them was not significant . In contrast to the lower success rates of O ##LM and micro ##su ##rg ##ical disc ##ec ##tom ##y , MI ##S - T ##L ##IF seemed to have a higher success rate than P ##EL ##D . Liu C , et al [ 52 ] reported a prospective co ##hor ##t study of 401 patients with re ##current L ##D ##H who were treated with P ##EL ##D ( n = 209 ) or MI ##S - T ##L ##IF ( n = 192 ) . At the mean duration follow - up of 46 . 5 months , the success rate in the two groups was 91 . 3 % and 95 . 2 % , respectively . [ 52 ] MI ##S - T ##L ##IF resulted in a higher success rate than P ##EL ##D , however , there was no significant difference between them . Regarding the operation time , the present study demonstrated that patients treated with P ##EL ##D had 18 . 14 minutes less of operation time than those with other surgical interventions . However , the reduced operation time of P ##EL ##D was only observed in the comparison with O ##LM , MI ##S - T ##L ##IF , micro ##su ##rg ##ical disc ##ec ##tom ##y and micro ##dis ##ce ##ct ##omy . Compared with these surgical approaches , P ##EL ##D had 11 . 66 minutes , 75 . 23 minutes , 23 . 21 minutes , and 17 minutes less of operation time , respectively . Kim M ##J , et al . [ 44 ] compared the clinical outcomes of P ##EL ##D with O ##LM , and they found the operation time in these two groups was 53 . 0 ± 13 . 0 minutes and 64 . 6 ± 28 . 7 minutes , respectively ( P < 0 . 00 ##1 ) . Yao Y , et al . [ 45 ] assessed the three minimal ##ly invasive spine surgical approaches ( P ##EL ##D , MI ##S - T ##L [SEP]\n",
      "INFO:tensorflow:token_to_orig_map: 11:536 12:537 13:538 14:539 15:539 16:540 17:541 18:542 19:543 20:543 21:543 22:543 23:544 24:544 25:545 26:545 27:546 28:547 29:548 30:549 31:550 32:551 33:552 34:552 35:553 36:554 37:555 38:556 39:557 40:558 41:559 42:560 43:561 44:561 45:562 46:563 47:563 48:563 49:563 50:564 51:564 52:564 53:564 54:564 55:565 56:565 57:565 58:565 59:565 60:565 61:566 62:567 63:568 64:569 65:570 66:571 67:572 68:573 69:574 70:574 71:574 72:574 73:575 74:576 75:576 76:577 77:578 78:578 79:578 80:578 81:579 82:580 83:581 84:582 85:582 86:582 87:583 88:584 89:585 90:586 91:587 92:588 93:588 94:589 95:589 96:589 97:590 98:591 99:592 100:593 101:594 102:594 103:594 104:595 105:595 106:596 107:597 108:597 109:598 110:599 111:599 112:599 113:599 114:599 115:599 116:600 117:600 118:601 119:602 120:602 121:602 122:603 123:604 124:605 125:606 126:607 127:607 128:607 129:608 130:609 131:609 132:609 133:610 134:610 135:611 136:612 137:613 138:614 139:615 140:616 141:617 142:618 143:619 144:619 145:619 146:619 147:620 148:621 149:621 150:621 151:621 152:621 153:622 154:622 155:622 156:622 157:622 158:623 159:623 160:623 161:623 162:623 163:623 164:624 165:625 166:626 167:627 168:628 169:629 170:630 171:631 172:631 173:631 174:631 175:632 176:632 177:633 178:634 179:635 180:636 181:637 182:638 183:639 184:639 185:640 186:641 187:642 188:643 189:643 190:644 191:645 192:646 193:647 194:648 195:649 196:650 197:651 198:652 199:652 200:652 201:653 202:654 203:654 204:654 205:655 206:656 207:657 208:658 209:659 210:660 211:661 212:662 213:663 214:664 215:665 216:665 217:666 218:666 219:667 220:668 221:669 222:670 223:671 224:672 225:672 226:672 227:673 228:674 229:675 230:676 231:677 232:678 233:679 234:680 235:680 236:680 237:681 238:681 239:681 240:681 241:681 242:681 243:681 244:682 245:682 246:682 247:682 248:683 249:683 250:683 251:683 252:684 253:685 254:685 255:685 256:685 257:685 258:685 259:686 260:687 261:688 262:689 263:690 264:690 265:691 266:691 267:691 268:692 269:693 270:693 271:693 272:694 273:694 274:695 275:695 276:695 277:696 278:696 279:697 280:697 281:697 282:698 283:698 284:699 285:700 286:701 287:702 288:703 289:704 290:705 291:705 292:706 293:706 294:707 295:708 296:708 297:708 298:709 299:710 300:710 301:710 302:710 303:710 304:711 305:712 306:713 307:714 308:715 309:716 310:716 311:716 312:717 313:718 314:718 315:718 316:719 317:720 318:721 319:722 320:723 321:724 322:725 323:726 324:727 325:728 326:729 327:730 328:730 329:730 330:731 331:732 332:732 333:732 334:733 335:734 336:735 337:735 338:735 339:736 340:737 341:737 342:737 343:738 344:738 345:739 346:740 347:740 348:741 349:742 350:742 351:742 352:742 353:742 354:742 355:743 356:744 357:744 358:745 359:746 360:746 361:746 362:746 363:746 364:747 365:748 366:749 367:750 368:750 369:751 370:752 371:753 372:754 373:755 374:755 375:755 376:755 377:755 378:756 379:756 380:756 381:756 382:756\n",
      "I1208 12:27:37.151397 139883775852736 run_factoid.py:445] token_to_orig_map: 11:536 12:537 13:538 14:539 15:539 16:540 17:541 18:542 19:543 20:543 21:543 22:543 23:544 24:544 25:545 26:545 27:546 28:547 29:548 30:549 31:550 32:551 33:552 34:552 35:553 36:554 37:555 38:556 39:557 40:558 41:559 42:560 43:561 44:561 45:562 46:563 47:563 48:563 49:563 50:564 51:564 52:564 53:564 54:564 55:565 56:565 57:565 58:565 59:565 60:565 61:566 62:567 63:568 64:569 65:570 66:571 67:572 68:573 69:574 70:574 71:574 72:574 73:575 74:576 75:576 76:577 77:578 78:578 79:578 80:578 81:579 82:580 83:581 84:582 85:582 86:582 87:583 88:584 89:585 90:586 91:587 92:588 93:588 94:589 95:589 96:589 97:590 98:591 99:592 100:593 101:594 102:594 103:594 104:595 105:595 106:596 107:597 108:597 109:598 110:599 111:599 112:599 113:599 114:599 115:599 116:600 117:600 118:601 119:602 120:602 121:602 122:603 123:604 124:605 125:606 126:607 127:607 128:607 129:608 130:609 131:609 132:609 133:610 134:610 135:611 136:612 137:613 138:614 139:615 140:616 141:617 142:618 143:619 144:619 145:619 146:619 147:620 148:621 149:621 150:621 151:621 152:621 153:622 154:622 155:622 156:622 157:622 158:623 159:623 160:623 161:623 162:623 163:623 164:624 165:625 166:626 167:627 168:628 169:629 170:630 171:631 172:631 173:631 174:631 175:632 176:632 177:633 178:634 179:635 180:636 181:637 182:638 183:639 184:639 185:640 186:641 187:642 188:643 189:643 190:644 191:645 192:646 193:647 194:648 195:649 196:650 197:651 198:652 199:652 200:652 201:653 202:654 203:654 204:654 205:655 206:656 207:657 208:658 209:659 210:660 211:661 212:662 213:663 214:664 215:665 216:665 217:666 218:666 219:667 220:668 221:669 222:670 223:671 224:672 225:672 226:672 227:673 228:674 229:675 230:676 231:677 232:678 233:679 234:680 235:680 236:680 237:681 238:681 239:681 240:681 241:681 242:681 243:681 244:682 245:682 246:682 247:682 248:683 249:683 250:683 251:683 252:684 253:685 254:685 255:685 256:685 257:685 258:685 259:686 260:687 261:688 262:689 263:690 264:690 265:691 266:691 267:691 268:692 269:693 270:693 271:693 272:694 273:694 274:695 275:695 276:695 277:696 278:696 279:697 280:697 281:697 282:698 283:698 284:699 285:700 286:701 287:702 288:703 289:704 290:705 291:705 292:706 293:706 294:707 295:708 296:708 297:708 298:709 299:710 300:710 301:710 302:710 303:710 304:711 305:712 306:713 307:714 308:715 309:716 310:716 311:716 312:717 313:718 314:718 315:718 316:719 317:720 318:721 319:722 320:723 321:724 322:725 323:726 324:727 325:728 326:729 327:730 328:730 329:730 330:731 331:732 332:732 333:732 334:733 335:734 336:735 337:735 338:735 339:736 340:737 341:737 342:737 343:738 344:738 345:739 346:740 347:740 348:741 349:742 350:742 351:742 352:742 353:742 354:742 355:743 356:744 357:744 358:745 359:746 360:746 361:746 362:746 363:746 364:747 365:748 366:749 367:750 368:750 369:751 370:752 371:753 372:754 373:755 374:755 375:755 376:755 377:755 378:756 379:756 380:756 381:756 382:756\n",
      "INFO:tensorflow:token_is_max_context: 11:False 12:False 13:False 14:False 15:False 16:False 17:False 18:False 19:False 20:False 21:False 22:False 23:False 24:False 25:False 26:False 27:False 28:False 29:False 30:False 31:False 32:False 33:False 34:False 35:False 36:False 37:False 38:False 39:False 40:False 41:False 42:False 43:False 44:False 45:False 46:False 47:False 48:False 49:False 50:False 51:False 52:False 53:False 54:False 55:False 56:False 57:False 58:False 59:False 60:False 61:False 62:False 63:False 64:False 65:False 66:False 67:False 68:False 69:False 70:False 71:False 72:False 73:False 74:False 75:False 76:False 77:False 78:False 79:False 80:False 81:False 82:False 83:False 84:False 85:False 86:False 87:False 88:False 89:False 90:False 91:False 92:False 93:False 94:False 95:False 96:False 97:False 98:False 99:False 100:False 101:False 102:False 103:False 104:False 105:False 106:False 107:False 108:False 109:False 110:False 111:False 112:False 113:False 114:False 115:False 116:False 117:False 118:False 119:False 120:False 121:False 122:False 123:False 124:False 125:False 126:False 127:False 128:False 129:False 130:False 131:False 132:False 133:True 134:True 135:True 136:True 137:True 138:True 139:True 140:True 141:True 142:True 143:True 144:True 145:True 146:True 147:True 148:True 149:True 150:True 151:True 152:True 153:True 154:True 155:True 156:True 157:True 158:True 159:True 160:True 161:True 162:True 163:True 164:True 165:True 166:True 167:True 168:True 169:True 170:True 171:True 172:True 173:True 174:True 175:True 176:True 177:True 178:True 179:True 180:True 181:True 182:True 183:True 184:True 185:True 186:True 187:True 188:True 189:True 190:True 191:True 192:True 193:True 194:True 195:True 196:True 197:True 198:True 199:True 200:True 201:True 202:True 203:True 204:True 205:True 206:True 207:True 208:True 209:True 210:True 211:True 212:True 213:True 214:True 215:True 216:True 217:True 218:True 219:True 220:True 221:True 222:True 223:True 224:True 225:True 226:True 227:True 228:True 229:True 230:True 231:True 232:True 233:True 234:True 235:True 236:True 237:True 238:True 239:True 240:True 241:True 242:True 243:True 244:True 245:True 246:True 247:True 248:True 249:True 250:True 251:True 252:True 253:True 254:True 255:True 256:True 257:True 258:True 259:True 260:True 261:False 262:False 263:False 264:False 265:False 266:False 267:False 268:False 269:False 270:False 271:False 272:False 273:False 274:False 275:False 276:False 277:False 278:False 279:False 280:False 281:False 282:False 283:False 284:False 285:False 286:False 287:False 288:False 289:False 290:False 291:False 292:False 293:False 294:False 295:False 296:False 297:False 298:False 299:False 300:False 301:False 302:False 303:False 304:False 305:False 306:False 307:False 308:False 309:False 310:False 311:False 312:False 313:False 314:False 315:False 316:False 317:False 318:False 319:False 320:False 321:False 322:False 323:False 324:False 325:False 326:False 327:False 328:False 329:False 330:False 331:False 332:False 333:False 334:False 335:False 336:False 337:False 338:False 339:False 340:False 341:False 342:False 343:False 344:False 345:False 346:False 347:False 348:False 349:False 350:False 351:False 352:False 353:False 354:False 355:False 356:False 357:False 358:False 359:False 360:False 361:False 362:False 363:False 364:False 365:False 366:False 367:False 368:False 369:False 370:False 371:False 372:False 373:False 374:False 375:False 376:False 377:False 378:False 379:False 380:False 381:False 382:False\n",
      "I1208 12:27:37.151512 139883775852736 run_factoid.py:447] token_is_max_context: 11:False 12:False 13:False 14:False 15:False 16:False 17:False 18:False 19:False 20:False 21:False 22:False 23:False 24:False 25:False 26:False 27:False 28:False 29:False 30:False 31:False 32:False 33:False 34:False 35:False 36:False 37:False 38:False 39:False 40:False 41:False 42:False 43:False 44:False 45:False 46:False 47:False 48:False 49:False 50:False 51:False 52:False 53:False 54:False 55:False 56:False 57:False 58:False 59:False 60:False 61:False 62:False 63:False 64:False 65:False 66:False 67:False 68:False 69:False 70:False 71:False 72:False 73:False 74:False 75:False 76:False 77:False 78:False 79:False 80:False 81:False 82:False 83:False 84:False 85:False 86:False 87:False 88:False 89:False 90:False 91:False 92:False 93:False 94:False 95:False 96:False 97:False 98:False 99:False 100:False 101:False 102:False 103:False 104:False 105:False 106:False 107:False 108:False 109:False 110:False 111:False 112:False 113:False 114:False 115:False 116:False 117:False 118:False 119:False 120:False 121:False 122:False 123:False 124:False 125:False 126:False 127:False 128:False 129:False 130:False 131:False 132:False 133:True 134:True 135:True 136:True 137:True 138:True 139:True 140:True 141:True 142:True 143:True 144:True 145:True 146:True 147:True 148:True 149:True 150:True 151:True 152:True 153:True 154:True 155:True 156:True 157:True 158:True 159:True 160:True 161:True 162:True 163:True 164:True 165:True 166:True 167:True 168:True 169:True 170:True 171:True 172:True 173:True 174:True 175:True 176:True 177:True 178:True 179:True 180:True 181:True 182:True 183:True 184:True 185:True 186:True 187:True 188:True 189:True 190:True 191:True 192:True 193:True 194:True 195:True 196:True 197:True 198:True 199:True 200:True 201:True 202:True 203:True 204:True 205:True 206:True 207:True 208:True 209:True 210:True 211:True 212:True 213:True 214:True 215:True 216:True 217:True 218:True 219:True 220:True 221:True 222:True 223:True 224:True 225:True 226:True 227:True 228:True 229:True 230:True 231:True 232:True 233:True 234:True 235:True 236:True 237:True 238:True 239:True 240:True 241:True 242:True 243:True 244:True 245:True 246:True 247:True 248:True 249:True 250:True 251:True 252:True 253:True 254:True 255:True 256:True 257:True 258:True 259:True 260:True 261:False 262:False 263:False 264:False 265:False 266:False 267:False 268:False 269:False 270:False 271:False 272:False 273:False 274:False 275:False 276:False 277:False 278:False 279:False 280:False 281:False 282:False 283:False 284:False 285:False 286:False 287:False 288:False 289:False 290:False 291:False 292:False 293:False 294:False 295:False 296:False 297:False 298:False 299:False 300:False 301:False 302:False 303:False 304:False 305:False 306:False 307:False 308:False 309:False 310:False 311:False 312:False 313:False 314:False 315:False 316:False 317:False 318:False 319:False 320:False 321:False 322:False 323:False 324:False 325:False 326:False 327:False 328:False 329:False 330:False 331:False 332:False 333:False 334:False 335:False 336:False 337:False 338:False 339:False 340:False 341:False 342:False 343:False 344:False 345:False 346:False 347:False 348:False 349:False 350:False 351:False 352:False 353:False 354:False 355:False 356:False 357:False 358:False 359:False 360:False 361:False 362:False 363:False 364:False 365:False 366:False 367:False 368:False 369:False 370:False 371:False 372:False 373:False 374:False 375:False 376:False 377:False 378:False 379:False 380:False 381:False 382:False\n",
      "INFO:tensorflow:input_ids: 101 2091 1103 9505 12864 1113 5351 17898 1116 136 102 1112 3402 1114 5942 110 1104 4420 1114 17599 6385 10805 4571 5531 119 1438 117 1103 3719 1206 1172 1108 1136 2418 119 1130 5014 1106 1103 2211 2244 5600 1104 152 22074 1105 17599 6385 10805 4571 6187 10294 18778 1183 117 26574 1708 118 157 2162 15499 1882 1106 1138 170 2299 2244 2603 1190 153 21678 2137 119 8411 140 117 3084 2393 164 3882 166 2103 170 19916 1884 13252 1204 2025 1104 25182 4420 1114 1231 21754 149 2137 3048 1150 1127 5165 1114 153 21678 2137 113 183 134 21040 114 1137 26574 1708 118 157 2162 15499 113 183 134 18868 114 119 1335 1103 1928 9355 2812 118 1146 1104 3993 119 126 1808 117 1103 2244 2603 1107 1103 1160 2114 1108 5539 119 124 110 1105 4573 119 123 110 117 3569 119 164 3882 166 26574 1708 118 157 2162 15499 3657 1107 170 2299 2244 2603 1190 153 21678 2137 117 1649 117 1175 1108 1185 2418 3719 1206 1172 119 23840 1103 2805 1159 117 1103 1675 2025 7160 1115 4420 5165 1114 153 21678 2137 1125 1407 119 1489 1904 1750 1104 2805 1159 1190 1343 1114 1168 13467 22496 119 1438 117 1103 3549 2805 1159 1104 153 21678 2137 1108 1178 4379 1107 1103 7577 1114 152 22074 117 26574 1708 118 157 2162 15499 117 17599 6385 10805 4571 6187 10294 18778 1183 1105 17599 10396 2093 5822 18574 119 22439 1114 1292 13467 8015 117 153 21678 2137 1125 1429 119 5046 1904 117 3453 119 1695 1904 117 1695 119 1626 1904 117 1105 1542 1904 1750 1104 2805 1159 117 3569 119 4246 150 4538 117 3084 2393 119 164 3140 166 3402 1103 7300 13950 1104 153 21678 2137 1114 152 22074 117 1105 1152 1276 1103 2805 1159 1107 1292 1160 2114 1108 4389 119 121 212 1492 119 121 1904 1105 3324 119 127 212 1743 119 128 1904 117 3569 113 153 133 121 119 3135 1475 114 119 27762 162 117 3084 2393 119 164 2532 166 14758 1103 1210 10298 1193 19849 8340 13467 8015 113 153 21678 2137 117 26574 1708 118 157 2162 102\n",
      "I1208 12:27:37.151617 139883775852736 run_factoid.py:449] input_ids: 101 2091 1103 9505 12864 1113 5351 17898 1116 136 102 1112 3402 1114 5942 110 1104 4420 1114 17599 6385 10805 4571 5531 119 1438 117 1103 3719 1206 1172 1108 1136 2418 119 1130 5014 1106 1103 2211 2244 5600 1104 152 22074 1105 17599 6385 10805 4571 6187 10294 18778 1183 117 26574 1708 118 157 2162 15499 1882 1106 1138 170 2299 2244 2603 1190 153 21678 2137 119 8411 140 117 3084 2393 164 3882 166 2103 170 19916 1884 13252 1204 2025 1104 25182 4420 1114 1231 21754 149 2137 3048 1150 1127 5165 1114 153 21678 2137 113 183 134 21040 114 1137 26574 1708 118 157 2162 15499 113 183 134 18868 114 119 1335 1103 1928 9355 2812 118 1146 1104 3993 119 126 1808 117 1103 2244 2603 1107 1103 1160 2114 1108 5539 119 124 110 1105 4573 119 123 110 117 3569 119 164 3882 166 26574 1708 118 157 2162 15499 3657 1107 170 2299 2244 2603 1190 153 21678 2137 117 1649 117 1175 1108 1185 2418 3719 1206 1172 119 23840 1103 2805 1159 117 1103 1675 2025 7160 1115 4420 5165 1114 153 21678 2137 1125 1407 119 1489 1904 1750 1104 2805 1159 1190 1343 1114 1168 13467 22496 119 1438 117 1103 3549 2805 1159 1104 153 21678 2137 1108 1178 4379 1107 1103 7577 1114 152 22074 117 26574 1708 118 157 2162 15499 117 17599 6385 10805 4571 6187 10294 18778 1183 1105 17599 10396 2093 5822 18574 119 22439 1114 1292 13467 8015 117 153 21678 2137 1125 1429 119 5046 1904 117 3453 119 1695 1904 117 1695 119 1626 1904 117 1105 1542 1904 1750 1104 2805 1159 117 3569 119 4246 150 4538 117 3084 2393 119 164 3140 166 3402 1103 7300 13950 1104 153 21678 2137 1114 152 22074 117 1105 1152 1276 1103 2805 1159 1107 1292 1160 2114 1108 4389 119 121 212 1492 119 121 1904 1105 3324 119 127 212 1743 119 128 1904 117 3569 113 153 133 121 119 3135 1475 114 119 27762 162 117 3084 2393 119 164 2532 166 14758 1103 1210 10298 1193 19849 8340 13467 8015 113 153 21678 2137 117 26574 1708 118 157 2162 102\n",
      "INFO:tensorflow:input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      "I1208 12:27:37.151709 139883775852736 run_factoid.py:451] input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      "INFO:tensorflow:segment_ids: 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      "I1208 12:27:37.151798 139883775852736 run_factoid.py:453] segment_ids: 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      "INFO:tensorflow:*** Example ***\n",
      "I1208 12:27:37.153650 139883775852736 run_factoid.py:438] *** Example ***\n",
      "INFO:tensorflow:unique_id: 1000000048\n",
      "I1208 12:27:37.153712 139883775852736 run_factoid.py:439] unique_id: 1000000048\n",
      "INFO:tensorflow:example_index: 8\n",
      "I1208 12:27:37.153750 139883775852736 run_factoid.py:440] example_index: 8\n",
      "INFO:tensorflow:doc_span_index: 8\n",
      "I1208 12:27:37.153784 139883775852736 run_factoid.py:441] doc_span_index: 8\n",
      "INFO:tensorflow:tokens: [CLS] Do the findings depend on patient demographic ##s ? [SEP] the two groups was 91 . 3 % and 95 . 2 % , respectively . [ 52 ] MI ##S - T ##L ##IF resulted in a higher success rate than P ##EL ##D , however , there was no significant difference between them . Regarding the operation time , the present study demonstrated that patients treated with P ##EL ##D had 18 . 14 minutes less of operation time than those with other surgical interventions . However , the reduced operation time of P ##EL ##D was only observed in the comparison with O ##LM , MI ##S - T ##L ##IF , micro ##su ##rg ##ical disc ##ec ##tom ##y and micro ##dis ##ce ##ct ##omy . Compared with these surgical approaches , P ##EL ##D had 11 . 66 minutes , 75 . 23 minutes , 23 . 21 minutes , and 17 minutes less of operation time , respectively . Kim M ##J , et al . [ 44 ] compared the clinical outcomes of P ##EL ##D with O ##LM , and they found the operation time in these two groups was 53 . 0 ± 13 . 0 minutes and 64 . 6 ± 28 . 7 minutes , respectively ( P < 0 . 00 ##1 ) . Yao Y , et al . [ 45 ] assessed the three minimal ##ly invasive spine surgical approaches ( P ##EL ##D , MI ##S - T ##L ##IF , and ME ##D ) for re ##current her ##nia ##tion , and the mean operation time between them was 75 . 0 ± 31 . 56 minutes , 146 . 54 ± 38 . 07 minutes , and 85 . 25 ± 41 . 60 minutes , respectively . P ##EL ##D had a significantly less operation time than MI ##S - T ##L ##IF , but a comparable operation time with ME ##D . The functional outcomes were assessed by the VA ##S scores for back pain and leg pain . Our results suggested that patients treated with P ##EL ##D had comparable post ##oper ##ation VA ##S scores for back pain and leg pain with those treated with other surge ##ries . Our result [SEP]\n",
      "I1208 12:27:37.153898 139883775852736 run_factoid.py:443] tokens: [CLS] Do the findings depend on patient demographic ##s ? [SEP] the two groups was 91 . 3 % and 95 . 2 % , respectively . [ 52 ] MI ##S - T ##L ##IF resulted in a higher success rate than P ##EL ##D , however , there was no significant difference between them . Regarding the operation time , the present study demonstrated that patients treated with P ##EL ##D had 18 . 14 minutes less of operation time than those with other surgical interventions . However , the reduced operation time of P ##EL ##D was only observed in the comparison with O ##LM , MI ##S - T ##L ##IF , micro ##su ##rg ##ical disc ##ec ##tom ##y and micro ##dis ##ce ##ct ##omy . Compared with these surgical approaches , P ##EL ##D had 11 . 66 minutes , 75 . 23 minutes , 23 . 21 minutes , and 17 minutes less of operation time , respectively . Kim M ##J , et al . [ 44 ] compared the clinical outcomes of P ##EL ##D with O ##LM , and they found the operation time in these two groups was 53 . 0 ± 13 . 0 minutes and 64 . 6 ± 28 . 7 minutes , respectively ( P < 0 . 00 ##1 ) . Yao Y , et al . [ 45 ] assessed the three minimal ##ly invasive spine surgical approaches ( P ##EL ##D , MI ##S - T ##L ##IF , and ME ##D ) for re ##current her ##nia ##tion , and the mean operation time between them was 75 . 0 ± 31 . 56 minutes , 146 . 54 ± 38 . 07 minutes , and 85 . 25 ± 41 . 60 minutes , respectively . P ##EL ##D had a significantly less operation time than MI ##S - T ##L ##IF , but a comparable operation time with ME ##D . The functional outcomes were assessed by the VA ##S scores for back pain and leg pain . Our results suggested that patients treated with P ##EL ##D had comparable post ##oper ##ation VA ##S scores for back pain and leg pain with those treated with other surge ##ries . Our result [SEP]\n",
      "INFO:tensorflow:token_to_orig_map: 11:615 12:616 13:617 14:618 15:619 16:619 17:619 18:619 19:620 20:621 21:621 22:621 23:621 24:621 25:622 26:622 27:622 28:622 29:622 30:623 31:623 32:623 33:623 34:623 35:623 36:624 37:625 38:626 39:627 40:628 41:629 42:630 43:631 44:631 45:631 46:631 47:632 48:632 49:633 50:634 51:635 52:636 53:637 54:638 55:639 56:639 57:640 58:641 59:642 60:643 61:643 62:644 63:645 64:646 65:647 66:648 67:649 68:650 69:651 70:652 71:652 72:652 73:653 74:654 75:654 76:654 77:655 78:656 79:657 80:658 81:659 82:660 83:661 84:662 85:663 86:664 87:665 88:665 89:666 90:666 91:667 92:668 93:669 94:670 95:671 96:672 97:672 98:672 99:673 100:674 101:675 102:676 103:677 104:678 105:679 106:680 107:680 108:680 109:681 110:681 111:681 112:681 113:681 114:681 115:681 116:682 117:682 118:682 119:682 120:683 121:683 122:683 123:683 124:684 125:685 126:685 127:685 128:685 129:685 130:685 131:686 132:687 133:688 134:689 135:690 136:690 137:691 138:691 139:691 140:692 141:693 142:693 143:693 144:694 145:694 146:695 147:695 148:695 149:696 150:696 151:697 152:697 153:697 154:698 155:698 156:699 157:700 158:701 159:702 160:703 161:704 162:705 163:705 164:706 165:706 166:707 167:708 168:708 169:708 170:709 171:710 172:710 173:710 174:710 175:710 176:711 177:712 178:713 179:714 180:715 181:716 182:716 183:716 184:717 185:718 186:718 187:718 188:719 189:720 190:721 191:722 192:723 193:724 194:725 195:726 196:727 197:728 198:729 199:730 200:730 201:730 202:731 203:732 204:732 205:732 206:733 207:734 208:735 209:735 210:735 211:736 212:737 213:737 214:737 215:738 216:738 217:739 218:740 219:740 220:741 221:742 222:742 223:742 224:742 225:742 226:742 227:743 228:744 229:744 230:745 231:746 232:746 233:746 234:746 235:746 236:747 237:748 238:749 239:750 240:750 241:751 242:752 243:753 244:754 245:755 246:755 247:755 248:755 249:755 250:756 251:756 252:756 253:756 254:756 255:756 256:756 257:757 258:758 259:758 260:758 261:759 262:760 263:760 264:761 265:761 266:761 267:761 268:762 269:763 270:764 271:765 272:766 273:767 274:768 275:769 276:770 277:770 278:770 279:771 280:772 281:772 282:772 283:773 284:773 285:774 286:774 287:774 288:775 289:776 290:776 291:776 292:777 293:777 294:778 295:779 296:779 297:779 298:780 299:781 300:781 301:781 302:782 303:782 304:783 305:783 306:784 307:784 308:784 309:785 310:786 311:787 312:788 313:789 314:790 315:791 316:792 317:792 318:792 319:792 320:792 321:792 322:792 323:793 324:794 325:795 326:796 327:797 328:798 329:799 330:799 331:799 332:800 333:801 334:802 335:803 336:804 337:805 338:806 339:807 340:807 341:808 342:809 343:810 344:811 345:812 346:813 347:814 348:814 349:815 350:816 351:817 352:818 353:819 354:820 355:821 356:822 357:822 358:822 359:823 360:824 361:825 362:825 363:825 364:826 365:826 366:827 367:828 368:829 369:830 370:831 371:832 372:833 373:834 374:835 375:836 376:837 377:838 378:839 379:839 380:839 381:840 382:841\n",
      "I1208 12:27:37.154020 139883775852736 run_factoid.py:445] token_to_orig_map: 11:615 12:616 13:617 14:618 15:619 16:619 17:619 18:619 19:620 20:621 21:621 22:621 23:621 24:621 25:622 26:622 27:622 28:622 29:622 30:623 31:623 32:623 33:623 34:623 35:623 36:624 37:625 38:626 39:627 40:628 41:629 42:630 43:631 44:631 45:631 46:631 47:632 48:632 49:633 50:634 51:635 52:636 53:637 54:638 55:639 56:639 57:640 58:641 59:642 60:643 61:643 62:644 63:645 64:646 65:647 66:648 67:649 68:650 69:651 70:652 71:652 72:652 73:653 74:654 75:654 76:654 77:655 78:656 79:657 80:658 81:659 82:660 83:661 84:662 85:663 86:664 87:665 88:665 89:666 90:666 91:667 92:668 93:669 94:670 95:671 96:672 97:672 98:672 99:673 100:674 101:675 102:676 103:677 104:678 105:679 106:680 107:680 108:680 109:681 110:681 111:681 112:681 113:681 114:681 115:681 116:682 117:682 118:682 119:682 120:683 121:683 122:683 123:683 124:684 125:685 126:685 127:685 128:685 129:685 130:685 131:686 132:687 133:688 134:689 135:690 136:690 137:691 138:691 139:691 140:692 141:693 142:693 143:693 144:694 145:694 146:695 147:695 148:695 149:696 150:696 151:697 152:697 153:697 154:698 155:698 156:699 157:700 158:701 159:702 160:703 161:704 162:705 163:705 164:706 165:706 166:707 167:708 168:708 169:708 170:709 171:710 172:710 173:710 174:710 175:710 176:711 177:712 178:713 179:714 180:715 181:716 182:716 183:716 184:717 185:718 186:718 187:718 188:719 189:720 190:721 191:722 192:723 193:724 194:725 195:726 196:727 197:728 198:729 199:730 200:730 201:730 202:731 203:732 204:732 205:732 206:733 207:734 208:735 209:735 210:735 211:736 212:737 213:737 214:737 215:738 216:738 217:739 218:740 219:740 220:741 221:742 222:742 223:742 224:742 225:742 226:742 227:743 228:744 229:744 230:745 231:746 232:746 233:746 234:746 235:746 236:747 237:748 238:749 239:750 240:750 241:751 242:752 243:753 244:754 245:755 246:755 247:755 248:755 249:755 250:756 251:756 252:756 253:756 254:756 255:756 256:756 257:757 258:758 259:758 260:758 261:759 262:760 263:760 264:761 265:761 266:761 267:761 268:762 269:763 270:764 271:765 272:766 273:767 274:768 275:769 276:770 277:770 278:770 279:771 280:772 281:772 282:772 283:773 284:773 285:774 286:774 287:774 288:775 289:776 290:776 291:776 292:777 293:777 294:778 295:779 296:779 297:779 298:780 299:781 300:781 301:781 302:782 303:782 304:783 305:783 306:784 307:784 308:784 309:785 310:786 311:787 312:788 313:789 314:790 315:791 316:792 317:792 318:792 319:792 320:792 321:792 322:792 323:793 324:794 325:795 326:796 327:797 328:798 329:799 330:799 331:799 332:800 333:801 334:802 335:803 336:804 337:805 338:806 339:807 340:807 341:808 342:809 343:810 344:811 345:812 346:813 347:814 348:814 349:815 350:816 351:817 352:818 353:819 354:820 355:821 356:822 357:822 358:822 359:823 360:824 361:825 362:825 363:825 364:826 365:826 366:827 367:828 368:829 369:830 370:831 371:832 372:833 373:834 374:835 375:836 376:837 377:838 378:839 379:839 380:839 381:840 382:841\n",
      "INFO:tensorflow:token_is_max_context: 11:False 12:False 13:False 14:False 15:False 16:False 17:False 18:False 19:False 20:False 21:False 22:False 23:False 24:False 25:False 26:False 27:False 28:False 29:False 30:False 31:False 32:False 33:False 34:False 35:False 36:False 37:False 38:False 39:False 40:False 41:False 42:False 43:False 44:False 45:False 46:False 47:False 48:False 49:False 50:False 51:False 52:False 53:False 54:False 55:False 56:False 57:False 58:False 59:False 60:False 61:False 62:False 63:False 64:False 65:False 66:False 67:False 68:False 69:False 70:False 71:False 72:False 73:False 74:False 75:False 76:False 77:False 78:False 79:False 80:False 81:False 82:False 83:False 84:False 85:False 86:False 87:False 88:False 89:False 90:False 91:False 92:False 93:False 94:False 95:False 96:False 97:False 98:False 99:False 100:False 101:False 102:False 103:False 104:False 105:False 106:False 107:False 108:False 109:False 110:False 111:False 112:False 113:False 114:False 115:False 116:False 117:False 118:False 119:False 120:False 121:False 122:False 123:False 124:False 125:False 126:False 127:False 128:False 129:False 130:False 131:False 132:False 133:True 134:True 135:True 136:True 137:True 138:True 139:True 140:True 141:True 142:True 143:True 144:True 145:True 146:True 147:True 148:True 149:True 150:True 151:True 152:True 153:True 154:True 155:True 156:True 157:True 158:True 159:True 160:True 161:True 162:True 163:True 164:True 165:True 166:True 167:True 168:True 169:True 170:True 171:True 172:True 173:True 174:True 175:True 176:True 177:True 178:True 179:True 180:True 181:True 182:True 183:True 184:True 185:True 186:True 187:True 188:True 189:True 190:True 191:True 192:True 193:True 194:True 195:True 196:True 197:True 198:True 199:True 200:True 201:True 202:True 203:True 204:True 205:True 206:True 207:True 208:True 209:True 210:True 211:True 212:True 213:True 214:True 215:True 216:True 217:True 218:True 219:True 220:True 221:True 222:True 223:True 224:True 225:True 226:True 227:True 228:True 229:True 230:True 231:True 232:True 233:True 234:True 235:True 236:True 237:True 238:True 239:True 240:True 241:True 242:True 243:True 244:True 245:True 246:True 247:True 248:True 249:True 250:True 251:True 252:True 253:True 254:True 255:True 256:True 257:True 258:True 259:True 260:True 261:False 262:False 263:False 264:False 265:False 266:False 267:False 268:False 269:False 270:False 271:False 272:False 273:False 274:False 275:False 276:False 277:False 278:False 279:False 280:False 281:False 282:False 283:False 284:False 285:False 286:False 287:False 288:False 289:False 290:False 291:False 292:False 293:False 294:False 295:False 296:False 297:False 298:False 299:False 300:False 301:False 302:False 303:False 304:False 305:False 306:False 307:False 308:False 309:False 310:False 311:False 312:False 313:False 314:False 315:False 316:False 317:False 318:False 319:False 320:False 321:False 322:False 323:False 324:False 325:False 326:False 327:False 328:False 329:False 330:False 331:False 332:False 333:False 334:False 335:False 336:False 337:False 338:False 339:False 340:False 341:False 342:False 343:False 344:False 345:False 346:False 347:False 348:False 349:False 350:False 351:False 352:False 353:False 354:False 355:False 356:False 357:False 358:False 359:False 360:False 361:False 362:False 363:False 364:False 365:False 366:False 367:False 368:False 369:False 370:False 371:False 372:False 373:False 374:False 375:False 376:False 377:False 378:False 379:False 380:False 381:False 382:False\n",
      "I1208 12:27:37.154132 139883775852736 run_factoid.py:447] token_is_max_context: 11:False 12:False 13:False 14:False 15:False 16:False 17:False 18:False 19:False 20:False 21:False 22:False 23:False 24:False 25:False 26:False 27:False 28:False 29:False 30:False 31:False 32:False 33:False 34:False 35:False 36:False 37:False 38:False 39:False 40:False 41:False 42:False 43:False 44:False 45:False 46:False 47:False 48:False 49:False 50:False 51:False 52:False 53:False 54:False 55:False 56:False 57:False 58:False 59:False 60:False 61:False 62:False 63:False 64:False 65:False 66:False 67:False 68:False 69:False 70:False 71:False 72:False 73:False 74:False 75:False 76:False 77:False 78:False 79:False 80:False 81:False 82:False 83:False 84:False 85:False 86:False 87:False 88:False 89:False 90:False 91:False 92:False 93:False 94:False 95:False 96:False 97:False 98:False 99:False 100:False 101:False 102:False 103:False 104:False 105:False 106:False 107:False 108:False 109:False 110:False 111:False 112:False 113:False 114:False 115:False 116:False 117:False 118:False 119:False 120:False 121:False 122:False 123:False 124:False 125:False 126:False 127:False 128:False 129:False 130:False 131:False 132:False 133:True 134:True 135:True 136:True 137:True 138:True 139:True 140:True 141:True 142:True 143:True 144:True 145:True 146:True 147:True 148:True 149:True 150:True 151:True 152:True 153:True 154:True 155:True 156:True 157:True 158:True 159:True 160:True 161:True 162:True 163:True 164:True 165:True 166:True 167:True 168:True 169:True 170:True 171:True 172:True 173:True 174:True 175:True 176:True 177:True 178:True 179:True 180:True 181:True 182:True 183:True 184:True 185:True 186:True 187:True 188:True 189:True 190:True 191:True 192:True 193:True 194:True 195:True 196:True 197:True 198:True 199:True 200:True 201:True 202:True 203:True 204:True 205:True 206:True 207:True 208:True 209:True 210:True 211:True 212:True 213:True 214:True 215:True 216:True 217:True 218:True 219:True 220:True 221:True 222:True 223:True 224:True 225:True 226:True 227:True 228:True 229:True 230:True 231:True 232:True 233:True 234:True 235:True 236:True 237:True 238:True 239:True 240:True 241:True 242:True 243:True 244:True 245:True 246:True 247:True 248:True 249:True 250:True 251:True 252:True 253:True 254:True 255:True 256:True 257:True 258:True 259:True 260:True 261:False 262:False 263:False 264:False 265:False 266:False 267:False 268:False 269:False 270:False 271:False 272:False 273:False 274:False 275:False 276:False 277:False 278:False 279:False 280:False 281:False 282:False 283:False 284:False 285:False 286:False 287:False 288:False 289:False 290:False 291:False 292:False 293:False 294:False 295:False 296:False 297:False 298:False 299:False 300:False 301:False 302:False 303:False 304:False 305:False 306:False 307:False 308:False 309:False 310:False 311:False 312:False 313:False 314:False 315:False 316:False 317:False 318:False 319:False 320:False 321:False 322:False 323:False 324:False 325:False 326:False 327:False 328:False 329:False 330:False 331:False 332:False 333:False 334:False 335:False 336:False 337:False 338:False 339:False 340:False 341:False 342:False 343:False 344:False 345:False 346:False 347:False 348:False 349:False 350:False 351:False 352:False 353:False 354:False 355:False 356:False 357:False 358:False 359:False 360:False 361:False 362:False 363:False 364:False 365:False 366:False 367:False 368:False 369:False 370:False 371:False 372:False 373:False 374:False 375:False 376:False 377:False 378:False 379:False 380:False 381:False 382:False\n",
      "INFO:tensorflow:input_ids: 101 2091 1103 9505 12864 1113 5351 17898 1116 136 102 1103 1160 2114 1108 5539 119 124 110 1105 4573 119 123 110 117 3569 119 164 3882 166 26574 1708 118 157 2162 15499 3657 1107 170 2299 2244 2603 1190 153 21678 2137 117 1649 117 1175 1108 1185 2418 3719 1206 1172 119 23840 1103 2805 1159 117 1103 1675 2025 7160 1115 4420 5165 1114 153 21678 2137 1125 1407 119 1489 1904 1750 1104 2805 1159 1190 1343 1114 1168 13467 22496 119 1438 117 1103 3549 2805 1159 1104 153 21678 2137 1108 1178 4379 1107 1103 7577 1114 152 22074 117 26574 1708 118 157 2162 15499 117 17599 6385 10805 4571 6187 10294 18778 1183 1105 17599 10396 2093 5822 18574 119 22439 1114 1292 13467 8015 117 153 21678 2137 1125 1429 119 5046 1904 117 3453 119 1695 1904 117 1695 119 1626 1904 117 1105 1542 1904 1750 1104 2805 1159 117 3569 119 4246 150 4538 117 3084 2393 119 164 3140 166 3402 1103 7300 13950 1104 153 21678 2137 1114 152 22074 117 1105 1152 1276 1103 2805 1159 1107 1292 1160 2114 1108 4389 119 121 212 1492 119 121 1904 1105 3324 119 127 212 1743 119 128 1904 117 3569 113 153 133 121 119 3135 1475 114 119 27762 162 117 3084 2393 119 164 2532 166 14758 1103 1210 10298 1193 19849 8340 13467 8015 113 153 21678 2137 117 26574 1708 118 157 2162 15499 117 1105 22157 2137 114 1111 1231 21754 1123 5813 2116 117 1105 1103 1928 2805 1159 1206 1172 1108 3453 119 121 212 1955 119 4376 1904 117 17350 119 4335 212 3383 119 5004 1904 117 1105 4859 119 1512 212 3746 119 2539 1904 117 3569 119 153 21678 2137 1125 170 5409 1750 2805 1159 1190 26574 1708 118 157 2162 15499 117 1133 170 12763 2805 1159 1114 22157 2137 119 1109 8458 13950 1127 14758 1118 1103 19497 1708 7432 1111 1171 2489 1105 3420 2489 119 3458 2686 3228 1115 4420 5165 1114 153 21678 2137 1125 12763 2112 19807 1891 19497 1708 7432 1111 1171 2489 1105 3420 2489 1114 1343 5165 1114 1168 12814 3377 119 3458 1871 102\n",
      "I1208 12:27:37.154235 139883775852736 run_factoid.py:449] input_ids: 101 2091 1103 9505 12864 1113 5351 17898 1116 136 102 1103 1160 2114 1108 5539 119 124 110 1105 4573 119 123 110 117 3569 119 164 3882 166 26574 1708 118 157 2162 15499 3657 1107 170 2299 2244 2603 1190 153 21678 2137 117 1649 117 1175 1108 1185 2418 3719 1206 1172 119 23840 1103 2805 1159 117 1103 1675 2025 7160 1115 4420 5165 1114 153 21678 2137 1125 1407 119 1489 1904 1750 1104 2805 1159 1190 1343 1114 1168 13467 22496 119 1438 117 1103 3549 2805 1159 1104 153 21678 2137 1108 1178 4379 1107 1103 7577 1114 152 22074 117 26574 1708 118 157 2162 15499 117 17599 6385 10805 4571 6187 10294 18778 1183 1105 17599 10396 2093 5822 18574 119 22439 1114 1292 13467 8015 117 153 21678 2137 1125 1429 119 5046 1904 117 3453 119 1695 1904 117 1695 119 1626 1904 117 1105 1542 1904 1750 1104 2805 1159 117 3569 119 4246 150 4538 117 3084 2393 119 164 3140 166 3402 1103 7300 13950 1104 153 21678 2137 1114 152 22074 117 1105 1152 1276 1103 2805 1159 1107 1292 1160 2114 1108 4389 119 121 212 1492 119 121 1904 1105 3324 119 127 212 1743 119 128 1904 117 3569 113 153 133 121 119 3135 1475 114 119 27762 162 117 3084 2393 119 164 2532 166 14758 1103 1210 10298 1193 19849 8340 13467 8015 113 153 21678 2137 117 26574 1708 118 157 2162 15499 117 1105 22157 2137 114 1111 1231 21754 1123 5813 2116 117 1105 1103 1928 2805 1159 1206 1172 1108 3453 119 121 212 1955 119 4376 1904 117 17350 119 4335 212 3383 119 5004 1904 117 1105 4859 119 1512 212 3746 119 2539 1904 117 3569 119 153 21678 2137 1125 170 5409 1750 2805 1159 1190 26574 1708 118 157 2162 15499 117 1133 170 12763 2805 1159 1114 22157 2137 119 1109 8458 13950 1127 14758 1118 1103 19497 1708 7432 1111 1171 2489 1105 3420 2489 119 3458 2686 3228 1115 4420 5165 1114 153 21678 2137 1125 12763 2112 19807 1891 19497 1708 7432 1111 1171 2489 1105 3420 2489 1114 1343 5165 1114 1168 12814 3377 119 3458 1871 102\n",
      "INFO:tensorflow:input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      "I1208 12:27:37.154326 139883775852736 run_factoid.py:451] input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      "INFO:tensorflow:segment_ids: 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      "I1208 12:27:37.154415 139883775852736 run_factoid.py:453] segment_ids: 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      "INFO:tensorflow:*** Example ***\n",
      "I1208 12:27:37.156279 139883775852736 run_factoid.py:438] *** Example ***\n",
      "INFO:tensorflow:unique_id: 1000000049\n",
      "I1208 12:27:37.156339 139883775852736 run_factoid.py:439] unique_id: 1000000049\n",
      "INFO:tensorflow:example_index: 8\n",
      "I1208 12:27:37.156376 139883775852736 run_factoid.py:440] example_index: 8\n",
      "INFO:tensorflow:doc_span_index: 9\n",
      "I1208 12:27:37.156410 139883775852736 run_factoid.py:441] doc_span_index: 9\n",
      "INFO:tensorflow:tokens: [CLS] Do the findings depend on patient demographic ##s ? [SEP] ##D had 11 . 66 minutes , 75 . 23 minutes , 23 . 21 minutes , and 17 minutes less of operation time , respectively . Kim M ##J , et al . [ 44 ] compared the clinical outcomes of P ##EL ##D with O ##LM , and they found the operation time in these two groups was 53 . 0 ± 13 . 0 minutes and 64 . 6 ± 28 . 7 minutes , respectively ( P < 0 . 00 ##1 ) . Yao Y , et al . [ 45 ] assessed the three minimal ##ly invasive spine surgical approaches ( P ##EL ##D , MI ##S - T ##L ##IF , and ME ##D ) for re ##current her ##nia ##tion , and the mean operation time between them was 75 . 0 ± 31 . 56 minutes , 146 . 54 ± 38 . 07 minutes , and 85 . 25 ± 41 . 60 minutes , respectively . P ##EL ##D had a significantly less operation time than MI ##S - T ##L ##IF , but a comparable operation time with ME ##D . The functional outcomes were assessed by the VA ##S scores for back pain and leg pain . Our results suggested that patients treated with P ##EL ##D had comparable post ##oper ##ation VA ##S scores for back pain and leg pain with those treated with other surge ##ries . Our result was in consistent with the previous findings . [ 50 , 52 , 54 ] Yao Y , et al [ 54 ] reported that the pre ##oper ##ative VA ##S scores for back pain and leg pain were 5 . 88 ± 1 . 24 and 7 . 05 ± 1 . 08 in the MI ##S - T ##L ##IF group , 5 . 92 ± 1 . 33 and 7 . 13 ± 1 . 09 respectively in the P ##EL ##D group ( P = . 88 ##8 ) . [ 54 ] At the follow - up duration of 12 months , the VA ##S scores significantly reduced in the two groups as compared with pre ##oper ##ative values . However , there [SEP]\n",
      "I1208 12:27:37.156523 139883775852736 run_factoid.py:443] tokens: [CLS] Do the findings depend on patient demographic ##s ? [SEP] ##D had 11 . 66 minutes , 75 . 23 minutes , 23 . 21 minutes , and 17 minutes less of operation time , respectively . Kim M ##J , et al . [ 44 ] compared the clinical outcomes of P ##EL ##D with O ##LM , and they found the operation time in these two groups was 53 . 0 ± 13 . 0 minutes and 64 . 6 ± 28 . 7 minutes , respectively ( P < 0 . 00 ##1 ) . Yao Y , et al . [ 45 ] assessed the three minimal ##ly invasive spine surgical approaches ( P ##EL ##D , MI ##S - T ##L ##IF , and ME ##D ) for re ##current her ##nia ##tion , and the mean operation time between them was 75 . 0 ± 31 . 56 minutes , 146 . 54 ± 38 . 07 minutes , and 85 . 25 ± 41 . 60 minutes , respectively . P ##EL ##D had a significantly less operation time than MI ##S - T ##L ##IF , but a comparable operation time with ME ##D . The functional outcomes were assessed by the VA ##S scores for back pain and leg pain . Our results suggested that patients treated with P ##EL ##D had comparable post ##oper ##ation VA ##S scores for back pain and leg pain with those treated with other surge ##ries . Our result was in consistent with the previous findings . [ 50 , 52 , 54 ] Yao Y , et al [ 54 ] reported that the pre ##oper ##ative VA ##S scores for back pain and leg pain were 5 . 88 ± 1 . 24 and 7 . 05 ± 1 . 08 in the MI ##S - T ##L ##IF group , 5 . 92 ± 1 . 33 and 7 . 13 ± 1 . 09 respectively in the P ##EL ##D group ( P = . 88 ##8 ) . [ 54 ] At the follow - up duration of 12 months , the VA ##S scores significantly reduced in the two groups as compared with pre ##oper ##ative values . However , there [SEP]\n",
      "INFO:tensorflow:token_to_orig_map: 11:691 12:692 13:693 14:693 15:693 16:694 17:694 18:695 19:695 20:695 21:696 22:696 23:697 24:697 25:697 26:698 27:698 28:699 29:700 30:701 31:702 32:703 33:704 34:705 35:705 36:706 37:706 38:707 39:708 40:708 41:708 42:709 43:710 44:710 45:710 46:710 47:710 48:711 49:712 50:713 51:714 52:715 53:716 54:716 55:716 56:717 57:718 58:718 59:718 60:719 61:720 62:721 63:722 64:723 65:724 66:725 67:726 68:727 69:728 70:729 71:730 72:730 73:730 74:731 75:732 76:732 77:732 78:733 79:734 80:735 81:735 82:735 83:736 84:737 85:737 86:737 87:738 88:738 89:739 90:740 91:740 92:741 93:742 94:742 95:742 96:742 97:742 98:742 99:743 100:744 101:744 102:745 103:746 104:746 105:746 106:746 107:746 108:747 109:748 110:749 111:750 112:750 113:751 114:752 115:753 116:754 117:755 118:755 119:755 120:755 121:755 122:756 123:756 124:756 125:756 126:756 127:756 128:756 129:757 130:758 131:758 132:758 133:759 134:760 135:760 136:761 137:761 138:761 139:761 140:762 141:763 142:764 143:765 144:766 145:767 146:768 147:769 148:770 149:770 150:770 151:771 152:772 153:772 154:772 155:773 156:773 157:774 158:774 159:774 160:775 161:776 162:776 163:776 164:777 165:777 166:778 167:779 168:779 169:779 170:780 171:781 172:781 173:781 174:782 175:782 176:783 177:783 178:784 179:784 180:784 181:785 182:786 183:787 184:788 185:789 186:790 187:791 188:792 189:792 190:792 191:792 192:792 193:792 194:792 195:793 196:794 197:795 198:796 199:797 200:798 201:799 202:799 203:799 204:800 205:801 206:802 207:803 208:804 209:805 210:806 211:807 212:807 213:808 214:809 215:810 216:811 217:812 218:813 219:814 220:814 221:815 222:816 223:817 224:818 225:819 226:820 227:821 228:822 229:822 230:822 231:823 232:824 233:825 234:825 235:825 236:826 237:826 238:827 239:828 240:829 241:830 242:831 243:832 244:833 245:834 246:835 247:836 248:837 249:838 250:839 251:839 252:839 253:840 254:841 255:842 256:843 257:844 258:845 259:846 260:847 261:848 262:848 263:848 264:848 265:848 266:848 267:848 268:848 269:848 270:849 271:850 272:850 273:851 274:852 275:852 276:852 277:852 278:853 279:854 280:855 281:856 282:856 283:856 284:857 285:857 286:858 287:859 288:860 289:861 290:862 291:863 292:864 293:865 294:866 295:866 296:866 297:867 298:868 299:868 300:868 301:869 302:870 303:870 304:870 305:871 306:872 307:872 308:872 309:873 310:874 311:875 312:875 313:875 314:876 315:876 316:876 317:877 318:877 319:878 320:878 321:878 322:879 323:880 324:880 325:880 326:881 327:882 328:882 329:882 330:883 331:884 332:884 333:884 334:885 335:886 336:887 337:888 338:888 339:888 340:889 341:890 342:890 343:891 344:892 345:892 346:892 347:892 348:892 349:892 350:892 351:892 352:893 353:894 354:895 355:895 356:895 357:896 358:897 359:898 360:899 361:899 362:900 363:901 364:901 365:902 366:903 367:904 368:905 369:906 370:907 371:908 372:909 373:910 374:911 375:912 376:912 377:912 378:913 379:913 380:914 381:914 382:915\n",
      "I1208 12:27:37.156650 139883775852736 run_factoid.py:445] token_to_orig_map: 11:691 12:692 13:693 14:693 15:693 16:694 17:694 18:695 19:695 20:695 21:696 22:696 23:697 24:697 25:697 26:698 27:698 28:699 29:700 30:701 31:702 32:703 33:704 34:705 35:705 36:706 37:706 38:707 39:708 40:708 41:708 42:709 43:710 44:710 45:710 46:710 47:710 48:711 49:712 50:713 51:714 52:715 53:716 54:716 55:716 56:717 57:718 58:718 59:718 60:719 61:720 62:721 63:722 64:723 65:724 66:725 67:726 68:727 69:728 70:729 71:730 72:730 73:730 74:731 75:732 76:732 77:732 78:733 79:734 80:735 81:735 82:735 83:736 84:737 85:737 86:737 87:738 88:738 89:739 90:740 91:740 92:741 93:742 94:742 95:742 96:742 97:742 98:742 99:743 100:744 101:744 102:745 103:746 104:746 105:746 106:746 107:746 108:747 109:748 110:749 111:750 112:750 113:751 114:752 115:753 116:754 117:755 118:755 119:755 120:755 121:755 122:756 123:756 124:756 125:756 126:756 127:756 128:756 129:757 130:758 131:758 132:758 133:759 134:760 135:760 136:761 137:761 138:761 139:761 140:762 141:763 142:764 143:765 144:766 145:767 146:768 147:769 148:770 149:770 150:770 151:771 152:772 153:772 154:772 155:773 156:773 157:774 158:774 159:774 160:775 161:776 162:776 163:776 164:777 165:777 166:778 167:779 168:779 169:779 170:780 171:781 172:781 173:781 174:782 175:782 176:783 177:783 178:784 179:784 180:784 181:785 182:786 183:787 184:788 185:789 186:790 187:791 188:792 189:792 190:792 191:792 192:792 193:792 194:792 195:793 196:794 197:795 198:796 199:797 200:798 201:799 202:799 203:799 204:800 205:801 206:802 207:803 208:804 209:805 210:806 211:807 212:807 213:808 214:809 215:810 216:811 217:812 218:813 219:814 220:814 221:815 222:816 223:817 224:818 225:819 226:820 227:821 228:822 229:822 230:822 231:823 232:824 233:825 234:825 235:825 236:826 237:826 238:827 239:828 240:829 241:830 242:831 243:832 244:833 245:834 246:835 247:836 248:837 249:838 250:839 251:839 252:839 253:840 254:841 255:842 256:843 257:844 258:845 259:846 260:847 261:848 262:848 263:848 264:848 265:848 266:848 267:848 268:848 269:848 270:849 271:850 272:850 273:851 274:852 275:852 276:852 277:852 278:853 279:854 280:855 281:856 282:856 283:856 284:857 285:857 286:858 287:859 288:860 289:861 290:862 291:863 292:864 293:865 294:866 295:866 296:866 297:867 298:868 299:868 300:868 301:869 302:870 303:870 304:870 305:871 306:872 307:872 308:872 309:873 310:874 311:875 312:875 313:875 314:876 315:876 316:876 317:877 318:877 319:878 320:878 321:878 322:879 323:880 324:880 325:880 326:881 327:882 328:882 329:882 330:883 331:884 332:884 333:884 334:885 335:886 336:887 337:888 338:888 339:888 340:889 341:890 342:890 343:891 344:892 345:892 346:892 347:892 348:892 349:892 350:892 351:892 352:893 353:894 354:895 355:895 356:895 357:896 358:897 359:898 360:899 361:899 362:900 363:901 364:901 365:902 366:903 367:904 368:905 369:906 370:907 371:908 372:909 373:910 374:911 375:912 376:912 377:912 378:913 379:913 380:914 381:914 382:915\n",
      "INFO:tensorflow:token_is_max_context: 11:False 12:False 13:False 14:False 15:False 16:False 17:False 18:False 19:False 20:False 21:False 22:False 23:False 24:False 25:False 26:False 27:False 28:False 29:False 30:False 31:False 32:False 33:False 34:False 35:False 36:False 37:False 38:False 39:False 40:False 41:False 42:False 43:False 44:False 45:False 46:False 47:False 48:False 49:False 50:False 51:False 52:False 53:False 54:False 55:False 56:False 57:False 58:False 59:False 60:False 61:False 62:False 63:False 64:False 65:False 66:False 67:False 68:False 69:False 70:False 71:False 72:False 73:False 74:False 75:False 76:False 77:False 78:False 79:False 80:False 81:False 82:False 83:False 84:False 85:False 86:False 87:False 88:False 89:False 90:False 91:False 92:False 93:False 94:False 95:False 96:False 97:False 98:False 99:False 100:False 101:False 102:False 103:False 104:False 105:False 106:False 107:False 108:False 109:False 110:False 111:False 112:False 113:False 114:False 115:False 116:False 117:False 118:False 119:False 120:False 121:False 122:False 123:False 124:False 125:False 126:False 127:False 128:False 129:False 130:False 131:False 132:False 133:True 134:True 135:True 136:True 137:True 138:True 139:True 140:True 141:True 142:True 143:True 144:True 145:True 146:True 147:True 148:True 149:True 150:True 151:True 152:True 153:True 154:True 155:True 156:True 157:True 158:True 159:True 160:True 161:True 162:True 163:True 164:True 165:True 166:True 167:True 168:True 169:True 170:True 171:True 172:True 173:True 174:True 175:True 176:True 177:True 178:True 179:True 180:True 181:True 182:True 183:True 184:True 185:True 186:True 187:True 188:True 189:True 190:True 191:True 192:True 193:True 194:True 195:True 196:True 197:True 198:True 199:True 200:True 201:True 202:True 203:True 204:True 205:True 206:True 207:True 208:True 209:True 210:True 211:True 212:True 213:True 214:True 215:True 216:True 217:True 218:True 219:True 220:True 221:True 222:True 223:True 224:True 225:True 226:True 227:True 228:True 229:True 230:True 231:True 232:True 233:True 234:True 235:True 236:True 237:True 238:True 239:True 240:True 241:True 242:True 243:True 244:True 245:True 246:True 247:True 248:True 249:True 250:True 251:True 252:True 253:True 254:True 255:True 256:True 257:True 258:True 259:True 260:True 261:False 262:False 263:False 264:False 265:False 266:False 267:False 268:False 269:False 270:False 271:False 272:False 273:False 274:False 275:False 276:False 277:False 278:False 279:False 280:False 281:False 282:False 283:False 284:False 285:False 286:False 287:False 288:False 289:False 290:False 291:False 292:False 293:False 294:False 295:False 296:False 297:False 298:False 299:False 300:False 301:False 302:False 303:False 304:False 305:False 306:False 307:False 308:False 309:False 310:False 311:False 312:False 313:False 314:False 315:False 316:False 317:False 318:False 319:False 320:False 321:False 322:False 323:False 324:False 325:False 326:False 327:False 328:False 329:False 330:False 331:False 332:False 333:False 334:False 335:False 336:False 337:False 338:False 339:False 340:False 341:False 342:False 343:False 344:False 345:False 346:False 347:False 348:False 349:False 350:False 351:False 352:False 353:False 354:False 355:False 356:False 357:False 358:False 359:False 360:False 361:False 362:False 363:False 364:False 365:False 366:False 367:False 368:False 369:False 370:False 371:False 372:False 373:False 374:False 375:False 376:False 377:False 378:False 379:False 380:False 381:False 382:False\n",
      "I1208 12:27:37.156763 139883775852736 run_factoid.py:447] token_is_max_context: 11:False 12:False 13:False 14:False 15:False 16:False 17:False 18:False 19:False 20:False 21:False 22:False 23:False 24:False 25:False 26:False 27:False 28:False 29:False 30:False 31:False 32:False 33:False 34:False 35:False 36:False 37:False 38:False 39:False 40:False 41:False 42:False 43:False 44:False 45:False 46:False 47:False 48:False 49:False 50:False 51:False 52:False 53:False 54:False 55:False 56:False 57:False 58:False 59:False 60:False 61:False 62:False 63:False 64:False 65:False 66:False 67:False 68:False 69:False 70:False 71:False 72:False 73:False 74:False 75:False 76:False 77:False 78:False 79:False 80:False 81:False 82:False 83:False 84:False 85:False 86:False 87:False 88:False 89:False 90:False 91:False 92:False 93:False 94:False 95:False 96:False 97:False 98:False 99:False 100:False 101:False 102:False 103:False 104:False 105:False 106:False 107:False 108:False 109:False 110:False 111:False 112:False 113:False 114:False 115:False 116:False 117:False 118:False 119:False 120:False 121:False 122:False 123:False 124:False 125:False 126:False 127:False 128:False 129:False 130:False 131:False 132:False 133:True 134:True 135:True 136:True 137:True 138:True 139:True 140:True 141:True 142:True 143:True 144:True 145:True 146:True 147:True 148:True 149:True 150:True 151:True 152:True 153:True 154:True 155:True 156:True 157:True 158:True 159:True 160:True 161:True 162:True 163:True 164:True 165:True 166:True 167:True 168:True 169:True 170:True 171:True 172:True 173:True 174:True 175:True 176:True 177:True 178:True 179:True 180:True 181:True 182:True 183:True 184:True 185:True 186:True 187:True 188:True 189:True 190:True 191:True 192:True 193:True 194:True 195:True 196:True 197:True 198:True 199:True 200:True 201:True 202:True 203:True 204:True 205:True 206:True 207:True 208:True 209:True 210:True 211:True 212:True 213:True 214:True 215:True 216:True 217:True 218:True 219:True 220:True 221:True 222:True 223:True 224:True 225:True 226:True 227:True 228:True 229:True 230:True 231:True 232:True 233:True 234:True 235:True 236:True 237:True 238:True 239:True 240:True 241:True 242:True 243:True 244:True 245:True 246:True 247:True 248:True 249:True 250:True 251:True 252:True 253:True 254:True 255:True 256:True 257:True 258:True 259:True 260:True 261:False 262:False 263:False 264:False 265:False 266:False 267:False 268:False 269:False 270:False 271:False 272:False 273:False 274:False 275:False 276:False 277:False 278:False 279:False 280:False 281:False 282:False 283:False 284:False 285:False 286:False 287:False 288:False 289:False 290:False 291:False 292:False 293:False 294:False 295:False 296:False 297:False 298:False 299:False 300:False 301:False 302:False 303:False 304:False 305:False 306:False 307:False 308:False 309:False 310:False 311:False 312:False 313:False 314:False 315:False 316:False 317:False 318:False 319:False 320:False 321:False 322:False 323:False 324:False 325:False 326:False 327:False 328:False 329:False 330:False 331:False 332:False 333:False 334:False 335:False 336:False 337:False 338:False 339:False 340:False 341:False 342:False 343:False 344:False 345:False 346:False 347:False 348:False 349:False 350:False 351:False 352:False 353:False 354:False 355:False 356:False 357:False 358:False 359:False 360:False 361:False 362:False 363:False 364:False 365:False 366:False 367:False 368:False 369:False 370:False 371:False 372:False 373:False 374:False 375:False 376:False 377:False 378:False 379:False 380:False 381:False 382:False\n",
      "INFO:tensorflow:input_ids: 101 2091 1103 9505 12864 1113 5351 17898 1116 136 102 2137 1125 1429 119 5046 1904 117 3453 119 1695 1904 117 1695 119 1626 1904 117 1105 1542 1904 1750 1104 2805 1159 117 3569 119 4246 150 4538 117 3084 2393 119 164 3140 166 3402 1103 7300 13950 1104 153 21678 2137 1114 152 22074 117 1105 1152 1276 1103 2805 1159 1107 1292 1160 2114 1108 4389 119 121 212 1492 119 121 1904 1105 3324 119 127 212 1743 119 128 1904 117 3569 113 153 133 121 119 3135 1475 114 119 27762 162 117 3084 2393 119 164 2532 166 14758 1103 1210 10298 1193 19849 8340 13467 8015 113 153 21678 2137 117 26574 1708 118 157 2162 15499 117 1105 22157 2137 114 1111 1231 21754 1123 5813 2116 117 1105 1103 1928 2805 1159 1206 1172 1108 3453 119 121 212 1955 119 4376 1904 117 17350 119 4335 212 3383 119 5004 1904 117 1105 4859 119 1512 212 3746 119 2539 1904 117 3569 119 153 21678 2137 1125 170 5409 1750 2805 1159 1190 26574 1708 118 157 2162 15499 117 1133 170 12763 2805 1159 1114 22157 2137 119 1109 8458 13950 1127 14758 1118 1103 19497 1708 7432 1111 1171 2489 1105 3420 2489 119 3458 2686 3228 1115 4420 5165 1114 153 21678 2137 1125 12763 2112 19807 1891 19497 1708 7432 1111 1171 2489 1105 3420 2489 1114 1343 5165 1114 1168 12814 3377 119 3458 1871 1108 1107 8080 1114 1103 2166 9505 119 164 1851 117 3882 117 4335 166 27762 162 117 3084 2393 164 4335 166 2103 1115 1103 3073 19807 5838 19497 1708 7432 1111 1171 2489 1105 3420 2489 1127 126 119 5385 212 122 119 1572 1105 128 119 4991 212 122 119 4775 1107 1103 26574 1708 118 157 2162 15499 1372 117 126 119 5556 212 122 119 3081 1105 128 119 1492 212 122 119 4925 3569 1107 1103 153 21678 2137 1372 113 153 134 119 5385 1604 114 119 164 4335 166 1335 1103 2812 118 1146 9355 1104 1367 1808 117 1103 19497 1708 7432 5409 3549 1107 1103 1160 2114 1112 3402 1114 3073 19807 5838 4718 119 1438 117 1175 102\n",
      "I1208 12:27:37.156865 139883775852736 run_factoid.py:449] input_ids: 101 2091 1103 9505 12864 1113 5351 17898 1116 136 102 2137 1125 1429 119 5046 1904 117 3453 119 1695 1904 117 1695 119 1626 1904 117 1105 1542 1904 1750 1104 2805 1159 117 3569 119 4246 150 4538 117 3084 2393 119 164 3140 166 3402 1103 7300 13950 1104 153 21678 2137 1114 152 22074 117 1105 1152 1276 1103 2805 1159 1107 1292 1160 2114 1108 4389 119 121 212 1492 119 121 1904 1105 3324 119 127 212 1743 119 128 1904 117 3569 113 153 133 121 119 3135 1475 114 119 27762 162 117 3084 2393 119 164 2532 166 14758 1103 1210 10298 1193 19849 8340 13467 8015 113 153 21678 2137 117 26574 1708 118 157 2162 15499 117 1105 22157 2137 114 1111 1231 21754 1123 5813 2116 117 1105 1103 1928 2805 1159 1206 1172 1108 3453 119 121 212 1955 119 4376 1904 117 17350 119 4335 212 3383 119 5004 1904 117 1105 4859 119 1512 212 3746 119 2539 1904 117 3569 119 153 21678 2137 1125 170 5409 1750 2805 1159 1190 26574 1708 118 157 2162 15499 117 1133 170 12763 2805 1159 1114 22157 2137 119 1109 8458 13950 1127 14758 1118 1103 19497 1708 7432 1111 1171 2489 1105 3420 2489 119 3458 2686 3228 1115 4420 5165 1114 153 21678 2137 1125 12763 2112 19807 1891 19497 1708 7432 1111 1171 2489 1105 3420 2489 1114 1343 5165 1114 1168 12814 3377 119 3458 1871 1108 1107 8080 1114 1103 2166 9505 119 164 1851 117 3882 117 4335 166 27762 162 117 3084 2393 164 4335 166 2103 1115 1103 3073 19807 5838 19497 1708 7432 1111 1171 2489 1105 3420 2489 1127 126 119 5385 212 122 119 1572 1105 128 119 4991 212 122 119 4775 1107 1103 26574 1708 118 157 2162 15499 1372 117 126 119 5556 212 122 119 3081 1105 128 119 1492 212 122 119 4925 3569 1107 1103 153 21678 2137 1372 113 153 134 119 5385 1604 114 119 164 4335 166 1335 1103 2812 118 1146 9355 1104 1367 1808 117 1103 19497 1708 7432 5409 3549 1107 1103 1160 2114 1112 3402 1114 3073 19807 5838 4718 119 1438 117 1175 102\n",
      "INFO:tensorflow:input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      "I1208 12:27:37.156957 139883775852736 run_factoid.py:451] input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      "INFO:tensorflow:segment_ids: 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      "I1208 12:27:37.157046 139883775852736 run_factoid.py:453] segment_ids: 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      "INFO:tensorflow:*** Example ***\n",
      "I1208 12:27:37.158885 139883775852736 run_factoid.py:438] *** Example ***\n",
      "INFO:tensorflow:unique_id: 1000000050\n",
      "I1208 12:27:37.158942 139883775852736 run_factoid.py:439] unique_id: 1000000050\n",
      "INFO:tensorflow:example_index: 8\n",
      "I1208 12:27:37.158979 139883775852736 run_factoid.py:440] example_index: 8\n",
      "INFO:tensorflow:doc_span_index: 10\n",
      "I1208 12:27:37.159014 139883775852736 run_factoid.py:441] doc_span_index: 10\n",
      "INFO:tensorflow:tokens: [CLS] Do the findings depend on patient demographic ##s ? [SEP] , and the mean operation time between them was 75 . 0 ± 31 . 56 minutes , 146 . 54 ± 38 . 07 minutes , and 85 . 25 ± 41 . 60 minutes , respectively . P ##EL ##D had a significantly less operation time than MI ##S - T ##L ##IF , but a comparable operation time with ME ##D . The functional outcomes were assessed by the VA ##S scores for back pain and leg pain . Our results suggested that patients treated with P ##EL ##D had comparable post ##oper ##ation VA ##S scores for back pain and leg pain with those treated with other surge ##ries . Our result was in consistent with the previous findings . [ 50 , 52 , 54 ] Yao Y , et al [ 54 ] reported that the pre ##oper ##ative VA ##S scores for back pain and leg pain were 5 . 88 ± 1 . 24 and 7 . 05 ± 1 . 08 in the MI ##S - T ##L ##IF group , 5 . 92 ± 1 . 33 and 7 . 13 ± 1 . 09 respectively in the P ##EL ##D group ( P = . 88 ##8 ) . [ 54 ] At the follow - up duration of 12 months , the VA ##S scores significantly reduced in the two groups as compared with pre ##oper ##ative values . However , there was no significant differences between the them in the post ##oper ##ation VA ##S scores for back pain and leg pain . [ 54 ] The authors attributed the results to the relatively larger injury of soft tissue and disruption of spinal stability , which were caused by the inter ##body fusion than disc ##ec ##tom ##y . [ 54 ] There were several potential limitations in this meta - analysis . First , for some outcomes , the data analysis was based on relatively small number of included studies and sample size ; thus , the conclusions about the outcomes should be interpreted with caution . Second , most of the included studies were retrospective co ##hor ##t study , and the grade evidence was inferior to [SEP]\n",
      "I1208 12:27:37.159127 139883775852736 run_factoid.py:443] tokens: [CLS] Do the findings depend on patient demographic ##s ? [SEP] , and the mean operation time between them was 75 . 0 ± 31 . 56 minutes , 146 . 54 ± 38 . 07 minutes , and 85 . 25 ± 41 . 60 minutes , respectively . P ##EL ##D had a significantly less operation time than MI ##S - T ##L ##IF , but a comparable operation time with ME ##D . The functional outcomes were assessed by the VA ##S scores for back pain and leg pain . Our results suggested that patients treated with P ##EL ##D had comparable post ##oper ##ation VA ##S scores for back pain and leg pain with those treated with other surge ##ries . Our result was in consistent with the previous findings . [ 50 , 52 , 54 ] Yao Y , et al [ 54 ] reported that the pre ##oper ##ative VA ##S scores for back pain and leg pain were 5 . 88 ± 1 . 24 and 7 . 05 ± 1 . 08 in the MI ##S - T ##L ##IF group , 5 . 92 ± 1 . 33 and 7 . 13 ± 1 . 09 respectively in the P ##EL ##D group ( P = . 88 ##8 ) . [ 54 ] At the follow - up duration of 12 months , the VA ##S scores significantly reduced in the two groups as compared with pre ##oper ##ative values . However , there was no significant differences between the them in the post ##oper ##ation VA ##S scores for back pain and leg pain . [ 54 ] The authors attributed the results to the relatively larger injury of soft tissue and disruption of spinal stability , which were caused by the inter ##body fusion than disc ##ec ##tom ##y . [ 54 ] There were several potential limitations in this meta - analysis . First , for some outcomes , the data analysis was based on relatively small number of included studies and sample size ; thus , the conclusions about the outcomes should be interpreted with caution . Second , most of the included studies were retrospective co ##hor ##t study , and the grade evidence was inferior to [SEP]\n",
      "INFO:tensorflow:token_to_orig_map: 11:761 12:762 13:763 14:764 15:765 16:766 17:767 18:768 19:769 20:770 21:770 22:770 23:771 24:772 25:772 26:772 27:773 28:773 29:774 30:774 31:774 32:775 33:776 34:776 35:776 36:777 37:777 38:778 39:779 40:779 41:779 42:780 43:781 44:781 45:781 46:782 47:782 48:783 49:783 50:784 51:784 52:784 53:785 54:786 55:787 56:788 57:789 58:790 59:791 60:792 61:792 62:792 63:792 64:792 65:792 66:792 67:793 68:794 69:795 70:796 71:797 72:798 73:799 74:799 75:799 76:800 77:801 78:802 79:803 80:804 81:805 82:806 83:807 84:807 85:808 86:809 87:810 88:811 89:812 90:813 91:814 92:814 93:815 94:816 95:817 96:818 97:819 98:820 99:821 100:822 101:822 102:822 103:823 104:824 105:825 106:825 107:825 108:826 109:826 110:827 111:828 112:829 113:830 114:831 115:832 116:833 117:834 118:835 119:836 120:837 121:838 122:839 123:839 124:839 125:840 126:841 127:842 128:843 129:844 130:845 131:846 132:847 133:848 134:848 135:848 136:848 137:848 138:848 139:848 140:848 141:848 142:849 143:850 144:850 145:851 146:852 147:852 148:852 149:852 150:853 151:854 152:855 153:856 154:856 155:856 156:857 157:857 158:858 159:859 160:860 161:861 162:862 163:863 164:864 165:865 166:866 167:866 168:866 169:867 170:868 171:868 172:868 173:869 174:870 175:870 176:870 177:871 178:872 179:872 180:872 181:873 182:874 183:875 184:875 185:875 186:876 187:876 188:876 189:877 190:877 191:878 192:878 193:878 194:879 195:880 196:880 197:880 198:881 199:882 200:882 201:882 202:883 203:884 204:884 205:884 206:885 207:886 208:887 209:888 210:888 211:888 212:889 213:890 214:890 215:891 216:892 217:892 218:892 219:892 220:892 221:892 222:892 223:892 224:893 225:894 226:895 227:895 228:895 229:896 230:897 231:898 232:899 233:899 234:900 235:901 236:901 237:902 238:903 239:904 240:905 241:906 242:907 243:908 244:909 245:910 246:911 247:912 248:912 249:912 250:913 251:913 252:914 253:914 254:915 255:916 256:917 257:918 258:919 259:920 260:921 261:922 262:923 263:924 264:925 265:925 266:925 267:926 268:926 269:927 270:928 271:929 272:930 273:931 274:932 275:933 276:933 277:933 278:933 279:933 280:934 281:935 282:936 283:937 284:938 285:939 286:940 287:941 288:942 289:943 290:944 291:945 292:946 293:947 294:948 295:949 296:950 297:951 298:951 299:952 300:953 301:954 302:955 303:956 304:957 305:957 306:958 307:959 308:960 309:960 310:960 311:960 312:960 313:960 314:960 315:960 316:961 317:962 318:963 319:964 320:965 321:966 322:967 323:968 324:968 325:968 326:968 327:969 328:969 329:970 330:971 331:972 332:972 333:973 334:974 335:975 336:976 337:977 338:978 339:979 340:980 341:981 342:982 343:983 344:984 345:985 346:986 347:987 348:987 349:988 350:988 351:989 352:990 353:991 354:992 355:993 356:994 357:995 358:996 359:997 360:998 361:998 362:999 363:999 364:1000 365:1001 366:1002 367:1003 368:1004 369:1005 370:1006 371:1007 372:1007 373:1007 374:1008 375:1008 376:1009 377:1010 378:1011 379:1012 380:1013 381:1014 382:1015\n",
      "I1208 12:27:37.159247 139883775852736 run_factoid.py:445] token_to_orig_map: 11:761 12:762 13:763 14:764 15:765 16:766 17:767 18:768 19:769 20:770 21:770 22:770 23:771 24:772 25:772 26:772 27:773 28:773 29:774 30:774 31:774 32:775 33:776 34:776 35:776 36:777 37:777 38:778 39:779 40:779 41:779 42:780 43:781 44:781 45:781 46:782 47:782 48:783 49:783 50:784 51:784 52:784 53:785 54:786 55:787 56:788 57:789 58:790 59:791 60:792 61:792 62:792 63:792 64:792 65:792 66:792 67:793 68:794 69:795 70:796 71:797 72:798 73:799 74:799 75:799 76:800 77:801 78:802 79:803 80:804 81:805 82:806 83:807 84:807 85:808 86:809 87:810 88:811 89:812 90:813 91:814 92:814 93:815 94:816 95:817 96:818 97:819 98:820 99:821 100:822 101:822 102:822 103:823 104:824 105:825 106:825 107:825 108:826 109:826 110:827 111:828 112:829 113:830 114:831 115:832 116:833 117:834 118:835 119:836 120:837 121:838 122:839 123:839 124:839 125:840 126:841 127:842 128:843 129:844 130:845 131:846 132:847 133:848 134:848 135:848 136:848 137:848 138:848 139:848 140:848 141:848 142:849 143:850 144:850 145:851 146:852 147:852 148:852 149:852 150:853 151:854 152:855 153:856 154:856 155:856 156:857 157:857 158:858 159:859 160:860 161:861 162:862 163:863 164:864 165:865 166:866 167:866 168:866 169:867 170:868 171:868 172:868 173:869 174:870 175:870 176:870 177:871 178:872 179:872 180:872 181:873 182:874 183:875 184:875 185:875 186:876 187:876 188:876 189:877 190:877 191:878 192:878 193:878 194:879 195:880 196:880 197:880 198:881 199:882 200:882 201:882 202:883 203:884 204:884 205:884 206:885 207:886 208:887 209:888 210:888 211:888 212:889 213:890 214:890 215:891 216:892 217:892 218:892 219:892 220:892 221:892 222:892 223:892 224:893 225:894 226:895 227:895 228:895 229:896 230:897 231:898 232:899 233:899 234:900 235:901 236:901 237:902 238:903 239:904 240:905 241:906 242:907 243:908 244:909 245:910 246:911 247:912 248:912 249:912 250:913 251:913 252:914 253:914 254:915 255:916 256:917 257:918 258:919 259:920 260:921 261:922 262:923 263:924 264:925 265:925 266:925 267:926 268:926 269:927 270:928 271:929 272:930 273:931 274:932 275:933 276:933 277:933 278:933 279:933 280:934 281:935 282:936 283:937 284:938 285:939 286:940 287:941 288:942 289:943 290:944 291:945 292:946 293:947 294:948 295:949 296:950 297:951 298:951 299:952 300:953 301:954 302:955 303:956 304:957 305:957 306:958 307:959 308:960 309:960 310:960 311:960 312:960 313:960 314:960 315:960 316:961 317:962 318:963 319:964 320:965 321:966 322:967 323:968 324:968 325:968 326:968 327:969 328:969 329:970 330:971 331:972 332:972 333:973 334:974 335:975 336:976 337:977 338:978 339:979 340:980 341:981 342:982 343:983 344:984 345:985 346:986 347:987 348:987 349:988 350:988 351:989 352:990 353:991 354:992 355:993 356:994 357:995 358:996 359:997 360:998 361:998 362:999 363:999 364:1000 365:1001 366:1002 367:1003 368:1004 369:1005 370:1006 371:1007 372:1007 373:1007 374:1008 375:1008 376:1009 377:1010 378:1011 379:1012 380:1013 381:1014 382:1015\n",
      "INFO:tensorflow:token_is_max_context: 11:False 12:False 13:False 14:False 15:False 16:False 17:False 18:False 19:False 20:False 21:False 22:False 23:False 24:False 25:False 26:False 27:False 28:False 29:False 30:False 31:False 32:False 33:False 34:False 35:False 36:False 37:False 38:False 39:False 40:False 41:False 42:False 43:False 44:False 45:False 46:False 47:False 48:False 49:False 50:False 51:False 52:False 53:False 54:False 55:False 56:False 57:False 58:False 59:False 60:False 61:False 62:False 63:False 64:False 65:False 66:False 67:False 68:False 69:False 70:False 71:False 72:False 73:False 74:False 75:False 76:False 77:False 78:False 79:False 80:False 81:False 82:False 83:False 84:False 85:False 86:False 87:False 88:False 89:False 90:False 91:False 92:False 93:False 94:False 95:False 96:False 97:False 98:False 99:False 100:False 101:False 102:False 103:False 104:False 105:False 106:False 107:False 108:False 109:False 110:False 111:False 112:False 113:False 114:False 115:False 116:False 117:False 118:False 119:False 120:False 121:False 122:False 123:False 124:False 125:False 126:False 127:False 128:False 129:False 130:False 131:False 132:False 133:True 134:True 135:True 136:True 137:True 138:True 139:True 140:True 141:True 142:True 143:True 144:True 145:True 146:True 147:True 148:True 149:True 150:True 151:True 152:True 153:True 154:True 155:True 156:True 157:True 158:True 159:True 160:True 161:True 162:True 163:True 164:True 165:True 166:True 167:True 168:True 169:True 170:True 171:True 172:True 173:True 174:True 175:True 176:True 177:True 178:True 179:True 180:True 181:True 182:True 183:True 184:True 185:True 186:True 187:True 188:True 189:True 190:True 191:True 192:True 193:True 194:True 195:True 196:True 197:True 198:True 199:True 200:True 201:True 202:True 203:True 204:True 205:True 206:True 207:True 208:True 209:True 210:True 211:True 212:True 213:True 214:True 215:True 216:True 217:True 218:True 219:True 220:True 221:True 222:True 223:True 224:True 225:True 226:True 227:True 228:True 229:True 230:True 231:True 232:True 233:True 234:True 235:True 236:True 237:True 238:True 239:True 240:True 241:True 242:True 243:True 244:True 245:True 246:True 247:True 248:True 249:True 250:True 251:True 252:True 253:True 254:True 255:True 256:True 257:True 258:True 259:True 260:True 261:False 262:False 263:False 264:False 265:False 266:False 267:False 268:False 269:False 270:False 271:False 272:False 273:False 274:False 275:False 276:False 277:False 278:False 279:False 280:False 281:False 282:False 283:False 284:False 285:False 286:False 287:False 288:False 289:False 290:False 291:False 292:False 293:False 294:False 295:False 296:False 297:False 298:False 299:False 300:False 301:False 302:False 303:False 304:False 305:False 306:False 307:False 308:False 309:False 310:False 311:False 312:False 313:False 314:False 315:False 316:False 317:False 318:False 319:False 320:False 321:False 322:False 323:False 324:False 325:False 326:False 327:False 328:False 329:False 330:False 331:False 332:False 333:False 334:False 335:False 336:False 337:False 338:False 339:False 340:False 341:False 342:False 343:False 344:False 345:False 346:False 347:False 348:False 349:False 350:False 351:False 352:False 353:False 354:False 355:False 356:False 357:False 358:False 359:False 360:False 361:False 362:False 363:False 364:False 365:False 366:False 367:False 368:False 369:False 370:False 371:False 372:False 373:False 374:False 375:False 376:False 377:False 378:False 379:False 380:False 381:False 382:False\n",
      "I1208 12:27:37.159359 139883775852736 run_factoid.py:447] token_is_max_context: 11:False 12:False 13:False 14:False 15:False 16:False 17:False 18:False 19:False 20:False 21:False 22:False 23:False 24:False 25:False 26:False 27:False 28:False 29:False 30:False 31:False 32:False 33:False 34:False 35:False 36:False 37:False 38:False 39:False 40:False 41:False 42:False 43:False 44:False 45:False 46:False 47:False 48:False 49:False 50:False 51:False 52:False 53:False 54:False 55:False 56:False 57:False 58:False 59:False 60:False 61:False 62:False 63:False 64:False 65:False 66:False 67:False 68:False 69:False 70:False 71:False 72:False 73:False 74:False 75:False 76:False 77:False 78:False 79:False 80:False 81:False 82:False 83:False 84:False 85:False 86:False 87:False 88:False 89:False 90:False 91:False 92:False 93:False 94:False 95:False 96:False 97:False 98:False 99:False 100:False 101:False 102:False 103:False 104:False 105:False 106:False 107:False 108:False 109:False 110:False 111:False 112:False 113:False 114:False 115:False 116:False 117:False 118:False 119:False 120:False 121:False 122:False 123:False 124:False 125:False 126:False 127:False 128:False 129:False 130:False 131:False 132:False 133:True 134:True 135:True 136:True 137:True 138:True 139:True 140:True 141:True 142:True 143:True 144:True 145:True 146:True 147:True 148:True 149:True 150:True 151:True 152:True 153:True 154:True 155:True 156:True 157:True 158:True 159:True 160:True 161:True 162:True 163:True 164:True 165:True 166:True 167:True 168:True 169:True 170:True 171:True 172:True 173:True 174:True 175:True 176:True 177:True 178:True 179:True 180:True 181:True 182:True 183:True 184:True 185:True 186:True 187:True 188:True 189:True 190:True 191:True 192:True 193:True 194:True 195:True 196:True 197:True 198:True 199:True 200:True 201:True 202:True 203:True 204:True 205:True 206:True 207:True 208:True 209:True 210:True 211:True 212:True 213:True 214:True 215:True 216:True 217:True 218:True 219:True 220:True 221:True 222:True 223:True 224:True 225:True 226:True 227:True 228:True 229:True 230:True 231:True 232:True 233:True 234:True 235:True 236:True 237:True 238:True 239:True 240:True 241:True 242:True 243:True 244:True 245:True 246:True 247:True 248:True 249:True 250:True 251:True 252:True 253:True 254:True 255:True 256:True 257:True 258:True 259:True 260:True 261:False 262:False 263:False 264:False 265:False 266:False 267:False 268:False 269:False 270:False 271:False 272:False 273:False 274:False 275:False 276:False 277:False 278:False 279:False 280:False 281:False 282:False 283:False 284:False 285:False 286:False 287:False 288:False 289:False 290:False 291:False 292:False 293:False 294:False 295:False 296:False 297:False 298:False 299:False 300:False 301:False 302:False 303:False 304:False 305:False 306:False 307:False 308:False 309:False 310:False 311:False 312:False 313:False 314:False 315:False 316:False 317:False 318:False 319:False 320:False 321:False 322:False 323:False 324:False 325:False 326:False 327:False 328:False 329:False 330:False 331:False 332:False 333:False 334:False 335:False 336:False 337:False 338:False 339:False 340:False 341:False 342:False 343:False 344:False 345:False 346:False 347:False 348:False 349:False 350:False 351:False 352:False 353:False 354:False 355:False 356:False 357:False 358:False 359:False 360:False 361:False 362:False 363:False 364:False 365:False 366:False 367:False 368:False 369:False 370:False 371:False 372:False 373:False 374:False 375:False 376:False 377:False 378:False 379:False 380:False 381:False 382:False\n",
      "INFO:tensorflow:input_ids: 101 2091 1103 9505 12864 1113 5351 17898 1116 136 102 117 1105 1103 1928 2805 1159 1206 1172 1108 3453 119 121 212 1955 119 4376 1904 117 17350 119 4335 212 3383 119 5004 1904 117 1105 4859 119 1512 212 3746 119 2539 1904 117 3569 119 153 21678 2137 1125 170 5409 1750 2805 1159 1190 26574 1708 118 157 2162 15499 117 1133 170 12763 2805 1159 1114 22157 2137 119 1109 8458 13950 1127 14758 1118 1103 19497 1708 7432 1111 1171 2489 1105 3420 2489 119 3458 2686 3228 1115 4420 5165 1114 153 21678 2137 1125 12763 2112 19807 1891 19497 1708 7432 1111 1171 2489 1105 3420 2489 1114 1343 5165 1114 1168 12814 3377 119 3458 1871 1108 1107 8080 1114 1103 2166 9505 119 164 1851 117 3882 117 4335 166 27762 162 117 3084 2393 164 4335 166 2103 1115 1103 3073 19807 5838 19497 1708 7432 1111 1171 2489 1105 3420 2489 1127 126 119 5385 212 122 119 1572 1105 128 119 4991 212 122 119 4775 1107 1103 26574 1708 118 157 2162 15499 1372 117 126 119 5556 212 122 119 3081 1105 128 119 1492 212 122 119 4925 3569 1107 1103 153 21678 2137 1372 113 153 134 119 5385 1604 114 119 164 4335 166 1335 1103 2812 118 1146 9355 1104 1367 1808 117 1103 19497 1708 7432 5409 3549 1107 1103 1160 2114 1112 3402 1114 3073 19807 5838 4718 119 1438 117 1175 1108 1185 2418 5408 1206 1103 1172 1107 1103 2112 19807 1891 19497 1708 7432 1111 1171 2489 1105 3420 2489 119 164 4335 166 1109 5752 6547 1103 2686 1106 1103 3860 2610 3773 1104 2991 7918 1105 23730 1104 19245 9397 117 1134 1127 2416 1118 1103 9455 14637 11970 1190 6187 10294 18778 1183 119 164 4335 166 1247 1127 1317 3209 13004 1107 1142 27154 118 3622 119 1752 117 1111 1199 13950 117 1103 2233 3622 1108 1359 1113 3860 1353 1295 1104 1529 2527 1105 6876 2060 132 2456 117 1103 16421 1164 1103 13950 1431 1129 9829 1114 15597 119 2307 117 1211 1104 1103 1529 2527 1127 18675 1884 13252 1204 2025 117 1105 1103 3654 2554 1108 15543 1106 102\n",
      "I1208 12:27:37.159461 139883775852736 run_factoid.py:449] input_ids: 101 2091 1103 9505 12864 1113 5351 17898 1116 136 102 117 1105 1103 1928 2805 1159 1206 1172 1108 3453 119 121 212 1955 119 4376 1904 117 17350 119 4335 212 3383 119 5004 1904 117 1105 4859 119 1512 212 3746 119 2539 1904 117 3569 119 153 21678 2137 1125 170 5409 1750 2805 1159 1190 26574 1708 118 157 2162 15499 117 1133 170 12763 2805 1159 1114 22157 2137 119 1109 8458 13950 1127 14758 1118 1103 19497 1708 7432 1111 1171 2489 1105 3420 2489 119 3458 2686 3228 1115 4420 5165 1114 153 21678 2137 1125 12763 2112 19807 1891 19497 1708 7432 1111 1171 2489 1105 3420 2489 1114 1343 5165 1114 1168 12814 3377 119 3458 1871 1108 1107 8080 1114 1103 2166 9505 119 164 1851 117 3882 117 4335 166 27762 162 117 3084 2393 164 4335 166 2103 1115 1103 3073 19807 5838 19497 1708 7432 1111 1171 2489 1105 3420 2489 1127 126 119 5385 212 122 119 1572 1105 128 119 4991 212 122 119 4775 1107 1103 26574 1708 118 157 2162 15499 1372 117 126 119 5556 212 122 119 3081 1105 128 119 1492 212 122 119 4925 3569 1107 1103 153 21678 2137 1372 113 153 134 119 5385 1604 114 119 164 4335 166 1335 1103 2812 118 1146 9355 1104 1367 1808 117 1103 19497 1708 7432 5409 3549 1107 1103 1160 2114 1112 3402 1114 3073 19807 5838 4718 119 1438 117 1175 1108 1185 2418 5408 1206 1103 1172 1107 1103 2112 19807 1891 19497 1708 7432 1111 1171 2489 1105 3420 2489 119 164 4335 166 1109 5752 6547 1103 2686 1106 1103 3860 2610 3773 1104 2991 7918 1105 23730 1104 19245 9397 117 1134 1127 2416 1118 1103 9455 14637 11970 1190 6187 10294 18778 1183 119 164 4335 166 1247 1127 1317 3209 13004 1107 1142 27154 118 3622 119 1752 117 1111 1199 13950 117 1103 2233 3622 1108 1359 1113 3860 1353 1295 1104 1529 2527 1105 6876 2060 132 2456 117 1103 16421 1164 1103 13950 1431 1129 9829 1114 15597 119 2307 117 1211 1104 1103 1529 2527 1127 18675 1884 13252 1204 2025 117 1105 1103 3654 2554 1108 15543 1106 102\n",
      "INFO:tensorflow:input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      "I1208 12:27:37.159552 139883775852736 run_factoid.py:451] input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      "INFO:tensorflow:segment_ids: 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      "I1208 12:27:37.159641 139883775852736 run_factoid.py:453] segment_ids: 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      "INFO:tensorflow:*** Example ***\n",
      "I1208 12:27:37.161442 139883775852736 run_factoid.py:438] *** Example ***\n",
      "INFO:tensorflow:unique_id: 1000000051\n",
      "I1208 12:27:37.161504 139883775852736 run_factoid.py:439] unique_id: 1000000051\n",
      "INFO:tensorflow:example_index: 8\n",
      "I1208 12:27:37.161541 139883775852736 run_factoid.py:440] example_index: 8\n",
      "INFO:tensorflow:doc_span_index: 11\n",
      "I1208 12:27:37.161576 139883775852736 run_factoid.py:441] doc_span_index: 11\n",
      "INFO:tensorflow:tokens: [CLS] Do the findings depend on patient demographic ##s ? [SEP] , 54 ] Yao Y , et al [ 54 ] reported that the pre ##oper ##ative VA ##S scores for back pain and leg pain were 5 . 88 ± 1 . 24 and 7 . 05 ± 1 . 08 in the MI ##S - T ##L ##IF group , 5 . 92 ± 1 . 33 and 7 . 13 ± 1 . 09 respectively in the P ##EL ##D group ( P = . 88 ##8 ) . [ 54 ] At the follow - up duration of 12 months , the VA ##S scores significantly reduced in the two groups as compared with pre ##oper ##ative values . However , there was no significant differences between the them in the post ##oper ##ation VA ##S scores for back pain and leg pain . [ 54 ] The authors attributed the results to the relatively larger injury of soft tissue and disruption of spinal stability , which were caused by the inter ##body fusion than disc ##ec ##tom ##y . [ 54 ] There were several potential limitations in this meta - analysis . First , for some outcomes , the data analysis was based on relatively small number of included studies and sample size ; thus , the conclusions about the outcomes should be interpreted with caution . Second , most of the included studies were retrospective co ##hor ##t study , and the grade evidence was inferior to that of RC ##T ##s . Third , despite we performed sensitivity analysis and subgroup analysis to explore the der ##ivation of he ##tero ##gene ##ity , no valuable information was found . We thought that some potential reasons may account for the great he ##tero ##gene ##ity , including patients ’ characteristics ( age , sex , B ##MI , type of disc her ##nia ##tion , and surgical segment ) , duration of follow - up , case definition , and surgical approaches . These factors may have an impact on our results . thus , considering these limitations , caution is advised when interpret ##ing our findings and applying them into the clinical practice . In conclusion , the present meta - analysis of 14 [SEP]\n",
      "I1208 12:27:37.161699 139883775852736 run_factoid.py:443] tokens: [CLS] Do the findings depend on patient demographic ##s ? [SEP] , 54 ] Yao Y , et al [ 54 ] reported that the pre ##oper ##ative VA ##S scores for back pain and leg pain were 5 . 88 ± 1 . 24 and 7 . 05 ± 1 . 08 in the MI ##S - T ##L ##IF group , 5 . 92 ± 1 . 33 and 7 . 13 ± 1 . 09 respectively in the P ##EL ##D group ( P = . 88 ##8 ) . [ 54 ] At the follow - up duration of 12 months , the VA ##S scores significantly reduced in the two groups as compared with pre ##oper ##ative values . However , there was no significant differences between the them in the post ##oper ##ation VA ##S scores for back pain and leg pain . [ 54 ] The authors attributed the results to the relatively larger injury of soft tissue and disruption of spinal stability , which were caused by the inter ##body fusion than disc ##ec ##tom ##y . [ 54 ] There were several potential limitations in this meta - analysis . First , for some outcomes , the data analysis was based on relatively small number of included studies and sample size ; thus , the conclusions about the outcomes should be interpreted with caution . Second , most of the included studies were retrospective co ##hor ##t study , and the grade evidence was inferior to that of RC ##T ##s . Third , despite we performed sensitivity analysis and subgroup analysis to explore the der ##ivation of he ##tero ##gene ##ity , no valuable information was found . We thought that some potential reasons may account for the great he ##tero ##gene ##ity , including patients ’ characteristics ( age , sex , B ##MI , type of disc her ##nia ##tion , and surgical segment ) , duration of follow - up , case definition , and surgical approaches . These factors may have an impact on our results . thus , considering these limitations , caution is advised when interpret ##ing our findings and applying them into the clinical practice . In conclusion , the present meta - analysis of 14 [SEP]\n",
      "INFO:tensorflow:token_to_orig_map: 11:848 12:848 13:848 14:849 15:850 16:850 17:851 18:852 19:852 20:852 21:852 22:853 23:854 24:855 25:856 26:856 27:856 28:857 29:857 30:858 31:859 32:860 33:861 34:862 35:863 36:864 37:865 38:866 39:866 40:866 41:867 42:868 43:868 44:868 45:869 46:870 47:870 48:870 49:871 50:872 51:872 52:872 53:873 54:874 55:875 56:875 57:875 58:876 59:876 60:876 61:877 62:877 63:878 64:878 65:878 66:879 67:880 68:880 69:880 70:881 71:882 72:882 73:882 74:883 75:884 76:884 77:884 78:885 79:886 80:887 81:888 82:888 83:888 84:889 85:890 86:890 87:891 88:892 89:892 90:892 91:892 92:892 93:892 94:892 95:892 96:893 97:894 98:895 99:895 100:895 101:896 102:897 103:898 104:899 105:899 106:900 107:901 108:901 109:902 110:903 111:904 112:905 113:906 114:907 115:908 116:909 117:910 118:911 119:912 120:912 121:912 122:913 123:913 124:914 125:914 126:915 127:916 128:917 129:918 130:919 131:920 132:921 133:922 134:923 135:924 136:925 137:925 138:925 139:926 140:926 141:927 142:928 143:929 144:930 145:931 146:932 147:933 148:933 149:933 150:933 151:933 152:934 153:935 154:936 155:937 156:938 157:939 158:940 159:941 160:942 161:943 162:944 163:945 164:946 165:947 166:948 167:949 168:950 169:951 170:951 171:952 172:953 173:954 174:955 175:956 176:957 177:957 178:958 179:959 180:960 181:960 182:960 183:960 184:960 185:960 186:960 187:960 188:961 189:962 190:963 191:964 192:965 193:966 194:967 195:968 196:968 197:968 198:968 199:969 200:969 201:970 202:971 203:972 204:972 205:973 206:974 207:975 208:976 209:977 210:978 211:979 212:980 213:981 214:982 215:983 216:984 217:985 218:986 219:987 220:987 221:988 222:988 223:989 224:990 225:991 226:992 227:993 228:994 229:995 230:996 231:997 232:998 233:998 234:999 235:999 236:1000 237:1001 238:1002 239:1003 240:1004 241:1005 242:1006 243:1007 244:1007 245:1007 246:1008 247:1008 248:1009 249:1010 250:1011 251:1012 252:1013 253:1014 254:1015 255:1016 256:1017 257:1018 258:1018 259:1018 260:1018 261:1019 262:1019 263:1020 264:1021 265:1022 266:1023 267:1024 268:1025 269:1026 270:1027 271:1028 272:1029 273:1030 274:1031 275:1031 276:1032 277:1033 278:1033 279:1033 280:1033 281:1033 282:1034 283:1035 284:1036 285:1037 286:1038 287:1038 288:1039 289:1040 290:1041 291:1042 292:1043 293:1044 294:1045 295:1046 296:1047 297:1048 298:1049 299:1050 300:1050 301:1050 302:1050 303:1050 304:1051 305:1052 306:1052 307:1053 308:1054 309:1054 310:1054 311:1055 312:1055 313:1056 314:1056 315:1056 316:1057 317:1058 318:1059 319:1060 320:1060 321:1060 322:1060 323:1061 324:1062 325:1063 326:1063 327:1063 328:1064 329:1065 330:1066 331:1066 332:1066 333:1066 334:1067 335:1068 336:1068 337:1069 338:1070 339:1071 340:1071 341:1072 342:1073 343:1074 344:1075 345:1076 346:1077 347:1078 348:1079 349:1080 350:1080 351:1081 352:1081 353:1082 354:1083 355:1084 356:1084 357:1085 358:1086 359:1087 360:1088 361:1089 362:1089 363:1090 364:1091 365:1092 366:1093 367:1094 368:1095 369:1096 370:1097 371:1098 372:1098 373:1099 374:1100 375:1100 376:1101 377:1102 378:1103 379:1103 380:1103 381:1104 382:1105\n",
      "I1208 12:27:37.161824 139883775852736 run_factoid.py:445] token_to_orig_map: 11:848 12:848 13:848 14:849 15:850 16:850 17:851 18:852 19:852 20:852 21:852 22:853 23:854 24:855 25:856 26:856 27:856 28:857 29:857 30:858 31:859 32:860 33:861 34:862 35:863 36:864 37:865 38:866 39:866 40:866 41:867 42:868 43:868 44:868 45:869 46:870 47:870 48:870 49:871 50:872 51:872 52:872 53:873 54:874 55:875 56:875 57:875 58:876 59:876 60:876 61:877 62:877 63:878 64:878 65:878 66:879 67:880 68:880 69:880 70:881 71:882 72:882 73:882 74:883 75:884 76:884 77:884 78:885 79:886 80:887 81:888 82:888 83:888 84:889 85:890 86:890 87:891 88:892 89:892 90:892 91:892 92:892 93:892 94:892 95:892 96:893 97:894 98:895 99:895 100:895 101:896 102:897 103:898 104:899 105:899 106:900 107:901 108:901 109:902 110:903 111:904 112:905 113:906 114:907 115:908 116:909 117:910 118:911 119:912 120:912 121:912 122:913 123:913 124:914 125:914 126:915 127:916 128:917 129:918 130:919 131:920 132:921 133:922 134:923 135:924 136:925 137:925 138:925 139:926 140:926 141:927 142:928 143:929 144:930 145:931 146:932 147:933 148:933 149:933 150:933 151:933 152:934 153:935 154:936 155:937 156:938 157:939 158:940 159:941 160:942 161:943 162:944 163:945 164:946 165:947 166:948 167:949 168:950 169:951 170:951 171:952 172:953 173:954 174:955 175:956 176:957 177:957 178:958 179:959 180:960 181:960 182:960 183:960 184:960 185:960 186:960 187:960 188:961 189:962 190:963 191:964 192:965 193:966 194:967 195:968 196:968 197:968 198:968 199:969 200:969 201:970 202:971 203:972 204:972 205:973 206:974 207:975 208:976 209:977 210:978 211:979 212:980 213:981 214:982 215:983 216:984 217:985 218:986 219:987 220:987 221:988 222:988 223:989 224:990 225:991 226:992 227:993 228:994 229:995 230:996 231:997 232:998 233:998 234:999 235:999 236:1000 237:1001 238:1002 239:1003 240:1004 241:1005 242:1006 243:1007 244:1007 245:1007 246:1008 247:1008 248:1009 249:1010 250:1011 251:1012 252:1013 253:1014 254:1015 255:1016 256:1017 257:1018 258:1018 259:1018 260:1018 261:1019 262:1019 263:1020 264:1021 265:1022 266:1023 267:1024 268:1025 269:1026 270:1027 271:1028 272:1029 273:1030 274:1031 275:1031 276:1032 277:1033 278:1033 279:1033 280:1033 281:1033 282:1034 283:1035 284:1036 285:1037 286:1038 287:1038 288:1039 289:1040 290:1041 291:1042 292:1043 293:1044 294:1045 295:1046 296:1047 297:1048 298:1049 299:1050 300:1050 301:1050 302:1050 303:1050 304:1051 305:1052 306:1052 307:1053 308:1054 309:1054 310:1054 311:1055 312:1055 313:1056 314:1056 315:1056 316:1057 317:1058 318:1059 319:1060 320:1060 321:1060 322:1060 323:1061 324:1062 325:1063 326:1063 327:1063 328:1064 329:1065 330:1066 331:1066 332:1066 333:1066 334:1067 335:1068 336:1068 337:1069 338:1070 339:1071 340:1071 341:1072 342:1073 343:1074 344:1075 345:1076 346:1077 347:1078 348:1079 349:1080 350:1080 351:1081 352:1081 353:1082 354:1083 355:1084 356:1084 357:1085 358:1086 359:1087 360:1088 361:1089 362:1089 363:1090 364:1091 365:1092 366:1093 367:1094 368:1095 369:1096 370:1097 371:1098 372:1098 373:1099 374:1100 375:1100 376:1101 377:1102 378:1103 379:1103 380:1103 381:1104 382:1105\n",
      "INFO:tensorflow:token_is_max_context: 11:False 12:False 13:False 14:False 15:False 16:False 17:False 18:False 19:False 20:False 21:False 22:False 23:False 24:False 25:False 26:False 27:False 28:False 29:False 30:False 31:False 32:False 33:False 34:False 35:False 36:False 37:False 38:False 39:False 40:False 41:False 42:False 43:False 44:False 45:False 46:False 47:False 48:False 49:False 50:False 51:False 52:False 53:False 54:False 55:False 56:False 57:False 58:False 59:False 60:False 61:False 62:False 63:False 64:False 65:False 66:False 67:False 68:False 69:False 70:False 71:False 72:False 73:False 74:False 75:False 76:False 77:False 78:False 79:False 80:False 81:False 82:False 83:False 84:False 85:False 86:False 87:False 88:False 89:False 90:False 91:False 92:False 93:False 94:False 95:False 96:False 97:False 98:False 99:False 100:False 101:False 102:False 103:False 104:False 105:False 106:False 107:False 108:False 109:False 110:False 111:False 112:False 113:False 114:False 115:False 116:False 117:False 118:False 119:False 120:False 121:False 122:False 123:False 124:False 125:False 126:False 127:False 128:False 129:False 130:False 131:False 132:False 133:True 134:True 135:True 136:True 137:True 138:True 139:True 140:True 141:True 142:True 143:True 144:True 145:True 146:True 147:True 148:True 149:True 150:True 151:True 152:True 153:True 154:True 155:True 156:True 157:True 158:True 159:True 160:True 161:True 162:True 163:True 164:True 165:True 166:True 167:True 168:True 169:True 170:True 171:True 172:True 173:True 174:True 175:True 176:True 177:True 178:True 179:True 180:True 181:True 182:True 183:True 184:True 185:True 186:True 187:True 188:True 189:True 190:True 191:True 192:True 193:True 194:True 195:True 196:True 197:True 198:True 199:True 200:True 201:True 202:True 203:True 204:True 205:True 206:True 207:True 208:True 209:True 210:True 211:True 212:True 213:True 214:True 215:True 216:True 217:True 218:True 219:True 220:True 221:True 222:True 223:True 224:True 225:True 226:True 227:True 228:True 229:True 230:True 231:True 232:True 233:True 234:True 235:True 236:True 237:True 238:True 239:True 240:True 241:True 242:True 243:True 244:True 245:True 246:True 247:True 248:True 249:True 250:True 251:True 252:True 253:True 254:True 255:True 256:True 257:True 258:True 259:True 260:True 261:False 262:False 263:False 264:False 265:False 266:False 267:False 268:False 269:False 270:False 271:False 272:False 273:False 274:False 275:False 276:False 277:False 278:False 279:False 280:False 281:False 282:False 283:False 284:False 285:False 286:False 287:False 288:False 289:False 290:False 291:False 292:False 293:False 294:False 295:False 296:False 297:False 298:False 299:False 300:False 301:False 302:False 303:False 304:False 305:False 306:False 307:False 308:False 309:False 310:False 311:False 312:False 313:False 314:False 315:False 316:False 317:False 318:False 319:False 320:False 321:False 322:False 323:False 324:False 325:False 326:False 327:False 328:False 329:False 330:False 331:False 332:False 333:False 334:False 335:False 336:False 337:False 338:False 339:False 340:False 341:False 342:False 343:False 344:False 345:False 346:False 347:False 348:False 349:False 350:False 351:False 352:False 353:False 354:False 355:False 356:False 357:False 358:False 359:False 360:False 361:False 362:False 363:False 364:False 365:False 366:False 367:False 368:False 369:False 370:False 371:False 372:False 373:False 374:False 375:False 376:False 377:False 378:False 379:False 380:False 381:False 382:False\n",
      "I1208 12:27:37.161932 139883775852736 run_factoid.py:447] token_is_max_context: 11:False 12:False 13:False 14:False 15:False 16:False 17:False 18:False 19:False 20:False 21:False 22:False 23:False 24:False 25:False 26:False 27:False 28:False 29:False 30:False 31:False 32:False 33:False 34:False 35:False 36:False 37:False 38:False 39:False 40:False 41:False 42:False 43:False 44:False 45:False 46:False 47:False 48:False 49:False 50:False 51:False 52:False 53:False 54:False 55:False 56:False 57:False 58:False 59:False 60:False 61:False 62:False 63:False 64:False 65:False 66:False 67:False 68:False 69:False 70:False 71:False 72:False 73:False 74:False 75:False 76:False 77:False 78:False 79:False 80:False 81:False 82:False 83:False 84:False 85:False 86:False 87:False 88:False 89:False 90:False 91:False 92:False 93:False 94:False 95:False 96:False 97:False 98:False 99:False 100:False 101:False 102:False 103:False 104:False 105:False 106:False 107:False 108:False 109:False 110:False 111:False 112:False 113:False 114:False 115:False 116:False 117:False 118:False 119:False 120:False 121:False 122:False 123:False 124:False 125:False 126:False 127:False 128:False 129:False 130:False 131:False 132:False 133:True 134:True 135:True 136:True 137:True 138:True 139:True 140:True 141:True 142:True 143:True 144:True 145:True 146:True 147:True 148:True 149:True 150:True 151:True 152:True 153:True 154:True 155:True 156:True 157:True 158:True 159:True 160:True 161:True 162:True 163:True 164:True 165:True 166:True 167:True 168:True 169:True 170:True 171:True 172:True 173:True 174:True 175:True 176:True 177:True 178:True 179:True 180:True 181:True 182:True 183:True 184:True 185:True 186:True 187:True 188:True 189:True 190:True 191:True 192:True 193:True 194:True 195:True 196:True 197:True 198:True 199:True 200:True 201:True 202:True 203:True 204:True 205:True 206:True 207:True 208:True 209:True 210:True 211:True 212:True 213:True 214:True 215:True 216:True 217:True 218:True 219:True 220:True 221:True 222:True 223:True 224:True 225:True 226:True 227:True 228:True 229:True 230:True 231:True 232:True 233:True 234:True 235:True 236:True 237:True 238:True 239:True 240:True 241:True 242:True 243:True 244:True 245:True 246:True 247:True 248:True 249:True 250:True 251:True 252:True 253:True 254:True 255:True 256:True 257:True 258:True 259:True 260:True 261:False 262:False 263:False 264:False 265:False 266:False 267:False 268:False 269:False 270:False 271:False 272:False 273:False 274:False 275:False 276:False 277:False 278:False 279:False 280:False 281:False 282:False 283:False 284:False 285:False 286:False 287:False 288:False 289:False 290:False 291:False 292:False 293:False 294:False 295:False 296:False 297:False 298:False 299:False 300:False 301:False 302:False 303:False 304:False 305:False 306:False 307:False 308:False 309:False 310:False 311:False 312:False 313:False 314:False 315:False 316:False 317:False 318:False 319:False 320:False 321:False 322:False 323:False 324:False 325:False 326:False 327:False 328:False 329:False 330:False 331:False 332:False 333:False 334:False 335:False 336:False 337:False 338:False 339:False 340:False 341:False 342:False 343:False 344:False 345:False 346:False 347:False 348:False 349:False 350:False 351:False 352:False 353:False 354:False 355:False 356:False 357:False 358:False 359:False 360:False 361:False 362:False 363:False 364:False 365:False 366:False 367:False 368:False 369:False 370:False 371:False 372:False 373:False 374:False 375:False 376:False 377:False 378:False 379:False 380:False 381:False 382:False\n",
      "INFO:tensorflow:input_ids: 101 2091 1103 9505 12864 1113 5351 17898 1116 136 102 117 4335 166 27762 162 117 3084 2393 164 4335 166 2103 1115 1103 3073 19807 5838 19497 1708 7432 1111 1171 2489 1105 3420 2489 1127 126 119 5385 212 122 119 1572 1105 128 119 4991 212 122 119 4775 1107 1103 26574 1708 118 157 2162 15499 1372 117 126 119 5556 212 122 119 3081 1105 128 119 1492 212 122 119 4925 3569 1107 1103 153 21678 2137 1372 113 153 134 119 5385 1604 114 119 164 4335 166 1335 1103 2812 118 1146 9355 1104 1367 1808 117 1103 19497 1708 7432 5409 3549 1107 1103 1160 2114 1112 3402 1114 3073 19807 5838 4718 119 1438 117 1175 1108 1185 2418 5408 1206 1103 1172 1107 1103 2112 19807 1891 19497 1708 7432 1111 1171 2489 1105 3420 2489 119 164 4335 166 1109 5752 6547 1103 2686 1106 1103 3860 2610 3773 1104 2991 7918 1105 23730 1104 19245 9397 117 1134 1127 2416 1118 1103 9455 14637 11970 1190 6187 10294 18778 1183 119 164 4335 166 1247 1127 1317 3209 13004 1107 1142 27154 118 3622 119 1752 117 1111 1199 13950 117 1103 2233 3622 1108 1359 1113 3860 1353 1295 1104 1529 2527 1105 6876 2060 132 2456 117 1103 16421 1164 1103 13950 1431 1129 9829 1114 15597 119 2307 117 1211 1104 1103 1529 2527 1127 18675 1884 13252 1204 2025 117 1105 1103 3654 2554 1108 15543 1106 1115 1104 25157 1942 1116 119 4180 117 2693 1195 1982 15750 3622 1105 23470 3622 1106 8664 1103 4167 16617 1104 1119 25710 27054 1785 117 1185 7468 1869 1108 1276 119 1284 1354 1115 1199 3209 3672 1336 3300 1111 1103 1632 1119 25710 27054 1785 117 1259 4420 787 5924 113 1425 117 2673 117 139 14038 117 2076 1104 6187 1123 5813 2116 117 1105 13467 6441 114 117 9355 1104 2812 118 1146 117 1692 5754 117 1105 13467 8015 119 1636 5320 1336 1138 1126 3772 1113 1412 2686 119 2456 117 6103 1292 13004 117 15597 1110 9213 1165 19348 1158 1412 9505 1105 11892 1172 1154 1103 7300 2415 119 1130 6593 117 1103 1675 27154 118 3622 1104 1489 102\n",
      "I1208 12:27:37.162033 139883775852736 run_factoid.py:449] input_ids: 101 2091 1103 9505 12864 1113 5351 17898 1116 136 102 117 4335 166 27762 162 117 3084 2393 164 4335 166 2103 1115 1103 3073 19807 5838 19497 1708 7432 1111 1171 2489 1105 3420 2489 1127 126 119 5385 212 122 119 1572 1105 128 119 4991 212 122 119 4775 1107 1103 26574 1708 118 157 2162 15499 1372 117 126 119 5556 212 122 119 3081 1105 128 119 1492 212 122 119 4925 3569 1107 1103 153 21678 2137 1372 113 153 134 119 5385 1604 114 119 164 4335 166 1335 1103 2812 118 1146 9355 1104 1367 1808 117 1103 19497 1708 7432 5409 3549 1107 1103 1160 2114 1112 3402 1114 3073 19807 5838 4718 119 1438 117 1175 1108 1185 2418 5408 1206 1103 1172 1107 1103 2112 19807 1891 19497 1708 7432 1111 1171 2489 1105 3420 2489 119 164 4335 166 1109 5752 6547 1103 2686 1106 1103 3860 2610 3773 1104 2991 7918 1105 23730 1104 19245 9397 117 1134 1127 2416 1118 1103 9455 14637 11970 1190 6187 10294 18778 1183 119 164 4335 166 1247 1127 1317 3209 13004 1107 1142 27154 118 3622 119 1752 117 1111 1199 13950 117 1103 2233 3622 1108 1359 1113 3860 1353 1295 1104 1529 2527 1105 6876 2060 132 2456 117 1103 16421 1164 1103 13950 1431 1129 9829 1114 15597 119 2307 117 1211 1104 1103 1529 2527 1127 18675 1884 13252 1204 2025 117 1105 1103 3654 2554 1108 15543 1106 1115 1104 25157 1942 1116 119 4180 117 2693 1195 1982 15750 3622 1105 23470 3622 1106 8664 1103 4167 16617 1104 1119 25710 27054 1785 117 1185 7468 1869 1108 1276 119 1284 1354 1115 1199 3209 3672 1336 3300 1111 1103 1632 1119 25710 27054 1785 117 1259 4420 787 5924 113 1425 117 2673 117 139 14038 117 2076 1104 6187 1123 5813 2116 117 1105 13467 6441 114 117 9355 1104 2812 118 1146 117 1692 5754 117 1105 13467 8015 119 1636 5320 1336 1138 1126 3772 1113 1412 2686 119 2456 117 6103 1292 13004 117 15597 1110 9213 1165 19348 1158 1412 9505 1105 11892 1172 1154 1103 7300 2415 119 1130 6593 117 1103 1675 27154 118 3622 1104 1489 102\n",
      "INFO:tensorflow:input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      "I1208 12:27:37.162125 139883775852736 run_factoid.py:451] input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      "INFO:tensorflow:segment_ids: 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      "I1208 12:27:37.162215 139883775852736 run_factoid.py:453] segment_ids: 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      "INFO:tensorflow:*** Example ***\n",
      "I1208 12:27:37.163712 139883775852736 run_factoid.py:438] *** Example ***\n",
      "INFO:tensorflow:unique_id: 1000000052\n",
      "I1208 12:27:37.163770 139883775852736 run_factoid.py:439] unique_id: 1000000052\n",
      "INFO:tensorflow:example_index: 8\n",
      "I1208 12:27:37.163807 139883775852736 run_factoid.py:440] example_index: 8\n",
      "INFO:tensorflow:doc_span_index: 12\n",
      "I1208 12:27:37.163842 139883775852736 run_factoid.py:441] doc_span_index: 12\n",
      "INFO:tensorflow:tokens: [CLS] Do the findings depend on patient demographic ##s ? [SEP] VA ##S scores for back pain and leg pain . [ 54 ] The authors attributed the results to the relatively larger injury of soft tissue and disruption of spinal stability , which were caused by the inter ##body fusion than disc ##ec ##tom ##y . [ 54 ] There were several potential limitations in this meta - analysis . First , for some outcomes , the data analysis was based on relatively small number of included studies and sample size ; thus , the conclusions about the outcomes should be interpreted with caution . Second , most of the included studies were retrospective co ##hor ##t study , and the grade evidence was inferior to that of RC ##T ##s . Third , despite we performed sensitivity analysis and subgroup analysis to explore the der ##ivation of he ##tero ##gene ##ity , no valuable information was found . We thought that some potential reasons may account for the great he ##tero ##gene ##ity , including patients ’ characteristics ( age , sex , B ##MI , type of disc her ##nia ##tion , and surgical segment ) , duration of follow - up , case definition , and surgical approaches . These factors may have an impact on our results . thus , considering these limitations , caution is advised when interpret ##ing our findings and applying them into the clinical practice . In conclusion , the present meta - analysis of 14 studies suggested that , P ##EL ##D was associated with better effects and similar complications with other surge ##ries in the treatment of L ##D ##H . However , it also resulted in a higher re ##cu ##rrence rate . Considering the potential limitations in the present study , further large - scale , well - performed random ##ized trials are needed to verify our findings . [SEP]\n",
      "I1208 12:27:37.163947 139883775852736 run_factoid.py:443] tokens: [CLS] Do the findings depend on patient demographic ##s ? [SEP] VA ##S scores for back pain and leg pain . [ 54 ] The authors attributed the results to the relatively larger injury of soft tissue and disruption of spinal stability , which were caused by the inter ##body fusion than disc ##ec ##tom ##y . [ 54 ] There were several potential limitations in this meta - analysis . First , for some outcomes , the data analysis was based on relatively small number of included studies and sample size ; thus , the conclusions about the outcomes should be interpreted with caution . Second , most of the included studies were retrospective co ##hor ##t study , and the grade evidence was inferior to that of RC ##T ##s . Third , despite we performed sensitivity analysis and subgroup analysis to explore the der ##ivation of he ##tero ##gene ##ity , no valuable information was found . We thought that some potential reasons may account for the great he ##tero ##gene ##ity , including patients ’ characteristics ( age , sex , B ##MI , type of disc her ##nia ##tion , and surgical segment ) , duration of follow - up , case definition , and surgical approaches . These factors may have an impact on our results . thus , considering these limitations , caution is advised when interpret ##ing our findings and applying them into the clinical practice . In conclusion , the present meta - analysis of 14 studies suggested that , P ##EL ##D was associated with better effects and similar complications with other surge ##ries in the treatment of L ##D ##H . However , it also resulted in a higher re ##cu ##rrence rate . Considering the potential limitations in the present study , further large - scale , well - performed random ##ized trials are needed to verify our findings . [SEP]\n",
      "INFO:tensorflow:token_to_orig_map: 11:926 12:926 13:927 14:928 15:929 16:930 17:931 18:932 19:933 20:933 21:933 22:933 23:933 24:934 25:935 26:936 27:937 28:938 29:939 30:940 31:941 32:942 33:943 34:944 35:945 36:946 37:947 38:948 39:949 40:950 41:951 42:951 43:952 44:953 45:954 46:955 47:956 48:957 49:957 50:958 51:959 52:960 53:960 54:960 55:960 56:960 57:960 58:960 59:960 60:961 61:962 62:963 63:964 64:965 65:966 66:967 67:968 68:968 69:968 70:968 71:969 72:969 73:970 74:971 75:972 76:972 77:973 78:974 79:975 80:976 81:977 82:978 83:979 84:980 85:981 86:982 87:983 88:984 89:985 90:986 91:987 92:987 93:988 94:988 95:989 96:990 97:991 98:992 99:993 100:994 101:995 102:996 103:997 104:998 105:998 106:999 107:999 108:1000 109:1001 110:1002 111:1003 112:1004 113:1005 114:1006 115:1007 116:1007 117:1007 118:1008 119:1008 120:1009 121:1010 122:1011 123:1012 124:1013 125:1014 126:1015 127:1016 128:1017 129:1018 130:1018 131:1018 132:1018 133:1019 134:1019 135:1020 136:1021 137:1022 138:1023 139:1024 140:1025 141:1026 142:1027 143:1028 144:1029 145:1030 146:1031 147:1031 148:1032 149:1033 150:1033 151:1033 152:1033 153:1033 154:1034 155:1035 156:1036 157:1037 158:1038 159:1038 160:1039 161:1040 162:1041 163:1042 164:1043 165:1044 166:1045 167:1046 168:1047 169:1048 170:1049 171:1050 172:1050 173:1050 174:1050 175:1050 176:1051 177:1052 178:1052 179:1053 180:1054 181:1054 182:1054 183:1055 184:1055 185:1056 186:1056 187:1056 188:1057 189:1058 190:1059 191:1060 192:1060 193:1060 194:1060 195:1061 196:1062 197:1063 198:1063 199:1063 200:1064 201:1065 202:1066 203:1066 204:1066 205:1066 206:1067 207:1068 208:1068 209:1069 210:1070 211:1071 212:1071 213:1072 214:1073 215:1074 216:1075 217:1076 218:1077 219:1078 220:1079 221:1080 222:1080 223:1081 224:1081 225:1082 226:1083 227:1084 228:1084 229:1085 230:1086 231:1087 232:1088 233:1089 234:1089 235:1090 236:1091 237:1092 238:1093 239:1094 240:1095 241:1096 242:1097 243:1098 244:1098 245:1099 246:1100 247:1100 248:1101 249:1102 250:1103 251:1103 252:1103 253:1104 254:1105 255:1106 256:1107 257:1108 258:1108 259:1109 260:1109 261:1109 262:1110 263:1111 264:1112 265:1113 266:1114 267:1115 268:1116 269:1117 270:1118 271:1119 272:1120 273:1120 274:1121 275:1122 276:1123 277:1124 278:1125 279:1125 280:1125 281:1125 282:1126 283:1126 284:1127 285:1128 286:1129 287:1130 288:1131 289:1132 290:1133 291:1133 292:1133 293:1134 294:1134 295:1135 296:1136 297:1137 298:1138 299:1139 300:1140 301:1141 302:1142 303:1142 304:1143 305:1144 306:1144 307:1144 308:1144 309:1145 310:1145 311:1145 312:1146 313:1146 314:1147 315:1148 316:1149 317:1150 318:1151 319:1152 320:1153 321:1153\n",
      "I1208 12:27:37.164057 139883775852736 run_factoid.py:445] token_to_orig_map: 11:926 12:926 13:927 14:928 15:929 16:930 17:931 18:932 19:933 20:933 21:933 22:933 23:933 24:934 25:935 26:936 27:937 28:938 29:939 30:940 31:941 32:942 33:943 34:944 35:945 36:946 37:947 38:948 39:949 40:950 41:951 42:951 43:952 44:953 45:954 46:955 47:956 48:957 49:957 50:958 51:959 52:960 53:960 54:960 55:960 56:960 57:960 58:960 59:960 60:961 61:962 62:963 63:964 64:965 65:966 66:967 67:968 68:968 69:968 70:968 71:969 72:969 73:970 74:971 75:972 76:972 77:973 78:974 79:975 80:976 81:977 82:978 83:979 84:980 85:981 86:982 87:983 88:984 89:985 90:986 91:987 92:987 93:988 94:988 95:989 96:990 97:991 98:992 99:993 100:994 101:995 102:996 103:997 104:998 105:998 106:999 107:999 108:1000 109:1001 110:1002 111:1003 112:1004 113:1005 114:1006 115:1007 116:1007 117:1007 118:1008 119:1008 120:1009 121:1010 122:1011 123:1012 124:1013 125:1014 126:1015 127:1016 128:1017 129:1018 130:1018 131:1018 132:1018 133:1019 134:1019 135:1020 136:1021 137:1022 138:1023 139:1024 140:1025 141:1026 142:1027 143:1028 144:1029 145:1030 146:1031 147:1031 148:1032 149:1033 150:1033 151:1033 152:1033 153:1033 154:1034 155:1035 156:1036 157:1037 158:1038 159:1038 160:1039 161:1040 162:1041 163:1042 164:1043 165:1044 166:1045 167:1046 168:1047 169:1048 170:1049 171:1050 172:1050 173:1050 174:1050 175:1050 176:1051 177:1052 178:1052 179:1053 180:1054 181:1054 182:1054 183:1055 184:1055 185:1056 186:1056 187:1056 188:1057 189:1058 190:1059 191:1060 192:1060 193:1060 194:1060 195:1061 196:1062 197:1063 198:1063 199:1063 200:1064 201:1065 202:1066 203:1066 204:1066 205:1066 206:1067 207:1068 208:1068 209:1069 210:1070 211:1071 212:1071 213:1072 214:1073 215:1074 216:1075 217:1076 218:1077 219:1078 220:1079 221:1080 222:1080 223:1081 224:1081 225:1082 226:1083 227:1084 228:1084 229:1085 230:1086 231:1087 232:1088 233:1089 234:1089 235:1090 236:1091 237:1092 238:1093 239:1094 240:1095 241:1096 242:1097 243:1098 244:1098 245:1099 246:1100 247:1100 248:1101 249:1102 250:1103 251:1103 252:1103 253:1104 254:1105 255:1106 256:1107 257:1108 258:1108 259:1109 260:1109 261:1109 262:1110 263:1111 264:1112 265:1113 266:1114 267:1115 268:1116 269:1117 270:1118 271:1119 272:1120 273:1120 274:1121 275:1122 276:1123 277:1124 278:1125 279:1125 280:1125 281:1125 282:1126 283:1126 284:1127 285:1128 286:1129 287:1130 288:1131 289:1132 290:1133 291:1133 292:1133 293:1134 294:1134 295:1135 296:1136 297:1137 298:1138 299:1139 300:1140 301:1141 302:1142 303:1142 304:1143 305:1144 306:1144 307:1144 308:1144 309:1145 310:1145 311:1145 312:1146 313:1146 314:1147 315:1148 316:1149 317:1150 318:1151 319:1152 320:1153 321:1153\n",
      "INFO:tensorflow:token_is_max_context: 11:False 12:False 13:False 14:False 15:False 16:False 17:False 18:False 19:False 20:False 21:False 22:False 23:False 24:False 25:False 26:False 27:False 28:False 29:False 30:False 31:False 32:False 33:False 34:False 35:False 36:False 37:False 38:False 39:False 40:False 41:False 42:False 43:False 44:False 45:False 46:False 47:False 48:False 49:False 50:False 51:False 52:False 53:False 54:False 55:False 56:False 57:False 58:False 59:False 60:False 61:False 62:False 63:False 64:False 65:False 66:False 67:False 68:False 69:False 70:False 71:False 72:False 73:False 74:False 75:False 76:False 77:False 78:False 79:False 80:False 81:False 82:False 83:False 84:False 85:False 86:False 87:False 88:False 89:False 90:False 91:False 92:False 93:False 94:False 95:False 96:False 97:False 98:False 99:False 100:False 101:False 102:False 103:False 104:False 105:False 106:False 107:False 108:False 109:False 110:False 111:False 112:False 113:False 114:False 115:False 116:False 117:False 118:False 119:False 120:False 121:False 122:False 123:False 124:False 125:False 126:False 127:False 128:False 129:False 130:False 131:False 132:False 133:True 134:True 135:True 136:True 137:True 138:True 139:True 140:True 141:True 142:True 143:True 144:True 145:True 146:True 147:True 148:True 149:True 150:True 151:True 152:True 153:True 154:True 155:True 156:True 157:True 158:True 159:True 160:True 161:True 162:True 163:True 164:True 165:True 166:True 167:True 168:True 169:True 170:True 171:True 172:True 173:True 174:True 175:True 176:True 177:True 178:True 179:True 180:True 181:True 182:True 183:True 184:True 185:True 186:True 187:True 188:True 189:True 190:True 191:True 192:True 193:True 194:True 195:True 196:True 197:True 198:True 199:True 200:True 201:True 202:True 203:True 204:True 205:True 206:True 207:True 208:True 209:True 210:True 211:True 212:True 213:True 214:True 215:True 216:True 217:True 218:True 219:True 220:True 221:True 222:True 223:True 224:True 225:True 226:True 227:True 228:True 229:True 230:True 231:True 232:True 233:True 234:True 235:True 236:True 237:True 238:True 239:True 240:True 241:True 242:True 243:True 244:True 245:True 246:True 247:True 248:True 249:True 250:True 251:True 252:True 253:True 254:True 255:True 256:True 257:True 258:True 259:True 260:True 261:True 262:True 263:True 264:True 265:True 266:True 267:True 268:True 269:True 270:True 271:True 272:True 273:True 274:True 275:True 276:True 277:True 278:True 279:True 280:True 281:True 282:True 283:True 284:True 285:True 286:True 287:True 288:True 289:True 290:True 291:True 292:True 293:True 294:True 295:True 296:True 297:True 298:True 299:True 300:True 301:True 302:True 303:True 304:True 305:True 306:True 307:True 308:True 309:True 310:True 311:True 312:True 313:True 314:True 315:True 316:True 317:True 318:True 319:True 320:True 321:True\n",
      "I1208 12:27:37.164155 139883775852736 run_factoid.py:447] token_is_max_context: 11:False 12:False 13:False 14:False 15:False 16:False 17:False 18:False 19:False 20:False 21:False 22:False 23:False 24:False 25:False 26:False 27:False 28:False 29:False 30:False 31:False 32:False 33:False 34:False 35:False 36:False 37:False 38:False 39:False 40:False 41:False 42:False 43:False 44:False 45:False 46:False 47:False 48:False 49:False 50:False 51:False 52:False 53:False 54:False 55:False 56:False 57:False 58:False 59:False 60:False 61:False 62:False 63:False 64:False 65:False 66:False 67:False 68:False 69:False 70:False 71:False 72:False 73:False 74:False 75:False 76:False 77:False 78:False 79:False 80:False 81:False 82:False 83:False 84:False 85:False 86:False 87:False 88:False 89:False 90:False 91:False 92:False 93:False 94:False 95:False 96:False 97:False 98:False 99:False 100:False 101:False 102:False 103:False 104:False 105:False 106:False 107:False 108:False 109:False 110:False 111:False 112:False 113:False 114:False 115:False 116:False 117:False 118:False 119:False 120:False 121:False 122:False 123:False 124:False 125:False 126:False 127:False 128:False 129:False 130:False 131:False 132:False 133:True 134:True 135:True 136:True 137:True 138:True 139:True 140:True 141:True 142:True 143:True 144:True 145:True 146:True 147:True 148:True 149:True 150:True 151:True 152:True 153:True 154:True 155:True 156:True 157:True 158:True 159:True 160:True 161:True 162:True 163:True 164:True 165:True 166:True 167:True 168:True 169:True 170:True 171:True 172:True 173:True 174:True 175:True 176:True 177:True 178:True 179:True 180:True 181:True 182:True 183:True 184:True 185:True 186:True 187:True 188:True 189:True 190:True 191:True 192:True 193:True 194:True 195:True 196:True 197:True 198:True 199:True 200:True 201:True 202:True 203:True 204:True 205:True 206:True 207:True 208:True 209:True 210:True 211:True 212:True 213:True 214:True 215:True 216:True 217:True 218:True 219:True 220:True 221:True 222:True 223:True 224:True 225:True 226:True 227:True 228:True 229:True 230:True 231:True 232:True 233:True 234:True 235:True 236:True 237:True 238:True 239:True 240:True 241:True 242:True 243:True 244:True 245:True 246:True 247:True 248:True 249:True 250:True 251:True 252:True 253:True 254:True 255:True 256:True 257:True 258:True 259:True 260:True 261:True 262:True 263:True 264:True 265:True 266:True 267:True 268:True 269:True 270:True 271:True 272:True 273:True 274:True 275:True 276:True 277:True 278:True 279:True 280:True 281:True 282:True 283:True 284:True 285:True 286:True 287:True 288:True 289:True 290:True 291:True 292:True 293:True 294:True 295:True 296:True 297:True 298:True 299:True 300:True 301:True 302:True 303:True 304:True 305:True 306:True 307:True 308:True 309:True 310:True 311:True 312:True 313:True 314:True 315:True 316:True 317:True 318:True 319:True 320:True 321:True\n",
      "INFO:tensorflow:input_ids: 101 2091 1103 9505 12864 1113 5351 17898 1116 136 102 19497 1708 7432 1111 1171 2489 1105 3420 2489 119 164 4335 166 1109 5752 6547 1103 2686 1106 1103 3860 2610 3773 1104 2991 7918 1105 23730 1104 19245 9397 117 1134 1127 2416 1118 1103 9455 14637 11970 1190 6187 10294 18778 1183 119 164 4335 166 1247 1127 1317 3209 13004 1107 1142 27154 118 3622 119 1752 117 1111 1199 13950 117 1103 2233 3622 1108 1359 1113 3860 1353 1295 1104 1529 2527 1105 6876 2060 132 2456 117 1103 16421 1164 1103 13950 1431 1129 9829 1114 15597 119 2307 117 1211 1104 1103 1529 2527 1127 18675 1884 13252 1204 2025 117 1105 1103 3654 2554 1108 15543 1106 1115 1104 25157 1942 1116 119 4180 117 2693 1195 1982 15750 3622 1105 23470 3622 1106 8664 1103 4167 16617 1104 1119 25710 27054 1785 117 1185 7468 1869 1108 1276 119 1284 1354 1115 1199 3209 3672 1336 3300 1111 1103 1632 1119 25710 27054 1785 117 1259 4420 787 5924 113 1425 117 2673 117 139 14038 117 2076 1104 6187 1123 5813 2116 117 1105 13467 6441 114 117 9355 1104 2812 118 1146 117 1692 5754 117 1105 13467 8015 119 1636 5320 1336 1138 1126 3772 1113 1412 2686 119 2456 117 6103 1292 13004 117 15597 1110 9213 1165 19348 1158 1412 9505 1105 11892 1172 1154 1103 7300 2415 119 1130 6593 117 1103 1675 27154 118 3622 1104 1489 2527 3228 1115 117 153 21678 2137 1108 2628 1114 1618 3154 1105 1861 13522 1114 1168 12814 3377 1107 1103 3252 1104 149 2137 3048 119 1438 117 1122 1145 3657 1107 170 2299 1231 10182 21629 2603 119 23243 1103 3209 13004 1107 1103 1675 2025 117 1748 1415 118 3418 117 1218 118 1982 7091 2200 7356 1132 1834 1106 23073 1412 9505 119 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "I1208 12:27:37.164255 139883775852736 run_factoid.py:449] input_ids: 101 2091 1103 9505 12864 1113 5351 17898 1116 136 102 19497 1708 7432 1111 1171 2489 1105 3420 2489 119 164 4335 166 1109 5752 6547 1103 2686 1106 1103 3860 2610 3773 1104 2991 7918 1105 23730 1104 19245 9397 117 1134 1127 2416 1118 1103 9455 14637 11970 1190 6187 10294 18778 1183 119 164 4335 166 1247 1127 1317 3209 13004 1107 1142 27154 118 3622 119 1752 117 1111 1199 13950 117 1103 2233 3622 1108 1359 1113 3860 1353 1295 1104 1529 2527 1105 6876 2060 132 2456 117 1103 16421 1164 1103 13950 1431 1129 9829 1114 15597 119 2307 117 1211 1104 1103 1529 2527 1127 18675 1884 13252 1204 2025 117 1105 1103 3654 2554 1108 15543 1106 1115 1104 25157 1942 1116 119 4180 117 2693 1195 1982 15750 3622 1105 23470 3622 1106 8664 1103 4167 16617 1104 1119 25710 27054 1785 117 1185 7468 1869 1108 1276 119 1284 1354 1115 1199 3209 3672 1336 3300 1111 1103 1632 1119 25710 27054 1785 117 1259 4420 787 5924 113 1425 117 2673 117 139 14038 117 2076 1104 6187 1123 5813 2116 117 1105 13467 6441 114 117 9355 1104 2812 118 1146 117 1692 5754 117 1105 13467 8015 119 1636 5320 1336 1138 1126 3772 1113 1412 2686 119 2456 117 6103 1292 13004 117 15597 1110 9213 1165 19348 1158 1412 9505 1105 11892 1172 1154 1103 7300 2415 119 1130 6593 117 1103 1675 27154 118 3622 1104 1489 2527 3228 1115 117 153 21678 2137 1108 2628 1114 1618 3154 1105 1861 13522 1114 1168 12814 3377 1107 1103 3252 1104 149 2137 3048 119 1438 117 1122 1145 3657 1107 170 2299 1231 10182 21629 2603 119 23243 1103 3209 13004 1107 1103 1675 2025 117 1748 1415 118 3418 117 1218 118 1982 7091 2200 7356 1132 1834 1106 23073 1412 9505 119 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "INFO:tensorflow:input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "I1208 12:27:37.164347 139883775852736 run_factoid.py:451] input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "INFO:tensorflow:segment_ids: 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "I1208 12:27:37.164436 139883775852736 run_factoid.py:453] segment_ids: 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "INFO:tensorflow:*** Example ***\n",
      "I1208 12:27:37.183111 139883775852736 run_factoid.py:438] *** Example ***\n",
      "INFO:tensorflow:unique_id: 1000000053\n",
      "I1208 12:27:37.183186 139883775852736 run_factoid.py:439] unique_id: 1000000053\n",
      "INFO:tensorflow:example_index: 9\n",
      "I1208 12:27:37.183226 139883775852736 run_factoid.py:440] example_index: 9\n",
      "INFO:tensorflow:doc_span_index: 0\n",
      "I1208 12:27:37.183263 139883775852736 run_factoid.py:441] doc_span_index: 0\n",
      "INFO:tensorflow:tokens: [CLS] What are the limitations of the findings ? [SEP] The present meta - analysis of 14 trials involving 2 , 52 ##8 patients provided evidence that P ##EL ##D had favorable clinical outcomes for L ##DF , including shorter operation time and hospital stay , less blood loss , and improved SF ##12 - MC ##S and SF ##12 - PC ##S score . However , it also was associated with a significantly higher rate of re ##current disc her ##nia ##tion . In the present study , we found that patients who underwent P ##EL ##D had a significantly higher re ##cu ##rrence rate than those treated with other surgical interventions . However , in the subgroup analysis based on the com ##par ##ators , the higher rate of re ##current di ##s her ##nia ##tion was only observed in the comparison with MI ##S - T ##L ##IF . Yao Y , et al . [ 45 ] performed a retrospective co ##hor ##t study to compare the outcomes of three minimal ##ly invasive spine surge ##ries ( MI ##S - T ##L ##IF , ME ##D , and P ##EL ##D ) in the treatment of re ##current her ##nia ##tion . At the follow - up duration of 12 ##mont ##hs , no patients ( 0 . 0 % ) in the MI ##S - T ##L ##IF group , 3 patients ( 15 . 0 % ) in the ME ##D group , and 7 patients ( 25 . 0 % ) in the P ##EL ##D group developed re ##cu ##rrence . [ 45 ] The re ##cu ##rrence rate in the P ##EL ##D group was significantly higher than that in the MI ##S - T ##L ##IF group . Similarly , in their another recently published trial , [ 54 ] they also reported a higher re ##cu ##rrence rate of P ##EL ##D than MI ##S - T ##L ##IF . In that study , the authors enrolled 105 patients who underwent either P ##EL ##D ( n = 47 ) or MI ##S - T ##L ##IF ( n = 58 ) for revision of ME ##D re ##cu ##rrence . [ 54 ] At the 12 - month follow - up [SEP]\n",
      "I1208 12:27:37.183373 139883775852736 run_factoid.py:443] tokens: [CLS] What are the limitations of the findings ? [SEP] The present meta - analysis of 14 trials involving 2 , 52 ##8 patients provided evidence that P ##EL ##D had favorable clinical outcomes for L ##DF , including shorter operation time and hospital stay , less blood loss , and improved SF ##12 - MC ##S and SF ##12 - PC ##S score . However , it also was associated with a significantly higher rate of re ##current disc her ##nia ##tion . In the present study , we found that patients who underwent P ##EL ##D had a significantly higher re ##cu ##rrence rate than those treated with other surgical interventions . However , in the subgroup analysis based on the com ##par ##ators , the higher rate of re ##current di ##s her ##nia ##tion was only observed in the comparison with MI ##S - T ##L ##IF . Yao Y , et al . [ 45 ] performed a retrospective co ##hor ##t study to compare the outcomes of three minimal ##ly invasive spine surge ##ries ( MI ##S - T ##L ##IF , ME ##D , and P ##EL ##D ) in the treatment of re ##current her ##nia ##tion . At the follow - up duration of 12 ##mont ##hs , no patients ( 0 . 0 % ) in the MI ##S - T ##L ##IF group , 3 patients ( 15 . 0 % ) in the ME ##D group , and 7 patients ( 25 . 0 % ) in the P ##EL ##D group developed re ##cu ##rrence . [ 45 ] The re ##cu ##rrence rate in the P ##EL ##D group was significantly higher than that in the MI ##S - T ##L ##IF group . Similarly , in their another recently published trial , [ 54 ] they also reported a higher re ##cu ##rrence rate of P ##EL ##D than MI ##S - T ##L ##IF . In that study , the authors enrolled 105 patients who underwent either P ##EL ##D ( n = 47 ) or MI ##S - T ##L ##IF ( n = 58 ) for revision of ME ##D re ##cu ##rrence . [ 54 ] At the 12 - month follow - up [SEP]\n",
      "INFO:tensorflow:token_to_orig_map: 10:0 11:1 12:2 13:2 14:2 15:3 16:4 17:5 18:6 19:7 20:7 21:7 22:7 23:8 24:9 25:10 26:11 27:12 28:12 29:12 30:13 31:14 32:15 33:16 34:17 35:18 36:18 37:18 38:19 39:20 40:21 41:22 42:23 43:24 44:25 45:25 46:26 47:27 48:28 49:28 50:29 51:30 52:31 53:31 54:31 55:31 56:31 57:32 58:33 59:33 60:33 61:33 62:33 63:34 64:34 65:35 66:35 67:36 68:37 69:38 70:39 71:40 72:41 73:42 74:43 75:44 76:45 77:46 78:46 79:47 80:48 81:48 82:48 83:48 84:49 85:50 86:51 87:52 88:52 89:53 90:54 91:55 92:56 93:57 94:58 95:59 96:59 97:59 98:60 99:61 100:62 101:63 102:64 103:64 104:64 105:65 106:66 107:67 108:68 109:69 110:70 111:71 112:72 113:72 114:73 115:73 116:74 117:75 118:76 119:77 120:78 121:79 122:80 123:81 124:81 125:81 126:81 127:82 128:83 129:84 130:85 131:86 132:86 133:87 134:87 135:88 136:88 137:88 138:89 139:90 140:91 141:92 142:93 143:94 144:95 145:96 146:96 147:96 148:96 149:96 150:96 151:96 152:97 153:98 154:98 155:99 156:100 157:100 158:100 159:100 160:100 161:101 162:102 163:103 164:104 165:104 166:104 167:105 168:106 169:107 170:108 171:109 172:110 173:111 174:112 175:112 176:113 177:114 178:115 179:115 180:116 181:116 182:116 183:116 184:117 185:117 186:117 187:117 188:118 189:118 190:118 191:119 192:120 193:120 194:120 195:120 196:121 197:122 198:123 199:124 200:125 201:125 202:126 203:126 204:126 205:126 206:127 207:128 208:129 209:129 210:129 211:130 212:131 213:132 214:132 215:132 216:132 217:133 218:134 219:135 220:135 221:135 222:135 223:135 224:135 225:136 226:137 227:138 228:138 229:138 230:138 231:138 232:138 233:139 234:139 235:140 236:141 237:142 238:142 239:142 240:142 241:142 242:142 243:143 244:144 245:145 246:145 247:146 248:146 249:147 250:148 251:149 252:150 253:150 254:150 255:150 256:150 257:150 258:151 259:152 260:153 261:153 262:153 263:154 264:155 265:156 266:156 267:156 268:156 269:156 270:156 271:156 272:157 273:158 274:158 275:158 276:159 277:160 278:161 279:162 280:162 281:162 282:163 283:164 284:165 285:166 286:167 287:168 288:169 289:170 290:171 291:171 292:171 293:171 294:171 295:171 296:172 297:172 298:173 299:173 300:174 301:175 302:176 303:177 304:178 305:179 306:179 307:179 308:179 309:179 310:180 311:181 312:182 313:183 314:184 315:185 316:185 317:185 318:186 319:187 320:188 321:188 322:188 323:189 324:190 325:190 326:190 327:190 328:190 329:190 330:190 331:191 332:192 333:193 334:193 335:194 336:195 337:196 338:197 339:198 340:199 341:200 342:201 343:202 344:202 345:202 346:203 347:203 348:204 349:205 350:205 351:206 352:207 353:207 354:207 355:207 356:207 357:207 358:208 359:208 360:209 361:210 362:210 363:211 364:212 365:213 366:214 367:214 368:215 369:215 370:215 371:215 372:215 373:215 374:215 375:216 376:217 377:218 378:218 379:218 380:219 381:219 382:219\n",
      "I1208 12:27:37.183489 139883775852736 run_factoid.py:445] token_to_orig_map: 10:0 11:1 12:2 13:2 14:2 15:3 16:4 17:5 18:6 19:7 20:7 21:7 22:7 23:8 24:9 25:10 26:11 27:12 28:12 29:12 30:13 31:14 32:15 33:16 34:17 35:18 36:18 37:18 38:19 39:20 40:21 41:22 42:23 43:24 44:25 45:25 46:26 47:27 48:28 49:28 50:29 51:30 52:31 53:31 54:31 55:31 56:31 57:32 58:33 59:33 60:33 61:33 62:33 63:34 64:34 65:35 66:35 67:36 68:37 69:38 70:39 71:40 72:41 73:42 74:43 75:44 76:45 77:46 78:46 79:47 80:48 81:48 82:48 83:48 84:49 85:50 86:51 87:52 88:52 89:53 90:54 91:55 92:56 93:57 94:58 95:59 96:59 97:59 98:60 99:61 100:62 101:63 102:64 103:64 104:64 105:65 106:66 107:67 108:68 109:69 110:70 111:71 112:72 113:72 114:73 115:73 116:74 117:75 118:76 119:77 120:78 121:79 122:80 123:81 124:81 125:81 126:81 127:82 128:83 129:84 130:85 131:86 132:86 133:87 134:87 135:88 136:88 137:88 138:89 139:90 140:91 141:92 142:93 143:94 144:95 145:96 146:96 147:96 148:96 149:96 150:96 151:96 152:97 153:98 154:98 155:99 156:100 157:100 158:100 159:100 160:100 161:101 162:102 163:103 164:104 165:104 166:104 167:105 168:106 169:107 170:108 171:109 172:110 173:111 174:112 175:112 176:113 177:114 178:115 179:115 180:116 181:116 182:116 183:116 184:117 185:117 186:117 187:117 188:118 189:118 190:118 191:119 192:120 193:120 194:120 195:120 196:121 197:122 198:123 199:124 200:125 201:125 202:126 203:126 204:126 205:126 206:127 207:128 208:129 209:129 210:129 211:130 212:131 213:132 214:132 215:132 216:132 217:133 218:134 219:135 220:135 221:135 222:135 223:135 224:135 225:136 226:137 227:138 228:138 229:138 230:138 231:138 232:138 233:139 234:139 235:140 236:141 237:142 238:142 239:142 240:142 241:142 242:142 243:143 244:144 245:145 246:145 247:146 248:146 249:147 250:148 251:149 252:150 253:150 254:150 255:150 256:150 257:150 258:151 259:152 260:153 261:153 262:153 263:154 264:155 265:156 266:156 267:156 268:156 269:156 270:156 271:156 272:157 273:158 274:158 275:158 276:159 277:160 278:161 279:162 280:162 281:162 282:163 283:164 284:165 285:166 286:167 287:168 288:169 289:170 290:171 291:171 292:171 293:171 294:171 295:171 296:172 297:172 298:173 299:173 300:174 301:175 302:176 303:177 304:178 305:179 306:179 307:179 308:179 309:179 310:180 311:181 312:182 313:183 314:184 315:185 316:185 317:185 318:186 319:187 320:188 321:188 322:188 323:189 324:190 325:190 326:190 327:190 328:190 329:190 330:190 331:191 332:192 333:193 334:193 335:194 336:195 337:196 338:197 339:198 340:199 341:200 342:201 343:202 344:202 345:202 346:203 347:203 348:204 349:205 350:205 351:206 352:207 353:207 354:207 355:207 356:207 357:207 358:208 359:208 360:209 361:210 362:210 363:211 364:212 365:213 366:214 367:214 368:215 369:215 370:215 371:215 372:215 373:215 374:215 375:216 376:217 377:218 378:218 379:218 380:219 381:219 382:219\n",
      "INFO:tensorflow:token_is_max_context: 10:True 11:True 12:True 13:True 14:True 15:True 16:True 17:True 18:True 19:True 20:True 21:True 22:True 23:True 24:True 25:True 26:True 27:True 28:True 29:True 30:True 31:True 32:True 33:True 34:True 35:True 36:True 37:True 38:True 39:True 40:True 41:True 42:True 43:True 44:True 45:True 46:True 47:True 48:True 49:True 50:True 51:True 52:True 53:True 54:True 55:True 56:True 57:True 58:True 59:True 60:True 61:True 62:True 63:True 64:True 65:True 66:True 67:True 68:True 69:True 70:True 71:True 72:True 73:True 74:True 75:True 76:True 77:True 78:True 79:True 80:True 81:True 82:True 83:True 84:True 85:True 86:True 87:True 88:True 89:True 90:True 91:True 92:True 93:True 94:True 95:True 96:True 97:True 98:True 99:True 100:True 101:True 102:True 103:True 104:True 105:True 106:True 107:True 108:True 109:True 110:True 111:True 112:True 113:True 114:True 115:True 116:True 117:True 118:True 119:True 120:True 121:True 122:True 123:True 124:True 125:True 126:True 127:True 128:True 129:True 130:True 131:True 132:True 133:True 134:True 135:True 136:True 137:True 138:True 139:True 140:True 141:True 142:True 143:True 144:True 145:True 146:True 147:True 148:True 149:True 150:True 151:True 152:True 153:True 154:True 155:True 156:True 157:True 158:True 159:True 160:True 161:True 162:True 163:True 164:True 165:True 166:True 167:True 168:True 169:True 170:True 171:True 172:True 173:True 174:True 175:True 176:True 177:True 178:True 179:True 180:True 181:True 182:True 183:True 184:True 185:True 186:True 187:True 188:True 189:True 190:True 191:True 192:True 193:True 194:True 195:True 196:True 197:True 198:True 199:True 200:True 201:True 202:True 203:True 204:True 205:True 206:True 207:True 208:True 209:True 210:True 211:True 212:True 213:True 214:True 215:True 216:True 217:True 218:True 219:True 220:True 221:True 222:True 223:True 224:True 225:True 226:True 227:True 228:True 229:True 230:True 231:True 232:True 233:True 234:True 235:True 236:True 237:True 238:True 239:True 240:True 241:True 242:True 243:True 244:True 245:True 246:True 247:True 248:True 249:True 250:True 251:True 252:True 253:True 254:True 255:True 256:True 257:True 258:True 259:True 260:True 261:False 262:False 263:False 264:False 265:False 266:False 267:False 268:False 269:False 270:False 271:False 272:False 273:False 274:False 275:False 276:False 277:False 278:False 279:False 280:False 281:False 282:False 283:False 284:False 285:False 286:False 287:False 288:False 289:False 290:False 291:False 292:False 293:False 294:False 295:False 296:False 297:False 298:False 299:False 300:False 301:False 302:False 303:False 304:False 305:False 306:False 307:False 308:False 309:False 310:False 311:False 312:False 313:False 314:False 315:False 316:False 317:False 318:False 319:False 320:False 321:False 322:False 323:False 324:False 325:False 326:False 327:False 328:False 329:False 330:False 331:False 332:False 333:False 334:False 335:False 336:False 337:False 338:False 339:False 340:False 341:False 342:False 343:False 344:False 345:False 346:False 347:False 348:False 349:False 350:False 351:False 352:False 353:False 354:False 355:False 356:False 357:False 358:False 359:False 360:False 361:False 362:False 363:False 364:False 365:False 366:False 367:False 368:False 369:False 370:False 371:False 372:False 373:False 374:False 375:False 376:False 377:False 378:False 379:False 380:False 381:False 382:False\n",
      "I1208 12:27:37.183597 139883775852736 run_factoid.py:447] token_is_max_context: 10:True 11:True 12:True 13:True 14:True 15:True 16:True 17:True 18:True 19:True 20:True 21:True 22:True 23:True 24:True 25:True 26:True 27:True 28:True 29:True 30:True 31:True 32:True 33:True 34:True 35:True 36:True 37:True 38:True 39:True 40:True 41:True 42:True 43:True 44:True 45:True 46:True 47:True 48:True 49:True 50:True 51:True 52:True 53:True 54:True 55:True 56:True 57:True 58:True 59:True 60:True 61:True 62:True 63:True 64:True 65:True 66:True 67:True 68:True 69:True 70:True 71:True 72:True 73:True 74:True 75:True 76:True 77:True 78:True 79:True 80:True 81:True 82:True 83:True 84:True 85:True 86:True 87:True 88:True 89:True 90:True 91:True 92:True 93:True 94:True 95:True 96:True 97:True 98:True 99:True 100:True 101:True 102:True 103:True 104:True 105:True 106:True 107:True 108:True 109:True 110:True 111:True 112:True 113:True 114:True 115:True 116:True 117:True 118:True 119:True 120:True 121:True 122:True 123:True 124:True 125:True 126:True 127:True 128:True 129:True 130:True 131:True 132:True 133:True 134:True 135:True 136:True 137:True 138:True 139:True 140:True 141:True 142:True 143:True 144:True 145:True 146:True 147:True 148:True 149:True 150:True 151:True 152:True 153:True 154:True 155:True 156:True 157:True 158:True 159:True 160:True 161:True 162:True 163:True 164:True 165:True 166:True 167:True 168:True 169:True 170:True 171:True 172:True 173:True 174:True 175:True 176:True 177:True 178:True 179:True 180:True 181:True 182:True 183:True 184:True 185:True 186:True 187:True 188:True 189:True 190:True 191:True 192:True 193:True 194:True 195:True 196:True 197:True 198:True 199:True 200:True 201:True 202:True 203:True 204:True 205:True 206:True 207:True 208:True 209:True 210:True 211:True 212:True 213:True 214:True 215:True 216:True 217:True 218:True 219:True 220:True 221:True 222:True 223:True 224:True 225:True 226:True 227:True 228:True 229:True 230:True 231:True 232:True 233:True 234:True 235:True 236:True 237:True 238:True 239:True 240:True 241:True 242:True 243:True 244:True 245:True 246:True 247:True 248:True 249:True 250:True 251:True 252:True 253:True 254:True 255:True 256:True 257:True 258:True 259:True 260:True 261:False 262:False 263:False 264:False 265:False 266:False 267:False 268:False 269:False 270:False 271:False 272:False 273:False 274:False 275:False 276:False 277:False 278:False 279:False 280:False 281:False 282:False 283:False 284:False 285:False 286:False 287:False 288:False 289:False 290:False 291:False 292:False 293:False 294:False 295:False 296:False 297:False 298:False 299:False 300:False 301:False 302:False 303:False 304:False 305:False 306:False 307:False 308:False 309:False 310:False 311:False 312:False 313:False 314:False 315:False 316:False 317:False 318:False 319:False 320:False 321:False 322:False 323:False 324:False 325:False 326:False 327:False 328:False 329:False 330:False 331:False 332:False 333:False 334:False 335:False 336:False 337:False 338:False 339:False 340:False 341:False 342:False 343:False 344:False 345:False 346:False 347:False 348:False 349:False 350:False 351:False 352:False 353:False 354:False 355:False 356:False 357:False 358:False 359:False 360:False 361:False 362:False 363:False 364:False 365:False 366:False 367:False 368:False 369:False 370:False 371:False 372:False 373:False 374:False 375:False 376:False 377:False 378:False 379:False 380:False 381:False 382:False\n",
      "INFO:tensorflow:input_ids: 101 1327 1132 1103 13004 1104 1103 9505 136 102 1109 1675 27154 118 3622 1104 1489 7356 5336 123 117 3882 1604 4420 2136 2554 1115 153 21678 2137 1125 11169 7300 13950 1111 149 16395 117 1259 7681 2805 1159 1105 2704 2215 117 1750 1892 2445 117 1105 4725 18659 11964 118 12029 1708 1105 18659 11964 118 7054 1708 2794 119 1438 117 1122 1145 1108 2628 1114 170 5409 2299 2603 1104 1231 21754 6187 1123 5813 2116 119 1130 1103 1675 2025 117 1195 1276 1115 4420 1150 9315 153 21678 2137 1125 170 5409 2299 1231 10182 21629 2603 1190 1343 5165 1114 1168 13467 22496 119 1438 117 1107 1103 23470 3622 1359 1113 1103 3254 17482 11664 117 1103 2299 2603 1104 1231 21754 4267 1116 1123 5813 2116 1108 1178 4379 1107 1103 7577 1114 26574 1708 118 157 2162 15499 119 27762 162 117 3084 2393 119 164 2532 166 1982 170 18675 1884 13252 1204 2025 1106 14133 1103 13950 1104 1210 10298 1193 19849 8340 12814 3377 113 26574 1708 118 157 2162 15499 117 22157 2137 117 1105 153 21678 2137 114 1107 1103 3252 1104 1231 21754 1123 5813 2116 119 1335 1103 2812 118 1146 9355 1104 1367 7578 9524 117 1185 4420 113 121 119 121 110 114 1107 1103 26574 1708 118 157 2162 15499 1372 117 124 4420 113 1405 119 121 110 114 1107 1103 22157 2137 1372 117 1105 128 4420 113 1512 119 121 110 114 1107 1103 153 21678 2137 1372 1872 1231 10182 21629 119 164 2532 166 1109 1231 10182 21629 2603 1107 1103 153 21678 2137 1372 1108 5409 2299 1190 1115 1107 1103 26574 1708 118 157 2162 15499 1372 119 10321 117 1107 1147 1330 3055 1502 3443 117 164 4335 166 1152 1145 2103 170 2299 1231 10182 21629 2603 1104 153 21678 2137 1190 26574 1708 118 157 2162 15499 119 1130 1115 2025 117 1103 5752 7945 8359 4420 1150 9315 1719 153 21678 2137 113 183 134 3862 114 1137 26574 1708 118 157 2162 15499 113 183 134 4650 114 1111 16547 1104 22157 2137 1231 10182 21629 119 164 4335 166 1335 1103 1367 118 2370 2812 118 1146 102\n",
      "I1208 12:27:37.183697 139883775852736 run_factoid.py:449] input_ids: 101 1327 1132 1103 13004 1104 1103 9505 136 102 1109 1675 27154 118 3622 1104 1489 7356 5336 123 117 3882 1604 4420 2136 2554 1115 153 21678 2137 1125 11169 7300 13950 1111 149 16395 117 1259 7681 2805 1159 1105 2704 2215 117 1750 1892 2445 117 1105 4725 18659 11964 118 12029 1708 1105 18659 11964 118 7054 1708 2794 119 1438 117 1122 1145 1108 2628 1114 170 5409 2299 2603 1104 1231 21754 6187 1123 5813 2116 119 1130 1103 1675 2025 117 1195 1276 1115 4420 1150 9315 153 21678 2137 1125 170 5409 2299 1231 10182 21629 2603 1190 1343 5165 1114 1168 13467 22496 119 1438 117 1107 1103 23470 3622 1359 1113 1103 3254 17482 11664 117 1103 2299 2603 1104 1231 21754 4267 1116 1123 5813 2116 1108 1178 4379 1107 1103 7577 1114 26574 1708 118 157 2162 15499 119 27762 162 117 3084 2393 119 164 2532 166 1982 170 18675 1884 13252 1204 2025 1106 14133 1103 13950 1104 1210 10298 1193 19849 8340 12814 3377 113 26574 1708 118 157 2162 15499 117 22157 2137 117 1105 153 21678 2137 114 1107 1103 3252 1104 1231 21754 1123 5813 2116 119 1335 1103 2812 118 1146 9355 1104 1367 7578 9524 117 1185 4420 113 121 119 121 110 114 1107 1103 26574 1708 118 157 2162 15499 1372 117 124 4420 113 1405 119 121 110 114 1107 1103 22157 2137 1372 117 1105 128 4420 113 1512 119 121 110 114 1107 1103 153 21678 2137 1372 1872 1231 10182 21629 119 164 2532 166 1109 1231 10182 21629 2603 1107 1103 153 21678 2137 1372 1108 5409 2299 1190 1115 1107 1103 26574 1708 118 157 2162 15499 1372 119 10321 117 1107 1147 1330 3055 1502 3443 117 164 4335 166 1152 1145 2103 170 2299 1231 10182 21629 2603 1104 153 21678 2137 1190 26574 1708 118 157 2162 15499 119 1130 1115 2025 117 1103 5752 7945 8359 4420 1150 9315 1719 153 21678 2137 113 183 134 3862 114 1137 26574 1708 118 157 2162 15499 113 183 134 4650 114 1111 16547 1104 22157 2137 1231 10182 21629 119 164 4335 166 1335 1103 1367 118 2370 2812 118 1146 102\n",
      "INFO:tensorflow:input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      "I1208 12:27:37.183789 139883775852736 run_factoid.py:451] input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      "INFO:tensorflow:segment_ids: 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      "I1208 12:27:37.183878 139883775852736 run_factoid.py:453] segment_ids: 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      "INFO:tensorflow:*** Example ***\n",
      "I1208 12:27:37.185614 139883775852736 run_factoid.py:438] *** Example ***\n",
      "INFO:tensorflow:unique_id: 1000000054\n",
      "I1208 12:27:37.185677 139883775852736 run_factoid.py:439] unique_id: 1000000054\n",
      "INFO:tensorflow:example_index: 9\n",
      "I1208 12:27:37.185714 139883775852736 run_factoid.py:440] example_index: 9\n",
      "INFO:tensorflow:doc_span_index: 1\n",
      "I1208 12:27:37.185746 139883775852736 run_factoid.py:441] doc_span_index: 1\n",
      "INFO:tensorflow:tokens: [CLS] What are the limitations of the findings ? [SEP] was only observed in the comparison with MI ##S - T ##L ##IF . Yao Y , et al . [ 45 ] performed a retrospective co ##hor ##t study to compare the outcomes of three minimal ##ly invasive spine surge ##ries ( MI ##S - T ##L ##IF , ME ##D , and P ##EL ##D ) in the treatment of re ##current her ##nia ##tion . At the follow - up duration of 12 ##mont ##hs , no patients ( 0 . 0 % ) in the MI ##S - T ##L ##IF group , 3 patients ( 15 . 0 % ) in the ME ##D group , and 7 patients ( 25 . 0 % ) in the P ##EL ##D group developed re ##cu ##rrence . [ 45 ] The re ##cu ##rrence rate in the P ##EL ##D group was significantly higher than that in the MI ##S - T ##L ##IF group . Similarly , in their another recently published trial , [ 54 ] they also reported a higher re ##cu ##rrence rate of P ##EL ##D than MI ##S - T ##L ##IF . In that study , the authors enrolled 105 patients who underwent either P ##EL ##D ( n = 47 ) or MI ##S - T ##L ##IF ( n = 58 ) for revision of ME ##D re ##cu ##rrence . [ 54 ] At the 12 - month follow - up , patients who underwent P ##EL ##D had a significantly higher re ##cu ##rrence rate ( 10 . 64 % ) than those treated with MI ##S - T ##L ##IF ( 0 . 0 % ) . [ 54 ] The authors attributed the findings to the following reasons : ( 1 ) there was some risk factors that were predict ##ive of re ##cu ##rrence in P ##EL ##D patients . For example , old age , o ##besity , and Mo ##dic change have been identified as significant risk factors for the P ##EL ##D re ##cu ##r - re ##nce . [ 58 , 59 ] And the 5 patients who experienced re ##cu ##rrence in the P ##EL ##D group were all relatively [SEP]\n",
      "I1208 12:27:37.185856 139883775852736 run_factoid.py:443] tokens: [CLS] What are the limitations of the findings ? [SEP] was only observed in the comparison with MI ##S - T ##L ##IF . Yao Y , et al . [ 45 ] performed a retrospective co ##hor ##t study to compare the outcomes of three minimal ##ly invasive spine surge ##ries ( MI ##S - T ##L ##IF , ME ##D , and P ##EL ##D ) in the treatment of re ##current her ##nia ##tion . At the follow - up duration of 12 ##mont ##hs , no patients ( 0 . 0 % ) in the MI ##S - T ##L ##IF group , 3 patients ( 15 . 0 % ) in the ME ##D group , and 7 patients ( 25 . 0 % ) in the P ##EL ##D group developed re ##cu ##rrence . [ 45 ] The re ##cu ##rrence rate in the P ##EL ##D group was significantly higher than that in the MI ##S - T ##L ##IF group . Similarly , in their another recently published trial , [ 54 ] they also reported a higher re ##cu ##rrence rate of P ##EL ##D than MI ##S - T ##L ##IF . In that study , the authors enrolled 105 patients who underwent either P ##EL ##D ( n = 47 ) or MI ##S - T ##L ##IF ( n = 58 ) for revision of ME ##D re ##cu ##rrence . [ 54 ] At the 12 - month follow - up , patients who underwent P ##EL ##D had a significantly higher re ##cu ##rrence rate ( 10 . 64 % ) than those treated with MI ##S - T ##L ##IF ( 0 . 0 % ) . [ 54 ] The authors attributed the findings to the following reasons : ( 1 ) there was some risk factors that were predict ##ive of re ##cu ##rrence in P ##EL ##D patients . For example , old age , o ##besity , and Mo ##dic change have been identified as significant risk factors for the P ##EL ##D re ##cu ##r - re ##nce . [ 58 , 59 ] And the 5 patients who experienced re ##cu ##rrence in the P ##EL ##D group were all relatively [SEP]\n",
      "INFO:tensorflow:token_to_orig_map: 10:89 11:90 12:91 13:92 14:93 15:94 16:95 17:96 18:96 19:96 20:96 21:96 22:96 23:96 24:97 25:98 26:98 27:99 28:100 29:100 30:100 31:100 32:100 33:101 34:102 35:103 36:104 37:104 38:104 39:105 40:106 41:107 42:108 43:109 44:110 45:111 46:112 47:112 48:113 49:114 50:115 51:115 52:116 53:116 54:116 55:116 56:117 57:117 58:117 59:117 60:118 61:118 62:118 63:119 64:120 65:120 66:120 67:120 68:121 69:122 70:123 71:124 72:125 73:125 74:126 75:126 76:126 77:126 78:127 79:128 80:129 81:129 82:129 83:130 84:131 85:132 86:132 87:132 88:132 89:133 90:134 91:135 92:135 93:135 94:135 95:135 96:135 97:136 98:137 99:138 100:138 101:138 102:138 103:138 104:138 105:139 106:139 107:140 108:141 109:142 110:142 111:142 112:142 113:142 114:142 115:143 116:144 117:145 118:145 119:146 120:146 121:147 122:148 123:149 124:150 125:150 126:150 127:150 128:150 129:150 130:151 131:152 132:153 133:153 134:153 135:154 136:155 137:156 138:156 139:156 140:156 141:156 142:156 143:156 144:157 145:158 146:158 147:158 148:159 149:160 150:161 151:162 152:162 153:162 154:163 155:164 156:165 157:166 158:167 159:168 160:169 161:170 162:171 163:171 164:171 165:171 166:171 167:171 168:172 169:172 170:173 171:173 172:174 173:175 174:176 175:177 176:178 177:179 178:179 179:179 180:179 181:179 182:180 183:181 184:182 185:183 186:184 187:185 188:185 189:185 190:186 191:187 192:188 193:188 194:188 195:189 196:190 197:190 198:190 199:190 200:190 201:190 202:190 203:191 204:192 205:193 206:193 207:194 208:195 209:196 210:197 211:198 212:199 213:200 214:201 215:202 216:202 217:202 218:203 219:203 220:204 221:205 222:205 223:206 224:207 225:207 226:207 227:207 228:207 229:207 230:208 231:208 232:209 233:210 234:210 235:211 236:212 237:213 238:214 239:214 240:215 241:215 242:215 243:215 244:215 245:215 246:215 247:216 248:217 249:218 250:218 251:218 252:219 253:219 254:219 255:219 256:220 257:221 258:222 259:223 260:223 261:223 262:224 263:225 264:226 265:227 266:228 267:228 268:228 269:229 270:230 271:230 272:230 273:230 274:230 275:230 276:231 277:232 278:233 279:234 280:235 281:235 282:235 283:235 284:235 285:235 286:236 287:236 288:236 289:236 290:236 291:236 292:236 293:236 294:236 295:236 296:237 297:238 298:239 299:240 300:241 301:242 302:243 303:244 304:245 305:245 306:246 307:246 308:246 309:247 310:248 311:249 312:250 313:251 314:252 315:253 316:254 317:254 318:255 319:256 320:256 321:256 322:257 323:258 324:258 325:258 326:259 327:259 328:260 329:261 330:261 331:262 332:263 333:263 334:264 335:264 336:264 337:265 338:266 339:266 340:267 341:268 342:269 343:270 344:271 345:272 346:273 347:274 348:275 349:276 350:277 351:277 352:277 353:278 354:278 355:278 356:278 357:279 358:279 359:279 360:279 361:279 362:279 363:279 364:279 365:280 366:281 367:282 368:283 369:284 370:285 371:286 372:286 373:286 374:287 375:288 376:289 377:289 378:289 379:290 380:291 381:292 382:293\n",
      "I1208 12:27:37.185969 139883775852736 run_factoid.py:445] token_to_orig_map: 10:89 11:90 12:91 13:92 14:93 15:94 16:95 17:96 18:96 19:96 20:96 21:96 22:96 23:96 24:97 25:98 26:98 27:99 28:100 29:100 30:100 31:100 32:100 33:101 34:102 35:103 36:104 37:104 38:104 39:105 40:106 41:107 42:108 43:109 44:110 45:111 46:112 47:112 48:113 49:114 50:115 51:115 52:116 53:116 54:116 55:116 56:117 57:117 58:117 59:117 60:118 61:118 62:118 63:119 64:120 65:120 66:120 67:120 68:121 69:122 70:123 71:124 72:125 73:125 74:126 75:126 76:126 77:126 78:127 79:128 80:129 81:129 82:129 83:130 84:131 85:132 86:132 87:132 88:132 89:133 90:134 91:135 92:135 93:135 94:135 95:135 96:135 97:136 98:137 99:138 100:138 101:138 102:138 103:138 104:138 105:139 106:139 107:140 108:141 109:142 110:142 111:142 112:142 113:142 114:142 115:143 116:144 117:145 118:145 119:146 120:146 121:147 122:148 123:149 124:150 125:150 126:150 127:150 128:150 129:150 130:151 131:152 132:153 133:153 134:153 135:154 136:155 137:156 138:156 139:156 140:156 141:156 142:156 143:156 144:157 145:158 146:158 147:158 148:159 149:160 150:161 151:162 152:162 153:162 154:163 155:164 156:165 157:166 158:167 159:168 160:169 161:170 162:171 163:171 164:171 165:171 166:171 167:171 168:172 169:172 170:173 171:173 172:174 173:175 174:176 175:177 176:178 177:179 178:179 179:179 180:179 181:179 182:180 183:181 184:182 185:183 186:184 187:185 188:185 189:185 190:186 191:187 192:188 193:188 194:188 195:189 196:190 197:190 198:190 199:190 200:190 201:190 202:190 203:191 204:192 205:193 206:193 207:194 208:195 209:196 210:197 211:198 212:199 213:200 214:201 215:202 216:202 217:202 218:203 219:203 220:204 221:205 222:205 223:206 224:207 225:207 226:207 227:207 228:207 229:207 230:208 231:208 232:209 233:210 234:210 235:211 236:212 237:213 238:214 239:214 240:215 241:215 242:215 243:215 244:215 245:215 246:215 247:216 248:217 249:218 250:218 251:218 252:219 253:219 254:219 255:219 256:220 257:221 258:222 259:223 260:223 261:223 262:224 263:225 264:226 265:227 266:228 267:228 268:228 269:229 270:230 271:230 272:230 273:230 274:230 275:230 276:231 277:232 278:233 279:234 280:235 281:235 282:235 283:235 284:235 285:235 286:236 287:236 288:236 289:236 290:236 291:236 292:236 293:236 294:236 295:236 296:237 297:238 298:239 299:240 300:241 301:242 302:243 303:244 304:245 305:245 306:246 307:246 308:246 309:247 310:248 311:249 312:250 313:251 314:252 315:253 316:254 317:254 318:255 319:256 320:256 321:256 322:257 323:258 324:258 325:258 326:259 327:259 328:260 329:261 330:261 331:262 332:263 333:263 334:264 335:264 336:264 337:265 338:266 339:266 340:267 341:268 342:269 343:270 344:271 345:272 346:273 347:274 348:275 349:276 350:277 351:277 352:277 353:278 354:278 355:278 356:278 357:279 358:279 359:279 360:279 361:279 362:279 363:279 364:279 365:280 366:281 367:282 368:283 369:284 370:285 371:286 372:286 373:286 374:287 375:288 376:289 377:289 378:289 379:290 380:291 381:292 382:293\n",
      "INFO:tensorflow:token_is_max_context: 10:False 11:False 12:False 13:False 14:False 15:False 16:False 17:False 18:False 19:False 20:False 21:False 22:False 23:False 24:False 25:False 26:False 27:False 28:False 29:False 30:False 31:False 32:False 33:False 34:False 35:False 36:False 37:False 38:False 39:False 40:False 41:False 42:False 43:False 44:False 45:False 46:False 47:False 48:False 49:False 50:False 51:False 52:False 53:False 54:False 55:False 56:False 57:False 58:False 59:False 60:False 61:False 62:False 63:False 64:False 65:False 66:False 67:False 68:False 69:False 70:False 71:False 72:False 73:False 74:False 75:False 76:False 77:False 78:False 79:False 80:False 81:False 82:False 83:False 84:False 85:False 86:False 87:False 88:False 89:False 90:False 91:False 92:False 93:False 94:False 95:False 96:False 97:False 98:False 99:False 100:False 101:False 102:False 103:False 104:False 105:False 106:False 107:False 108:False 109:False 110:False 111:False 112:False 113:False 114:False 115:False 116:False 117:False 118:False 119:False 120:False 121:False 122:False 123:False 124:False 125:False 126:False 127:False 128:False 129:False 130:False 131:False 132:False 133:True 134:True 135:True 136:True 137:True 138:True 139:True 140:True 141:True 142:True 143:True 144:True 145:True 146:True 147:True 148:True 149:True 150:True 151:True 152:True 153:True 154:True 155:True 156:True 157:True 158:True 159:True 160:True 161:True 162:True 163:True 164:True 165:True 166:True 167:True 168:True 169:True 170:True 171:True 172:True 173:True 174:True 175:True 176:True 177:True 178:True 179:True 180:True 181:True 182:True 183:True 184:True 185:True 186:True 187:True 188:True 189:True 190:True 191:True 192:True 193:True 194:True 195:True 196:True 197:True 198:True 199:True 200:True 201:True 202:True 203:True 204:True 205:True 206:True 207:True 208:True 209:True 210:True 211:True 212:True 213:True 214:True 215:True 216:True 217:True 218:True 219:True 220:True 221:True 222:True 223:True 224:True 225:True 226:True 227:True 228:True 229:True 230:True 231:True 232:True 233:True 234:True 235:True 236:True 237:True 238:True 239:True 240:True 241:True 242:True 243:True 244:True 245:True 246:True 247:True 248:True 249:True 250:True 251:True 252:True 253:True 254:True 255:True 256:True 257:True 258:True 259:True 260:True 261:False 262:False 263:False 264:False 265:False 266:False 267:False 268:False 269:False 270:False 271:False 272:False 273:False 274:False 275:False 276:False 277:False 278:False 279:False 280:False 281:False 282:False 283:False 284:False 285:False 286:False 287:False 288:False 289:False 290:False 291:False 292:False 293:False 294:False 295:False 296:False 297:False 298:False 299:False 300:False 301:False 302:False 303:False 304:False 305:False 306:False 307:False 308:False 309:False 310:False 311:False 312:False 313:False 314:False 315:False 316:False 317:False 318:False 319:False 320:False 321:False 322:False 323:False 324:False 325:False 326:False 327:False 328:False 329:False 330:False 331:False 332:False 333:False 334:False 335:False 336:False 337:False 338:False 339:False 340:False 341:False 342:False 343:False 344:False 345:False 346:False 347:False 348:False 349:False 350:False 351:False 352:False 353:False 354:False 355:False 356:False 357:False 358:False 359:False 360:False 361:False 362:False 363:False 364:False 365:False 366:False 367:False 368:False 369:False 370:False 371:False 372:False 373:False 374:False 375:False 376:False 377:False 378:False 379:False 380:False 381:False 382:False\n",
      "I1208 12:27:37.186078 139883775852736 run_factoid.py:447] token_is_max_context: 10:False 11:False 12:False 13:False 14:False 15:False 16:False 17:False 18:False 19:False 20:False 21:False 22:False 23:False 24:False 25:False 26:False 27:False 28:False 29:False 30:False 31:False 32:False 33:False 34:False 35:False 36:False 37:False 38:False 39:False 40:False 41:False 42:False 43:False 44:False 45:False 46:False 47:False 48:False 49:False 50:False 51:False 52:False 53:False 54:False 55:False 56:False 57:False 58:False 59:False 60:False 61:False 62:False 63:False 64:False 65:False 66:False 67:False 68:False 69:False 70:False 71:False 72:False 73:False 74:False 75:False 76:False 77:False 78:False 79:False 80:False 81:False 82:False 83:False 84:False 85:False 86:False 87:False 88:False 89:False 90:False 91:False 92:False 93:False 94:False 95:False 96:False 97:False 98:False 99:False 100:False 101:False 102:False 103:False 104:False 105:False 106:False 107:False 108:False 109:False 110:False 111:False 112:False 113:False 114:False 115:False 116:False 117:False 118:False 119:False 120:False 121:False 122:False 123:False 124:False 125:False 126:False 127:False 128:False 129:False 130:False 131:False 132:False 133:True 134:True 135:True 136:True 137:True 138:True 139:True 140:True 141:True 142:True 143:True 144:True 145:True 146:True 147:True 148:True 149:True 150:True 151:True 152:True 153:True 154:True 155:True 156:True 157:True 158:True 159:True 160:True 161:True 162:True 163:True 164:True 165:True 166:True 167:True 168:True 169:True 170:True 171:True 172:True 173:True 174:True 175:True 176:True 177:True 178:True 179:True 180:True 181:True 182:True 183:True 184:True 185:True 186:True 187:True 188:True 189:True 190:True 191:True 192:True 193:True 194:True 195:True 196:True 197:True 198:True 199:True 200:True 201:True 202:True 203:True 204:True 205:True 206:True 207:True 208:True 209:True 210:True 211:True 212:True 213:True 214:True 215:True 216:True 217:True 218:True 219:True 220:True 221:True 222:True 223:True 224:True 225:True 226:True 227:True 228:True 229:True 230:True 231:True 232:True 233:True 234:True 235:True 236:True 237:True 238:True 239:True 240:True 241:True 242:True 243:True 244:True 245:True 246:True 247:True 248:True 249:True 250:True 251:True 252:True 253:True 254:True 255:True 256:True 257:True 258:True 259:True 260:True 261:False 262:False 263:False 264:False 265:False 266:False 267:False 268:False 269:False 270:False 271:False 272:False 273:False 274:False 275:False 276:False 277:False 278:False 279:False 280:False 281:False 282:False 283:False 284:False 285:False 286:False 287:False 288:False 289:False 290:False 291:False 292:False 293:False 294:False 295:False 296:False 297:False 298:False 299:False 300:False 301:False 302:False 303:False 304:False 305:False 306:False 307:False 308:False 309:False 310:False 311:False 312:False 313:False 314:False 315:False 316:False 317:False 318:False 319:False 320:False 321:False 322:False 323:False 324:False 325:False 326:False 327:False 328:False 329:False 330:False 331:False 332:False 333:False 334:False 335:False 336:False 337:False 338:False 339:False 340:False 341:False 342:False 343:False 344:False 345:False 346:False 347:False 348:False 349:False 350:False 351:False 352:False 353:False 354:False 355:False 356:False 357:False 358:False 359:False 360:False 361:False 362:False 363:False 364:False 365:False 366:False 367:False 368:False 369:False 370:False 371:False 372:False 373:False 374:False 375:False 376:False 377:False 378:False 379:False 380:False 381:False 382:False\n",
      "INFO:tensorflow:input_ids: 101 1327 1132 1103 13004 1104 1103 9505 136 102 1108 1178 4379 1107 1103 7577 1114 26574 1708 118 157 2162 15499 119 27762 162 117 3084 2393 119 164 2532 166 1982 170 18675 1884 13252 1204 2025 1106 14133 1103 13950 1104 1210 10298 1193 19849 8340 12814 3377 113 26574 1708 118 157 2162 15499 117 22157 2137 117 1105 153 21678 2137 114 1107 1103 3252 1104 1231 21754 1123 5813 2116 119 1335 1103 2812 118 1146 9355 1104 1367 7578 9524 117 1185 4420 113 121 119 121 110 114 1107 1103 26574 1708 118 157 2162 15499 1372 117 124 4420 113 1405 119 121 110 114 1107 1103 22157 2137 1372 117 1105 128 4420 113 1512 119 121 110 114 1107 1103 153 21678 2137 1372 1872 1231 10182 21629 119 164 2532 166 1109 1231 10182 21629 2603 1107 1103 153 21678 2137 1372 1108 5409 2299 1190 1115 1107 1103 26574 1708 118 157 2162 15499 1372 119 10321 117 1107 1147 1330 3055 1502 3443 117 164 4335 166 1152 1145 2103 170 2299 1231 10182 21629 2603 1104 153 21678 2137 1190 26574 1708 118 157 2162 15499 119 1130 1115 2025 117 1103 5752 7945 8359 4420 1150 9315 1719 153 21678 2137 113 183 134 3862 114 1137 26574 1708 118 157 2162 15499 113 183 134 4650 114 1111 16547 1104 22157 2137 1231 10182 21629 119 164 4335 166 1335 1103 1367 118 2370 2812 118 1146 117 4420 1150 9315 153 21678 2137 1125 170 5409 2299 1231 10182 21629 2603 113 1275 119 3324 110 114 1190 1343 5165 1114 26574 1708 118 157 2162 15499 113 121 119 121 110 114 119 164 4335 166 1109 5752 6547 1103 9505 1106 1103 1378 3672 131 113 122 114 1175 1108 1199 3187 5320 1115 1127 17163 2109 1104 1231 10182 21629 1107 153 21678 2137 4420 119 1370 1859 117 1385 1425 117 184 27655 117 1105 12556 13328 1849 1138 1151 3626 1112 2418 3187 5320 1111 1103 153 21678 2137 1231 10182 1197 118 1231 3633 119 164 4650 117 4589 166 1262 1103 126 4420 1150 4531 1231 10182 21629 1107 1103 153 21678 2137 1372 1127 1155 3860 102\n",
      "I1208 12:27:37.186180 139883775852736 run_factoid.py:449] input_ids: 101 1327 1132 1103 13004 1104 1103 9505 136 102 1108 1178 4379 1107 1103 7577 1114 26574 1708 118 157 2162 15499 119 27762 162 117 3084 2393 119 164 2532 166 1982 170 18675 1884 13252 1204 2025 1106 14133 1103 13950 1104 1210 10298 1193 19849 8340 12814 3377 113 26574 1708 118 157 2162 15499 117 22157 2137 117 1105 153 21678 2137 114 1107 1103 3252 1104 1231 21754 1123 5813 2116 119 1335 1103 2812 118 1146 9355 1104 1367 7578 9524 117 1185 4420 113 121 119 121 110 114 1107 1103 26574 1708 118 157 2162 15499 1372 117 124 4420 113 1405 119 121 110 114 1107 1103 22157 2137 1372 117 1105 128 4420 113 1512 119 121 110 114 1107 1103 153 21678 2137 1372 1872 1231 10182 21629 119 164 2532 166 1109 1231 10182 21629 2603 1107 1103 153 21678 2137 1372 1108 5409 2299 1190 1115 1107 1103 26574 1708 118 157 2162 15499 1372 119 10321 117 1107 1147 1330 3055 1502 3443 117 164 4335 166 1152 1145 2103 170 2299 1231 10182 21629 2603 1104 153 21678 2137 1190 26574 1708 118 157 2162 15499 119 1130 1115 2025 117 1103 5752 7945 8359 4420 1150 9315 1719 153 21678 2137 113 183 134 3862 114 1137 26574 1708 118 157 2162 15499 113 183 134 4650 114 1111 16547 1104 22157 2137 1231 10182 21629 119 164 4335 166 1335 1103 1367 118 2370 2812 118 1146 117 4420 1150 9315 153 21678 2137 1125 170 5409 2299 1231 10182 21629 2603 113 1275 119 3324 110 114 1190 1343 5165 1114 26574 1708 118 157 2162 15499 113 121 119 121 110 114 119 164 4335 166 1109 5752 6547 1103 9505 1106 1103 1378 3672 131 113 122 114 1175 1108 1199 3187 5320 1115 1127 17163 2109 1104 1231 10182 21629 1107 153 21678 2137 4420 119 1370 1859 117 1385 1425 117 184 27655 117 1105 12556 13328 1849 1138 1151 3626 1112 2418 3187 5320 1111 1103 153 21678 2137 1231 10182 1197 118 1231 3633 119 164 4650 117 4589 166 1262 1103 126 4420 1150 4531 1231 10182 21629 1107 1103 153 21678 2137 1372 1127 1155 3860 102\n",
      "INFO:tensorflow:input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      "I1208 12:27:37.186271 139883775852736 run_factoid.py:451] input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      "INFO:tensorflow:segment_ids: 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      "I1208 12:27:37.186361 139883775852736 run_factoid.py:453] segment_ids: 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      "INFO:tensorflow:*** Example ***\n",
      "I1208 12:27:37.188158 139883775852736 run_factoid.py:438] *** Example ***\n",
      "INFO:tensorflow:unique_id: 1000000055\n",
      "I1208 12:27:37.188217 139883775852736 run_factoid.py:439] unique_id: 1000000055\n",
      "INFO:tensorflow:example_index: 9\n",
      "I1208 12:27:37.188255 139883775852736 run_factoid.py:440] example_index: 9\n",
      "INFO:tensorflow:doc_span_index: 2\n",
      "I1208 12:27:37.188289 139883775852736 run_factoid.py:441] doc_span_index: 2\n",
      "INFO:tensorflow:tokens: [CLS] What are the limitations of the findings ? [SEP] ##cu ##rrence . [ 45 ] The re ##cu ##rrence rate in the P ##EL ##D group was significantly higher than that in the MI ##S - T ##L ##IF group . Similarly , in their another recently published trial , [ 54 ] they also reported a higher re ##cu ##rrence rate of P ##EL ##D than MI ##S - T ##L ##IF . In that study , the authors enrolled 105 patients who underwent either P ##EL ##D ( n = 47 ) or MI ##S - T ##L ##IF ( n = 58 ) for revision of ME ##D re ##cu ##rrence . [ 54 ] At the 12 - month follow - up , patients who underwent P ##EL ##D had a significantly higher re ##cu ##rrence rate ( 10 . 64 % ) than those treated with MI ##S - T ##L ##IF ( 0 . 0 % ) . [ 54 ] The authors attributed the findings to the following reasons : ( 1 ) there was some risk factors that were predict ##ive of re ##cu ##rrence in P ##EL ##D patients . For example , old age , o ##besity , and Mo ##dic change have been identified as significant risk factors for the P ##EL ##D re ##cu ##r - re ##nce . [ 58 , 59 ] And the 5 patients who experienced re ##cu ##rrence in the P ##EL ##D group were all relatively old ( ≥ ##60 years old ) and o ##bes ##e ; thus , they were at high risk of re ##current her ##nia ##tion . [ 54 ] ( 2 ) 3 of the 5 patients had her ##nia ##ted fragment that were highly migrated , and this made the surgery more difficult . [ 60 ] The residual fragment would result in unsuccessful surgical outcomes . [ 58 , 61 ] ( 3 ) After the primary ME ##D surgery , the artificial cracks in an ##nu ##lus fi ##bro ##sus would change the la ##minate structure , and make the an ##nu ##lus be more easily to del ##ami ##nation . [ 54 ] Based on the damage in an ##nu ##lus fi ##bro ##sus [SEP]\n",
      "I1208 12:27:37.188418 139883775852736 run_factoid.py:443] tokens: [CLS] What are the limitations of the findings ? [SEP] ##cu ##rrence . [ 45 ] The re ##cu ##rrence rate in the P ##EL ##D group was significantly higher than that in the MI ##S - T ##L ##IF group . Similarly , in their another recently published trial , [ 54 ] they also reported a higher re ##cu ##rrence rate of P ##EL ##D than MI ##S - T ##L ##IF . In that study , the authors enrolled 105 patients who underwent either P ##EL ##D ( n = 47 ) or MI ##S - T ##L ##IF ( n = 58 ) for revision of ME ##D re ##cu ##rrence . [ 54 ] At the 12 - month follow - up , patients who underwent P ##EL ##D had a significantly higher re ##cu ##rrence rate ( 10 . 64 % ) than those treated with MI ##S - T ##L ##IF ( 0 . 0 % ) . [ 54 ] The authors attributed the findings to the following reasons : ( 1 ) there was some risk factors that were predict ##ive of re ##cu ##rrence in P ##EL ##D patients . For example , old age , o ##besity , and Mo ##dic change have been identified as significant risk factors for the P ##EL ##D re ##cu ##r - re ##nce . [ 58 , 59 ] And the 5 patients who experienced re ##cu ##rrence in the P ##EL ##D group were all relatively old ( ≥ ##60 years old ) and o ##bes ##e ; thus , they were at high risk of re ##current her ##nia ##tion . [ 54 ] ( 2 ) 3 of the 5 patients had her ##nia ##ted fragment that were highly migrated , and this made the surgery more difficult . [ 60 ] The residual fragment would result in unsuccessful surgical outcomes . [ 58 , 61 ] ( 3 ) After the primary ME ##D surgery , the artificial cracks in an ##nu ##lus fi ##bro ##sus would change the la ##minate structure , and make the an ##nu ##lus be more easily to del ##ami ##nation . [ 54 ] Based on the damage in an ##nu ##lus fi ##bro ##sus [SEP]\n",
      "INFO:tensorflow:token_to_orig_map: 10:156 11:156 12:156 13:156 14:156 15:156 16:157 17:158 18:158 19:158 20:159 21:160 22:161 23:162 24:162 25:162 26:163 27:164 28:165 29:166 30:167 31:168 32:169 33:170 34:171 35:171 36:171 37:171 38:171 39:171 40:172 41:172 42:173 43:173 44:174 45:175 46:176 47:177 48:178 49:179 50:179 51:179 52:179 53:179 54:180 55:181 56:182 57:183 58:184 59:185 60:185 61:185 62:186 63:187 64:188 65:188 66:188 67:189 68:190 69:190 70:190 71:190 72:190 73:190 74:190 75:191 76:192 77:193 78:193 79:194 80:195 81:196 82:197 83:198 84:199 85:200 86:201 87:202 88:202 89:202 90:203 91:203 92:204 93:205 94:205 95:206 96:207 97:207 98:207 99:207 100:207 101:207 102:208 103:208 104:209 105:210 106:210 107:211 108:212 109:213 110:214 111:214 112:215 113:215 114:215 115:215 116:215 117:215 118:215 119:216 120:217 121:218 122:218 123:218 124:219 125:219 126:219 127:219 128:220 129:221 130:222 131:223 132:223 133:223 134:224 135:225 136:226 137:227 138:228 139:228 140:228 141:229 142:230 143:230 144:230 145:230 146:230 147:230 148:231 149:232 150:233 151:234 152:235 153:235 154:235 155:235 156:235 157:235 158:236 159:236 160:236 161:236 162:236 163:236 164:236 165:236 166:236 167:236 168:237 169:238 170:239 171:240 172:241 173:242 174:243 175:244 176:245 177:245 178:246 179:246 180:246 181:247 182:248 183:249 184:250 185:251 186:252 187:253 188:254 189:254 190:255 191:256 192:256 193:256 194:257 195:258 196:258 197:258 198:259 199:259 200:260 201:261 202:261 203:262 204:263 205:263 206:264 207:264 208:264 209:265 210:266 211:266 212:267 213:268 214:269 215:270 216:271 217:272 218:273 219:274 220:275 221:276 222:277 223:277 224:277 225:278 226:278 227:278 228:278 229:279 230:279 231:279 232:279 233:279 234:279 235:279 236:279 237:280 238:281 239:282 240:283 241:284 242:285 243:286 244:286 245:286 246:287 247:288 248:289 249:289 250:289 251:290 252:291 253:292 254:293 255:294 256:295 257:295 258:295 259:296 260:297 261:297 262:298 263:299 264:299 265:299 266:299 267:300 268:300 269:301 270:302 271:303 272:304 273:305 274:306 275:307 276:307 277:308 278:308 279:308 280:308 281:308 282:308 283:308 284:309 285:309 286:309 287:310 288:311 289:312 290:313 291:314 292:315 293:316 294:316 295:316 296:317 297:318 298:319 299:320 300:321 301:321 302:322 303:323 304:324 305:325 306:326 307:327 308:328 309:328 310:328 311:328 312:328 313:329 314:330 315:331 316:332 317:333 318:334 319:335 320:336 321:337 322:337 323:337 324:337 325:337 326:337 327:337 328:338 329:338 330:338 331:339 332:340 333:341 334:342 335:342 336:343 337:343 338:344 339:345 340:346 341:347 342:348 343:348 344:348 345:349 346:349 347:349 348:350 349:351 350:352 351:353 352:353 353:354 354:354 355:355 356:356 357:357 358:358 359:358 360:358 361:359 362:360 363:361 364:362 365:363 366:363 367:363 368:363 369:363 370:363 371:363 372:364 373:365 374:366 375:367 376:368 377:369 378:369 379:369 380:370 381:370 382:370\n",
      "I1208 12:27:37.188548 139883775852736 run_factoid.py:445] token_to_orig_map: 10:156 11:156 12:156 13:156 14:156 15:156 16:157 17:158 18:158 19:158 20:159 21:160 22:161 23:162 24:162 25:162 26:163 27:164 28:165 29:166 30:167 31:168 32:169 33:170 34:171 35:171 36:171 37:171 38:171 39:171 40:172 41:172 42:173 43:173 44:174 45:175 46:176 47:177 48:178 49:179 50:179 51:179 52:179 53:179 54:180 55:181 56:182 57:183 58:184 59:185 60:185 61:185 62:186 63:187 64:188 65:188 66:188 67:189 68:190 69:190 70:190 71:190 72:190 73:190 74:190 75:191 76:192 77:193 78:193 79:194 80:195 81:196 82:197 83:198 84:199 85:200 86:201 87:202 88:202 89:202 90:203 91:203 92:204 93:205 94:205 95:206 96:207 97:207 98:207 99:207 100:207 101:207 102:208 103:208 104:209 105:210 106:210 107:211 108:212 109:213 110:214 111:214 112:215 113:215 114:215 115:215 116:215 117:215 118:215 119:216 120:217 121:218 122:218 123:218 124:219 125:219 126:219 127:219 128:220 129:221 130:222 131:223 132:223 133:223 134:224 135:225 136:226 137:227 138:228 139:228 140:228 141:229 142:230 143:230 144:230 145:230 146:230 147:230 148:231 149:232 150:233 151:234 152:235 153:235 154:235 155:235 156:235 157:235 158:236 159:236 160:236 161:236 162:236 163:236 164:236 165:236 166:236 167:236 168:237 169:238 170:239 171:240 172:241 173:242 174:243 175:244 176:245 177:245 178:246 179:246 180:246 181:247 182:248 183:249 184:250 185:251 186:252 187:253 188:254 189:254 190:255 191:256 192:256 193:256 194:257 195:258 196:258 197:258 198:259 199:259 200:260 201:261 202:261 203:262 204:263 205:263 206:264 207:264 208:264 209:265 210:266 211:266 212:267 213:268 214:269 215:270 216:271 217:272 218:273 219:274 220:275 221:276 222:277 223:277 224:277 225:278 226:278 227:278 228:278 229:279 230:279 231:279 232:279 233:279 234:279 235:279 236:279 237:280 238:281 239:282 240:283 241:284 242:285 243:286 244:286 245:286 246:287 247:288 248:289 249:289 250:289 251:290 252:291 253:292 254:293 255:294 256:295 257:295 258:295 259:296 260:297 261:297 262:298 263:299 264:299 265:299 266:299 267:300 268:300 269:301 270:302 271:303 272:304 273:305 274:306 275:307 276:307 277:308 278:308 279:308 280:308 281:308 282:308 283:308 284:309 285:309 286:309 287:310 288:311 289:312 290:313 291:314 292:315 293:316 294:316 295:316 296:317 297:318 298:319 299:320 300:321 301:321 302:322 303:323 304:324 305:325 306:326 307:327 308:328 309:328 310:328 311:328 312:328 313:329 314:330 315:331 316:332 317:333 318:334 319:335 320:336 321:337 322:337 323:337 324:337 325:337 326:337 327:337 328:338 329:338 330:338 331:339 332:340 333:341 334:342 335:342 336:343 337:343 338:344 339:345 340:346 341:347 342:348 343:348 344:348 345:349 346:349 347:349 348:350 349:351 350:352 351:353 352:353 353:354 354:354 355:355 356:356 357:357 358:358 359:358 360:358 361:359 362:360 363:361 364:362 365:363 366:363 367:363 368:363 369:363 370:363 371:363 372:364 373:365 374:366 375:367 376:368 377:369 378:369 379:369 380:370 381:370 382:370\n",
      "INFO:tensorflow:token_is_max_context: 10:False 11:False 12:False 13:False 14:False 15:False 16:False 17:False 18:False 19:False 20:False 21:False 22:False 23:False 24:False 25:False 26:False 27:False 28:False 29:False 30:False 31:False 32:False 33:False 34:False 35:False 36:False 37:False 38:False 39:False 40:False 41:False 42:False 43:False 44:False 45:False 46:False 47:False 48:False 49:False 50:False 51:False 52:False 53:False 54:False 55:False 56:False 57:False 58:False 59:False 60:False 61:False 62:False 63:False 64:False 65:False 66:False 67:False 68:False 69:False 70:False 71:False 72:False 73:False 74:False 75:False 76:False 77:False 78:False 79:False 80:False 81:False 82:False 83:False 84:False 85:False 86:False 87:False 88:False 89:False 90:False 91:False 92:False 93:False 94:False 95:False 96:False 97:False 98:False 99:False 100:False 101:False 102:False 103:False 104:False 105:False 106:False 107:False 108:False 109:False 110:False 111:False 112:False 113:False 114:False 115:False 116:False 117:False 118:False 119:False 120:False 121:False 122:False 123:False 124:False 125:False 126:False 127:False 128:False 129:False 130:False 131:False 132:False 133:True 134:True 135:True 136:True 137:True 138:True 139:True 140:True 141:True 142:True 143:True 144:True 145:True 146:True 147:True 148:True 149:True 150:True 151:True 152:True 153:True 154:True 155:True 156:True 157:True 158:True 159:True 160:True 161:True 162:True 163:True 164:True 165:True 166:True 167:True 168:True 169:True 170:True 171:True 172:True 173:True 174:True 175:True 176:True 177:True 178:True 179:True 180:True 181:True 182:True 183:True 184:True 185:True 186:True 187:True 188:True 189:True 190:True 191:True 192:True 193:True 194:True 195:True 196:True 197:True 198:True 199:True 200:True 201:True 202:True 203:True 204:True 205:True 206:True 207:True 208:True 209:True 210:True 211:True 212:True 213:True 214:True 215:True 216:True 217:True 218:True 219:True 220:True 221:True 222:True 223:True 224:True 225:True 226:True 227:True 228:True 229:True 230:True 231:True 232:True 233:True 234:True 235:True 236:True 237:True 238:True 239:True 240:True 241:True 242:True 243:True 244:True 245:True 246:True 247:True 248:True 249:True 250:True 251:True 252:True 253:True 254:True 255:True 256:True 257:True 258:True 259:True 260:True 261:False 262:False 263:False 264:False 265:False 266:False 267:False 268:False 269:False 270:False 271:False 272:False 273:False 274:False 275:False 276:False 277:False 278:False 279:False 280:False 281:False 282:False 283:False 284:False 285:False 286:False 287:False 288:False 289:False 290:False 291:False 292:False 293:False 294:False 295:False 296:False 297:False 298:False 299:False 300:False 301:False 302:False 303:False 304:False 305:False 306:False 307:False 308:False 309:False 310:False 311:False 312:False 313:False 314:False 315:False 316:False 317:False 318:False 319:False 320:False 321:False 322:False 323:False 324:False 325:False 326:False 327:False 328:False 329:False 330:False 331:False 332:False 333:False 334:False 335:False 336:False 337:False 338:False 339:False 340:False 341:False 342:False 343:False 344:False 345:False 346:False 347:False 348:False 349:False 350:False 351:False 352:False 353:False 354:False 355:False 356:False 357:False 358:False 359:False 360:False 361:False 362:False 363:False 364:False 365:False 366:False 367:False 368:False 369:False 370:False 371:False 372:False 373:False 374:False 375:False 376:False 377:False 378:False 379:False 380:False 381:False 382:False\n",
      "I1208 12:27:37.188673 139883775852736 run_factoid.py:447] token_is_max_context: 10:False 11:False 12:False 13:False 14:False 15:False 16:False 17:False 18:False 19:False 20:False 21:False 22:False 23:False 24:False 25:False 26:False 27:False 28:False 29:False 30:False 31:False 32:False 33:False 34:False 35:False 36:False 37:False 38:False 39:False 40:False 41:False 42:False 43:False 44:False 45:False 46:False 47:False 48:False 49:False 50:False 51:False 52:False 53:False 54:False 55:False 56:False 57:False 58:False 59:False 60:False 61:False 62:False 63:False 64:False 65:False 66:False 67:False 68:False 69:False 70:False 71:False 72:False 73:False 74:False 75:False 76:False 77:False 78:False 79:False 80:False 81:False 82:False 83:False 84:False 85:False 86:False 87:False 88:False 89:False 90:False 91:False 92:False 93:False 94:False 95:False 96:False 97:False 98:False 99:False 100:False 101:False 102:False 103:False 104:False 105:False 106:False 107:False 108:False 109:False 110:False 111:False 112:False 113:False 114:False 115:False 116:False 117:False 118:False 119:False 120:False 121:False 122:False 123:False 124:False 125:False 126:False 127:False 128:False 129:False 130:False 131:False 132:False 133:True 134:True 135:True 136:True 137:True 138:True 139:True 140:True 141:True 142:True 143:True 144:True 145:True 146:True 147:True 148:True 149:True 150:True 151:True 152:True 153:True 154:True 155:True 156:True 157:True 158:True 159:True 160:True 161:True 162:True 163:True 164:True 165:True 166:True 167:True 168:True 169:True 170:True 171:True 172:True 173:True 174:True 175:True 176:True 177:True 178:True 179:True 180:True 181:True 182:True 183:True 184:True 185:True 186:True 187:True 188:True 189:True 190:True 191:True 192:True 193:True 194:True 195:True 196:True 197:True 198:True 199:True 200:True 201:True 202:True 203:True 204:True 205:True 206:True 207:True 208:True 209:True 210:True 211:True 212:True 213:True 214:True 215:True 216:True 217:True 218:True 219:True 220:True 221:True 222:True 223:True 224:True 225:True 226:True 227:True 228:True 229:True 230:True 231:True 232:True 233:True 234:True 235:True 236:True 237:True 238:True 239:True 240:True 241:True 242:True 243:True 244:True 245:True 246:True 247:True 248:True 249:True 250:True 251:True 252:True 253:True 254:True 255:True 256:True 257:True 258:True 259:True 260:True 261:False 262:False 263:False 264:False 265:False 266:False 267:False 268:False 269:False 270:False 271:False 272:False 273:False 274:False 275:False 276:False 277:False 278:False 279:False 280:False 281:False 282:False 283:False 284:False 285:False 286:False 287:False 288:False 289:False 290:False 291:False 292:False 293:False 294:False 295:False 296:False 297:False 298:False 299:False 300:False 301:False 302:False 303:False 304:False 305:False 306:False 307:False 308:False 309:False 310:False 311:False 312:False 313:False 314:False 315:False 316:False 317:False 318:False 319:False 320:False 321:False 322:False 323:False 324:False 325:False 326:False 327:False 328:False 329:False 330:False 331:False 332:False 333:False 334:False 335:False 336:False 337:False 338:False 339:False 340:False 341:False 342:False 343:False 344:False 345:False 346:False 347:False 348:False 349:False 350:False 351:False 352:False 353:False 354:False 355:False 356:False 357:False 358:False 359:False 360:False 361:False 362:False 363:False 364:False 365:False 366:False 367:False 368:False 369:False 370:False 371:False 372:False 373:False 374:False 375:False 376:False 377:False 378:False 379:False 380:False 381:False 382:False\n",
      "INFO:tensorflow:input_ids: 101 1327 1132 1103 13004 1104 1103 9505 136 102 10182 21629 119 164 2532 166 1109 1231 10182 21629 2603 1107 1103 153 21678 2137 1372 1108 5409 2299 1190 1115 1107 1103 26574 1708 118 157 2162 15499 1372 119 10321 117 1107 1147 1330 3055 1502 3443 117 164 4335 166 1152 1145 2103 170 2299 1231 10182 21629 2603 1104 153 21678 2137 1190 26574 1708 118 157 2162 15499 119 1130 1115 2025 117 1103 5752 7945 8359 4420 1150 9315 1719 153 21678 2137 113 183 134 3862 114 1137 26574 1708 118 157 2162 15499 113 183 134 4650 114 1111 16547 1104 22157 2137 1231 10182 21629 119 164 4335 166 1335 1103 1367 118 2370 2812 118 1146 117 4420 1150 9315 153 21678 2137 1125 170 5409 2299 1231 10182 21629 2603 113 1275 119 3324 110 114 1190 1343 5165 1114 26574 1708 118 157 2162 15499 113 121 119 121 110 114 119 164 4335 166 1109 5752 6547 1103 9505 1106 1103 1378 3672 131 113 122 114 1175 1108 1199 3187 5320 1115 1127 17163 2109 1104 1231 10182 21629 1107 153 21678 2137 4420 119 1370 1859 117 1385 1425 117 184 27655 117 1105 12556 13328 1849 1138 1151 3626 1112 2418 3187 5320 1111 1103 153 21678 2137 1231 10182 1197 118 1231 3633 119 164 4650 117 4589 166 1262 1103 126 4420 1150 4531 1231 10182 21629 1107 1103 153 21678 2137 1372 1127 1155 3860 1385 113 864 16480 1201 1385 114 1105 184 12866 1162 132 2456 117 1152 1127 1120 1344 3187 1104 1231 21754 1123 5813 2116 119 164 4335 166 113 123 114 124 1104 1103 126 4420 1125 1123 5813 1906 17906 1115 1127 3023 13793 117 1105 1142 1189 1103 6059 1167 2846 119 164 2539 166 1109 25399 17906 1156 1871 1107 7285 13467 13950 119 164 4650 117 5391 166 113 124 114 1258 1103 2425 22157 2137 6059 117 1103 8246 16694 1107 1126 14787 5954 20497 12725 14410 1156 1849 1103 2495 17379 2401 117 1105 1294 1103 1126 14787 5954 1129 1167 3253 1106 3687 11787 9199 119 164 4335 166 7457 1113 1103 3290 1107 1126 14787 5954 20497 12725 14410 102\n",
      "I1208 12:27:37.188784 139883775852736 run_factoid.py:449] input_ids: 101 1327 1132 1103 13004 1104 1103 9505 136 102 10182 21629 119 164 2532 166 1109 1231 10182 21629 2603 1107 1103 153 21678 2137 1372 1108 5409 2299 1190 1115 1107 1103 26574 1708 118 157 2162 15499 1372 119 10321 117 1107 1147 1330 3055 1502 3443 117 164 4335 166 1152 1145 2103 170 2299 1231 10182 21629 2603 1104 153 21678 2137 1190 26574 1708 118 157 2162 15499 119 1130 1115 2025 117 1103 5752 7945 8359 4420 1150 9315 1719 153 21678 2137 113 183 134 3862 114 1137 26574 1708 118 157 2162 15499 113 183 134 4650 114 1111 16547 1104 22157 2137 1231 10182 21629 119 164 4335 166 1335 1103 1367 118 2370 2812 118 1146 117 4420 1150 9315 153 21678 2137 1125 170 5409 2299 1231 10182 21629 2603 113 1275 119 3324 110 114 1190 1343 5165 1114 26574 1708 118 157 2162 15499 113 121 119 121 110 114 119 164 4335 166 1109 5752 6547 1103 9505 1106 1103 1378 3672 131 113 122 114 1175 1108 1199 3187 5320 1115 1127 17163 2109 1104 1231 10182 21629 1107 153 21678 2137 4420 119 1370 1859 117 1385 1425 117 184 27655 117 1105 12556 13328 1849 1138 1151 3626 1112 2418 3187 5320 1111 1103 153 21678 2137 1231 10182 1197 118 1231 3633 119 164 4650 117 4589 166 1262 1103 126 4420 1150 4531 1231 10182 21629 1107 1103 153 21678 2137 1372 1127 1155 3860 1385 113 864 16480 1201 1385 114 1105 184 12866 1162 132 2456 117 1152 1127 1120 1344 3187 1104 1231 21754 1123 5813 2116 119 164 4335 166 113 123 114 124 1104 1103 126 4420 1125 1123 5813 1906 17906 1115 1127 3023 13793 117 1105 1142 1189 1103 6059 1167 2846 119 164 2539 166 1109 25399 17906 1156 1871 1107 7285 13467 13950 119 164 4650 117 5391 166 113 124 114 1258 1103 2425 22157 2137 6059 117 1103 8246 16694 1107 1126 14787 5954 20497 12725 14410 1156 1849 1103 2495 17379 2401 117 1105 1294 1103 1126 14787 5954 1129 1167 3253 1106 3687 11787 9199 119 164 4335 166 7457 1113 1103 3290 1107 1126 14787 5954 20497 12725 14410 102\n",
      "INFO:tensorflow:input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      "I1208 12:27:37.188878 139883775852736 run_factoid.py:451] input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      "INFO:tensorflow:segment_ids: 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      "I1208 12:27:37.188969 139883775852736 run_factoid.py:453] segment_ids: 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      "INFO:tensorflow:*** Example ***\n",
      "I1208 12:27:37.190769 139883775852736 run_factoid.py:438] *** Example ***\n",
      "INFO:tensorflow:unique_id: 1000000056\n",
      "I1208 12:27:37.190829 139883775852736 run_factoid.py:439] unique_id: 1000000056\n",
      "INFO:tensorflow:example_index: 9\n",
      "I1208 12:27:37.190869 139883775852736 run_factoid.py:440] example_index: 9\n",
      "INFO:tensorflow:doc_span_index: 3\n",
      "I1208 12:27:37.190904 139883775852736 run_factoid.py:441] doc_span_index: 3\n",
      "INFO:tensorflow:tokens: [CLS] What are the limitations of the findings ? [SEP] re ##cu ##rrence rate ( 10 . 64 % ) than those treated with MI ##S - T ##L ##IF ( 0 . 0 % ) . [ 54 ] The authors attributed the findings to the following reasons : ( 1 ) there was some risk factors that were predict ##ive of re ##cu ##rrence in P ##EL ##D patients . For example , old age , o ##besity , and Mo ##dic change have been identified as significant risk factors for the P ##EL ##D re ##cu ##r - re ##nce . [ 58 , 59 ] And the 5 patients who experienced re ##cu ##rrence in the P ##EL ##D group were all relatively old ( ≥ ##60 years old ) and o ##bes ##e ; thus , they were at high risk of re ##current her ##nia ##tion . [ 54 ] ( 2 ) 3 of the 5 patients had her ##nia ##ted fragment that were highly migrated , and this made the surgery more difficult . [ 60 ] The residual fragment would result in unsuccessful surgical outcomes . [ 58 , 61 ] ( 3 ) After the primary ME ##D surgery , the artificial cracks in an ##nu ##lus fi ##bro ##sus would change the la ##minate structure , and make the an ##nu ##lus be more easily to del ##ami ##nation . [ 54 ] Based on the damage in an ##nu ##lus fi ##bro ##sus , the re ##current her ##nia ##tion easily occurred . [ 62 ] Therefore , it is unable for P ##EL ##D to solve this problem thoroughly , and a through inter ##body fusion ( MI ##S - T ##L ##IF ) might be a better choice . [ 54 ] The success rate in the P ##EL ##D group and other surgical intervention group were 7 . 2 % and 4 . 1 % , respectively . Although patients treated with P ##EL ##D achieved a significantly higher success rate than those with other surge ##ries , the difference between them was not significant . Lee SH , et al [ 46 ] performed a matched co ##hor ##t study evaluation of 60 consecutive patients with L [SEP]\n",
      "I1208 12:27:37.191026 139883775852736 run_factoid.py:443] tokens: [CLS] What are the limitations of the findings ? [SEP] re ##cu ##rrence rate ( 10 . 64 % ) than those treated with MI ##S - T ##L ##IF ( 0 . 0 % ) . [ 54 ] The authors attributed the findings to the following reasons : ( 1 ) there was some risk factors that were predict ##ive of re ##cu ##rrence in P ##EL ##D patients . For example , old age , o ##besity , and Mo ##dic change have been identified as significant risk factors for the P ##EL ##D re ##cu ##r - re ##nce . [ 58 , 59 ] And the 5 patients who experienced re ##cu ##rrence in the P ##EL ##D group were all relatively old ( ≥ ##60 years old ) and o ##bes ##e ; thus , they were at high risk of re ##current her ##nia ##tion . [ 54 ] ( 2 ) 3 of the 5 patients had her ##nia ##ted fragment that were highly migrated , and this made the surgery more difficult . [ 60 ] The residual fragment would result in unsuccessful surgical outcomes . [ 58 , 61 ] ( 3 ) After the primary ME ##D surgery , the artificial cracks in an ##nu ##lus fi ##bro ##sus would change the la ##minate structure , and make the an ##nu ##lus be more easily to del ##ami ##nation . [ 54 ] Based on the damage in an ##nu ##lus fi ##bro ##sus , the re ##current her ##nia ##tion easily occurred . [ 62 ] Therefore , it is unable for P ##EL ##D to solve this problem thoroughly , and a through inter ##body fusion ( MI ##S - T ##L ##IF ) might be a better choice . [ 54 ] The success rate in the P ##EL ##D group and other surgical intervention group were 7 . 2 % and 4 . 1 % , respectively . Although patients treated with P ##EL ##D achieved a significantly higher success rate than those with other surge ##ries , the difference between them was not significant . Lee SH , et al [ 46 ] performed a matched co ##hor ##t study evaluation of 60 consecutive patients with L [SEP]\n",
      "INFO:tensorflow:token_to_orig_map: 10:228 11:228 12:228 13:229 14:230 15:230 16:230 17:230 18:230 19:230 20:231 21:232 22:233 23:234 24:235 25:235 26:235 27:235 28:235 29:235 30:236 31:236 32:236 33:236 34:236 35:236 36:236 37:236 38:236 39:236 40:237 41:238 42:239 43:240 44:241 45:242 46:243 47:244 48:245 49:245 50:246 51:246 52:246 53:247 54:248 55:249 56:250 57:251 58:252 59:253 60:254 61:254 62:255 63:256 64:256 65:256 66:257 67:258 68:258 69:258 70:259 71:259 72:260 73:261 74:261 75:262 76:263 77:263 78:264 79:264 80:264 81:265 82:266 83:266 84:267 85:268 86:269 87:270 88:271 89:272 90:273 91:274 92:275 93:276 94:277 95:277 96:277 97:278 98:278 99:278 100:278 101:279 102:279 103:279 104:279 105:279 106:279 107:279 108:279 109:280 110:281 111:282 112:283 113:284 114:285 115:286 116:286 117:286 118:287 119:288 120:289 121:289 122:289 123:290 124:291 125:292 126:293 127:294 128:295 129:295 130:295 131:296 132:297 133:297 134:298 135:299 136:299 137:299 138:299 139:300 140:300 141:301 142:302 143:303 144:304 145:305 146:306 147:307 148:307 149:308 150:308 151:308 152:308 153:308 154:308 155:308 156:309 157:309 158:309 159:310 160:311 161:312 162:313 163:314 164:315 165:316 166:316 167:316 168:317 169:318 170:319 171:320 172:321 173:321 174:322 175:323 176:324 177:325 178:326 179:327 180:328 181:328 182:328 183:328 184:328 185:329 186:330 187:331 188:332 189:333 190:334 191:335 192:336 193:337 194:337 195:337 196:337 197:337 198:337 199:337 200:338 201:338 202:338 203:339 204:340 205:341 206:342 207:342 208:343 209:343 210:344 211:345 212:346 213:347 214:348 215:348 216:348 217:349 218:349 219:349 220:350 221:351 222:352 223:353 224:353 225:354 226:354 227:355 228:356 229:357 230:358 231:358 232:358 233:359 234:360 235:361 236:362 237:363 238:363 239:363 240:363 241:363 242:363 243:363 244:364 245:365 246:366 247:367 248:368 249:369 250:369 251:369 252:370 253:370 254:370 255:370 256:371 257:372 258:372 259:373 260:373 261:373 262:374 263:375 264:375 265:375 266:375 267:375 268:376 269:376 270:377 271:378 272:379 273:380 274:381 275:381 276:381 277:382 278:383 279:384 280:385 281:386 282:386 283:387 284:388 285:389 286:390 287:390 288:391 289:392 290:392 291:392 292:392 293:392 294:392 295:392 296:392 297:393 298:394 299:395 300:396 301:397 302:397 303:397 304:397 305:397 306:398 307:399 308:400 309:401 310:402 311:403 312:403 313:403 314:404 315:405 316:406 317:407 318:408 319:409 320:410 321:411 322:411 323:411 324:411 325:412 326:413 327:413 328:413 329:413 330:413 331:414 332:414 333:415 334:416 335:417 336:418 337:419 338:419 339:419 340:420 341:421 342:422 343:423 344:424 345:425 346:426 347:427 348:428 349:429 350:430 351:430 352:430 353:431 354:432 355:433 356:434 357:435 358:436 359:437 360:437 361:438 362:439 363:439 364:440 365:441 366:441 367:441 368:441 369:442 370:443 371:444 372:445 373:445 374:445 375:446 376:447 377:448 378:449 379:450 380:451 381:452 382:453\n",
      "I1208 12:27:37.191146 139883775852736 run_factoid.py:445] token_to_orig_map: 10:228 11:228 12:228 13:229 14:230 15:230 16:230 17:230 18:230 19:230 20:231 21:232 22:233 23:234 24:235 25:235 26:235 27:235 28:235 29:235 30:236 31:236 32:236 33:236 34:236 35:236 36:236 37:236 38:236 39:236 40:237 41:238 42:239 43:240 44:241 45:242 46:243 47:244 48:245 49:245 50:246 51:246 52:246 53:247 54:248 55:249 56:250 57:251 58:252 59:253 60:254 61:254 62:255 63:256 64:256 65:256 66:257 67:258 68:258 69:258 70:259 71:259 72:260 73:261 74:261 75:262 76:263 77:263 78:264 79:264 80:264 81:265 82:266 83:266 84:267 85:268 86:269 87:270 88:271 89:272 90:273 91:274 92:275 93:276 94:277 95:277 96:277 97:278 98:278 99:278 100:278 101:279 102:279 103:279 104:279 105:279 106:279 107:279 108:279 109:280 110:281 111:282 112:283 113:284 114:285 115:286 116:286 117:286 118:287 119:288 120:289 121:289 122:289 123:290 124:291 125:292 126:293 127:294 128:295 129:295 130:295 131:296 132:297 133:297 134:298 135:299 136:299 137:299 138:299 139:300 140:300 141:301 142:302 143:303 144:304 145:305 146:306 147:307 148:307 149:308 150:308 151:308 152:308 153:308 154:308 155:308 156:309 157:309 158:309 159:310 160:311 161:312 162:313 163:314 164:315 165:316 166:316 167:316 168:317 169:318 170:319 171:320 172:321 173:321 174:322 175:323 176:324 177:325 178:326 179:327 180:328 181:328 182:328 183:328 184:328 185:329 186:330 187:331 188:332 189:333 190:334 191:335 192:336 193:337 194:337 195:337 196:337 197:337 198:337 199:337 200:338 201:338 202:338 203:339 204:340 205:341 206:342 207:342 208:343 209:343 210:344 211:345 212:346 213:347 214:348 215:348 216:348 217:349 218:349 219:349 220:350 221:351 222:352 223:353 224:353 225:354 226:354 227:355 228:356 229:357 230:358 231:358 232:358 233:359 234:360 235:361 236:362 237:363 238:363 239:363 240:363 241:363 242:363 243:363 244:364 245:365 246:366 247:367 248:368 249:369 250:369 251:369 252:370 253:370 254:370 255:370 256:371 257:372 258:372 259:373 260:373 261:373 262:374 263:375 264:375 265:375 266:375 267:375 268:376 269:376 270:377 271:378 272:379 273:380 274:381 275:381 276:381 277:382 278:383 279:384 280:385 281:386 282:386 283:387 284:388 285:389 286:390 287:390 288:391 289:392 290:392 291:392 292:392 293:392 294:392 295:392 296:392 297:393 298:394 299:395 300:396 301:397 302:397 303:397 304:397 305:397 306:398 307:399 308:400 309:401 310:402 311:403 312:403 313:403 314:404 315:405 316:406 317:407 318:408 319:409 320:410 321:411 322:411 323:411 324:411 325:412 326:413 327:413 328:413 329:413 330:413 331:414 332:414 333:415 334:416 335:417 336:418 337:419 338:419 339:419 340:420 341:421 342:422 343:423 344:424 345:425 346:426 347:427 348:428 349:429 350:430 351:430 352:430 353:431 354:432 355:433 356:434 357:435 358:436 359:437 360:437 361:438 362:439 363:439 364:440 365:441 366:441 367:441 368:441 369:442 370:443 371:444 372:445 373:445 374:445 375:446 376:447 377:448 378:449 379:450 380:451 381:452 382:453\n",
      "INFO:tensorflow:token_is_max_context: 10:False 11:False 12:False 13:False 14:False 15:False 16:False 17:False 18:False 19:False 20:False 21:False 22:False 23:False 24:False 25:False 26:False 27:False 28:False 29:False 30:False 31:False 32:False 33:False 34:False 35:False 36:False 37:False 38:False 39:False 40:False 41:False 42:False 43:False 44:False 45:False 46:False 47:False 48:False 49:False 50:False 51:False 52:False 53:False 54:False 55:False 56:False 57:False 58:False 59:False 60:False 61:False 62:False 63:False 64:False 65:False 66:False 67:False 68:False 69:False 70:False 71:False 72:False 73:False 74:False 75:False 76:False 77:False 78:False 79:False 80:False 81:False 82:False 83:False 84:False 85:False 86:False 87:False 88:False 89:False 90:False 91:False 92:False 93:False 94:False 95:False 96:False 97:False 98:False 99:False 100:False 101:False 102:False 103:False 104:False 105:False 106:False 107:False 108:False 109:False 110:False 111:False 112:False 113:False 114:False 115:False 116:False 117:False 118:False 119:False 120:False 121:False 122:False 123:False 124:False 125:False 126:False 127:False 128:False 129:False 130:False 131:False 132:False 133:True 134:True 135:True 136:True 137:True 138:True 139:True 140:True 141:True 142:True 143:True 144:True 145:True 146:True 147:True 148:True 149:True 150:True 151:True 152:True 153:True 154:True 155:True 156:True 157:True 158:True 159:True 160:True 161:True 162:True 163:True 164:True 165:True 166:True 167:True 168:True 169:True 170:True 171:True 172:True 173:True 174:True 175:True 176:True 177:True 178:True 179:True 180:True 181:True 182:True 183:True 184:True 185:True 186:True 187:True 188:True 189:True 190:True 191:True 192:True 193:True 194:True 195:True 196:True 197:True 198:True 199:True 200:True 201:True 202:True 203:True 204:True 205:True 206:True 207:True 208:True 209:True 210:True 211:True 212:True 213:True 214:True 215:True 216:True 217:True 218:True 219:True 220:True 221:True 222:True 223:True 224:True 225:True 226:True 227:True 228:True 229:True 230:True 231:True 232:True 233:True 234:True 235:True 236:True 237:True 238:True 239:True 240:True 241:True 242:True 243:True 244:True 245:True 246:True 247:True 248:True 249:True 250:True 251:True 252:True 253:True 254:True 255:True 256:True 257:True 258:True 259:True 260:True 261:False 262:False 263:False 264:False 265:False 266:False 267:False 268:False 269:False 270:False 271:False 272:False 273:False 274:False 275:False 276:False 277:False 278:False 279:False 280:False 281:False 282:False 283:False 284:False 285:False 286:False 287:False 288:False 289:False 290:False 291:False 292:False 293:False 294:False 295:False 296:False 297:False 298:False 299:False 300:False 301:False 302:False 303:False 304:False 305:False 306:False 307:False 308:False 309:False 310:False 311:False 312:False 313:False 314:False 315:False 316:False 317:False 318:False 319:False 320:False 321:False 322:False 323:False 324:False 325:False 326:False 327:False 328:False 329:False 330:False 331:False 332:False 333:False 334:False 335:False 336:False 337:False 338:False 339:False 340:False 341:False 342:False 343:False 344:False 345:False 346:False 347:False 348:False 349:False 350:False 351:False 352:False 353:False 354:False 355:False 356:False 357:False 358:False 359:False 360:False 361:False 362:False 363:False 364:False 365:False 366:False 367:False 368:False 369:False 370:False 371:False 372:False 373:False 374:False 375:False 376:False 377:False 378:False 379:False 380:False 381:False 382:False\n",
      "I1208 12:27:37.191253 139883775852736 run_factoid.py:447] token_is_max_context: 10:False 11:False 12:False 13:False 14:False 15:False 16:False 17:False 18:False 19:False 20:False 21:False 22:False 23:False 24:False 25:False 26:False 27:False 28:False 29:False 30:False 31:False 32:False 33:False 34:False 35:False 36:False 37:False 38:False 39:False 40:False 41:False 42:False 43:False 44:False 45:False 46:False 47:False 48:False 49:False 50:False 51:False 52:False 53:False 54:False 55:False 56:False 57:False 58:False 59:False 60:False 61:False 62:False 63:False 64:False 65:False 66:False 67:False 68:False 69:False 70:False 71:False 72:False 73:False 74:False 75:False 76:False 77:False 78:False 79:False 80:False 81:False 82:False 83:False 84:False 85:False 86:False 87:False 88:False 89:False 90:False 91:False 92:False 93:False 94:False 95:False 96:False 97:False 98:False 99:False 100:False 101:False 102:False 103:False 104:False 105:False 106:False 107:False 108:False 109:False 110:False 111:False 112:False 113:False 114:False 115:False 116:False 117:False 118:False 119:False 120:False 121:False 122:False 123:False 124:False 125:False 126:False 127:False 128:False 129:False 130:False 131:False 132:False 133:True 134:True 135:True 136:True 137:True 138:True 139:True 140:True 141:True 142:True 143:True 144:True 145:True 146:True 147:True 148:True 149:True 150:True 151:True 152:True 153:True 154:True 155:True 156:True 157:True 158:True 159:True 160:True 161:True 162:True 163:True 164:True 165:True 166:True 167:True 168:True 169:True 170:True 171:True 172:True 173:True 174:True 175:True 176:True 177:True 178:True 179:True 180:True 181:True 182:True 183:True 184:True 185:True 186:True 187:True 188:True 189:True 190:True 191:True 192:True 193:True 194:True 195:True 196:True 197:True 198:True 199:True 200:True 201:True 202:True 203:True 204:True 205:True 206:True 207:True 208:True 209:True 210:True 211:True 212:True 213:True 214:True 215:True 216:True 217:True 218:True 219:True 220:True 221:True 222:True 223:True 224:True 225:True 226:True 227:True 228:True 229:True 230:True 231:True 232:True 233:True 234:True 235:True 236:True 237:True 238:True 239:True 240:True 241:True 242:True 243:True 244:True 245:True 246:True 247:True 248:True 249:True 250:True 251:True 252:True 253:True 254:True 255:True 256:True 257:True 258:True 259:True 260:True 261:False 262:False 263:False 264:False 265:False 266:False 267:False 268:False 269:False 270:False 271:False 272:False 273:False 274:False 275:False 276:False 277:False 278:False 279:False 280:False 281:False 282:False 283:False 284:False 285:False 286:False 287:False 288:False 289:False 290:False 291:False 292:False 293:False 294:False 295:False 296:False 297:False 298:False 299:False 300:False 301:False 302:False 303:False 304:False 305:False 306:False 307:False 308:False 309:False 310:False 311:False 312:False 313:False 314:False 315:False 316:False 317:False 318:False 319:False 320:False 321:False 322:False 323:False 324:False 325:False 326:False 327:False 328:False 329:False 330:False 331:False 332:False 333:False 334:False 335:False 336:False 337:False 338:False 339:False 340:False 341:False 342:False 343:False 344:False 345:False 346:False 347:False 348:False 349:False 350:False 351:False 352:False 353:False 354:False 355:False 356:False 357:False 358:False 359:False 360:False 361:False 362:False 363:False 364:False 365:False 366:False 367:False 368:False 369:False 370:False 371:False 372:False 373:False 374:False 375:False 376:False 377:False 378:False 379:False 380:False 381:False 382:False\n",
      "INFO:tensorflow:input_ids: 101 1327 1132 1103 13004 1104 1103 9505 136 102 1231 10182 21629 2603 113 1275 119 3324 110 114 1190 1343 5165 1114 26574 1708 118 157 2162 15499 113 121 119 121 110 114 119 164 4335 166 1109 5752 6547 1103 9505 1106 1103 1378 3672 131 113 122 114 1175 1108 1199 3187 5320 1115 1127 17163 2109 1104 1231 10182 21629 1107 153 21678 2137 4420 119 1370 1859 117 1385 1425 117 184 27655 117 1105 12556 13328 1849 1138 1151 3626 1112 2418 3187 5320 1111 1103 153 21678 2137 1231 10182 1197 118 1231 3633 119 164 4650 117 4589 166 1262 1103 126 4420 1150 4531 1231 10182 21629 1107 1103 153 21678 2137 1372 1127 1155 3860 1385 113 864 16480 1201 1385 114 1105 184 12866 1162 132 2456 117 1152 1127 1120 1344 3187 1104 1231 21754 1123 5813 2116 119 164 4335 166 113 123 114 124 1104 1103 126 4420 1125 1123 5813 1906 17906 1115 1127 3023 13793 117 1105 1142 1189 1103 6059 1167 2846 119 164 2539 166 1109 25399 17906 1156 1871 1107 7285 13467 13950 119 164 4650 117 5391 166 113 124 114 1258 1103 2425 22157 2137 6059 117 1103 8246 16694 1107 1126 14787 5954 20497 12725 14410 1156 1849 1103 2495 17379 2401 117 1105 1294 1103 1126 14787 5954 1129 1167 3253 1106 3687 11787 9199 119 164 4335 166 7457 1113 1103 3290 1107 1126 14787 5954 20497 12725 14410 117 1103 1231 21754 1123 5813 2116 3253 3296 119 164 5073 166 6589 117 1122 1110 3372 1111 153 21678 2137 1106 9474 1142 2463 12678 117 1105 170 1194 9455 14637 11970 113 26574 1708 118 157 2162 15499 114 1547 1129 170 1618 3026 119 164 4335 166 1109 2244 2603 1107 1103 153 21678 2137 1372 1105 1168 13467 9108 1372 1127 128 119 123 110 1105 125 119 122 110 117 3569 119 1966 4420 5165 1114 153 21678 2137 3890 170 5409 2299 2244 2603 1190 1343 1114 1168 12814 3377 117 1103 3719 1206 1172 1108 1136 2418 119 2499 17730 117 3084 2393 164 3993 166 1982 170 10260 1884 13252 1204 2025 10540 1104 2539 4776 4420 1114 149 102\n",
      "I1208 12:27:37.191358 139883775852736 run_factoid.py:449] input_ids: 101 1327 1132 1103 13004 1104 1103 9505 136 102 1231 10182 21629 2603 113 1275 119 3324 110 114 1190 1343 5165 1114 26574 1708 118 157 2162 15499 113 121 119 121 110 114 119 164 4335 166 1109 5752 6547 1103 9505 1106 1103 1378 3672 131 113 122 114 1175 1108 1199 3187 5320 1115 1127 17163 2109 1104 1231 10182 21629 1107 153 21678 2137 4420 119 1370 1859 117 1385 1425 117 184 27655 117 1105 12556 13328 1849 1138 1151 3626 1112 2418 3187 5320 1111 1103 153 21678 2137 1231 10182 1197 118 1231 3633 119 164 4650 117 4589 166 1262 1103 126 4420 1150 4531 1231 10182 21629 1107 1103 153 21678 2137 1372 1127 1155 3860 1385 113 864 16480 1201 1385 114 1105 184 12866 1162 132 2456 117 1152 1127 1120 1344 3187 1104 1231 21754 1123 5813 2116 119 164 4335 166 113 123 114 124 1104 1103 126 4420 1125 1123 5813 1906 17906 1115 1127 3023 13793 117 1105 1142 1189 1103 6059 1167 2846 119 164 2539 166 1109 25399 17906 1156 1871 1107 7285 13467 13950 119 164 4650 117 5391 166 113 124 114 1258 1103 2425 22157 2137 6059 117 1103 8246 16694 1107 1126 14787 5954 20497 12725 14410 1156 1849 1103 2495 17379 2401 117 1105 1294 1103 1126 14787 5954 1129 1167 3253 1106 3687 11787 9199 119 164 4335 166 7457 1113 1103 3290 1107 1126 14787 5954 20497 12725 14410 117 1103 1231 21754 1123 5813 2116 3253 3296 119 164 5073 166 6589 117 1122 1110 3372 1111 153 21678 2137 1106 9474 1142 2463 12678 117 1105 170 1194 9455 14637 11970 113 26574 1708 118 157 2162 15499 114 1547 1129 170 1618 3026 119 164 4335 166 1109 2244 2603 1107 1103 153 21678 2137 1372 1105 1168 13467 9108 1372 1127 128 119 123 110 1105 125 119 122 110 117 3569 119 1966 4420 5165 1114 153 21678 2137 3890 170 5409 2299 2244 2603 1190 1343 1114 1168 12814 3377 117 1103 3719 1206 1172 1108 1136 2418 119 2499 17730 117 3084 2393 164 3993 166 1982 170 10260 1884 13252 1204 2025 10540 1104 2539 4776 4420 1114 149 102\n",
      "INFO:tensorflow:input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      "I1208 12:27:37.191449 139883775852736 run_factoid.py:451] input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      "INFO:tensorflow:segment_ids: 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      "I1208 12:27:37.191539 139883775852736 run_factoid.py:453] segment_ids: 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      "INFO:tensorflow:*** Example ***\n",
      "I1208 12:27:37.193341 139883775852736 run_factoid.py:438] *** Example ***\n",
      "INFO:tensorflow:unique_id: 1000000057\n",
      "I1208 12:27:37.193401 139883775852736 run_factoid.py:439] unique_id: 1000000057\n",
      "INFO:tensorflow:example_index: 9\n",
      "I1208 12:27:37.193439 139883775852736 run_factoid.py:440] example_index: 9\n",
      "INFO:tensorflow:doc_span_index: 4\n",
      "I1208 12:27:37.193472 139883775852736 run_factoid.py:441] doc_span_index: 4\n",
      "INFO:tensorflow:tokens: [CLS] What are the limitations of the findings ? [SEP] ; thus , they were at high risk of re ##current her ##nia ##tion . [ 54 ] ( 2 ) 3 of the 5 patients had her ##nia ##ted fragment that were highly migrated , and this made the surgery more difficult . [ 60 ] The residual fragment would result in unsuccessful surgical outcomes . [ 58 , 61 ] ( 3 ) After the primary ME ##D surgery , the artificial cracks in an ##nu ##lus fi ##bro ##sus would change the la ##minate structure , and make the an ##nu ##lus be more easily to del ##ami ##nation . [ 54 ] Based on the damage in an ##nu ##lus fi ##bro ##sus , the re ##current her ##nia ##tion easily occurred . [ 62 ] Therefore , it is unable for P ##EL ##D to solve this problem thoroughly , and a through inter ##body fusion ( MI ##S - T ##L ##IF ) might be a better choice . [ 54 ] The success rate in the P ##EL ##D group and other surgical intervention group were 7 . 2 % and 4 . 1 % , respectively . Although patients treated with P ##EL ##D achieved a significantly higher success rate than those with other surge ##ries , the difference between them was not significant . Lee SH , et al [ 46 ] performed a matched co ##hor ##t study evaluation of 60 consecutive patients with L ##D ##H . Of them , 30 patients were underwent P ##EL ##D , and 30 were treated with O ##LM . [ 46 ] At the follow - up duration of 36 ##mont ##hs , 96 . 7 % of patients in the P ##EL ##D group and 93 . 3 % of patients in the O ##LM group achieved good or excellent results . [ 46 ] For micro ##su ##rg ##ical disc ##ec ##tom ##y , our result also showed a similar success rate with P ##EL ##D . R ##utt ##en S , et al [ 48 ] performed a prospective random ##ized study to compare the clinical outcomes of P ##EL ##D with micro ##su ##rg ##ical technique . In that study , [SEP]\n",
      "I1208 12:27:37.193585 139883775852736 run_factoid.py:443] tokens: [CLS] What are the limitations of the findings ? [SEP] ; thus , they were at high risk of re ##current her ##nia ##tion . [ 54 ] ( 2 ) 3 of the 5 patients had her ##nia ##ted fragment that were highly migrated , and this made the surgery more difficult . [ 60 ] The residual fragment would result in unsuccessful surgical outcomes . [ 58 , 61 ] ( 3 ) After the primary ME ##D surgery , the artificial cracks in an ##nu ##lus fi ##bro ##sus would change the la ##minate structure , and make the an ##nu ##lus be more easily to del ##ami ##nation . [ 54 ] Based on the damage in an ##nu ##lus fi ##bro ##sus , the re ##current her ##nia ##tion easily occurred . [ 62 ] Therefore , it is unable for P ##EL ##D to solve this problem thoroughly , and a through inter ##body fusion ( MI ##S - T ##L ##IF ) might be a better choice . [ 54 ] The success rate in the P ##EL ##D group and other surgical intervention group were 7 . 2 % and 4 . 1 % , respectively . Although patients treated with P ##EL ##D achieved a significantly higher success rate than those with other surge ##ries , the difference between them was not significant . Lee SH , et al [ 46 ] performed a matched co ##hor ##t study evaluation of 60 consecutive patients with L ##D ##H . Of them , 30 patients were underwent P ##EL ##D , and 30 were treated with O ##LM . [ 46 ] At the follow - up duration of 36 ##mont ##hs , 96 . 7 % of patients in the P ##EL ##D group and 93 . 3 % of patients in the O ##LM group achieved good or excellent results . [ 46 ] For micro ##su ##rg ##ical disc ##ec ##tom ##y , our result also showed a similar success rate with P ##EL ##D . R ##utt ##en S , et al [ 48 ] performed a prospective random ##ized study to compare the clinical outcomes of P ##EL ##D with micro ##su ##rg ##ical technique . In that study , [SEP]\n",
      "INFO:tensorflow:token_to_orig_map: 10:299 11:300 12:300 13:301 14:302 15:303 16:304 17:305 18:306 19:307 20:307 21:308 22:308 23:308 24:308 25:308 26:308 27:308 28:309 29:309 30:309 31:310 32:311 33:312 34:313 35:314 36:315 37:316 38:316 39:316 40:317 41:318 42:319 43:320 44:321 45:321 46:322 47:323 48:324 49:325 50:326 51:327 52:328 53:328 54:328 55:328 56:328 57:329 58:330 59:331 60:332 61:333 62:334 63:335 64:336 65:337 66:337 67:337 68:337 69:337 70:337 71:337 72:338 73:338 74:338 75:339 76:340 77:341 78:342 79:342 80:343 81:343 82:344 83:345 84:346 85:347 86:348 87:348 88:348 89:349 90:349 91:349 92:350 93:351 94:352 95:353 96:353 97:354 98:354 99:355 100:356 101:357 102:358 103:358 104:358 105:359 106:360 107:361 108:362 109:363 110:363 111:363 112:363 113:363 114:363 115:363 116:364 117:365 118:366 119:367 120:368 121:369 122:369 123:369 124:370 125:370 126:370 127:370 128:371 129:372 130:372 131:373 132:373 133:373 134:374 135:375 136:375 137:375 138:375 139:375 140:376 141:376 142:377 143:378 144:379 145:380 146:381 147:381 148:381 149:382 150:383 151:384 152:385 153:386 154:386 155:387 156:388 157:389 158:390 159:390 160:391 161:392 162:392 163:392 164:392 165:392 166:392 167:392 168:392 169:393 170:394 171:395 172:396 173:397 174:397 175:397 176:397 177:397 178:398 179:399 180:400 181:401 182:402 183:403 184:403 185:403 186:404 187:405 188:406 189:407 190:408 191:409 192:410 193:411 194:411 195:411 196:411 197:412 198:413 199:413 200:413 201:413 202:413 203:414 204:414 205:415 206:416 207:417 208:418 209:419 210:419 211:419 212:420 213:421 214:422 215:423 216:424 217:425 218:426 219:427 220:428 221:429 222:430 223:430 224:430 225:431 226:432 227:433 228:434 229:435 230:436 231:437 232:437 233:438 234:439 235:439 236:440 237:441 238:441 239:441 240:441 241:442 242:443 243:444 244:445 245:445 246:445 247:446 248:447 249:448 250:449 251:450 252:451 253:452 254:453 255:453 256:453 257:453 258:454 259:455 260:455 261:456 262:457 263:458 264:459 265:460 266:460 267:460 268:460 269:461 270:462 271:463 272:464 273:465 274:466 275:466 276:466 277:466 278:466 279:466 280:467 281:468 282:469 283:469 284:469 285:470 286:471 287:472 288:472 289:472 290:472 291:473 292:473 293:473 294:473 295:474 296:475 297:476 298:477 299:478 300:478 301:478 302:479 303:480 304:481 305:481 306:481 307:481 308:482 309:483 310:484 311:485 312:486 313:486 314:487 315:488 316:489 317:490 318:491 319:492 320:492 321:492 322:492 323:492 324:493 325:494 326:494 327:494 328:494 329:495 330:495 331:495 332:495 333:495 334:496 335:497 336:498 337:499 338:500 339:501 340:502 341:503 342:504 343:505 344:505 345:505 346:505 347:506 348:506 349:506 350:507 351:507 352:508 353:509 354:509 355:509 356:509 357:510 358:511 359:512 360:513 361:513 362:514 363:515 364:516 365:517 366:518 367:519 368:520 369:521 370:521 371:521 372:522 373:523 374:523 375:523 376:523 377:524 378:524 379:525 380:526 381:527 382:527\n",
      "I1208 12:27:37.193699 139883775852736 run_factoid.py:445] token_to_orig_map: 10:299 11:300 12:300 13:301 14:302 15:303 16:304 17:305 18:306 19:307 20:307 21:308 22:308 23:308 24:308 25:308 26:308 27:308 28:309 29:309 30:309 31:310 32:311 33:312 34:313 35:314 36:315 37:316 38:316 39:316 40:317 41:318 42:319 43:320 44:321 45:321 46:322 47:323 48:324 49:325 50:326 51:327 52:328 53:328 54:328 55:328 56:328 57:329 58:330 59:331 60:332 61:333 62:334 63:335 64:336 65:337 66:337 67:337 68:337 69:337 70:337 71:337 72:338 73:338 74:338 75:339 76:340 77:341 78:342 79:342 80:343 81:343 82:344 83:345 84:346 85:347 86:348 87:348 88:348 89:349 90:349 91:349 92:350 93:351 94:352 95:353 96:353 97:354 98:354 99:355 100:356 101:357 102:358 103:358 104:358 105:359 106:360 107:361 108:362 109:363 110:363 111:363 112:363 113:363 114:363 115:363 116:364 117:365 118:366 119:367 120:368 121:369 122:369 123:369 124:370 125:370 126:370 127:370 128:371 129:372 130:372 131:373 132:373 133:373 134:374 135:375 136:375 137:375 138:375 139:375 140:376 141:376 142:377 143:378 144:379 145:380 146:381 147:381 148:381 149:382 150:383 151:384 152:385 153:386 154:386 155:387 156:388 157:389 158:390 159:390 160:391 161:392 162:392 163:392 164:392 165:392 166:392 167:392 168:392 169:393 170:394 171:395 172:396 173:397 174:397 175:397 176:397 177:397 178:398 179:399 180:400 181:401 182:402 183:403 184:403 185:403 186:404 187:405 188:406 189:407 190:408 191:409 192:410 193:411 194:411 195:411 196:411 197:412 198:413 199:413 200:413 201:413 202:413 203:414 204:414 205:415 206:416 207:417 208:418 209:419 210:419 211:419 212:420 213:421 214:422 215:423 216:424 217:425 218:426 219:427 220:428 221:429 222:430 223:430 224:430 225:431 226:432 227:433 228:434 229:435 230:436 231:437 232:437 233:438 234:439 235:439 236:440 237:441 238:441 239:441 240:441 241:442 242:443 243:444 244:445 245:445 246:445 247:446 248:447 249:448 250:449 251:450 252:451 253:452 254:453 255:453 256:453 257:453 258:454 259:455 260:455 261:456 262:457 263:458 264:459 265:460 266:460 267:460 268:460 269:461 270:462 271:463 272:464 273:465 274:466 275:466 276:466 277:466 278:466 279:466 280:467 281:468 282:469 283:469 284:469 285:470 286:471 287:472 288:472 289:472 290:472 291:473 292:473 293:473 294:473 295:474 296:475 297:476 298:477 299:478 300:478 301:478 302:479 303:480 304:481 305:481 306:481 307:481 308:482 309:483 310:484 311:485 312:486 313:486 314:487 315:488 316:489 317:490 318:491 319:492 320:492 321:492 322:492 323:492 324:493 325:494 326:494 327:494 328:494 329:495 330:495 331:495 332:495 333:495 334:496 335:497 336:498 337:499 338:500 339:501 340:502 341:503 342:504 343:505 344:505 345:505 346:505 347:506 348:506 349:506 350:507 351:507 352:508 353:509 354:509 355:509 356:509 357:510 358:511 359:512 360:513 361:513 362:514 363:515 364:516 365:517 366:518 367:519 368:520 369:521 370:521 371:521 372:522 373:523 374:523 375:523 376:523 377:524 378:524 379:525 380:526 381:527 382:527\n",
      "INFO:tensorflow:token_is_max_context: 10:False 11:False 12:False 13:False 14:False 15:False 16:False 17:False 18:False 19:False 20:False 21:False 22:False 23:False 24:False 25:False 26:False 27:False 28:False 29:False 30:False 31:False 32:False 33:False 34:False 35:False 36:False 37:False 38:False 39:False 40:False 41:False 42:False 43:False 44:False 45:False 46:False 47:False 48:False 49:False 50:False 51:False 52:False 53:False 54:False 55:False 56:False 57:False 58:False 59:False 60:False 61:False 62:False 63:False 64:False 65:False 66:False 67:False 68:False 69:False 70:False 71:False 72:False 73:False 74:False 75:False 76:False 77:False 78:False 79:False 80:False 81:False 82:False 83:False 84:False 85:False 86:False 87:False 88:False 89:False 90:False 91:False 92:False 93:False 94:False 95:False 96:False 97:False 98:False 99:False 100:False 101:False 102:False 103:False 104:False 105:False 106:False 107:False 108:False 109:False 110:False 111:False 112:False 113:False 114:False 115:False 116:False 117:False 118:False 119:False 120:False 121:False 122:False 123:False 124:False 125:False 126:False 127:False 128:False 129:False 130:False 131:False 132:False 133:True 134:True 135:True 136:True 137:True 138:True 139:True 140:True 141:True 142:True 143:True 144:True 145:True 146:True 147:True 148:True 149:True 150:True 151:True 152:True 153:True 154:True 155:True 156:True 157:True 158:True 159:True 160:True 161:True 162:True 163:True 164:True 165:True 166:True 167:True 168:True 169:True 170:True 171:True 172:True 173:True 174:True 175:True 176:True 177:True 178:True 179:True 180:True 181:True 182:True 183:True 184:True 185:True 186:True 187:True 188:True 189:True 190:True 191:True 192:True 193:True 194:True 195:True 196:True 197:True 198:True 199:True 200:True 201:True 202:True 203:True 204:True 205:True 206:True 207:True 208:True 209:True 210:True 211:True 212:True 213:True 214:True 215:True 216:True 217:True 218:True 219:True 220:True 221:True 222:True 223:True 224:True 225:True 226:True 227:True 228:True 229:True 230:True 231:True 232:True 233:True 234:True 235:True 236:True 237:True 238:True 239:True 240:True 241:True 242:True 243:True 244:True 245:True 246:True 247:True 248:True 249:True 250:True 251:True 252:True 253:True 254:True 255:True 256:True 257:True 258:True 259:True 260:True 261:False 262:False 263:False 264:False 265:False 266:False 267:False 268:False 269:False 270:False 271:False 272:False 273:False 274:False 275:False 276:False 277:False 278:False 279:False 280:False 281:False 282:False 283:False 284:False 285:False 286:False 287:False 288:False 289:False 290:False 291:False 292:False 293:False 294:False 295:False 296:False 297:False 298:False 299:False 300:False 301:False 302:False 303:False 304:False 305:False 306:False 307:False 308:False 309:False 310:False 311:False 312:False 313:False 314:False 315:False 316:False 317:False 318:False 319:False 320:False 321:False 322:False 323:False 324:False 325:False 326:False 327:False 328:False 329:False 330:False 331:False 332:False 333:False 334:False 335:False 336:False 337:False 338:False 339:False 340:False 341:False 342:False 343:False 344:False 345:False 346:False 347:False 348:False 349:False 350:False 351:False 352:False 353:False 354:False 355:False 356:False 357:False 358:False 359:False 360:False 361:False 362:False 363:False 364:False 365:False 366:False 367:False 368:False 369:False 370:False 371:False 372:False 373:False 374:False 375:False 376:False 377:False 378:False 379:False 380:False 381:False 382:False\n",
      "I1208 12:27:37.193813 139883775852736 run_factoid.py:447] token_is_max_context: 10:False 11:False 12:False 13:False 14:False 15:False 16:False 17:False 18:False 19:False 20:False 21:False 22:False 23:False 24:False 25:False 26:False 27:False 28:False 29:False 30:False 31:False 32:False 33:False 34:False 35:False 36:False 37:False 38:False 39:False 40:False 41:False 42:False 43:False 44:False 45:False 46:False 47:False 48:False 49:False 50:False 51:False 52:False 53:False 54:False 55:False 56:False 57:False 58:False 59:False 60:False 61:False 62:False 63:False 64:False 65:False 66:False 67:False 68:False 69:False 70:False 71:False 72:False 73:False 74:False 75:False 76:False 77:False 78:False 79:False 80:False 81:False 82:False 83:False 84:False 85:False 86:False 87:False 88:False 89:False 90:False 91:False 92:False 93:False 94:False 95:False 96:False 97:False 98:False 99:False 100:False 101:False 102:False 103:False 104:False 105:False 106:False 107:False 108:False 109:False 110:False 111:False 112:False 113:False 114:False 115:False 116:False 117:False 118:False 119:False 120:False 121:False 122:False 123:False 124:False 125:False 126:False 127:False 128:False 129:False 130:False 131:False 132:False 133:True 134:True 135:True 136:True 137:True 138:True 139:True 140:True 141:True 142:True 143:True 144:True 145:True 146:True 147:True 148:True 149:True 150:True 151:True 152:True 153:True 154:True 155:True 156:True 157:True 158:True 159:True 160:True 161:True 162:True 163:True 164:True 165:True 166:True 167:True 168:True 169:True 170:True 171:True 172:True 173:True 174:True 175:True 176:True 177:True 178:True 179:True 180:True 181:True 182:True 183:True 184:True 185:True 186:True 187:True 188:True 189:True 190:True 191:True 192:True 193:True 194:True 195:True 196:True 197:True 198:True 199:True 200:True 201:True 202:True 203:True 204:True 205:True 206:True 207:True 208:True 209:True 210:True 211:True 212:True 213:True 214:True 215:True 216:True 217:True 218:True 219:True 220:True 221:True 222:True 223:True 224:True 225:True 226:True 227:True 228:True 229:True 230:True 231:True 232:True 233:True 234:True 235:True 236:True 237:True 238:True 239:True 240:True 241:True 242:True 243:True 244:True 245:True 246:True 247:True 248:True 249:True 250:True 251:True 252:True 253:True 254:True 255:True 256:True 257:True 258:True 259:True 260:True 261:False 262:False 263:False 264:False 265:False 266:False 267:False 268:False 269:False 270:False 271:False 272:False 273:False 274:False 275:False 276:False 277:False 278:False 279:False 280:False 281:False 282:False 283:False 284:False 285:False 286:False 287:False 288:False 289:False 290:False 291:False 292:False 293:False 294:False 295:False 296:False 297:False 298:False 299:False 300:False 301:False 302:False 303:False 304:False 305:False 306:False 307:False 308:False 309:False 310:False 311:False 312:False 313:False 314:False 315:False 316:False 317:False 318:False 319:False 320:False 321:False 322:False 323:False 324:False 325:False 326:False 327:False 328:False 329:False 330:False 331:False 332:False 333:False 334:False 335:False 336:False 337:False 338:False 339:False 340:False 341:False 342:False 343:False 344:False 345:False 346:False 347:False 348:False 349:False 350:False 351:False 352:False 353:False 354:False 355:False 356:False 357:False 358:False 359:False 360:False 361:False 362:False 363:False 364:False 365:False 366:False 367:False 368:False 369:False 370:False 371:False 372:False 373:False 374:False 375:False 376:False 377:False 378:False 379:False 380:False 381:False 382:False\n",
      "INFO:tensorflow:input_ids: 101 1327 1132 1103 13004 1104 1103 9505 136 102 132 2456 117 1152 1127 1120 1344 3187 1104 1231 21754 1123 5813 2116 119 164 4335 166 113 123 114 124 1104 1103 126 4420 1125 1123 5813 1906 17906 1115 1127 3023 13793 117 1105 1142 1189 1103 6059 1167 2846 119 164 2539 166 1109 25399 17906 1156 1871 1107 7285 13467 13950 119 164 4650 117 5391 166 113 124 114 1258 1103 2425 22157 2137 6059 117 1103 8246 16694 1107 1126 14787 5954 20497 12725 14410 1156 1849 1103 2495 17379 2401 117 1105 1294 1103 1126 14787 5954 1129 1167 3253 1106 3687 11787 9199 119 164 4335 166 7457 1113 1103 3290 1107 1126 14787 5954 20497 12725 14410 117 1103 1231 21754 1123 5813 2116 3253 3296 119 164 5073 166 6589 117 1122 1110 3372 1111 153 21678 2137 1106 9474 1142 2463 12678 117 1105 170 1194 9455 14637 11970 113 26574 1708 118 157 2162 15499 114 1547 1129 170 1618 3026 119 164 4335 166 1109 2244 2603 1107 1103 153 21678 2137 1372 1105 1168 13467 9108 1372 1127 128 119 123 110 1105 125 119 122 110 117 3569 119 1966 4420 5165 1114 153 21678 2137 3890 170 5409 2299 2244 2603 1190 1343 1114 1168 12814 3377 117 1103 3719 1206 1172 1108 1136 2418 119 2499 17730 117 3084 2393 164 3993 166 1982 170 10260 1884 13252 1204 2025 10540 1104 2539 4776 4420 1114 149 2137 3048 119 2096 1172 117 1476 4420 1127 9315 153 21678 2137 117 1105 1476 1127 5165 1114 152 22074 119 164 3993 166 1335 1103 2812 118 1146 9355 1104 3164 7578 9524 117 5306 119 128 110 1104 4420 1107 1103 153 21678 2137 1372 1105 5429 119 124 110 1104 4420 1107 1103 152 22074 1372 3890 1363 1137 6548 2686 119 164 3993 166 1370 17599 6385 10805 4571 6187 10294 18778 1183 117 1412 1871 1145 2799 170 1861 2244 2603 1114 153 21678 2137 119 155 25131 1424 156 117 3084 2393 164 3615 166 1982 170 19916 7091 2200 2025 1106 14133 1103 7300 13950 1104 153 21678 2137 1114 17599 6385 10805 4571 5531 119 1130 1115 2025 117 102\n",
      "I1208 12:27:37.193923 139883775852736 run_factoid.py:449] input_ids: 101 1327 1132 1103 13004 1104 1103 9505 136 102 132 2456 117 1152 1127 1120 1344 3187 1104 1231 21754 1123 5813 2116 119 164 4335 166 113 123 114 124 1104 1103 126 4420 1125 1123 5813 1906 17906 1115 1127 3023 13793 117 1105 1142 1189 1103 6059 1167 2846 119 164 2539 166 1109 25399 17906 1156 1871 1107 7285 13467 13950 119 164 4650 117 5391 166 113 124 114 1258 1103 2425 22157 2137 6059 117 1103 8246 16694 1107 1126 14787 5954 20497 12725 14410 1156 1849 1103 2495 17379 2401 117 1105 1294 1103 1126 14787 5954 1129 1167 3253 1106 3687 11787 9199 119 164 4335 166 7457 1113 1103 3290 1107 1126 14787 5954 20497 12725 14410 117 1103 1231 21754 1123 5813 2116 3253 3296 119 164 5073 166 6589 117 1122 1110 3372 1111 153 21678 2137 1106 9474 1142 2463 12678 117 1105 170 1194 9455 14637 11970 113 26574 1708 118 157 2162 15499 114 1547 1129 170 1618 3026 119 164 4335 166 1109 2244 2603 1107 1103 153 21678 2137 1372 1105 1168 13467 9108 1372 1127 128 119 123 110 1105 125 119 122 110 117 3569 119 1966 4420 5165 1114 153 21678 2137 3890 170 5409 2299 2244 2603 1190 1343 1114 1168 12814 3377 117 1103 3719 1206 1172 1108 1136 2418 119 2499 17730 117 3084 2393 164 3993 166 1982 170 10260 1884 13252 1204 2025 10540 1104 2539 4776 4420 1114 149 2137 3048 119 2096 1172 117 1476 4420 1127 9315 153 21678 2137 117 1105 1476 1127 5165 1114 152 22074 119 164 3993 166 1335 1103 2812 118 1146 9355 1104 3164 7578 9524 117 5306 119 128 110 1104 4420 1107 1103 153 21678 2137 1372 1105 5429 119 124 110 1104 4420 1107 1103 152 22074 1372 3890 1363 1137 6548 2686 119 164 3993 166 1370 17599 6385 10805 4571 6187 10294 18778 1183 117 1412 1871 1145 2799 170 1861 2244 2603 1114 153 21678 2137 119 155 25131 1424 156 117 3084 2393 164 3615 166 1982 170 19916 7091 2200 2025 1106 14133 1103 7300 13950 1104 153 21678 2137 1114 17599 6385 10805 4571 5531 119 1130 1115 2025 117 102\n",
      "INFO:tensorflow:input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      "I1208 12:27:37.194015 139883775852736 run_factoid.py:451] input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      "INFO:tensorflow:segment_ids: 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      "I1208 12:27:37.194104 139883775852736 run_factoid.py:453] segment_ids: 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      "INFO:tensorflow:*** Example ***\n",
      "I1208 12:27:37.195924 139883775852736 run_factoid.py:438] *** Example ***\n",
      "INFO:tensorflow:unique_id: 1000000058\n",
      "I1208 12:27:37.195982 139883775852736 run_factoid.py:439] unique_id: 1000000058\n",
      "INFO:tensorflow:example_index: 9\n",
      "I1208 12:27:37.196019 139883775852736 run_factoid.py:440] example_index: 9\n",
      "INFO:tensorflow:doc_span_index: 5\n",
      "I1208 12:27:37.196054 139883775852736 run_factoid.py:441] doc_span_index: 5\n",
      "INFO:tensorflow:tokens: [CLS] What are the limitations of the findings ? [SEP] 62 ] Therefore , it is unable for P ##EL ##D to solve this problem thoroughly , and a through inter ##body fusion ( MI ##S - T ##L ##IF ) might be a better choice . [ 54 ] The success rate in the P ##EL ##D group and other surgical intervention group were 7 . 2 % and 4 . 1 % , respectively . Although patients treated with P ##EL ##D achieved a significantly higher success rate than those with other surge ##ries , the difference between them was not significant . Lee SH , et al [ 46 ] performed a matched co ##hor ##t study evaluation of 60 consecutive patients with L ##D ##H . Of them , 30 patients were underwent P ##EL ##D , and 30 were treated with O ##LM . [ 46 ] At the follow - up duration of 36 ##mont ##hs , 96 . 7 % of patients in the P ##EL ##D group and 93 . 3 % of patients in the O ##LM group achieved good or excellent results . [ 46 ] For micro ##su ##rg ##ical disc ##ec ##tom ##y , our result also showed a similar success rate with P ##EL ##D . R ##utt ##en S , et al [ 48 ] performed a prospective random ##ized study to compare the clinical outcomes of P ##EL ##D with micro ##su ##rg ##ical technique . In that study , 95 % of patients with P ##EL ##D reported subjective satisfaction as compared with 86 % of patients with micro ##su ##rg ##ical technique . However , the difference between them was not significant . In contrast to the lower success rates of O ##LM and micro ##su ##rg ##ical disc ##ec ##tom ##y , MI ##S - T ##L ##IF seemed to have a higher success rate than P ##EL ##D . Liu C , et al [ 52 ] reported a prospective co ##hor ##t study of 401 patients with re ##current L ##D ##H who were treated with P ##EL ##D ( n = 209 ) or MI ##S - T ##L ##IF ( n = 192 ) . At the mean duration follow - [SEP]\n",
      "I1208 12:27:37.196166 139883775852736 run_factoid.py:443] tokens: [CLS] What are the limitations of the findings ? [SEP] 62 ] Therefore , it is unable for P ##EL ##D to solve this problem thoroughly , and a through inter ##body fusion ( MI ##S - T ##L ##IF ) might be a better choice . [ 54 ] The success rate in the P ##EL ##D group and other surgical intervention group were 7 . 2 % and 4 . 1 % , respectively . Although patients treated with P ##EL ##D achieved a significantly higher success rate than those with other surge ##ries , the difference between them was not significant . Lee SH , et al [ 46 ] performed a matched co ##hor ##t study evaluation of 60 consecutive patients with L ##D ##H . Of them , 30 patients were underwent P ##EL ##D , and 30 were treated with O ##LM . [ 46 ] At the follow - up duration of 36 ##mont ##hs , 96 . 7 % of patients in the P ##EL ##D group and 93 . 3 % of patients in the O ##LM group achieved good or excellent results . [ 46 ] For micro ##su ##rg ##ical disc ##ec ##tom ##y , our result also showed a similar success rate with P ##EL ##D . R ##utt ##en S , et al [ 48 ] performed a prospective random ##ized study to compare the clinical outcomes of P ##EL ##D with micro ##su ##rg ##ical technique . In that study , 95 % of patients with P ##EL ##D reported subjective satisfaction as compared with 86 % of patients with micro ##su ##rg ##ical technique . However , the difference between them was not significant . In contrast to the lower success rates of O ##LM and micro ##su ##rg ##ical disc ##ec ##tom ##y , MI ##S - T ##L ##IF seemed to have a higher success rate than P ##EL ##D . Liu C , et al [ 52 ] reported a prospective co ##hor ##t study of 401 patients with re ##current L ##D ##H who were treated with P ##EL ##D ( n = 209 ) or MI ##S - T ##L ##IF ( n = 192 ) . At the mean duration follow - [SEP]\n",
      "INFO:tensorflow:token_to_orig_map: 10:375 11:375 12:376 13:376 14:377 15:378 16:379 17:380 18:381 19:381 20:381 21:382 22:383 23:384 24:385 25:386 26:386 27:387 28:388 29:389 30:390 31:390 32:391 33:392 34:392 35:392 36:392 37:392 38:392 39:392 40:392 41:393 42:394 43:395 44:396 45:397 46:397 47:397 48:397 49:397 50:398 51:399 52:400 53:401 54:402 55:403 56:403 57:403 58:404 59:405 60:406 61:407 62:408 63:409 64:410 65:411 66:411 67:411 68:411 69:412 70:413 71:413 72:413 73:413 74:413 75:414 76:414 77:415 78:416 79:417 80:418 81:419 82:419 83:419 84:420 85:421 86:422 87:423 88:424 89:425 90:426 91:427 92:428 93:429 94:430 95:430 96:430 97:431 98:432 99:433 100:434 101:435 102:436 103:437 104:437 105:438 106:439 107:439 108:440 109:441 110:441 111:441 112:441 113:442 114:443 115:444 116:445 117:445 118:445 119:446 120:447 121:448 122:449 123:450 124:451 125:452 126:453 127:453 128:453 129:453 130:454 131:455 132:455 133:456 134:457 135:458 136:459 137:460 138:460 139:460 140:460 141:461 142:462 143:463 144:464 145:465 146:466 147:466 148:466 149:466 150:466 151:466 152:467 153:468 154:469 155:469 156:469 157:470 158:471 159:472 160:472 161:472 162:472 163:473 164:473 165:473 166:473 167:474 168:475 169:476 170:477 171:478 172:478 173:478 174:479 175:480 176:481 177:481 178:481 179:481 180:482 181:483 182:484 183:485 184:486 185:486 186:487 187:488 188:489 189:490 190:491 191:492 192:492 193:492 194:492 195:492 196:493 197:494 198:494 199:494 200:494 201:495 202:495 203:495 204:495 205:495 206:496 207:497 208:498 209:499 210:500 211:501 212:502 213:503 214:504 215:505 216:505 217:505 218:505 219:506 220:506 221:506 222:507 223:507 224:508 225:509 226:509 227:509 228:509 229:510 230:511 231:512 232:513 233:513 234:514 235:515 236:516 237:517 238:518 239:519 240:520 241:521 242:521 243:521 244:522 245:523 246:523 247:523 248:523 249:524 250:524 251:525 252:526 253:527 254:527 255:528 256:528 257:529 258:530 259:531 260:532 261:532 262:532 263:533 264:534 265:535 266:536 267:537 268:538 269:539 270:539 271:540 272:541 273:542 274:543 275:543 276:543 277:543 278:544 279:544 280:545 281:545 282:546 283:547 284:548 285:549 286:550 287:551 288:552 289:552 290:553 291:554 292:555 293:556 294:557 295:558 296:559 297:560 298:561 299:561 300:562 301:563 302:563 303:563 304:563 305:564 306:564 307:564 308:564 309:564 310:565 311:565 312:565 313:565 314:565 315:565 316:566 317:567 318:568 319:569 320:570 321:571 322:572 323:573 324:574 325:574 326:574 327:574 328:575 329:576 330:576 331:577 332:578 333:578 334:578 335:578 336:579 337:580 338:581 339:582 340:582 341:582 342:583 343:584 344:585 345:586 346:587 347:588 348:588 349:589 350:589 351:589 352:590 353:591 354:592 355:593 356:594 357:594 358:594 359:595 360:595 361:596 362:597 363:597 364:598 365:599 366:599 367:599 368:599 369:599 370:599 371:600 372:600 373:601 374:602 375:602 376:602 377:603 378:604 379:605 380:606 381:607 382:607\n",
      "I1208 12:27:37.196283 139883775852736 run_factoid.py:445] token_to_orig_map: 10:375 11:375 12:376 13:376 14:377 15:378 16:379 17:380 18:381 19:381 20:381 21:382 22:383 23:384 24:385 25:386 26:386 27:387 28:388 29:389 30:390 31:390 32:391 33:392 34:392 35:392 36:392 37:392 38:392 39:392 40:392 41:393 42:394 43:395 44:396 45:397 46:397 47:397 48:397 49:397 50:398 51:399 52:400 53:401 54:402 55:403 56:403 57:403 58:404 59:405 60:406 61:407 62:408 63:409 64:410 65:411 66:411 67:411 68:411 69:412 70:413 71:413 72:413 73:413 74:413 75:414 76:414 77:415 78:416 79:417 80:418 81:419 82:419 83:419 84:420 85:421 86:422 87:423 88:424 89:425 90:426 91:427 92:428 93:429 94:430 95:430 96:430 97:431 98:432 99:433 100:434 101:435 102:436 103:437 104:437 105:438 106:439 107:439 108:440 109:441 110:441 111:441 112:441 113:442 114:443 115:444 116:445 117:445 118:445 119:446 120:447 121:448 122:449 123:450 124:451 125:452 126:453 127:453 128:453 129:453 130:454 131:455 132:455 133:456 134:457 135:458 136:459 137:460 138:460 139:460 140:460 141:461 142:462 143:463 144:464 145:465 146:466 147:466 148:466 149:466 150:466 151:466 152:467 153:468 154:469 155:469 156:469 157:470 158:471 159:472 160:472 161:472 162:472 163:473 164:473 165:473 166:473 167:474 168:475 169:476 170:477 171:478 172:478 173:478 174:479 175:480 176:481 177:481 178:481 179:481 180:482 181:483 182:484 183:485 184:486 185:486 186:487 187:488 188:489 189:490 190:491 191:492 192:492 193:492 194:492 195:492 196:493 197:494 198:494 199:494 200:494 201:495 202:495 203:495 204:495 205:495 206:496 207:497 208:498 209:499 210:500 211:501 212:502 213:503 214:504 215:505 216:505 217:505 218:505 219:506 220:506 221:506 222:507 223:507 224:508 225:509 226:509 227:509 228:509 229:510 230:511 231:512 232:513 233:513 234:514 235:515 236:516 237:517 238:518 239:519 240:520 241:521 242:521 243:521 244:522 245:523 246:523 247:523 248:523 249:524 250:524 251:525 252:526 253:527 254:527 255:528 256:528 257:529 258:530 259:531 260:532 261:532 262:532 263:533 264:534 265:535 266:536 267:537 268:538 269:539 270:539 271:540 272:541 273:542 274:543 275:543 276:543 277:543 278:544 279:544 280:545 281:545 282:546 283:547 284:548 285:549 286:550 287:551 288:552 289:552 290:553 291:554 292:555 293:556 294:557 295:558 296:559 297:560 298:561 299:561 300:562 301:563 302:563 303:563 304:563 305:564 306:564 307:564 308:564 309:564 310:565 311:565 312:565 313:565 314:565 315:565 316:566 317:567 318:568 319:569 320:570 321:571 322:572 323:573 324:574 325:574 326:574 327:574 328:575 329:576 330:576 331:577 332:578 333:578 334:578 335:578 336:579 337:580 338:581 339:582 340:582 341:582 342:583 343:584 344:585 345:586 346:587 347:588 348:588 349:589 350:589 351:589 352:590 353:591 354:592 355:593 356:594 357:594 358:594 359:595 360:595 361:596 362:597 363:597 364:598 365:599 366:599 367:599 368:599 369:599 370:599 371:600 372:600 373:601 374:602 375:602 376:602 377:603 378:604 379:605 380:606 381:607 382:607\n",
      "INFO:tensorflow:token_is_max_context: 10:False 11:False 12:False 13:False 14:False 15:False 16:False 17:False 18:False 19:False 20:False 21:False 22:False 23:False 24:False 25:False 26:False 27:False 28:False 29:False 30:False 31:False 32:False 33:False 34:False 35:False 36:False 37:False 38:False 39:False 40:False 41:False 42:False 43:False 44:False 45:False 46:False 47:False 48:False 49:False 50:False 51:False 52:False 53:False 54:False 55:False 56:False 57:False 58:False 59:False 60:False 61:False 62:False 63:False 64:False 65:False 66:False 67:False 68:False 69:False 70:False 71:False 72:False 73:False 74:False 75:False 76:False 77:False 78:False 79:False 80:False 81:False 82:False 83:False 84:False 85:False 86:False 87:False 88:False 89:False 90:False 91:False 92:False 93:False 94:False 95:False 96:False 97:False 98:False 99:False 100:False 101:False 102:False 103:False 104:False 105:False 106:False 107:False 108:False 109:False 110:False 111:False 112:False 113:False 114:False 115:False 116:False 117:False 118:False 119:False 120:False 121:False 122:False 123:False 124:False 125:False 126:False 127:False 128:False 129:False 130:False 131:False 132:False 133:True 134:True 135:True 136:True 137:True 138:True 139:True 140:True 141:True 142:True 143:True 144:True 145:True 146:True 147:True 148:True 149:True 150:True 151:True 152:True 153:True 154:True 155:True 156:True 157:True 158:True 159:True 160:True 161:True 162:True 163:True 164:True 165:True 166:True 167:True 168:True 169:True 170:True 171:True 172:True 173:True 174:True 175:True 176:True 177:True 178:True 179:True 180:True 181:True 182:True 183:True 184:True 185:True 186:True 187:True 188:True 189:True 190:True 191:True 192:True 193:True 194:True 195:True 196:True 197:True 198:True 199:True 200:True 201:True 202:True 203:True 204:True 205:True 206:True 207:True 208:True 209:True 210:True 211:True 212:True 213:True 214:True 215:True 216:True 217:True 218:True 219:True 220:True 221:True 222:True 223:True 224:True 225:True 226:True 227:True 228:True 229:True 230:True 231:True 232:True 233:True 234:True 235:True 236:True 237:True 238:True 239:True 240:True 241:True 242:True 243:True 244:True 245:True 246:True 247:True 248:True 249:True 250:True 251:True 252:True 253:True 254:True 255:True 256:True 257:True 258:True 259:True 260:True 261:False 262:False 263:False 264:False 265:False 266:False 267:False 268:False 269:False 270:False 271:False 272:False 273:False 274:False 275:False 276:False 277:False 278:False 279:False 280:False 281:False 282:False 283:False 284:False 285:False 286:False 287:False 288:False 289:False 290:False 291:False 292:False 293:False 294:False 295:False 296:False 297:False 298:False 299:False 300:False 301:False 302:False 303:False 304:False 305:False 306:False 307:False 308:False 309:False 310:False 311:False 312:False 313:False 314:False 315:False 316:False 317:False 318:False 319:False 320:False 321:False 322:False 323:False 324:False 325:False 326:False 327:False 328:False 329:False 330:False 331:False 332:False 333:False 334:False 335:False 336:False 337:False 338:False 339:False 340:False 341:False 342:False 343:False 344:False 345:False 346:False 347:False 348:False 349:False 350:False 351:False 352:False 353:False 354:False 355:False 356:False 357:False 358:False 359:False 360:False 361:False 362:False 363:False 364:False 365:False 366:False 367:False 368:False 369:False 370:False 371:False 372:False 373:False 374:False 375:False 376:False 377:False 378:False 379:False 380:False 381:False 382:False\n",
      "I1208 12:27:37.196394 139883775852736 run_factoid.py:447] token_is_max_context: 10:False 11:False 12:False 13:False 14:False 15:False 16:False 17:False 18:False 19:False 20:False 21:False 22:False 23:False 24:False 25:False 26:False 27:False 28:False 29:False 30:False 31:False 32:False 33:False 34:False 35:False 36:False 37:False 38:False 39:False 40:False 41:False 42:False 43:False 44:False 45:False 46:False 47:False 48:False 49:False 50:False 51:False 52:False 53:False 54:False 55:False 56:False 57:False 58:False 59:False 60:False 61:False 62:False 63:False 64:False 65:False 66:False 67:False 68:False 69:False 70:False 71:False 72:False 73:False 74:False 75:False 76:False 77:False 78:False 79:False 80:False 81:False 82:False 83:False 84:False 85:False 86:False 87:False 88:False 89:False 90:False 91:False 92:False 93:False 94:False 95:False 96:False 97:False 98:False 99:False 100:False 101:False 102:False 103:False 104:False 105:False 106:False 107:False 108:False 109:False 110:False 111:False 112:False 113:False 114:False 115:False 116:False 117:False 118:False 119:False 120:False 121:False 122:False 123:False 124:False 125:False 126:False 127:False 128:False 129:False 130:False 131:False 132:False 133:True 134:True 135:True 136:True 137:True 138:True 139:True 140:True 141:True 142:True 143:True 144:True 145:True 146:True 147:True 148:True 149:True 150:True 151:True 152:True 153:True 154:True 155:True 156:True 157:True 158:True 159:True 160:True 161:True 162:True 163:True 164:True 165:True 166:True 167:True 168:True 169:True 170:True 171:True 172:True 173:True 174:True 175:True 176:True 177:True 178:True 179:True 180:True 181:True 182:True 183:True 184:True 185:True 186:True 187:True 188:True 189:True 190:True 191:True 192:True 193:True 194:True 195:True 196:True 197:True 198:True 199:True 200:True 201:True 202:True 203:True 204:True 205:True 206:True 207:True 208:True 209:True 210:True 211:True 212:True 213:True 214:True 215:True 216:True 217:True 218:True 219:True 220:True 221:True 222:True 223:True 224:True 225:True 226:True 227:True 228:True 229:True 230:True 231:True 232:True 233:True 234:True 235:True 236:True 237:True 238:True 239:True 240:True 241:True 242:True 243:True 244:True 245:True 246:True 247:True 248:True 249:True 250:True 251:True 252:True 253:True 254:True 255:True 256:True 257:True 258:True 259:True 260:True 261:False 262:False 263:False 264:False 265:False 266:False 267:False 268:False 269:False 270:False 271:False 272:False 273:False 274:False 275:False 276:False 277:False 278:False 279:False 280:False 281:False 282:False 283:False 284:False 285:False 286:False 287:False 288:False 289:False 290:False 291:False 292:False 293:False 294:False 295:False 296:False 297:False 298:False 299:False 300:False 301:False 302:False 303:False 304:False 305:False 306:False 307:False 308:False 309:False 310:False 311:False 312:False 313:False 314:False 315:False 316:False 317:False 318:False 319:False 320:False 321:False 322:False 323:False 324:False 325:False 326:False 327:False 328:False 329:False 330:False 331:False 332:False 333:False 334:False 335:False 336:False 337:False 338:False 339:False 340:False 341:False 342:False 343:False 344:False 345:False 346:False 347:False 348:False 349:False 350:False 351:False 352:False 353:False 354:False 355:False 356:False 357:False 358:False 359:False 360:False 361:False 362:False 363:False 364:False 365:False 366:False 367:False 368:False 369:False 370:False 371:False 372:False 373:False 374:False 375:False 376:False 377:False 378:False 379:False 380:False 381:False 382:False\n",
      "INFO:tensorflow:input_ids: 101 1327 1132 1103 13004 1104 1103 9505 136 102 5073 166 6589 117 1122 1110 3372 1111 153 21678 2137 1106 9474 1142 2463 12678 117 1105 170 1194 9455 14637 11970 113 26574 1708 118 157 2162 15499 114 1547 1129 170 1618 3026 119 164 4335 166 1109 2244 2603 1107 1103 153 21678 2137 1372 1105 1168 13467 9108 1372 1127 128 119 123 110 1105 125 119 122 110 117 3569 119 1966 4420 5165 1114 153 21678 2137 3890 170 5409 2299 2244 2603 1190 1343 1114 1168 12814 3377 117 1103 3719 1206 1172 1108 1136 2418 119 2499 17730 117 3084 2393 164 3993 166 1982 170 10260 1884 13252 1204 2025 10540 1104 2539 4776 4420 1114 149 2137 3048 119 2096 1172 117 1476 4420 1127 9315 153 21678 2137 117 1105 1476 1127 5165 1114 152 22074 119 164 3993 166 1335 1103 2812 118 1146 9355 1104 3164 7578 9524 117 5306 119 128 110 1104 4420 1107 1103 153 21678 2137 1372 1105 5429 119 124 110 1104 4420 1107 1103 152 22074 1372 3890 1363 1137 6548 2686 119 164 3993 166 1370 17599 6385 10805 4571 6187 10294 18778 1183 117 1412 1871 1145 2799 170 1861 2244 2603 1114 153 21678 2137 119 155 25131 1424 156 117 3084 2393 164 3615 166 1982 170 19916 7091 2200 2025 1106 14133 1103 7300 13950 1104 153 21678 2137 1114 17599 6385 10805 4571 5531 119 1130 1115 2025 117 4573 110 1104 4420 1114 153 21678 2137 2103 23481 10241 1112 3402 1114 5942 110 1104 4420 1114 17599 6385 10805 4571 5531 119 1438 117 1103 3719 1206 1172 1108 1136 2418 119 1130 5014 1106 1103 2211 2244 5600 1104 152 22074 1105 17599 6385 10805 4571 6187 10294 18778 1183 117 26574 1708 118 157 2162 15499 1882 1106 1138 170 2299 2244 2603 1190 153 21678 2137 119 8411 140 117 3084 2393 164 3882 166 2103 170 19916 1884 13252 1204 2025 1104 25182 4420 1114 1231 21754 149 2137 3048 1150 1127 5165 1114 153 21678 2137 113 183 134 21040 114 1137 26574 1708 118 157 2162 15499 113 183 134 18868 114 119 1335 1103 1928 9355 2812 118 102\n",
      "I1208 12:27:37.196498 139883775852736 run_factoid.py:449] input_ids: 101 1327 1132 1103 13004 1104 1103 9505 136 102 5073 166 6589 117 1122 1110 3372 1111 153 21678 2137 1106 9474 1142 2463 12678 117 1105 170 1194 9455 14637 11970 113 26574 1708 118 157 2162 15499 114 1547 1129 170 1618 3026 119 164 4335 166 1109 2244 2603 1107 1103 153 21678 2137 1372 1105 1168 13467 9108 1372 1127 128 119 123 110 1105 125 119 122 110 117 3569 119 1966 4420 5165 1114 153 21678 2137 3890 170 5409 2299 2244 2603 1190 1343 1114 1168 12814 3377 117 1103 3719 1206 1172 1108 1136 2418 119 2499 17730 117 3084 2393 164 3993 166 1982 170 10260 1884 13252 1204 2025 10540 1104 2539 4776 4420 1114 149 2137 3048 119 2096 1172 117 1476 4420 1127 9315 153 21678 2137 117 1105 1476 1127 5165 1114 152 22074 119 164 3993 166 1335 1103 2812 118 1146 9355 1104 3164 7578 9524 117 5306 119 128 110 1104 4420 1107 1103 153 21678 2137 1372 1105 5429 119 124 110 1104 4420 1107 1103 152 22074 1372 3890 1363 1137 6548 2686 119 164 3993 166 1370 17599 6385 10805 4571 6187 10294 18778 1183 117 1412 1871 1145 2799 170 1861 2244 2603 1114 153 21678 2137 119 155 25131 1424 156 117 3084 2393 164 3615 166 1982 170 19916 7091 2200 2025 1106 14133 1103 7300 13950 1104 153 21678 2137 1114 17599 6385 10805 4571 5531 119 1130 1115 2025 117 4573 110 1104 4420 1114 153 21678 2137 2103 23481 10241 1112 3402 1114 5942 110 1104 4420 1114 17599 6385 10805 4571 5531 119 1438 117 1103 3719 1206 1172 1108 1136 2418 119 1130 5014 1106 1103 2211 2244 5600 1104 152 22074 1105 17599 6385 10805 4571 6187 10294 18778 1183 117 26574 1708 118 157 2162 15499 1882 1106 1138 170 2299 2244 2603 1190 153 21678 2137 119 8411 140 117 3084 2393 164 3882 166 2103 170 19916 1884 13252 1204 2025 1104 25182 4420 1114 1231 21754 149 2137 3048 1150 1127 5165 1114 153 21678 2137 113 183 134 21040 114 1137 26574 1708 118 157 2162 15499 113 183 134 18868 114 119 1335 1103 1928 9355 2812 118 102\n",
      "INFO:tensorflow:input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      "I1208 12:27:37.196590 139883775852736 run_factoid.py:451] input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      "INFO:tensorflow:segment_ids: 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      "I1208 12:27:37.196684 139883775852736 run_factoid.py:453] segment_ids: 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      "INFO:tensorflow:*** Example ***\n",
      "I1208 12:27:37.198522 139883775852736 run_factoid.py:438] *** Example ***\n",
      "INFO:tensorflow:unique_id: 1000000059\n",
      "I1208 12:27:37.198583 139883775852736 run_factoid.py:439] unique_id: 1000000059\n",
      "INFO:tensorflow:example_index: 9\n",
      "I1208 12:27:37.198621 139883775852736 run_factoid.py:440] example_index: 9\n",
      "INFO:tensorflow:doc_span_index: 6\n",
      "I1208 12:27:37.198654 139883775852736 run_factoid.py:441] doc_span_index: 6\n",
      "INFO:tensorflow:tokens: [CLS] What are the limitations of the findings ? [SEP] ##EL ##D , and 30 were treated with O ##LM . [ 46 ] At the follow - up duration of 36 ##mont ##hs , 96 . 7 % of patients in the P ##EL ##D group and 93 . 3 % of patients in the O ##LM group achieved good or excellent results . [ 46 ] For micro ##su ##rg ##ical disc ##ec ##tom ##y , our result also showed a similar success rate with P ##EL ##D . R ##utt ##en S , et al [ 48 ] performed a prospective random ##ized study to compare the clinical outcomes of P ##EL ##D with micro ##su ##rg ##ical technique . In that study , 95 % of patients with P ##EL ##D reported subjective satisfaction as compared with 86 % of patients with micro ##su ##rg ##ical technique . However , the difference between them was not significant . In contrast to the lower success rates of O ##LM and micro ##su ##rg ##ical disc ##ec ##tom ##y , MI ##S - T ##L ##IF seemed to have a higher success rate than P ##EL ##D . Liu C , et al [ 52 ] reported a prospective co ##hor ##t study of 401 patients with re ##current L ##D ##H who were treated with P ##EL ##D ( n = 209 ) or MI ##S - T ##L ##IF ( n = 192 ) . At the mean duration follow - up of 46 . 5 months , the success rate in the two groups was 91 . 3 % and 95 . 2 % , respectively . [ 52 ] MI ##S - T ##L ##IF resulted in a higher success rate than P ##EL ##D , however , there was no significant difference between them . Regarding the operation time , the present study demonstrated that patients treated with P ##EL ##D had 18 . 14 minutes less of operation time than those with other surgical interventions . However , the reduced operation time of P ##EL ##D was only observed in the comparison with O ##LM , MI ##S - T ##L ##IF , micro ##su ##rg ##ical disc ##ec ##tom ##y and micro ##dis ##ce [SEP]\n",
      "I1208 12:27:37.198768 139883775852736 run_factoid.py:443] tokens: [CLS] What are the limitations of the findings ? [SEP] ##EL ##D , and 30 were treated with O ##LM . [ 46 ] At the follow - up duration of 36 ##mont ##hs , 96 . 7 % of patients in the P ##EL ##D group and 93 . 3 % of patients in the O ##LM group achieved good or excellent results . [ 46 ] For micro ##su ##rg ##ical disc ##ec ##tom ##y , our result also showed a similar success rate with P ##EL ##D . R ##utt ##en S , et al [ 48 ] performed a prospective random ##ized study to compare the clinical outcomes of P ##EL ##D with micro ##su ##rg ##ical technique . In that study , 95 % of patients with P ##EL ##D reported subjective satisfaction as compared with 86 % of patients with micro ##su ##rg ##ical technique . However , the difference between them was not significant . In contrast to the lower success rates of O ##LM and micro ##su ##rg ##ical disc ##ec ##tom ##y , MI ##S - T ##L ##IF seemed to have a higher success rate than P ##EL ##D . Liu C , et al [ 52 ] reported a prospective co ##hor ##t study of 401 patients with re ##current L ##D ##H who were treated with P ##EL ##D ( n = 209 ) or MI ##S - T ##L ##IF ( n = 192 ) . At the mean duration follow - up of 46 . 5 months , the success rate in the two groups was 91 . 3 % and 95 . 2 % , respectively . [ 52 ] MI ##S - T ##L ##IF resulted in a higher success rate than P ##EL ##D , however , there was no significant difference between them . Regarding the operation time , the present study demonstrated that patients treated with P ##EL ##D had 18 . 14 minutes less of operation time than those with other surgical interventions . However , the reduced operation time of P ##EL ##D was only observed in the comparison with O ##LM , MI ##S - T ##L ##IF , micro ##su ##rg ##ical disc ##ec ##tom ##y and micro ##dis ##ce [SEP]\n",
      "INFO:tensorflow:token_to_orig_map: 10:460 11:460 12:460 13:461 14:462 15:463 16:464 17:465 18:466 19:466 20:466 21:466 22:466 23:466 24:467 25:468 26:469 27:469 28:469 29:470 30:471 31:472 32:472 33:472 34:472 35:473 36:473 37:473 38:473 39:474 40:475 41:476 42:477 43:478 44:478 45:478 46:479 47:480 48:481 49:481 50:481 51:481 52:482 53:483 54:484 55:485 56:486 57:486 58:487 59:488 60:489 61:490 62:491 63:492 64:492 65:492 66:492 67:492 68:493 69:494 70:494 71:494 72:494 73:495 74:495 75:495 76:495 77:495 78:496 79:497 80:498 81:499 82:500 83:501 84:502 85:503 86:504 87:505 88:505 89:505 90:505 91:506 92:506 93:506 94:507 95:507 96:508 97:509 98:509 99:509 100:509 101:510 102:511 103:512 104:513 105:513 106:514 107:515 108:516 109:517 110:518 111:519 112:520 113:521 114:521 115:521 116:522 117:523 118:523 119:523 120:523 121:524 122:524 123:525 124:526 125:527 126:527 127:528 128:528 129:529 130:530 131:531 132:532 133:532 134:532 135:533 136:534 137:535 138:536 139:537 140:538 141:539 142:539 143:540 144:541 145:542 146:543 147:543 148:543 149:543 150:544 151:544 152:545 153:545 154:546 155:547 156:548 157:549 158:550 159:551 160:552 161:552 162:553 163:554 164:555 165:556 166:557 167:558 168:559 169:560 170:561 171:561 172:562 173:563 174:563 175:563 176:563 177:564 178:564 179:564 180:564 181:564 182:565 183:565 184:565 185:565 186:565 187:565 188:566 189:567 190:568 191:569 192:570 193:571 194:572 195:573 196:574 197:574 198:574 199:574 200:575 201:576 202:576 203:577 204:578 205:578 206:578 207:578 208:579 209:580 210:581 211:582 212:582 213:582 214:583 215:584 216:585 217:586 218:587 219:588 220:588 221:589 222:589 223:589 224:590 225:591 226:592 227:593 228:594 229:594 230:594 231:595 232:595 233:596 234:597 235:597 236:598 237:599 238:599 239:599 240:599 241:599 242:599 243:600 244:600 245:601 246:602 247:602 248:602 249:603 250:604 251:605 252:606 253:607 254:607 255:607 256:608 257:609 258:609 259:609 260:610 261:610 262:611 263:612 264:613 265:614 266:615 267:616 268:617 269:618 270:619 271:619 272:619 273:619 274:620 275:621 276:621 277:621 278:621 279:621 280:622 281:622 282:622 283:622 284:622 285:623 286:623 287:623 288:623 289:623 290:623 291:624 292:625 293:626 294:627 295:628 296:629 297:630 298:631 299:631 300:631 301:631 302:632 303:632 304:633 305:634 306:635 307:636 308:637 309:638 310:639 311:639 312:640 313:641 314:642 315:643 316:643 317:644 318:645 319:646 320:647 321:648 322:649 323:650 324:651 325:652 326:652 327:652 328:653 329:654 330:654 331:654 332:655 333:656 334:657 335:658 336:659 337:660 338:661 339:662 340:663 341:664 342:665 343:665 344:666 345:666 346:667 347:668 348:669 349:670 350:671 351:672 352:672 353:672 354:673 355:674 356:675 357:676 358:677 359:678 360:679 361:680 362:680 363:680 364:681 365:681 366:681 367:681 368:681 369:681 370:681 371:682 372:682 373:682 374:682 375:683 376:683 377:683 378:683 379:684 380:685 381:685 382:685\n",
      "I1208 12:27:37.198885 139883775852736 run_factoid.py:445] token_to_orig_map: 10:460 11:460 12:460 13:461 14:462 15:463 16:464 17:465 18:466 19:466 20:466 21:466 22:466 23:466 24:467 25:468 26:469 27:469 28:469 29:470 30:471 31:472 32:472 33:472 34:472 35:473 36:473 37:473 38:473 39:474 40:475 41:476 42:477 43:478 44:478 45:478 46:479 47:480 48:481 49:481 50:481 51:481 52:482 53:483 54:484 55:485 56:486 57:486 58:487 59:488 60:489 61:490 62:491 63:492 64:492 65:492 66:492 67:492 68:493 69:494 70:494 71:494 72:494 73:495 74:495 75:495 76:495 77:495 78:496 79:497 80:498 81:499 82:500 83:501 84:502 85:503 86:504 87:505 88:505 89:505 90:505 91:506 92:506 93:506 94:507 95:507 96:508 97:509 98:509 99:509 100:509 101:510 102:511 103:512 104:513 105:513 106:514 107:515 108:516 109:517 110:518 111:519 112:520 113:521 114:521 115:521 116:522 117:523 118:523 119:523 120:523 121:524 122:524 123:525 124:526 125:527 126:527 127:528 128:528 129:529 130:530 131:531 132:532 133:532 134:532 135:533 136:534 137:535 138:536 139:537 140:538 141:539 142:539 143:540 144:541 145:542 146:543 147:543 148:543 149:543 150:544 151:544 152:545 153:545 154:546 155:547 156:548 157:549 158:550 159:551 160:552 161:552 162:553 163:554 164:555 165:556 166:557 167:558 168:559 169:560 170:561 171:561 172:562 173:563 174:563 175:563 176:563 177:564 178:564 179:564 180:564 181:564 182:565 183:565 184:565 185:565 186:565 187:565 188:566 189:567 190:568 191:569 192:570 193:571 194:572 195:573 196:574 197:574 198:574 199:574 200:575 201:576 202:576 203:577 204:578 205:578 206:578 207:578 208:579 209:580 210:581 211:582 212:582 213:582 214:583 215:584 216:585 217:586 218:587 219:588 220:588 221:589 222:589 223:589 224:590 225:591 226:592 227:593 228:594 229:594 230:594 231:595 232:595 233:596 234:597 235:597 236:598 237:599 238:599 239:599 240:599 241:599 242:599 243:600 244:600 245:601 246:602 247:602 248:602 249:603 250:604 251:605 252:606 253:607 254:607 255:607 256:608 257:609 258:609 259:609 260:610 261:610 262:611 263:612 264:613 265:614 266:615 267:616 268:617 269:618 270:619 271:619 272:619 273:619 274:620 275:621 276:621 277:621 278:621 279:621 280:622 281:622 282:622 283:622 284:622 285:623 286:623 287:623 288:623 289:623 290:623 291:624 292:625 293:626 294:627 295:628 296:629 297:630 298:631 299:631 300:631 301:631 302:632 303:632 304:633 305:634 306:635 307:636 308:637 309:638 310:639 311:639 312:640 313:641 314:642 315:643 316:643 317:644 318:645 319:646 320:647 321:648 322:649 323:650 324:651 325:652 326:652 327:652 328:653 329:654 330:654 331:654 332:655 333:656 334:657 335:658 336:659 337:660 338:661 339:662 340:663 341:664 342:665 343:665 344:666 345:666 346:667 347:668 348:669 349:670 350:671 351:672 352:672 353:672 354:673 355:674 356:675 357:676 358:677 359:678 360:679 361:680 362:680 363:680 364:681 365:681 366:681 367:681 368:681 369:681 370:681 371:682 372:682 373:682 374:682 375:683 376:683 377:683 378:683 379:684 380:685 381:685 382:685\n",
      "INFO:tensorflow:token_is_max_context: 10:False 11:False 12:False 13:False 14:False 15:False 16:False 17:False 18:False 19:False 20:False 21:False 22:False 23:False 24:False 25:False 26:False 27:False 28:False 29:False 30:False 31:False 32:False 33:False 34:False 35:False 36:False 37:False 38:False 39:False 40:False 41:False 42:False 43:False 44:False 45:False 46:False 47:False 48:False 49:False 50:False 51:False 52:False 53:False 54:False 55:False 56:False 57:False 58:False 59:False 60:False 61:False 62:False 63:False 64:False 65:False 66:False 67:False 68:False 69:False 70:False 71:False 72:False 73:False 74:False 75:False 76:False 77:False 78:False 79:False 80:False 81:False 82:False 83:False 84:False 85:False 86:False 87:False 88:False 89:False 90:False 91:False 92:False 93:False 94:False 95:False 96:False 97:False 98:False 99:False 100:False 101:False 102:False 103:False 104:False 105:False 106:False 107:False 108:False 109:False 110:False 111:False 112:False 113:False 114:False 115:False 116:False 117:False 118:False 119:False 120:False 121:False 122:False 123:False 124:False 125:False 126:False 127:False 128:False 129:False 130:False 131:False 132:False 133:True 134:True 135:True 136:True 137:True 138:True 139:True 140:True 141:True 142:True 143:True 144:True 145:True 146:True 147:True 148:True 149:True 150:True 151:True 152:True 153:True 154:True 155:True 156:True 157:True 158:True 159:True 160:True 161:True 162:True 163:True 164:True 165:True 166:True 167:True 168:True 169:True 170:True 171:True 172:True 173:True 174:True 175:True 176:True 177:True 178:True 179:True 180:True 181:True 182:True 183:True 184:True 185:True 186:True 187:True 188:True 189:True 190:True 191:True 192:True 193:True 194:True 195:True 196:True 197:True 198:True 199:True 200:True 201:True 202:True 203:True 204:True 205:True 206:True 207:True 208:True 209:True 210:True 211:True 212:True 213:True 214:True 215:True 216:True 217:True 218:True 219:True 220:True 221:True 222:True 223:True 224:True 225:True 226:True 227:True 228:True 229:True 230:True 231:True 232:True 233:True 234:True 235:True 236:True 237:True 238:True 239:True 240:True 241:True 242:True 243:True 244:True 245:True 246:True 247:True 248:True 249:True 250:True 251:True 252:True 253:True 254:True 255:True 256:True 257:True 258:True 259:True 260:True 261:False 262:False 263:False 264:False 265:False 266:False 267:False 268:False 269:False 270:False 271:False 272:False 273:False 274:False 275:False 276:False 277:False 278:False 279:False 280:False 281:False 282:False 283:False 284:False 285:False 286:False 287:False 288:False 289:False 290:False 291:False 292:False 293:False 294:False 295:False 296:False 297:False 298:False 299:False 300:False 301:False 302:False 303:False 304:False 305:False 306:False 307:False 308:False 309:False 310:False 311:False 312:False 313:False 314:False 315:False 316:False 317:False 318:False 319:False 320:False 321:False 322:False 323:False 324:False 325:False 326:False 327:False 328:False 329:False 330:False 331:False 332:False 333:False 334:False 335:False 336:False 337:False 338:False 339:False 340:False 341:False 342:False 343:False 344:False 345:False 346:False 347:False 348:False 349:False 350:False 351:False 352:False 353:False 354:False 355:False 356:False 357:False 358:False 359:False 360:False 361:False 362:False 363:False 364:False 365:False 366:False 367:False 368:False 369:False 370:False 371:False 372:False 373:False 374:False 375:False 376:False 377:False 378:False 379:False 380:False 381:False 382:False\n",
      "I1208 12:27:37.198997 139883775852736 run_factoid.py:447] token_is_max_context: 10:False 11:False 12:False 13:False 14:False 15:False 16:False 17:False 18:False 19:False 20:False 21:False 22:False 23:False 24:False 25:False 26:False 27:False 28:False 29:False 30:False 31:False 32:False 33:False 34:False 35:False 36:False 37:False 38:False 39:False 40:False 41:False 42:False 43:False 44:False 45:False 46:False 47:False 48:False 49:False 50:False 51:False 52:False 53:False 54:False 55:False 56:False 57:False 58:False 59:False 60:False 61:False 62:False 63:False 64:False 65:False 66:False 67:False 68:False 69:False 70:False 71:False 72:False 73:False 74:False 75:False 76:False 77:False 78:False 79:False 80:False 81:False 82:False 83:False 84:False 85:False 86:False 87:False 88:False 89:False 90:False 91:False 92:False 93:False 94:False 95:False 96:False 97:False 98:False 99:False 100:False 101:False 102:False 103:False 104:False 105:False 106:False 107:False 108:False 109:False 110:False 111:False 112:False 113:False 114:False 115:False 116:False 117:False 118:False 119:False 120:False 121:False 122:False 123:False 124:False 125:False 126:False 127:False 128:False 129:False 130:False 131:False 132:False 133:True 134:True 135:True 136:True 137:True 138:True 139:True 140:True 141:True 142:True 143:True 144:True 145:True 146:True 147:True 148:True 149:True 150:True 151:True 152:True 153:True 154:True 155:True 156:True 157:True 158:True 159:True 160:True 161:True 162:True 163:True 164:True 165:True 166:True 167:True 168:True 169:True 170:True 171:True 172:True 173:True 174:True 175:True 176:True 177:True 178:True 179:True 180:True 181:True 182:True 183:True 184:True 185:True 186:True 187:True 188:True 189:True 190:True 191:True 192:True 193:True 194:True 195:True 196:True 197:True 198:True 199:True 200:True 201:True 202:True 203:True 204:True 205:True 206:True 207:True 208:True 209:True 210:True 211:True 212:True 213:True 214:True 215:True 216:True 217:True 218:True 219:True 220:True 221:True 222:True 223:True 224:True 225:True 226:True 227:True 228:True 229:True 230:True 231:True 232:True 233:True 234:True 235:True 236:True 237:True 238:True 239:True 240:True 241:True 242:True 243:True 244:True 245:True 246:True 247:True 248:True 249:True 250:True 251:True 252:True 253:True 254:True 255:True 256:True 257:True 258:True 259:True 260:True 261:False 262:False 263:False 264:False 265:False 266:False 267:False 268:False 269:False 270:False 271:False 272:False 273:False 274:False 275:False 276:False 277:False 278:False 279:False 280:False 281:False 282:False 283:False 284:False 285:False 286:False 287:False 288:False 289:False 290:False 291:False 292:False 293:False 294:False 295:False 296:False 297:False 298:False 299:False 300:False 301:False 302:False 303:False 304:False 305:False 306:False 307:False 308:False 309:False 310:False 311:False 312:False 313:False 314:False 315:False 316:False 317:False 318:False 319:False 320:False 321:False 322:False 323:False 324:False 325:False 326:False 327:False 328:False 329:False 330:False 331:False 332:False 333:False 334:False 335:False 336:False 337:False 338:False 339:False 340:False 341:False 342:False 343:False 344:False 345:False 346:False 347:False 348:False 349:False 350:False 351:False 352:False 353:False 354:False 355:False 356:False 357:False 358:False 359:False 360:False 361:False 362:False 363:False 364:False 365:False 366:False 367:False 368:False 369:False 370:False 371:False 372:False 373:False 374:False 375:False 376:False 377:False 378:False 379:False 380:False 381:False 382:False\n",
      "INFO:tensorflow:input_ids: 101 1327 1132 1103 13004 1104 1103 9505 136 102 21678 2137 117 1105 1476 1127 5165 1114 152 22074 119 164 3993 166 1335 1103 2812 118 1146 9355 1104 3164 7578 9524 117 5306 119 128 110 1104 4420 1107 1103 153 21678 2137 1372 1105 5429 119 124 110 1104 4420 1107 1103 152 22074 1372 3890 1363 1137 6548 2686 119 164 3993 166 1370 17599 6385 10805 4571 6187 10294 18778 1183 117 1412 1871 1145 2799 170 1861 2244 2603 1114 153 21678 2137 119 155 25131 1424 156 117 3084 2393 164 3615 166 1982 170 19916 7091 2200 2025 1106 14133 1103 7300 13950 1104 153 21678 2137 1114 17599 6385 10805 4571 5531 119 1130 1115 2025 117 4573 110 1104 4420 1114 153 21678 2137 2103 23481 10241 1112 3402 1114 5942 110 1104 4420 1114 17599 6385 10805 4571 5531 119 1438 117 1103 3719 1206 1172 1108 1136 2418 119 1130 5014 1106 1103 2211 2244 5600 1104 152 22074 1105 17599 6385 10805 4571 6187 10294 18778 1183 117 26574 1708 118 157 2162 15499 1882 1106 1138 170 2299 2244 2603 1190 153 21678 2137 119 8411 140 117 3084 2393 164 3882 166 2103 170 19916 1884 13252 1204 2025 1104 25182 4420 1114 1231 21754 149 2137 3048 1150 1127 5165 1114 153 21678 2137 113 183 134 21040 114 1137 26574 1708 118 157 2162 15499 113 183 134 18868 114 119 1335 1103 1928 9355 2812 118 1146 1104 3993 119 126 1808 117 1103 2244 2603 1107 1103 1160 2114 1108 5539 119 124 110 1105 4573 119 123 110 117 3569 119 164 3882 166 26574 1708 118 157 2162 15499 3657 1107 170 2299 2244 2603 1190 153 21678 2137 117 1649 117 1175 1108 1185 2418 3719 1206 1172 119 23840 1103 2805 1159 117 1103 1675 2025 7160 1115 4420 5165 1114 153 21678 2137 1125 1407 119 1489 1904 1750 1104 2805 1159 1190 1343 1114 1168 13467 22496 119 1438 117 1103 3549 2805 1159 1104 153 21678 2137 1108 1178 4379 1107 1103 7577 1114 152 22074 117 26574 1708 118 157 2162 15499 117 17599 6385 10805 4571 6187 10294 18778 1183 1105 17599 10396 2093 102\n",
      "I1208 12:27:37.199101 139883775852736 run_factoid.py:449] input_ids: 101 1327 1132 1103 13004 1104 1103 9505 136 102 21678 2137 117 1105 1476 1127 5165 1114 152 22074 119 164 3993 166 1335 1103 2812 118 1146 9355 1104 3164 7578 9524 117 5306 119 128 110 1104 4420 1107 1103 153 21678 2137 1372 1105 5429 119 124 110 1104 4420 1107 1103 152 22074 1372 3890 1363 1137 6548 2686 119 164 3993 166 1370 17599 6385 10805 4571 6187 10294 18778 1183 117 1412 1871 1145 2799 170 1861 2244 2603 1114 153 21678 2137 119 155 25131 1424 156 117 3084 2393 164 3615 166 1982 170 19916 7091 2200 2025 1106 14133 1103 7300 13950 1104 153 21678 2137 1114 17599 6385 10805 4571 5531 119 1130 1115 2025 117 4573 110 1104 4420 1114 153 21678 2137 2103 23481 10241 1112 3402 1114 5942 110 1104 4420 1114 17599 6385 10805 4571 5531 119 1438 117 1103 3719 1206 1172 1108 1136 2418 119 1130 5014 1106 1103 2211 2244 5600 1104 152 22074 1105 17599 6385 10805 4571 6187 10294 18778 1183 117 26574 1708 118 157 2162 15499 1882 1106 1138 170 2299 2244 2603 1190 153 21678 2137 119 8411 140 117 3084 2393 164 3882 166 2103 170 19916 1884 13252 1204 2025 1104 25182 4420 1114 1231 21754 149 2137 3048 1150 1127 5165 1114 153 21678 2137 113 183 134 21040 114 1137 26574 1708 118 157 2162 15499 113 183 134 18868 114 119 1335 1103 1928 9355 2812 118 1146 1104 3993 119 126 1808 117 1103 2244 2603 1107 1103 1160 2114 1108 5539 119 124 110 1105 4573 119 123 110 117 3569 119 164 3882 166 26574 1708 118 157 2162 15499 3657 1107 170 2299 2244 2603 1190 153 21678 2137 117 1649 117 1175 1108 1185 2418 3719 1206 1172 119 23840 1103 2805 1159 117 1103 1675 2025 7160 1115 4420 5165 1114 153 21678 2137 1125 1407 119 1489 1904 1750 1104 2805 1159 1190 1343 1114 1168 13467 22496 119 1438 117 1103 3549 2805 1159 1104 153 21678 2137 1108 1178 4379 1107 1103 7577 1114 152 22074 117 26574 1708 118 157 2162 15499 117 17599 6385 10805 4571 6187 10294 18778 1183 1105 17599 10396 2093 102\n",
      "INFO:tensorflow:input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      "I1208 12:27:37.199194 139883775852736 run_factoid.py:451] input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      "INFO:tensorflow:segment_ids: 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      "I1208 12:27:37.199284 139883775852736 run_factoid.py:453] segment_ids: 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      "INFO:tensorflow:*** Example ***\n",
      "I1208 12:27:37.201115 139883775852736 run_factoid.py:438] *** Example ***\n",
      "INFO:tensorflow:unique_id: 1000000060\n",
      "I1208 12:27:37.201178 139883775852736 run_factoid.py:439] unique_id: 1000000060\n",
      "INFO:tensorflow:example_index: 9\n",
      "I1208 12:27:37.201216 139883775852736 run_factoid.py:440] example_index: 9\n",
      "INFO:tensorflow:doc_span_index: 7\n",
      "I1208 12:27:37.201250 139883775852736 run_factoid.py:441] doc_span_index: 7\n",
      "INFO:tensorflow:tokens: [CLS] What are the limitations of the findings ? [SEP] as compared with 86 % of patients with micro ##su ##rg ##ical technique . However , the difference between them was not significant . In contrast to the lower success rates of O ##LM and micro ##su ##rg ##ical disc ##ec ##tom ##y , MI ##S - T ##L ##IF seemed to have a higher success rate than P ##EL ##D . Liu C , et al [ 52 ] reported a prospective co ##hor ##t study of 401 patients with re ##current L ##D ##H who were treated with P ##EL ##D ( n = 209 ) or MI ##S - T ##L ##IF ( n = 192 ) . At the mean duration follow - up of 46 . 5 months , the success rate in the two groups was 91 . 3 % and 95 . 2 % , respectively . [ 52 ] MI ##S - T ##L ##IF resulted in a higher success rate than P ##EL ##D , however , there was no significant difference between them . Regarding the operation time , the present study demonstrated that patients treated with P ##EL ##D had 18 . 14 minutes less of operation time than those with other surgical interventions . However , the reduced operation time of P ##EL ##D was only observed in the comparison with O ##LM , MI ##S - T ##L ##IF , micro ##su ##rg ##ical disc ##ec ##tom ##y and micro ##dis ##ce ##ct ##omy . Compared with these surgical approaches , P ##EL ##D had 11 . 66 minutes , 75 . 23 minutes , 23 . 21 minutes , and 17 minutes less of operation time , respectively . Kim M ##J , et al . [ 44 ] compared the clinical outcomes of P ##EL ##D with O ##LM , and they found the operation time in these two groups was 53 . 0 ± 13 . 0 minutes and 64 . 6 ± 28 . 7 minutes , respectively ( P < 0 . 00 ##1 ) . Yao Y , et al . [ 45 ] assessed the three minimal ##ly invasive spine surgical approaches ( P ##EL ##D , MI ##S - T ##L ##IF [SEP]\n",
      "I1208 12:27:37.201362 139883775852736 run_factoid.py:443] tokens: [CLS] What are the limitations of the findings ? [SEP] as compared with 86 % of patients with micro ##su ##rg ##ical technique . However , the difference between them was not significant . In contrast to the lower success rates of O ##LM and micro ##su ##rg ##ical disc ##ec ##tom ##y , MI ##S - T ##L ##IF seemed to have a higher success rate than P ##EL ##D . Liu C , et al [ 52 ] reported a prospective co ##hor ##t study of 401 patients with re ##current L ##D ##H who were treated with P ##EL ##D ( n = 209 ) or MI ##S - T ##L ##IF ( n = 192 ) . At the mean duration follow - up of 46 . 5 months , the success rate in the two groups was 91 . 3 % and 95 . 2 % , respectively . [ 52 ] MI ##S - T ##L ##IF resulted in a higher success rate than P ##EL ##D , however , there was no significant difference between them . Regarding the operation time , the present study demonstrated that patients treated with P ##EL ##D had 18 . 14 minutes less of operation time than those with other surgical interventions . However , the reduced operation time of P ##EL ##D was only observed in the comparison with O ##LM , MI ##S - T ##L ##IF , micro ##su ##rg ##ical disc ##ec ##tom ##y and micro ##dis ##ce ##ct ##omy . Compared with these surgical approaches , P ##EL ##D had 11 . 66 minutes , 75 . 23 minutes , 23 . 21 minutes , and 17 minutes less of operation time , respectively . Kim M ##J , et al . [ 44 ] compared the clinical outcomes of P ##EL ##D with O ##LM , and they found the operation time in these two groups was 53 . 0 ± 13 . 0 minutes and 64 . 6 ± 28 . 7 minutes , respectively ( P < 0 . 00 ##1 ) . Yao Y , et al . [ 45 ] assessed the three minimal ##ly invasive spine surgical approaches ( P ##EL ##D , MI ##S - T ##L ##IF [SEP]\n",
      "INFO:tensorflow:token_to_orig_map: 10:536 11:537 12:538 13:539 14:539 15:540 16:541 17:542 18:543 19:543 20:543 21:543 22:544 23:544 24:545 25:545 26:546 27:547 28:548 29:549 30:550 31:551 32:552 33:552 34:553 35:554 36:555 37:556 38:557 39:558 40:559 41:560 42:561 43:561 44:562 45:563 46:563 47:563 48:563 49:564 50:564 51:564 52:564 53:564 54:565 55:565 56:565 57:565 58:565 59:565 60:566 61:567 62:568 63:569 64:570 65:571 66:572 67:573 68:574 69:574 70:574 71:574 72:575 73:576 74:576 75:577 76:578 77:578 78:578 79:578 80:579 81:580 82:581 83:582 84:582 85:582 86:583 87:584 88:585 89:586 90:587 91:588 92:588 93:589 94:589 95:589 96:590 97:591 98:592 99:593 100:594 101:594 102:594 103:595 104:595 105:596 106:597 107:597 108:598 109:599 110:599 111:599 112:599 113:599 114:599 115:600 116:600 117:601 118:602 119:602 120:602 121:603 122:604 123:605 124:606 125:607 126:607 127:607 128:608 129:609 130:609 131:609 132:610 133:610 134:611 135:612 136:613 137:614 138:615 139:616 140:617 141:618 142:619 143:619 144:619 145:619 146:620 147:621 148:621 149:621 150:621 151:621 152:622 153:622 154:622 155:622 156:622 157:623 158:623 159:623 160:623 161:623 162:623 163:624 164:625 165:626 166:627 167:628 168:629 169:630 170:631 171:631 172:631 173:631 174:632 175:632 176:633 177:634 178:635 179:636 180:637 181:638 182:639 183:639 184:640 185:641 186:642 187:643 188:643 189:644 190:645 191:646 192:647 193:648 194:649 195:650 196:651 197:652 198:652 199:652 200:653 201:654 202:654 203:654 204:655 205:656 206:657 207:658 208:659 209:660 210:661 211:662 212:663 213:664 214:665 215:665 216:666 217:666 218:667 219:668 220:669 221:670 222:671 223:672 224:672 225:672 226:673 227:674 228:675 229:676 230:677 231:678 232:679 233:680 234:680 235:680 236:681 237:681 238:681 239:681 240:681 241:681 242:681 243:682 244:682 245:682 246:682 247:683 248:683 249:683 250:683 251:684 252:685 253:685 254:685 255:685 256:685 257:685 258:686 259:687 260:688 261:689 262:690 263:690 264:691 265:691 266:691 267:692 268:693 269:693 270:693 271:694 272:694 273:695 274:695 275:695 276:696 277:696 278:697 279:697 280:697 281:698 282:698 283:699 284:700 285:701 286:702 287:703 288:704 289:705 290:705 291:706 292:706 293:707 294:708 295:708 296:708 297:709 298:710 299:710 300:710 301:710 302:710 303:711 304:712 305:713 306:714 307:715 308:716 309:716 310:716 311:717 312:718 313:718 314:718 315:719 316:720 317:721 318:722 319:723 320:724 321:725 322:726 323:727 324:728 325:729 326:730 327:730 328:730 329:731 330:732 331:732 332:732 333:733 334:734 335:735 336:735 337:735 338:736 339:737 340:737 341:737 342:738 343:738 344:739 345:740 346:740 347:741 348:742 349:742 350:742 351:742 352:742 353:742 354:743 355:744 356:744 357:745 358:746 359:746 360:746 361:746 362:746 363:747 364:748 365:749 366:750 367:750 368:751 369:752 370:753 371:754 372:755 373:755 374:755 375:755 376:755 377:756 378:756 379:756 380:756 381:756 382:756\n",
      "I1208 12:27:37.201485 139883775852736 run_factoid.py:445] token_to_orig_map: 10:536 11:537 12:538 13:539 14:539 15:540 16:541 17:542 18:543 19:543 20:543 21:543 22:544 23:544 24:545 25:545 26:546 27:547 28:548 29:549 30:550 31:551 32:552 33:552 34:553 35:554 36:555 37:556 38:557 39:558 40:559 41:560 42:561 43:561 44:562 45:563 46:563 47:563 48:563 49:564 50:564 51:564 52:564 53:564 54:565 55:565 56:565 57:565 58:565 59:565 60:566 61:567 62:568 63:569 64:570 65:571 66:572 67:573 68:574 69:574 70:574 71:574 72:575 73:576 74:576 75:577 76:578 77:578 78:578 79:578 80:579 81:580 82:581 83:582 84:582 85:582 86:583 87:584 88:585 89:586 90:587 91:588 92:588 93:589 94:589 95:589 96:590 97:591 98:592 99:593 100:594 101:594 102:594 103:595 104:595 105:596 106:597 107:597 108:598 109:599 110:599 111:599 112:599 113:599 114:599 115:600 116:600 117:601 118:602 119:602 120:602 121:603 122:604 123:605 124:606 125:607 126:607 127:607 128:608 129:609 130:609 131:609 132:610 133:610 134:611 135:612 136:613 137:614 138:615 139:616 140:617 141:618 142:619 143:619 144:619 145:619 146:620 147:621 148:621 149:621 150:621 151:621 152:622 153:622 154:622 155:622 156:622 157:623 158:623 159:623 160:623 161:623 162:623 163:624 164:625 165:626 166:627 167:628 168:629 169:630 170:631 171:631 172:631 173:631 174:632 175:632 176:633 177:634 178:635 179:636 180:637 181:638 182:639 183:639 184:640 185:641 186:642 187:643 188:643 189:644 190:645 191:646 192:647 193:648 194:649 195:650 196:651 197:652 198:652 199:652 200:653 201:654 202:654 203:654 204:655 205:656 206:657 207:658 208:659 209:660 210:661 211:662 212:663 213:664 214:665 215:665 216:666 217:666 218:667 219:668 220:669 221:670 222:671 223:672 224:672 225:672 226:673 227:674 228:675 229:676 230:677 231:678 232:679 233:680 234:680 235:680 236:681 237:681 238:681 239:681 240:681 241:681 242:681 243:682 244:682 245:682 246:682 247:683 248:683 249:683 250:683 251:684 252:685 253:685 254:685 255:685 256:685 257:685 258:686 259:687 260:688 261:689 262:690 263:690 264:691 265:691 266:691 267:692 268:693 269:693 270:693 271:694 272:694 273:695 274:695 275:695 276:696 277:696 278:697 279:697 280:697 281:698 282:698 283:699 284:700 285:701 286:702 287:703 288:704 289:705 290:705 291:706 292:706 293:707 294:708 295:708 296:708 297:709 298:710 299:710 300:710 301:710 302:710 303:711 304:712 305:713 306:714 307:715 308:716 309:716 310:716 311:717 312:718 313:718 314:718 315:719 316:720 317:721 318:722 319:723 320:724 321:725 322:726 323:727 324:728 325:729 326:730 327:730 328:730 329:731 330:732 331:732 332:732 333:733 334:734 335:735 336:735 337:735 338:736 339:737 340:737 341:737 342:738 343:738 344:739 345:740 346:740 347:741 348:742 349:742 350:742 351:742 352:742 353:742 354:743 355:744 356:744 357:745 358:746 359:746 360:746 361:746 362:746 363:747 364:748 365:749 366:750 367:750 368:751 369:752 370:753 371:754 372:755 373:755 374:755 375:755 376:755 377:756 378:756 379:756 380:756 381:756 382:756\n",
      "INFO:tensorflow:token_is_max_context: 10:False 11:False 12:False 13:False 14:False 15:False 16:False 17:False 18:False 19:False 20:False 21:False 22:False 23:False 24:False 25:False 26:False 27:False 28:False 29:False 30:False 31:False 32:False 33:False 34:False 35:False 36:False 37:False 38:False 39:False 40:False 41:False 42:False 43:False 44:False 45:False 46:False 47:False 48:False 49:False 50:False 51:False 52:False 53:False 54:False 55:False 56:False 57:False 58:False 59:False 60:False 61:False 62:False 63:False 64:False 65:False 66:False 67:False 68:False 69:False 70:False 71:False 72:False 73:False 74:False 75:False 76:False 77:False 78:False 79:False 80:False 81:False 82:False 83:False 84:False 85:False 86:False 87:False 88:False 89:False 90:False 91:False 92:False 93:False 94:False 95:False 96:False 97:False 98:False 99:False 100:False 101:False 102:False 103:False 104:False 105:False 106:False 107:False 108:False 109:False 110:False 111:False 112:False 113:False 114:False 115:False 116:False 117:False 118:False 119:False 120:False 121:False 122:False 123:False 124:False 125:False 126:False 127:False 128:False 129:False 130:False 131:False 132:False 133:True 134:True 135:True 136:True 137:True 138:True 139:True 140:True 141:True 142:True 143:True 144:True 145:True 146:True 147:True 148:True 149:True 150:True 151:True 152:True 153:True 154:True 155:True 156:True 157:True 158:True 159:True 160:True 161:True 162:True 163:True 164:True 165:True 166:True 167:True 168:True 169:True 170:True 171:True 172:True 173:True 174:True 175:True 176:True 177:True 178:True 179:True 180:True 181:True 182:True 183:True 184:True 185:True 186:True 187:True 188:True 189:True 190:True 191:True 192:True 193:True 194:True 195:True 196:True 197:True 198:True 199:True 200:True 201:True 202:True 203:True 204:True 205:True 206:True 207:True 208:True 209:True 210:True 211:True 212:True 213:True 214:True 215:True 216:True 217:True 218:True 219:True 220:True 221:True 222:True 223:True 224:True 225:True 226:True 227:True 228:True 229:True 230:True 231:True 232:True 233:True 234:True 235:True 236:True 237:True 238:True 239:True 240:True 241:True 242:True 243:True 244:True 245:True 246:True 247:True 248:True 249:True 250:True 251:True 252:True 253:True 254:True 255:True 256:True 257:True 258:True 259:True 260:True 261:False 262:False 263:False 264:False 265:False 266:False 267:False 268:False 269:False 270:False 271:False 272:False 273:False 274:False 275:False 276:False 277:False 278:False 279:False 280:False 281:False 282:False 283:False 284:False 285:False 286:False 287:False 288:False 289:False 290:False 291:False 292:False 293:False 294:False 295:False 296:False 297:False 298:False 299:False 300:False 301:False 302:False 303:False 304:False 305:False 306:False 307:False 308:False 309:False 310:False 311:False 312:False 313:False 314:False 315:False 316:False 317:False 318:False 319:False 320:False 321:False 322:False 323:False 324:False 325:False 326:False 327:False 328:False 329:False 330:False 331:False 332:False 333:False 334:False 335:False 336:False 337:False 338:False 339:False 340:False 341:False 342:False 343:False 344:False 345:False 346:False 347:False 348:False 349:False 350:False 351:False 352:False 353:False 354:False 355:False 356:False 357:False 358:False 359:False 360:False 361:False 362:False 363:False 364:False 365:False 366:False 367:False 368:False 369:False 370:False 371:False 372:False 373:False 374:False 375:False 376:False 377:False 378:False 379:False 380:False 381:False 382:False\n",
      "I1208 12:27:37.201600 139883775852736 run_factoid.py:447] token_is_max_context: 10:False 11:False 12:False 13:False 14:False 15:False 16:False 17:False 18:False 19:False 20:False 21:False 22:False 23:False 24:False 25:False 26:False 27:False 28:False 29:False 30:False 31:False 32:False 33:False 34:False 35:False 36:False 37:False 38:False 39:False 40:False 41:False 42:False 43:False 44:False 45:False 46:False 47:False 48:False 49:False 50:False 51:False 52:False 53:False 54:False 55:False 56:False 57:False 58:False 59:False 60:False 61:False 62:False 63:False 64:False 65:False 66:False 67:False 68:False 69:False 70:False 71:False 72:False 73:False 74:False 75:False 76:False 77:False 78:False 79:False 80:False 81:False 82:False 83:False 84:False 85:False 86:False 87:False 88:False 89:False 90:False 91:False 92:False 93:False 94:False 95:False 96:False 97:False 98:False 99:False 100:False 101:False 102:False 103:False 104:False 105:False 106:False 107:False 108:False 109:False 110:False 111:False 112:False 113:False 114:False 115:False 116:False 117:False 118:False 119:False 120:False 121:False 122:False 123:False 124:False 125:False 126:False 127:False 128:False 129:False 130:False 131:False 132:False 133:True 134:True 135:True 136:True 137:True 138:True 139:True 140:True 141:True 142:True 143:True 144:True 145:True 146:True 147:True 148:True 149:True 150:True 151:True 152:True 153:True 154:True 155:True 156:True 157:True 158:True 159:True 160:True 161:True 162:True 163:True 164:True 165:True 166:True 167:True 168:True 169:True 170:True 171:True 172:True 173:True 174:True 175:True 176:True 177:True 178:True 179:True 180:True 181:True 182:True 183:True 184:True 185:True 186:True 187:True 188:True 189:True 190:True 191:True 192:True 193:True 194:True 195:True 196:True 197:True 198:True 199:True 200:True 201:True 202:True 203:True 204:True 205:True 206:True 207:True 208:True 209:True 210:True 211:True 212:True 213:True 214:True 215:True 216:True 217:True 218:True 219:True 220:True 221:True 222:True 223:True 224:True 225:True 226:True 227:True 228:True 229:True 230:True 231:True 232:True 233:True 234:True 235:True 236:True 237:True 238:True 239:True 240:True 241:True 242:True 243:True 244:True 245:True 246:True 247:True 248:True 249:True 250:True 251:True 252:True 253:True 254:True 255:True 256:True 257:True 258:True 259:True 260:True 261:False 262:False 263:False 264:False 265:False 266:False 267:False 268:False 269:False 270:False 271:False 272:False 273:False 274:False 275:False 276:False 277:False 278:False 279:False 280:False 281:False 282:False 283:False 284:False 285:False 286:False 287:False 288:False 289:False 290:False 291:False 292:False 293:False 294:False 295:False 296:False 297:False 298:False 299:False 300:False 301:False 302:False 303:False 304:False 305:False 306:False 307:False 308:False 309:False 310:False 311:False 312:False 313:False 314:False 315:False 316:False 317:False 318:False 319:False 320:False 321:False 322:False 323:False 324:False 325:False 326:False 327:False 328:False 329:False 330:False 331:False 332:False 333:False 334:False 335:False 336:False 337:False 338:False 339:False 340:False 341:False 342:False 343:False 344:False 345:False 346:False 347:False 348:False 349:False 350:False 351:False 352:False 353:False 354:False 355:False 356:False 357:False 358:False 359:False 360:False 361:False 362:False 363:False 364:False 365:False 366:False 367:False 368:False 369:False 370:False 371:False 372:False 373:False 374:False 375:False 376:False 377:False 378:False 379:False 380:False 381:False 382:False\n",
      "INFO:tensorflow:input_ids: 101 1327 1132 1103 13004 1104 1103 9505 136 102 1112 3402 1114 5942 110 1104 4420 1114 17599 6385 10805 4571 5531 119 1438 117 1103 3719 1206 1172 1108 1136 2418 119 1130 5014 1106 1103 2211 2244 5600 1104 152 22074 1105 17599 6385 10805 4571 6187 10294 18778 1183 117 26574 1708 118 157 2162 15499 1882 1106 1138 170 2299 2244 2603 1190 153 21678 2137 119 8411 140 117 3084 2393 164 3882 166 2103 170 19916 1884 13252 1204 2025 1104 25182 4420 1114 1231 21754 149 2137 3048 1150 1127 5165 1114 153 21678 2137 113 183 134 21040 114 1137 26574 1708 118 157 2162 15499 113 183 134 18868 114 119 1335 1103 1928 9355 2812 118 1146 1104 3993 119 126 1808 117 1103 2244 2603 1107 1103 1160 2114 1108 5539 119 124 110 1105 4573 119 123 110 117 3569 119 164 3882 166 26574 1708 118 157 2162 15499 3657 1107 170 2299 2244 2603 1190 153 21678 2137 117 1649 117 1175 1108 1185 2418 3719 1206 1172 119 23840 1103 2805 1159 117 1103 1675 2025 7160 1115 4420 5165 1114 153 21678 2137 1125 1407 119 1489 1904 1750 1104 2805 1159 1190 1343 1114 1168 13467 22496 119 1438 117 1103 3549 2805 1159 1104 153 21678 2137 1108 1178 4379 1107 1103 7577 1114 152 22074 117 26574 1708 118 157 2162 15499 117 17599 6385 10805 4571 6187 10294 18778 1183 1105 17599 10396 2093 5822 18574 119 22439 1114 1292 13467 8015 117 153 21678 2137 1125 1429 119 5046 1904 117 3453 119 1695 1904 117 1695 119 1626 1904 117 1105 1542 1904 1750 1104 2805 1159 117 3569 119 4246 150 4538 117 3084 2393 119 164 3140 166 3402 1103 7300 13950 1104 153 21678 2137 1114 152 22074 117 1105 1152 1276 1103 2805 1159 1107 1292 1160 2114 1108 4389 119 121 212 1492 119 121 1904 1105 3324 119 127 212 1743 119 128 1904 117 3569 113 153 133 121 119 3135 1475 114 119 27762 162 117 3084 2393 119 164 2532 166 14758 1103 1210 10298 1193 19849 8340 13467 8015 113 153 21678 2137 117 26574 1708 118 157 2162 15499 102\n",
      "I1208 12:27:37.201708 139883775852736 run_factoid.py:449] input_ids: 101 1327 1132 1103 13004 1104 1103 9505 136 102 1112 3402 1114 5942 110 1104 4420 1114 17599 6385 10805 4571 5531 119 1438 117 1103 3719 1206 1172 1108 1136 2418 119 1130 5014 1106 1103 2211 2244 5600 1104 152 22074 1105 17599 6385 10805 4571 6187 10294 18778 1183 117 26574 1708 118 157 2162 15499 1882 1106 1138 170 2299 2244 2603 1190 153 21678 2137 119 8411 140 117 3084 2393 164 3882 166 2103 170 19916 1884 13252 1204 2025 1104 25182 4420 1114 1231 21754 149 2137 3048 1150 1127 5165 1114 153 21678 2137 113 183 134 21040 114 1137 26574 1708 118 157 2162 15499 113 183 134 18868 114 119 1335 1103 1928 9355 2812 118 1146 1104 3993 119 126 1808 117 1103 2244 2603 1107 1103 1160 2114 1108 5539 119 124 110 1105 4573 119 123 110 117 3569 119 164 3882 166 26574 1708 118 157 2162 15499 3657 1107 170 2299 2244 2603 1190 153 21678 2137 117 1649 117 1175 1108 1185 2418 3719 1206 1172 119 23840 1103 2805 1159 117 1103 1675 2025 7160 1115 4420 5165 1114 153 21678 2137 1125 1407 119 1489 1904 1750 1104 2805 1159 1190 1343 1114 1168 13467 22496 119 1438 117 1103 3549 2805 1159 1104 153 21678 2137 1108 1178 4379 1107 1103 7577 1114 152 22074 117 26574 1708 118 157 2162 15499 117 17599 6385 10805 4571 6187 10294 18778 1183 1105 17599 10396 2093 5822 18574 119 22439 1114 1292 13467 8015 117 153 21678 2137 1125 1429 119 5046 1904 117 3453 119 1695 1904 117 1695 119 1626 1904 117 1105 1542 1904 1750 1104 2805 1159 117 3569 119 4246 150 4538 117 3084 2393 119 164 3140 166 3402 1103 7300 13950 1104 153 21678 2137 1114 152 22074 117 1105 1152 1276 1103 2805 1159 1107 1292 1160 2114 1108 4389 119 121 212 1492 119 121 1904 1105 3324 119 127 212 1743 119 128 1904 117 3569 113 153 133 121 119 3135 1475 114 119 27762 162 117 3084 2393 119 164 2532 166 14758 1103 1210 10298 1193 19849 8340 13467 8015 113 153 21678 2137 117 26574 1708 118 157 2162 15499 102\n",
      "INFO:tensorflow:input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      "I1208 12:27:37.201801 139883775852736 run_factoid.py:451] input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      "INFO:tensorflow:segment_ids: 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      "I1208 12:27:37.201891 139883775852736 run_factoid.py:453] segment_ids: 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      "INFO:tensorflow:*** Example ***\n",
      "I1208 12:27:37.203709 139883775852736 run_factoid.py:438] *** Example ***\n",
      "INFO:tensorflow:unique_id: 1000000061\n",
      "I1208 12:27:37.203767 139883775852736 run_factoid.py:439] unique_id: 1000000061\n",
      "INFO:tensorflow:example_index: 9\n",
      "I1208 12:27:37.203805 139883775852736 run_factoid.py:440] example_index: 9\n",
      "INFO:tensorflow:doc_span_index: 8\n",
      "I1208 12:27:37.203839 139883775852736 run_factoid.py:441] doc_span_index: 8\n",
      "INFO:tensorflow:tokens: [CLS] What are the limitations of the findings ? [SEP] the two groups was 91 . 3 % and 95 . 2 % , respectively . [ 52 ] MI ##S - T ##L ##IF resulted in a higher success rate than P ##EL ##D , however , there was no significant difference between them . Regarding the operation time , the present study demonstrated that patients treated with P ##EL ##D had 18 . 14 minutes less of operation time than those with other surgical interventions . However , the reduced operation time of P ##EL ##D was only observed in the comparison with O ##LM , MI ##S - T ##L ##IF , micro ##su ##rg ##ical disc ##ec ##tom ##y and micro ##dis ##ce ##ct ##omy . Compared with these surgical approaches , P ##EL ##D had 11 . 66 minutes , 75 . 23 minutes , 23 . 21 minutes , and 17 minutes less of operation time , respectively . Kim M ##J , et al . [ 44 ] compared the clinical outcomes of P ##EL ##D with O ##LM , and they found the operation time in these two groups was 53 . 0 ± 13 . 0 minutes and 64 . 6 ± 28 . 7 minutes , respectively ( P < 0 . 00 ##1 ) . Yao Y , et al . [ 45 ] assessed the three minimal ##ly invasive spine surgical approaches ( P ##EL ##D , MI ##S - T ##L ##IF , and ME ##D ) for re ##current her ##nia ##tion , and the mean operation time between them was 75 . 0 ± 31 . 56 minutes , 146 . 54 ± 38 . 07 minutes , and 85 . 25 ± 41 . 60 minutes , respectively . P ##EL ##D had a significantly less operation time than MI ##S - T ##L ##IF , but a comparable operation time with ME ##D . The functional outcomes were assessed by the VA ##S scores for back pain and leg pain . Our results suggested that patients treated with P ##EL ##D had comparable post ##oper ##ation VA ##S scores for back pain and leg pain with those treated with other surge ##ries . Our result was [SEP]\n",
      "I1208 12:27:37.203952 139883775852736 run_factoid.py:443] tokens: [CLS] What are the limitations of the findings ? [SEP] the two groups was 91 . 3 % and 95 . 2 % , respectively . [ 52 ] MI ##S - T ##L ##IF resulted in a higher success rate than P ##EL ##D , however , there was no significant difference between them . Regarding the operation time , the present study demonstrated that patients treated with P ##EL ##D had 18 . 14 minutes less of operation time than those with other surgical interventions . However , the reduced operation time of P ##EL ##D was only observed in the comparison with O ##LM , MI ##S - T ##L ##IF , micro ##su ##rg ##ical disc ##ec ##tom ##y and micro ##dis ##ce ##ct ##omy . Compared with these surgical approaches , P ##EL ##D had 11 . 66 minutes , 75 . 23 minutes , 23 . 21 minutes , and 17 minutes less of operation time , respectively . Kim M ##J , et al . [ 44 ] compared the clinical outcomes of P ##EL ##D with O ##LM , and they found the operation time in these two groups was 53 . 0 ± 13 . 0 minutes and 64 . 6 ± 28 . 7 minutes , respectively ( P < 0 . 00 ##1 ) . Yao Y , et al . [ 45 ] assessed the three minimal ##ly invasive spine surgical approaches ( P ##EL ##D , MI ##S - T ##L ##IF , and ME ##D ) for re ##current her ##nia ##tion , and the mean operation time between them was 75 . 0 ± 31 . 56 minutes , 146 . 54 ± 38 . 07 minutes , and 85 . 25 ± 41 . 60 minutes , respectively . P ##EL ##D had a significantly less operation time than MI ##S - T ##L ##IF , but a comparable operation time with ME ##D . The functional outcomes were assessed by the VA ##S scores for back pain and leg pain . Our results suggested that patients treated with P ##EL ##D had comparable post ##oper ##ation VA ##S scores for back pain and leg pain with those treated with other surge ##ries . Our result was [SEP]\n",
      "INFO:tensorflow:token_to_orig_map: 10:615 11:616 12:617 13:618 14:619 15:619 16:619 17:619 18:620 19:621 20:621 21:621 22:621 23:621 24:622 25:622 26:622 27:622 28:622 29:623 30:623 31:623 32:623 33:623 34:623 35:624 36:625 37:626 38:627 39:628 40:629 41:630 42:631 43:631 44:631 45:631 46:632 47:632 48:633 49:634 50:635 51:636 52:637 53:638 54:639 55:639 56:640 57:641 58:642 59:643 60:643 61:644 62:645 63:646 64:647 65:648 66:649 67:650 68:651 69:652 70:652 71:652 72:653 73:654 74:654 75:654 76:655 77:656 78:657 79:658 80:659 81:660 82:661 83:662 84:663 85:664 86:665 87:665 88:666 89:666 90:667 91:668 92:669 93:670 94:671 95:672 96:672 97:672 98:673 99:674 100:675 101:676 102:677 103:678 104:679 105:680 106:680 107:680 108:681 109:681 110:681 111:681 112:681 113:681 114:681 115:682 116:682 117:682 118:682 119:683 120:683 121:683 122:683 123:684 124:685 125:685 126:685 127:685 128:685 129:685 130:686 131:687 132:688 133:689 134:690 135:690 136:691 137:691 138:691 139:692 140:693 141:693 142:693 143:694 144:694 145:695 146:695 147:695 148:696 149:696 150:697 151:697 152:697 153:698 154:698 155:699 156:700 157:701 158:702 159:703 160:704 161:705 162:705 163:706 164:706 165:707 166:708 167:708 168:708 169:709 170:710 171:710 172:710 173:710 174:710 175:711 176:712 177:713 178:714 179:715 180:716 181:716 182:716 183:717 184:718 185:718 186:718 187:719 188:720 189:721 190:722 191:723 192:724 193:725 194:726 195:727 196:728 197:729 198:730 199:730 200:730 201:731 202:732 203:732 204:732 205:733 206:734 207:735 208:735 209:735 210:736 211:737 212:737 213:737 214:738 215:738 216:739 217:740 218:740 219:741 220:742 221:742 222:742 223:742 224:742 225:742 226:743 227:744 228:744 229:745 230:746 231:746 232:746 233:746 234:746 235:747 236:748 237:749 238:750 239:750 240:751 241:752 242:753 243:754 244:755 245:755 246:755 247:755 248:755 249:756 250:756 251:756 252:756 253:756 254:756 255:756 256:757 257:758 258:758 259:758 260:759 261:760 262:760 263:761 264:761 265:761 266:761 267:762 268:763 269:764 270:765 271:766 272:767 273:768 274:769 275:770 276:770 277:770 278:771 279:772 280:772 281:772 282:773 283:773 284:774 285:774 286:774 287:775 288:776 289:776 290:776 291:777 292:777 293:778 294:779 295:779 296:779 297:780 298:781 299:781 300:781 301:782 302:782 303:783 304:783 305:784 306:784 307:784 308:785 309:786 310:787 311:788 312:789 313:790 314:791 315:792 316:792 317:792 318:792 319:792 320:792 321:792 322:793 323:794 324:795 325:796 326:797 327:798 328:799 329:799 330:799 331:800 332:801 333:802 334:803 335:804 336:805 337:806 338:807 339:807 340:808 341:809 342:810 343:811 344:812 345:813 346:814 347:814 348:815 349:816 350:817 351:818 352:819 353:820 354:821 355:822 356:822 357:822 358:823 359:824 360:825 361:825 362:825 363:826 364:826 365:827 366:828 367:829 368:830 369:831 370:832 371:833 372:834 373:835 374:836 375:837 376:838 377:839 378:839 379:839 380:840 381:841 382:842\n",
      "I1208 12:27:37.204075 139883775852736 run_factoid.py:445] token_to_orig_map: 10:615 11:616 12:617 13:618 14:619 15:619 16:619 17:619 18:620 19:621 20:621 21:621 22:621 23:621 24:622 25:622 26:622 27:622 28:622 29:623 30:623 31:623 32:623 33:623 34:623 35:624 36:625 37:626 38:627 39:628 40:629 41:630 42:631 43:631 44:631 45:631 46:632 47:632 48:633 49:634 50:635 51:636 52:637 53:638 54:639 55:639 56:640 57:641 58:642 59:643 60:643 61:644 62:645 63:646 64:647 65:648 66:649 67:650 68:651 69:652 70:652 71:652 72:653 73:654 74:654 75:654 76:655 77:656 78:657 79:658 80:659 81:660 82:661 83:662 84:663 85:664 86:665 87:665 88:666 89:666 90:667 91:668 92:669 93:670 94:671 95:672 96:672 97:672 98:673 99:674 100:675 101:676 102:677 103:678 104:679 105:680 106:680 107:680 108:681 109:681 110:681 111:681 112:681 113:681 114:681 115:682 116:682 117:682 118:682 119:683 120:683 121:683 122:683 123:684 124:685 125:685 126:685 127:685 128:685 129:685 130:686 131:687 132:688 133:689 134:690 135:690 136:691 137:691 138:691 139:692 140:693 141:693 142:693 143:694 144:694 145:695 146:695 147:695 148:696 149:696 150:697 151:697 152:697 153:698 154:698 155:699 156:700 157:701 158:702 159:703 160:704 161:705 162:705 163:706 164:706 165:707 166:708 167:708 168:708 169:709 170:710 171:710 172:710 173:710 174:710 175:711 176:712 177:713 178:714 179:715 180:716 181:716 182:716 183:717 184:718 185:718 186:718 187:719 188:720 189:721 190:722 191:723 192:724 193:725 194:726 195:727 196:728 197:729 198:730 199:730 200:730 201:731 202:732 203:732 204:732 205:733 206:734 207:735 208:735 209:735 210:736 211:737 212:737 213:737 214:738 215:738 216:739 217:740 218:740 219:741 220:742 221:742 222:742 223:742 224:742 225:742 226:743 227:744 228:744 229:745 230:746 231:746 232:746 233:746 234:746 235:747 236:748 237:749 238:750 239:750 240:751 241:752 242:753 243:754 244:755 245:755 246:755 247:755 248:755 249:756 250:756 251:756 252:756 253:756 254:756 255:756 256:757 257:758 258:758 259:758 260:759 261:760 262:760 263:761 264:761 265:761 266:761 267:762 268:763 269:764 270:765 271:766 272:767 273:768 274:769 275:770 276:770 277:770 278:771 279:772 280:772 281:772 282:773 283:773 284:774 285:774 286:774 287:775 288:776 289:776 290:776 291:777 292:777 293:778 294:779 295:779 296:779 297:780 298:781 299:781 300:781 301:782 302:782 303:783 304:783 305:784 306:784 307:784 308:785 309:786 310:787 311:788 312:789 313:790 314:791 315:792 316:792 317:792 318:792 319:792 320:792 321:792 322:793 323:794 324:795 325:796 326:797 327:798 328:799 329:799 330:799 331:800 332:801 333:802 334:803 335:804 336:805 337:806 338:807 339:807 340:808 341:809 342:810 343:811 344:812 345:813 346:814 347:814 348:815 349:816 350:817 351:818 352:819 353:820 354:821 355:822 356:822 357:822 358:823 359:824 360:825 361:825 362:825 363:826 364:826 365:827 366:828 367:829 368:830 369:831 370:832 371:833 372:834 373:835 374:836 375:837 376:838 377:839 378:839 379:839 380:840 381:841 382:842\n",
      "INFO:tensorflow:token_is_max_context: 10:False 11:False 12:False 13:False 14:False 15:False 16:False 17:False 18:False 19:False 20:False 21:False 22:False 23:False 24:False 25:False 26:False 27:False 28:False 29:False 30:False 31:False 32:False 33:False 34:False 35:False 36:False 37:False 38:False 39:False 40:False 41:False 42:False 43:False 44:False 45:False 46:False 47:False 48:False 49:False 50:False 51:False 52:False 53:False 54:False 55:False 56:False 57:False 58:False 59:False 60:False 61:False 62:False 63:False 64:False 65:False 66:False 67:False 68:False 69:False 70:False 71:False 72:False 73:False 74:False 75:False 76:False 77:False 78:False 79:False 80:False 81:False 82:False 83:False 84:False 85:False 86:False 87:False 88:False 89:False 90:False 91:False 92:False 93:False 94:False 95:False 96:False 97:False 98:False 99:False 100:False 101:False 102:False 103:False 104:False 105:False 106:False 107:False 108:False 109:False 110:False 111:False 112:False 113:False 114:False 115:False 116:False 117:False 118:False 119:False 120:False 121:False 122:False 123:False 124:False 125:False 126:False 127:False 128:False 129:False 130:False 131:False 132:False 133:True 134:True 135:True 136:True 137:True 138:True 139:True 140:True 141:True 142:True 143:True 144:True 145:True 146:True 147:True 148:True 149:True 150:True 151:True 152:True 153:True 154:True 155:True 156:True 157:True 158:True 159:True 160:True 161:True 162:True 163:True 164:True 165:True 166:True 167:True 168:True 169:True 170:True 171:True 172:True 173:True 174:True 175:True 176:True 177:True 178:True 179:True 180:True 181:True 182:True 183:True 184:True 185:True 186:True 187:True 188:True 189:True 190:True 191:True 192:True 193:True 194:True 195:True 196:True 197:True 198:True 199:True 200:True 201:True 202:True 203:True 204:True 205:True 206:True 207:True 208:True 209:True 210:True 211:True 212:True 213:True 214:True 215:True 216:True 217:True 218:True 219:True 220:True 221:True 222:True 223:True 224:True 225:True 226:True 227:True 228:True 229:True 230:True 231:True 232:True 233:True 234:True 235:True 236:True 237:True 238:True 239:True 240:True 241:True 242:True 243:True 244:True 245:True 246:True 247:True 248:True 249:True 250:True 251:True 252:True 253:True 254:True 255:True 256:True 257:True 258:True 259:True 260:True 261:False 262:False 263:False 264:False 265:False 266:False 267:False 268:False 269:False 270:False 271:False 272:False 273:False 274:False 275:False 276:False 277:False 278:False 279:False 280:False 281:False 282:False 283:False 284:False 285:False 286:False 287:False 288:False 289:False 290:False 291:False 292:False 293:False 294:False 295:False 296:False 297:False 298:False 299:False 300:False 301:False 302:False 303:False 304:False 305:False 306:False 307:False 308:False 309:False 310:False 311:False 312:False 313:False 314:False 315:False 316:False 317:False 318:False 319:False 320:False 321:False 322:False 323:False 324:False 325:False 326:False 327:False 328:False 329:False 330:False 331:False 332:False 333:False 334:False 335:False 336:False 337:False 338:False 339:False 340:False 341:False 342:False 343:False 344:False 345:False 346:False 347:False 348:False 349:False 350:False 351:False 352:False 353:False 354:False 355:False 356:False 357:False 358:False 359:False 360:False 361:False 362:False 363:False 364:False 365:False 366:False 367:False 368:False 369:False 370:False 371:False 372:False 373:False 374:False 375:False 376:False 377:False 378:False 379:False 380:False 381:False 382:False\n",
      "I1208 12:27:37.204188 139883775852736 run_factoid.py:447] token_is_max_context: 10:False 11:False 12:False 13:False 14:False 15:False 16:False 17:False 18:False 19:False 20:False 21:False 22:False 23:False 24:False 25:False 26:False 27:False 28:False 29:False 30:False 31:False 32:False 33:False 34:False 35:False 36:False 37:False 38:False 39:False 40:False 41:False 42:False 43:False 44:False 45:False 46:False 47:False 48:False 49:False 50:False 51:False 52:False 53:False 54:False 55:False 56:False 57:False 58:False 59:False 60:False 61:False 62:False 63:False 64:False 65:False 66:False 67:False 68:False 69:False 70:False 71:False 72:False 73:False 74:False 75:False 76:False 77:False 78:False 79:False 80:False 81:False 82:False 83:False 84:False 85:False 86:False 87:False 88:False 89:False 90:False 91:False 92:False 93:False 94:False 95:False 96:False 97:False 98:False 99:False 100:False 101:False 102:False 103:False 104:False 105:False 106:False 107:False 108:False 109:False 110:False 111:False 112:False 113:False 114:False 115:False 116:False 117:False 118:False 119:False 120:False 121:False 122:False 123:False 124:False 125:False 126:False 127:False 128:False 129:False 130:False 131:False 132:False 133:True 134:True 135:True 136:True 137:True 138:True 139:True 140:True 141:True 142:True 143:True 144:True 145:True 146:True 147:True 148:True 149:True 150:True 151:True 152:True 153:True 154:True 155:True 156:True 157:True 158:True 159:True 160:True 161:True 162:True 163:True 164:True 165:True 166:True 167:True 168:True 169:True 170:True 171:True 172:True 173:True 174:True 175:True 176:True 177:True 178:True 179:True 180:True 181:True 182:True 183:True 184:True 185:True 186:True 187:True 188:True 189:True 190:True 191:True 192:True 193:True 194:True 195:True 196:True 197:True 198:True 199:True 200:True 201:True 202:True 203:True 204:True 205:True 206:True 207:True 208:True 209:True 210:True 211:True 212:True 213:True 214:True 215:True 216:True 217:True 218:True 219:True 220:True 221:True 222:True 223:True 224:True 225:True 226:True 227:True 228:True 229:True 230:True 231:True 232:True 233:True 234:True 235:True 236:True 237:True 238:True 239:True 240:True 241:True 242:True 243:True 244:True 245:True 246:True 247:True 248:True 249:True 250:True 251:True 252:True 253:True 254:True 255:True 256:True 257:True 258:True 259:True 260:True 261:False 262:False 263:False 264:False 265:False 266:False 267:False 268:False 269:False 270:False 271:False 272:False 273:False 274:False 275:False 276:False 277:False 278:False 279:False 280:False 281:False 282:False 283:False 284:False 285:False 286:False 287:False 288:False 289:False 290:False 291:False 292:False 293:False 294:False 295:False 296:False 297:False 298:False 299:False 300:False 301:False 302:False 303:False 304:False 305:False 306:False 307:False 308:False 309:False 310:False 311:False 312:False 313:False 314:False 315:False 316:False 317:False 318:False 319:False 320:False 321:False 322:False 323:False 324:False 325:False 326:False 327:False 328:False 329:False 330:False 331:False 332:False 333:False 334:False 335:False 336:False 337:False 338:False 339:False 340:False 341:False 342:False 343:False 344:False 345:False 346:False 347:False 348:False 349:False 350:False 351:False 352:False 353:False 354:False 355:False 356:False 357:False 358:False 359:False 360:False 361:False 362:False 363:False 364:False 365:False 366:False 367:False 368:False 369:False 370:False 371:False 372:False 373:False 374:False 375:False 376:False 377:False 378:False 379:False 380:False 381:False 382:False\n",
      "INFO:tensorflow:input_ids: 101 1327 1132 1103 13004 1104 1103 9505 136 102 1103 1160 2114 1108 5539 119 124 110 1105 4573 119 123 110 117 3569 119 164 3882 166 26574 1708 118 157 2162 15499 3657 1107 170 2299 2244 2603 1190 153 21678 2137 117 1649 117 1175 1108 1185 2418 3719 1206 1172 119 23840 1103 2805 1159 117 1103 1675 2025 7160 1115 4420 5165 1114 153 21678 2137 1125 1407 119 1489 1904 1750 1104 2805 1159 1190 1343 1114 1168 13467 22496 119 1438 117 1103 3549 2805 1159 1104 153 21678 2137 1108 1178 4379 1107 1103 7577 1114 152 22074 117 26574 1708 118 157 2162 15499 117 17599 6385 10805 4571 6187 10294 18778 1183 1105 17599 10396 2093 5822 18574 119 22439 1114 1292 13467 8015 117 153 21678 2137 1125 1429 119 5046 1904 117 3453 119 1695 1904 117 1695 119 1626 1904 117 1105 1542 1904 1750 1104 2805 1159 117 3569 119 4246 150 4538 117 3084 2393 119 164 3140 166 3402 1103 7300 13950 1104 153 21678 2137 1114 152 22074 117 1105 1152 1276 1103 2805 1159 1107 1292 1160 2114 1108 4389 119 121 212 1492 119 121 1904 1105 3324 119 127 212 1743 119 128 1904 117 3569 113 153 133 121 119 3135 1475 114 119 27762 162 117 3084 2393 119 164 2532 166 14758 1103 1210 10298 1193 19849 8340 13467 8015 113 153 21678 2137 117 26574 1708 118 157 2162 15499 117 1105 22157 2137 114 1111 1231 21754 1123 5813 2116 117 1105 1103 1928 2805 1159 1206 1172 1108 3453 119 121 212 1955 119 4376 1904 117 17350 119 4335 212 3383 119 5004 1904 117 1105 4859 119 1512 212 3746 119 2539 1904 117 3569 119 153 21678 2137 1125 170 5409 1750 2805 1159 1190 26574 1708 118 157 2162 15499 117 1133 170 12763 2805 1159 1114 22157 2137 119 1109 8458 13950 1127 14758 1118 1103 19497 1708 7432 1111 1171 2489 1105 3420 2489 119 3458 2686 3228 1115 4420 5165 1114 153 21678 2137 1125 12763 2112 19807 1891 19497 1708 7432 1111 1171 2489 1105 3420 2489 1114 1343 5165 1114 1168 12814 3377 119 3458 1871 1108 102\n",
      "I1208 12:27:37.204292 139883775852736 run_factoid.py:449] input_ids: 101 1327 1132 1103 13004 1104 1103 9505 136 102 1103 1160 2114 1108 5539 119 124 110 1105 4573 119 123 110 117 3569 119 164 3882 166 26574 1708 118 157 2162 15499 3657 1107 170 2299 2244 2603 1190 153 21678 2137 117 1649 117 1175 1108 1185 2418 3719 1206 1172 119 23840 1103 2805 1159 117 1103 1675 2025 7160 1115 4420 5165 1114 153 21678 2137 1125 1407 119 1489 1904 1750 1104 2805 1159 1190 1343 1114 1168 13467 22496 119 1438 117 1103 3549 2805 1159 1104 153 21678 2137 1108 1178 4379 1107 1103 7577 1114 152 22074 117 26574 1708 118 157 2162 15499 117 17599 6385 10805 4571 6187 10294 18778 1183 1105 17599 10396 2093 5822 18574 119 22439 1114 1292 13467 8015 117 153 21678 2137 1125 1429 119 5046 1904 117 3453 119 1695 1904 117 1695 119 1626 1904 117 1105 1542 1904 1750 1104 2805 1159 117 3569 119 4246 150 4538 117 3084 2393 119 164 3140 166 3402 1103 7300 13950 1104 153 21678 2137 1114 152 22074 117 1105 1152 1276 1103 2805 1159 1107 1292 1160 2114 1108 4389 119 121 212 1492 119 121 1904 1105 3324 119 127 212 1743 119 128 1904 117 3569 113 153 133 121 119 3135 1475 114 119 27762 162 117 3084 2393 119 164 2532 166 14758 1103 1210 10298 1193 19849 8340 13467 8015 113 153 21678 2137 117 26574 1708 118 157 2162 15499 117 1105 22157 2137 114 1111 1231 21754 1123 5813 2116 117 1105 1103 1928 2805 1159 1206 1172 1108 3453 119 121 212 1955 119 4376 1904 117 17350 119 4335 212 3383 119 5004 1904 117 1105 4859 119 1512 212 3746 119 2539 1904 117 3569 119 153 21678 2137 1125 170 5409 1750 2805 1159 1190 26574 1708 118 157 2162 15499 117 1133 170 12763 2805 1159 1114 22157 2137 119 1109 8458 13950 1127 14758 1118 1103 19497 1708 7432 1111 1171 2489 1105 3420 2489 119 3458 2686 3228 1115 4420 5165 1114 153 21678 2137 1125 12763 2112 19807 1891 19497 1708 7432 1111 1171 2489 1105 3420 2489 1114 1343 5165 1114 1168 12814 3377 119 3458 1871 1108 102\n",
      "INFO:tensorflow:input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      "I1208 12:27:37.204383 139883775852736 run_factoid.py:451] input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      "INFO:tensorflow:segment_ids: 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      "I1208 12:27:37.204472 139883775852736 run_factoid.py:453] segment_ids: 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      "INFO:tensorflow:*** Example ***\n",
      "I1208 12:27:37.206326 139883775852736 run_factoid.py:438] *** Example ***\n",
      "INFO:tensorflow:unique_id: 1000000062\n",
      "I1208 12:27:37.206388 139883775852736 run_factoid.py:439] unique_id: 1000000062\n",
      "INFO:tensorflow:example_index: 9\n",
      "I1208 12:27:37.206426 139883775852736 run_factoid.py:440] example_index: 9\n",
      "INFO:tensorflow:doc_span_index: 9\n",
      "I1208 12:27:37.206460 139883775852736 run_factoid.py:441] doc_span_index: 9\n",
      "INFO:tensorflow:tokens: [CLS] What are the limitations of the findings ? [SEP] ##D had 11 . 66 minutes , 75 . 23 minutes , 23 . 21 minutes , and 17 minutes less of operation time , respectively . Kim M ##J , et al . [ 44 ] compared the clinical outcomes of P ##EL ##D with O ##LM , and they found the operation time in these two groups was 53 . 0 ± 13 . 0 minutes and 64 . 6 ± 28 . 7 minutes , respectively ( P < 0 . 00 ##1 ) . Yao Y , et al . [ 45 ] assessed the three minimal ##ly invasive spine surgical approaches ( P ##EL ##D , MI ##S - T ##L ##IF , and ME ##D ) for re ##current her ##nia ##tion , and the mean operation time between them was 75 . 0 ± 31 . 56 minutes , 146 . 54 ± 38 . 07 minutes , and 85 . 25 ± 41 . 60 minutes , respectively . P ##EL ##D had a significantly less operation time than MI ##S - T ##L ##IF , but a comparable operation time with ME ##D . The functional outcomes were assessed by the VA ##S scores for back pain and leg pain . Our results suggested that patients treated with P ##EL ##D had comparable post ##oper ##ation VA ##S scores for back pain and leg pain with those treated with other surge ##ries . Our result was in consistent with the previous findings . [ 50 , 52 , 54 ] Yao Y , et al [ 54 ] reported that the pre ##oper ##ative VA ##S scores for back pain and leg pain were 5 . 88 ± 1 . 24 and 7 . 05 ± 1 . 08 in the MI ##S - T ##L ##IF group , 5 . 92 ± 1 . 33 and 7 . 13 ± 1 . 09 respectively in the P ##EL ##D group ( P = . 88 ##8 ) . [ 54 ] At the follow - up duration of 12 months , the VA ##S scores significantly reduced in the two groups as compared with pre ##oper ##ative values . However , there was [SEP]\n",
      "I1208 12:27:37.206575 139883775852736 run_factoid.py:443] tokens: [CLS] What are the limitations of the findings ? [SEP] ##D had 11 . 66 minutes , 75 . 23 minutes , 23 . 21 minutes , and 17 minutes less of operation time , respectively . Kim M ##J , et al . [ 44 ] compared the clinical outcomes of P ##EL ##D with O ##LM , and they found the operation time in these two groups was 53 . 0 ± 13 . 0 minutes and 64 . 6 ± 28 . 7 minutes , respectively ( P < 0 . 00 ##1 ) . Yao Y , et al . [ 45 ] assessed the three minimal ##ly invasive spine surgical approaches ( P ##EL ##D , MI ##S - T ##L ##IF , and ME ##D ) for re ##current her ##nia ##tion , and the mean operation time between them was 75 . 0 ± 31 . 56 minutes , 146 . 54 ± 38 . 07 minutes , and 85 . 25 ± 41 . 60 minutes , respectively . P ##EL ##D had a significantly less operation time than MI ##S - T ##L ##IF , but a comparable operation time with ME ##D . The functional outcomes were assessed by the VA ##S scores for back pain and leg pain . Our results suggested that patients treated with P ##EL ##D had comparable post ##oper ##ation VA ##S scores for back pain and leg pain with those treated with other surge ##ries . Our result was in consistent with the previous findings . [ 50 , 52 , 54 ] Yao Y , et al [ 54 ] reported that the pre ##oper ##ative VA ##S scores for back pain and leg pain were 5 . 88 ± 1 . 24 and 7 . 05 ± 1 . 08 in the MI ##S - T ##L ##IF group , 5 . 92 ± 1 . 33 and 7 . 13 ± 1 . 09 respectively in the P ##EL ##D group ( P = . 88 ##8 ) . [ 54 ] At the follow - up duration of 12 months , the VA ##S scores significantly reduced in the two groups as compared with pre ##oper ##ative values . However , there was [SEP]\n",
      "INFO:tensorflow:token_to_orig_map: 10:691 11:692 12:693 13:693 14:693 15:694 16:694 17:695 18:695 19:695 20:696 21:696 22:697 23:697 24:697 25:698 26:698 27:699 28:700 29:701 30:702 31:703 32:704 33:705 34:705 35:706 36:706 37:707 38:708 39:708 40:708 41:709 42:710 43:710 44:710 45:710 46:710 47:711 48:712 49:713 50:714 51:715 52:716 53:716 54:716 55:717 56:718 57:718 58:718 59:719 60:720 61:721 62:722 63:723 64:724 65:725 66:726 67:727 68:728 69:729 70:730 71:730 72:730 73:731 74:732 75:732 76:732 77:733 78:734 79:735 80:735 81:735 82:736 83:737 84:737 85:737 86:738 87:738 88:739 89:740 90:740 91:741 92:742 93:742 94:742 95:742 96:742 97:742 98:743 99:744 100:744 101:745 102:746 103:746 104:746 105:746 106:746 107:747 108:748 109:749 110:750 111:750 112:751 113:752 114:753 115:754 116:755 117:755 118:755 119:755 120:755 121:756 122:756 123:756 124:756 125:756 126:756 127:756 128:757 129:758 130:758 131:758 132:759 133:760 134:760 135:761 136:761 137:761 138:761 139:762 140:763 141:764 142:765 143:766 144:767 145:768 146:769 147:770 148:770 149:770 150:771 151:772 152:772 153:772 154:773 155:773 156:774 157:774 158:774 159:775 160:776 161:776 162:776 163:777 164:777 165:778 166:779 167:779 168:779 169:780 170:781 171:781 172:781 173:782 174:782 175:783 176:783 177:784 178:784 179:784 180:785 181:786 182:787 183:788 184:789 185:790 186:791 187:792 188:792 189:792 190:792 191:792 192:792 193:792 194:793 195:794 196:795 197:796 198:797 199:798 200:799 201:799 202:799 203:800 204:801 205:802 206:803 207:804 208:805 209:806 210:807 211:807 212:808 213:809 214:810 215:811 216:812 217:813 218:814 219:814 220:815 221:816 222:817 223:818 224:819 225:820 226:821 227:822 228:822 229:822 230:823 231:824 232:825 233:825 234:825 235:826 236:826 237:827 238:828 239:829 240:830 241:831 242:832 243:833 244:834 245:835 246:836 247:837 248:838 249:839 250:839 251:839 252:840 253:841 254:842 255:843 256:844 257:845 258:846 259:847 260:848 261:848 262:848 263:848 264:848 265:848 266:848 267:848 268:848 269:849 270:850 271:850 272:851 273:852 274:852 275:852 276:852 277:853 278:854 279:855 280:856 281:856 282:856 283:857 284:857 285:858 286:859 287:860 288:861 289:862 290:863 291:864 292:865 293:866 294:866 295:866 296:867 297:868 298:868 299:868 300:869 301:870 302:870 303:870 304:871 305:872 306:872 307:872 308:873 309:874 310:875 311:875 312:875 313:876 314:876 315:876 316:877 317:877 318:878 319:878 320:878 321:879 322:880 323:880 324:880 325:881 326:882 327:882 328:882 329:883 330:884 331:884 332:884 333:885 334:886 335:887 336:888 337:888 338:888 339:889 340:890 341:890 342:891 343:892 344:892 345:892 346:892 347:892 348:892 349:892 350:892 351:893 352:894 353:895 354:895 355:895 356:896 357:897 358:898 359:899 360:899 361:900 362:901 363:901 364:902 365:903 366:904 367:905 368:906 369:907 370:908 371:909 372:910 373:911 374:912 375:912 376:912 377:913 378:913 379:914 380:914 381:915 382:916\n",
      "I1208 12:27:37.206693 139883775852736 run_factoid.py:445] token_to_orig_map: 10:691 11:692 12:693 13:693 14:693 15:694 16:694 17:695 18:695 19:695 20:696 21:696 22:697 23:697 24:697 25:698 26:698 27:699 28:700 29:701 30:702 31:703 32:704 33:705 34:705 35:706 36:706 37:707 38:708 39:708 40:708 41:709 42:710 43:710 44:710 45:710 46:710 47:711 48:712 49:713 50:714 51:715 52:716 53:716 54:716 55:717 56:718 57:718 58:718 59:719 60:720 61:721 62:722 63:723 64:724 65:725 66:726 67:727 68:728 69:729 70:730 71:730 72:730 73:731 74:732 75:732 76:732 77:733 78:734 79:735 80:735 81:735 82:736 83:737 84:737 85:737 86:738 87:738 88:739 89:740 90:740 91:741 92:742 93:742 94:742 95:742 96:742 97:742 98:743 99:744 100:744 101:745 102:746 103:746 104:746 105:746 106:746 107:747 108:748 109:749 110:750 111:750 112:751 113:752 114:753 115:754 116:755 117:755 118:755 119:755 120:755 121:756 122:756 123:756 124:756 125:756 126:756 127:756 128:757 129:758 130:758 131:758 132:759 133:760 134:760 135:761 136:761 137:761 138:761 139:762 140:763 141:764 142:765 143:766 144:767 145:768 146:769 147:770 148:770 149:770 150:771 151:772 152:772 153:772 154:773 155:773 156:774 157:774 158:774 159:775 160:776 161:776 162:776 163:777 164:777 165:778 166:779 167:779 168:779 169:780 170:781 171:781 172:781 173:782 174:782 175:783 176:783 177:784 178:784 179:784 180:785 181:786 182:787 183:788 184:789 185:790 186:791 187:792 188:792 189:792 190:792 191:792 192:792 193:792 194:793 195:794 196:795 197:796 198:797 199:798 200:799 201:799 202:799 203:800 204:801 205:802 206:803 207:804 208:805 209:806 210:807 211:807 212:808 213:809 214:810 215:811 216:812 217:813 218:814 219:814 220:815 221:816 222:817 223:818 224:819 225:820 226:821 227:822 228:822 229:822 230:823 231:824 232:825 233:825 234:825 235:826 236:826 237:827 238:828 239:829 240:830 241:831 242:832 243:833 244:834 245:835 246:836 247:837 248:838 249:839 250:839 251:839 252:840 253:841 254:842 255:843 256:844 257:845 258:846 259:847 260:848 261:848 262:848 263:848 264:848 265:848 266:848 267:848 268:848 269:849 270:850 271:850 272:851 273:852 274:852 275:852 276:852 277:853 278:854 279:855 280:856 281:856 282:856 283:857 284:857 285:858 286:859 287:860 288:861 289:862 290:863 291:864 292:865 293:866 294:866 295:866 296:867 297:868 298:868 299:868 300:869 301:870 302:870 303:870 304:871 305:872 306:872 307:872 308:873 309:874 310:875 311:875 312:875 313:876 314:876 315:876 316:877 317:877 318:878 319:878 320:878 321:879 322:880 323:880 324:880 325:881 326:882 327:882 328:882 329:883 330:884 331:884 332:884 333:885 334:886 335:887 336:888 337:888 338:888 339:889 340:890 341:890 342:891 343:892 344:892 345:892 346:892 347:892 348:892 349:892 350:892 351:893 352:894 353:895 354:895 355:895 356:896 357:897 358:898 359:899 360:899 361:900 362:901 363:901 364:902 365:903 366:904 367:905 368:906 369:907 370:908 371:909 372:910 373:911 374:912 375:912 376:912 377:913 378:913 379:914 380:914 381:915 382:916\n",
      "INFO:tensorflow:token_is_max_context: 10:False 11:False 12:False 13:False 14:False 15:False 16:False 17:False 18:False 19:False 20:False 21:False 22:False 23:False 24:False 25:False 26:False 27:False 28:False 29:False 30:False 31:False 32:False 33:False 34:False 35:False 36:False 37:False 38:False 39:False 40:False 41:False 42:False 43:False 44:False 45:False 46:False 47:False 48:False 49:False 50:False 51:False 52:False 53:False 54:False 55:False 56:False 57:False 58:False 59:False 60:False 61:False 62:False 63:False 64:False 65:False 66:False 67:False 68:False 69:False 70:False 71:False 72:False 73:False 74:False 75:False 76:False 77:False 78:False 79:False 80:False 81:False 82:False 83:False 84:False 85:False 86:False 87:False 88:False 89:False 90:False 91:False 92:False 93:False 94:False 95:False 96:False 97:False 98:False 99:False 100:False 101:False 102:False 103:False 104:False 105:False 106:False 107:False 108:False 109:False 110:False 111:False 112:False 113:False 114:False 115:False 116:False 117:False 118:False 119:False 120:False 121:False 122:False 123:False 124:False 125:False 126:False 127:False 128:False 129:False 130:False 131:False 132:False 133:True 134:True 135:True 136:True 137:True 138:True 139:True 140:True 141:True 142:True 143:True 144:True 145:True 146:True 147:True 148:True 149:True 150:True 151:True 152:True 153:True 154:True 155:True 156:True 157:True 158:True 159:True 160:True 161:True 162:True 163:True 164:True 165:True 166:True 167:True 168:True 169:True 170:True 171:True 172:True 173:True 174:True 175:True 176:True 177:True 178:True 179:True 180:True 181:True 182:True 183:True 184:True 185:True 186:True 187:True 188:True 189:True 190:True 191:True 192:True 193:True 194:True 195:True 196:True 197:True 198:True 199:True 200:True 201:True 202:True 203:True 204:True 205:True 206:True 207:True 208:True 209:True 210:True 211:True 212:True 213:True 214:True 215:True 216:True 217:True 218:True 219:True 220:True 221:True 222:True 223:True 224:True 225:True 226:True 227:True 228:True 229:True 230:True 231:True 232:True 233:True 234:True 235:True 236:True 237:True 238:True 239:True 240:True 241:True 242:True 243:True 244:True 245:True 246:True 247:True 248:True 249:True 250:True 251:True 252:True 253:True 254:True 255:True 256:True 257:True 258:True 259:True 260:True 261:False 262:False 263:False 264:False 265:False 266:False 267:False 268:False 269:False 270:False 271:False 272:False 273:False 274:False 275:False 276:False 277:False 278:False 279:False 280:False 281:False 282:False 283:False 284:False 285:False 286:False 287:False 288:False 289:False 290:False 291:False 292:False 293:False 294:False 295:False 296:False 297:False 298:False 299:False 300:False 301:False 302:False 303:False 304:False 305:False 306:False 307:False 308:False 309:False 310:False 311:False 312:False 313:False 314:False 315:False 316:False 317:False 318:False 319:False 320:False 321:False 322:False 323:False 324:False 325:False 326:False 327:False 328:False 329:False 330:False 331:False 332:False 333:False 334:False 335:False 336:False 337:False 338:False 339:False 340:False 341:False 342:False 343:False 344:False 345:False 346:False 347:False 348:False 349:False 350:False 351:False 352:False 353:False 354:False 355:False 356:False 357:False 358:False 359:False 360:False 361:False 362:False 363:False 364:False 365:False 366:False 367:False 368:False 369:False 370:False 371:False 372:False 373:False 374:False 375:False 376:False 377:False 378:False 379:False 380:False 381:False 382:False\n",
      "I1208 12:27:37.206806 139883775852736 run_factoid.py:447] token_is_max_context: 10:False 11:False 12:False 13:False 14:False 15:False 16:False 17:False 18:False 19:False 20:False 21:False 22:False 23:False 24:False 25:False 26:False 27:False 28:False 29:False 30:False 31:False 32:False 33:False 34:False 35:False 36:False 37:False 38:False 39:False 40:False 41:False 42:False 43:False 44:False 45:False 46:False 47:False 48:False 49:False 50:False 51:False 52:False 53:False 54:False 55:False 56:False 57:False 58:False 59:False 60:False 61:False 62:False 63:False 64:False 65:False 66:False 67:False 68:False 69:False 70:False 71:False 72:False 73:False 74:False 75:False 76:False 77:False 78:False 79:False 80:False 81:False 82:False 83:False 84:False 85:False 86:False 87:False 88:False 89:False 90:False 91:False 92:False 93:False 94:False 95:False 96:False 97:False 98:False 99:False 100:False 101:False 102:False 103:False 104:False 105:False 106:False 107:False 108:False 109:False 110:False 111:False 112:False 113:False 114:False 115:False 116:False 117:False 118:False 119:False 120:False 121:False 122:False 123:False 124:False 125:False 126:False 127:False 128:False 129:False 130:False 131:False 132:False 133:True 134:True 135:True 136:True 137:True 138:True 139:True 140:True 141:True 142:True 143:True 144:True 145:True 146:True 147:True 148:True 149:True 150:True 151:True 152:True 153:True 154:True 155:True 156:True 157:True 158:True 159:True 160:True 161:True 162:True 163:True 164:True 165:True 166:True 167:True 168:True 169:True 170:True 171:True 172:True 173:True 174:True 175:True 176:True 177:True 178:True 179:True 180:True 181:True 182:True 183:True 184:True 185:True 186:True 187:True 188:True 189:True 190:True 191:True 192:True 193:True 194:True 195:True 196:True 197:True 198:True 199:True 200:True 201:True 202:True 203:True 204:True 205:True 206:True 207:True 208:True 209:True 210:True 211:True 212:True 213:True 214:True 215:True 216:True 217:True 218:True 219:True 220:True 221:True 222:True 223:True 224:True 225:True 226:True 227:True 228:True 229:True 230:True 231:True 232:True 233:True 234:True 235:True 236:True 237:True 238:True 239:True 240:True 241:True 242:True 243:True 244:True 245:True 246:True 247:True 248:True 249:True 250:True 251:True 252:True 253:True 254:True 255:True 256:True 257:True 258:True 259:True 260:True 261:False 262:False 263:False 264:False 265:False 266:False 267:False 268:False 269:False 270:False 271:False 272:False 273:False 274:False 275:False 276:False 277:False 278:False 279:False 280:False 281:False 282:False 283:False 284:False 285:False 286:False 287:False 288:False 289:False 290:False 291:False 292:False 293:False 294:False 295:False 296:False 297:False 298:False 299:False 300:False 301:False 302:False 303:False 304:False 305:False 306:False 307:False 308:False 309:False 310:False 311:False 312:False 313:False 314:False 315:False 316:False 317:False 318:False 319:False 320:False 321:False 322:False 323:False 324:False 325:False 326:False 327:False 328:False 329:False 330:False 331:False 332:False 333:False 334:False 335:False 336:False 337:False 338:False 339:False 340:False 341:False 342:False 343:False 344:False 345:False 346:False 347:False 348:False 349:False 350:False 351:False 352:False 353:False 354:False 355:False 356:False 357:False 358:False 359:False 360:False 361:False 362:False 363:False 364:False 365:False 366:False 367:False 368:False 369:False 370:False 371:False 372:False 373:False 374:False 375:False 376:False 377:False 378:False 379:False 380:False 381:False 382:False\n",
      "INFO:tensorflow:input_ids: 101 1327 1132 1103 13004 1104 1103 9505 136 102 2137 1125 1429 119 5046 1904 117 3453 119 1695 1904 117 1695 119 1626 1904 117 1105 1542 1904 1750 1104 2805 1159 117 3569 119 4246 150 4538 117 3084 2393 119 164 3140 166 3402 1103 7300 13950 1104 153 21678 2137 1114 152 22074 117 1105 1152 1276 1103 2805 1159 1107 1292 1160 2114 1108 4389 119 121 212 1492 119 121 1904 1105 3324 119 127 212 1743 119 128 1904 117 3569 113 153 133 121 119 3135 1475 114 119 27762 162 117 3084 2393 119 164 2532 166 14758 1103 1210 10298 1193 19849 8340 13467 8015 113 153 21678 2137 117 26574 1708 118 157 2162 15499 117 1105 22157 2137 114 1111 1231 21754 1123 5813 2116 117 1105 1103 1928 2805 1159 1206 1172 1108 3453 119 121 212 1955 119 4376 1904 117 17350 119 4335 212 3383 119 5004 1904 117 1105 4859 119 1512 212 3746 119 2539 1904 117 3569 119 153 21678 2137 1125 170 5409 1750 2805 1159 1190 26574 1708 118 157 2162 15499 117 1133 170 12763 2805 1159 1114 22157 2137 119 1109 8458 13950 1127 14758 1118 1103 19497 1708 7432 1111 1171 2489 1105 3420 2489 119 3458 2686 3228 1115 4420 5165 1114 153 21678 2137 1125 12763 2112 19807 1891 19497 1708 7432 1111 1171 2489 1105 3420 2489 1114 1343 5165 1114 1168 12814 3377 119 3458 1871 1108 1107 8080 1114 1103 2166 9505 119 164 1851 117 3882 117 4335 166 27762 162 117 3084 2393 164 4335 166 2103 1115 1103 3073 19807 5838 19497 1708 7432 1111 1171 2489 1105 3420 2489 1127 126 119 5385 212 122 119 1572 1105 128 119 4991 212 122 119 4775 1107 1103 26574 1708 118 157 2162 15499 1372 117 126 119 5556 212 122 119 3081 1105 128 119 1492 212 122 119 4925 3569 1107 1103 153 21678 2137 1372 113 153 134 119 5385 1604 114 119 164 4335 166 1335 1103 2812 118 1146 9355 1104 1367 1808 117 1103 19497 1708 7432 5409 3549 1107 1103 1160 2114 1112 3402 1114 3073 19807 5838 4718 119 1438 117 1175 1108 102\n",
      "I1208 12:27:37.206910 139883775852736 run_factoid.py:449] input_ids: 101 1327 1132 1103 13004 1104 1103 9505 136 102 2137 1125 1429 119 5046 1904 117 3453 119 1695 1904 117 1695 119 1626 1904 117 1105 1542 1904 1750 1104 2805 1159 117 3569 119 4246 150 4538 117 3084 2393 119 164 3140 166 3402 1103 7300 13950 1104 153 21678 2137 1114 152 22074 117 1105 1152 1276 1103 2805 1159 1107 1292 1160 2114 1108 4389 119 121 212 1492 119 121 1904 1105 3324 119 127 212 1743 119 128 1904 117 3569 113 153 133 121 119 3135 1475 114 119 27762 162 117 3084 2393 119 164 2532 166 14758 1103 1210 10298 1193 19849 8340 13467 8015 113 153 21678 2137 117 26574 1708 118 157 2162 15499 117 1105 22157 2137 114 1111 1231 21754 1123 5813 2116 117 1105 1103 1928 2805 1159 1206 1172 1108 3453 119 121 212 1955 119 4376 1904 117 17350 119 4335 212 3383 119 5004 1904 117 1105 4859 119 1512 212 3746 119 2539 1904 117 3569 119 153 21678 2137 1125 170 5409 1750 2805 1159 1190 26574 1708 118 157 2162 15499 117 1133 170 12763 2805 1159 1114 22157 2137 119 1109 8458 13950 1127 14758 1118 1103 19497 1708 7432 1111 1171 2489 1105 3420 2489 119 3458 2686 3228 1115 4420 5165 1114 153 21678 2137 1125 12763 2112 19807 1891 19497 1708 7432 1111 1171 2489 1105 3420 2489 1114 1343 5165 1114 1168 12814 3377 119 3458 1871 1108 1107 8080 1114 1103 2166 9505 119 164 1851 117 3882 117 4335 166 27762 162 117 3084 2393 164 4335 166 2103 1115 1103 3073 19807 5838 19497 1708 7432 1111 1171 2489 1105 3420 2489 1127 126 119 5385 212 122 119 1572 1105 128 119 4991 212 122 119 4775 1107 1103 26574 1708 118 157 2162 15499 1372 117 126 119 5556 212 122 119 3081 1105 128 119 1492 212 122 119 4925 3569 1107 1103 153 21678 2137 1372 113 153 134 119 5385 1604 114 119 164 4335 166 1335 1103 2812 118 1146 9355 1104 1367 1808 117 1103 19497 1708 7432 5409 3549 1107 1103 1160 2114 1112 3402 1114 3073 19807 5838 4718 119 1438 117 1175 1108 102\n",
      "INFO:tensorflow:input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      "I1208 12:27:37.207001 139883775852736 run_factoid.py:451] input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      "INFO:tensorflow:segment_ids: 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      "I1208 12:27:37.207090 139883775852736 run_factoid.py:453] segment_ids: 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      "INFO:tensorflow:*** Example ***\n",
      "I1208 12:27:37.208935 139883775852736 run_factoid.py:438] *** Example ***\n",
      "INFO:tensorflow:unique_id: 1000000063\n",
      "I1208 12:27:37.208995 139883775852736 run_factoid.py:439] unique_id: 1000000063\n",
      "INFO:tensorflow:example_index: 9\n",
      "I1208 12:27:37.209032 139883775852736 run_factoid.py:440] example_index: 9\n",
      "INFO:tensorflow:doc_span_index: 10\n",
      "I1208 12:27:37.209067 139883775852736 run_factoid.py:441] doc_span_index: 10\n",
      "INFO:tensorflow:tokens: [CLS] What are the limitations of the findings ? [SEP] , and the mean operation time between them was 75 . 0 ± 31 . 56 minutes , 146 . 54 ± 38 . 07 minutes , and 85 . 25 ± 41 . 60 minutes , respectively . P ##EL ##D had a significantly less operation time than MI ##S - T ##L ##IF , but a comparable operation time with ME ##D . The functional outcomes were assessed by the VA ##S scores for back pain and leg pain . Our results suggested that patients treated with P ##EL ##D had comparable post ##oper ##ation VA ##S scores for back pain and leg pain with those treated with other surge ##ries . Our result was in consistent with the previous findings . [ 50 , 52 , 54 ] Yao Y , et al [ 54 ] reported that the pre ##oper ##ative VA ##S scores for back pain and leg pain were 5 . 88 ± 1 . 24 and 7 . 05 ± 1 . 08 in the MI ##S - T ##L ##IF group , 5 . 92 ± 1 . 33 and 7 . 13 ± 1 . 09 respectively in the P ##EL ##D group ( P = . 88 ##8 ) . [ 54 ] At the follow - up duration of 12 months , the VA ##S scores significantly reduced in the two groups as compared with pre ##oper ##ative values . However , there was no significant differences between the them in the post ##oper ##ation VA ##S scores for back pain and leg pain . [ 54 ] The authors attributed the results to the relatively larger injury of soft tissue and disruption of spinal stability , which were caused by the inter ##body fusion than disc ##ec ##tom ##y . [ 54 ] There were several potential limitations in this meta - analysis . First , for some outcomes , the data analysis was based on relatively small number of included studies and sample size ; thus , the conclusions about the outcomes should be interpreted with caution . Second , most of the included studies were retrospective co ##hor ##t study , and the grade evidence was inferior to that [SEP]\n",
      "I1208 12:27:37.209180 139883775852736 run_factoid.py:443] tokens: [CLS] What are the limitations of the findings ? [SEP] , and the mean operation time between them was 75 . 0 ± 31 . 56 minutes , 146 . 54 ± 38 . 07 minutes , and 85 . 25 ± 41 . 60 minutes , respectively . P ##EL ##D had a significantly less operation time than MI ##S - T ##L ##IF , but a comparable operation time with ME ##D . The functional outcomes were assessed by the VA ##S scores for back pain and leg pain . Our results suggested that patients treated with P ##EL ##D had comparable post ##oper ##ation VA ##S scores for back pain and leg pain with those treated with other surge ##ries . Our result was in consistent with the previous findings . [ 50 , 52 , 54 ] Yao Y , et al [ 54 ] reported that the pre ##oper ##ative VA ##S scores for back pain and leg pain were 5 . 88 ± 1 . 24 and 7 . 05 ± 1 . 08 in the MI ##S - T ##L ##IF group , 5 . 92 ± 1 . 33 and 7 . 13 ± 1 . 09 respectively in the P ##EL ##D group ( P = . 88 ##8 ) . [ 54 ] At the follow - up duration of 12 months , the VA ##S scores significantly reduced in the two groups as compared with pre ##oper ##ative values . However , there was no significant differences between the them in the post ##oper ##ation VA ##S scores for back pain and leg pain . [ 54 ] The authors attributed the results to the relatively larger injury of soft tissue and disruption of spinal stability , which were caused by the inter ##body fusion than disc ##ec ##tom ##y . [ 54 ] There were several potential limitations in this meta - analysis . First , for some outcomes , the data analysis was based on relatively small number of included studies and sample size ; thus , the conclusions about the outcomes should be interpreted with caution . Second , most of the included studies were retrospective co ##hor ##t study , and the grade evidence was inferior to that [SEP]\n",
      "INFO:tensorflow:token_to_orig_map: 10:761 11:762 12:763 13:764 14:765 15:766 16:767 17:768 18:769 19:770 20:770 21:770 22:771 23:772 24:772 25:772 26:773 27:773 28:774 29:774 30:774 31:775 32:776 33:776 34:776 35:777 36:777 37:778 38:779 39:779 40:779 41:780 42:781 43:781 44:781 45:782 46:782 47:783 48:783 49:784 50:784 51:784 52:785 53:786 54:787 55:788 56:789 57:790 58:791 59:792 60:792 61:792 62:792 63:792 64:792 65:792 66:793 67:794 68:795 69:796 70:797 71:798 72:799 73:799 74:799 75:800 76:801 77:802 78:803 79:804 80:805 81:806 82:807 83:807 84:808 85:809 86:810 87:811 88:812 89:813 90:814 91:814 92:815 93:816 94:817 95:818 96:819 97:820 98:821 99:822 100:822 101:822 102:823 103:824 104:825 105:825 106:825 107:826 108:826 109:827 110:828 111:829 112:830 113:831 114:832 115:833 116:834 117:835 118:836 119:837 120:838 121:839 122:839 123:839 124:840 125:841 126:842 127:843 128:844 129:845 130:846 131:847 132:848 133:848 134:848 135:848 136:848 137:848 138:848 139:848 140:848 141:849 142:850 143:850 144:851 145:852 146:852 147:852 148:852 149:853 150:854 151:855 152:856 153:856 154:856 155:857 156:857 157:858 158:859 159:860 160:861 161:862 162:863 163:864 164:865 165:866 166:866 167:866 168:867 169:868 170:868 171:868 172:869 173:870 174:870 175:870 176:871 177:872 178:872 179:872 180:873 181:874 182:875 183:875 184:875 185:876 186:876 187:876 188:877 189:877 190:878 191:878 192:878 193:879 194:880 195:880 196:880 197:881 198:882 199:882 200:882 201:883 202:884 203:884 204:884 205:885 206:886 207:887 208:888 209:888 210:888 211:889 212:890 213:890 214:891 215:892 216:892 217:892 218:892 219:892 220:892 221:892 222:892 223:893 224:894 225:895 226:895 227:895 228:896 229:897 230:898 231:899 232:899 233:900 234:901 235:901 236:902 237:903 238:904 239:905 240:906 241:907 242:908 243:909 244:910 245:911 246:912 247:912 248:912 249:913 250:913 251:914 252:914 253:915 254:916 255:917 256:918 257:919 258:920 259:921 260:922 261:923 262:924 263:925 264:925 265:925 266:926 267:926 268:927 269:928 270:929 271:930 272:931 273:932 274:933 275:933 276:933 277:933 278:933 279:934 280:935 281:936 282:937 283:938 284:939 285:940 286:941 287:942 288:943 289:944 290:945 291:946 292:947 293:948 294:949 295:950 296:951 297:951 298:952 299:953 300:954 301:955 302:956 303:957 304:957 305:958 306:959 307:960 308:960 309:960 310:960 311:960 312:960 313:960 314:960 315:961 316:962 317:963 318:964 319:965 320:966 321:967 322:968 323:968 324:968 325:968 326:969 327:969 328:970 329:971 330:972 331:972 332:973 333:974 334:975 335:976 336:977 337:978 338:979 339:980 340:981 341:982 342:983 343:984 344:985 345:986 346:987 347:987 348:988 349:988 350:989 351:990 352:991 353:992 354:993 355:994 356:995 357:996 358:997 359:998 360:998 361:999 362:999 363:1000 364:1001 365:1002 366:1003 367:1004 368:1005 369:1006 370:1007 371:1007 372:1007 373:1008 374:1008 375:1009 376:1010 377:1011 378:1012 379:1013 380:1014 381:1015 382:1016\n",
      "I1208 12:27:37.209300 139883775852736 run_factoid.py:445] token_to_orig_map: 10:761 11:762 12:763 13:764 14:765 15:766 16:767 17:768 18:769 19:770 20:770 21:770 22:771 23:772 24:772 25:772 26:773 27:773 28:774 29:774 30:774 31:775 32:776 33:776 34:776 35:777 36:777 37:778 38:779 39:779 40:779 41:780 42:781 43:781 44:781 45:782 46:782 47:783 48:783 49:784 50:784 51:784 52:785 53:786 54:787 55:788 56:789 57:790 58:791 59:792 60:792 61:792 62:792 63:792 64:792 65:792 66:793 67:794 68:795 69:796 70:797 71:798 72:799 73:799 74:799 75:800 76:801 77:802 78:803 79:804 80:805 81:806 82:807 83:807 84:808 85:809 86:810 87:811 88:812 89:813 90:814 91:814 92:815 93:816 94:817 95:818 96:819 97:820 98:821 99:822 100:822 101:822 102:823 103:824 104:825 105:825 106:825 107:826 108:826 109:827 110:828 111:829 112:830 113:831 114:832 115:833 116:834 117:835 118:836 119:837 120:838 121:839 122:839 123:839 124:840 125:841 126:842 127:843 128:844 129:845 130:846 131:847 132:848 133:848 134:848 135:848 136:848 137:848 138:848 139:848 140:848 141:849 142:850 143:850 144:851 145:852 146:852 147:852 148:852 149:853 150:854 151:855 152:856 153:856 154:856 155:857 156:857 157:858 158:859 159:860 160:861 161:862 162:863 163:864 164:865 165:866 166:866 167:866 168:867 169:868 170:868 171:868 172:869 173:870 174:870 175:870 176:871 177:872 178:872 179:872 180:873 181:874 182:875 183:875 184:875 185:876 186:876 187:876 188:877 189:877 190:878 191:878 192:878 193:879 194:880 195:880 196:880 197:881 198:882 199:882 200:882 201:883 202:884 203:884 204:884 205:885 206:886 207:887 208:888 209:888 210:888 211:889 212:890 213:890 214:891 215:892 216:892 217:892 218:892 219:892 220:892 221:892 222:892 223:893 224:894 225:895 226:895 227:895 228:896 229:897 230:898 231:899 232:899 233:900 234:901 235:901 236:902 237:903 238:904 239:905 240:906 241:907 242:908 243:909 244:910 245:911 246:912 247:912 248:912 249:913 250:913 251:914 252:914 253:915 254:916 255:917 256:918 257:919 258:920 259:921 260:922 261:923 262:924 263:925 264:925 265:925 266:926 267:926 268:927 269:928 270:929 271:930 272:931 273:932 274:933 275:933 276:933 277:933 278:933 279:934 280:935 281:936 282:937 283:938 284:939 285:940 286:941 287:942 288:943 289:944 290:945 291:946 292:947 293:948 294:949 295:950 296:951 297:951 298:952 299:953 300:954 301:955 302:956 303:957 304:957 305:958 306:959 307:960 308:960 309:960 310:960 311:960 312:960 313:960 314:960 315:961 316:962 317:963 318:964 319:965 320:966 321:967 322:968 323:968 324:968 325:968 326:969 327:969 328:970 329:971 330:972 331:972 332:973 333:974 334:975 335:976 336:977 337:978 338:979 339:980 340:981 341:982 342:983 343:984 344:985 345:986 346:987 347:987 348:988 349:988 350:989 351:990 352:991 353:992 354:993 355:994 356:995 357:996 358:997 359:998 360:998 361:999 362:999 363:1000 364:1001 365:1002 366:1003 367:1004 368:1005 369:1006 370:1007 371:1007 372:1007 373:1008 374:1008 375:1009 376:1010 377:1011 378:1012 379:1013 380:1014 381:1015 382:1016\n",
      "INFO:tensorflow:token_is_max_context: 10:False 11:False 12:False 13:False 14:False 15:False 16:False 17:False 18:False 19:False 20:False 21:False 22:False 23:False 24:False 25:False 26:False 27:False 28:False 29:False 30:False 31:False 32:False 33:False 34:False 35:False 36:False 37:False 38:False 39:False 40:False 41:False 42:False 43:False 44:False 45:False 46:False 47:False 48:False 49:False 50:False 51:False 52:False 53:False 54:False 55:False 56:False 57:False 58:False 59:False 60:False 61:False 62:False 63:False 64:False 65:False 66:False 67:False 68:False 69:False 70:False 71:False 72:False 73:False 74:False 75:False 76:False 77:False 78:False 79:False 80:False 81:False 82:False 83:False 84:False 85:False 86:False 87:False 88:False 89:False 90:False 91:False 92:False 93:False 94:False 95:False 96:False 97:False 98:False 99:False 100:False 101:False 102:False 103:False 104:False 105:False 106:False 107:False 108:False 109:False 110:False 111:False 112:False 113:False 114:False 115:False 116:False 117:False 118:False 119:False 120:False 121:False 122:False 123:False 124:False 125:False 126:False 127:False 128:False 129:False 130:False 131:False 132:False 133:True 134:True 135:True 136:True 137:True 138:True 139:True 140:True 141:True 142:True 143:True 144:True 145:True 146:True 147:True 148:True 149:True 150:True 151:True 152:True 153:True 154:True 155:True 156:True 157:True 158:True 159:True 160:True 161:True 162:True 163:True 164:True 165:True 166:True 167:True 168:True 169:True 170:True 171:True 172:True 173:True 174:True 175:True 176:True 177:True 178:True 179:True 180:True 181:True 182:True 183:True 184:True 185:True 186:True 187:True 188:True 189:True 190:True 191:True 192:True 193:True 194:True 195:True 196:True 197:True 198:True 199:True 200:True 201:True 202:True 203:True 204:True 205:True 206:True 207:True 208:True 209:True 210:True 211:True 212:True 213:True 214:True 215:True 216:True 217:True 218:True 219:True 220:True 221:True 222:True 223:True 224:True 225:True 226:True 227:True 228:True 229:True 230:True 231:True 232:True 233:True 234:True 235:True 236:True 237:True 238:True 239:True 240:True 241:True 242:True 243:True 244:True 245:True 246:True 247:True 248:True 249:True 250:True 251:True 252:True 253:True 254:True 255:True 256:True 257:True 258:True 259:True 260:True 261:False 262:False 263:False 264:False 265:False 266:False 267:False 268:False 269:False 270:False 271:False 272:False 273:False 274:False 275:False 276:False 277:False 278:False 279:False 280:False 281:False 282:False 283:False 284:False 285:False 286:False 287:False 288:False 289:False 290:False 291:False 292:False 293:False 294:False 295:False 296:False 297:False 298:False 299:False 300:False 301:False 302:False 303:False 304:False 305:False 306:False 307:False 308:False 309:False 310:False 311:False 312:False 313:False 314:False 315:False 316:False 317:False 318:False 319:False 320:False 321:False 322:False 323:False 324:False 325:False 326:False 327:False 328:False 329:False 330:False 331:False 332:False 333:False 334:False 335:False 336:False 337:False 338:False 339:False 340:False 341:False 342:False 343:False 344:False 345:False 346:False 347:False 348:False 349:False 350:False 351:False 352:False 353:False 354:False 355:False 356:False 357:False 358:False 359:False 360:False 361:False 362:False 363:False 364:False 365:False 366:False 367:False 368:False 369:False 370:False 371:False 372:False 373:False 374:False 375:False 376:False 377:False 378:False 379:False 380:False 381:False 382:False\n",
      "I1208 12:27:37.209411 139883775852736 run_factoid.py:447] token_is_max_context: 10:False 11:False 12:False 13:False 14:False 15:False 16:False 17:False 18:False 19:False 20:False 21:False 22:False 23:False 24:False 25:False 26:False 27:False 28:False 29:False 30:False 31:False 32:False 33:False 34:False 35:False 36:False 37:False 38:False 39:False 40:False 41:False 42:False 43:False 44:False 45:False 46:False 47:False 48:False 49:False 50:False 51:False 52:False 53:False 54:False 55:False 56:False 57:False 58:False 59:False 60:False 61:False 62:False 63:False 64:False 65:False 66:False 67:False 68:False 69:False 70:False 71:False 72:False 73:False 74:False 75:False 76:False 77:False 78:False 79:False 80:False 81:False 82:False 83:False 84:False 85:False 86:False 87:False 88:False 89:False 90:False 91:False 92:False 93:False 94:False 95:False 96:False 97:False 98:False 99:False 100:False 101:False 102:False 103:False 104:False 105:False 106:False 107:False 108:False 109:False 110:False 111:False 112:False 113:False 114:False 115:False 116:False 117:False 118:False 119:False 120:False 121:False 122:False 123:False 124:False 125:False 126:False 127:False 128:False 129:False 130:False 131:False 132:False 133:True 134:True 135:True 136:True 137:True 138:True 139:True 140:True 141:True 142:True 143:True 144:True 145:True 146:True 147:True 148:True 149:True 150:True 151:True 152:True 153:True 154:True 155:True 156:True 157:True 158:True 159:True 160:True 161:True 162:True 163:True 164:True 165:True 166:True 167:True 168:True 169:True 170:True 171:True 172:True 173:True 174:True 175:True 176:True 177:True 178:True 179:True 180:True 181:True 182:True 183:True 184:True 185:True 186:True 187:True 188:True 189:True 190:True 191:True 192:True 193:True 194:True 195:True 196:True 197:True 198:True 199:True 200:True 201:True 202:True 203:True 204:True 205:True 206:True 207:True 208:True 209:True 210:True 211:True 212:True 213:True 214:True 215:True 216:True 217:True 218:True 219:True 220:True 221:True 222:True 223:True 224:True 225:True 226:True 227:True 228:True 229:True 230:True 231:True 232:True 233:True 234:True 235:True 236:True 237:True 238:True 239:True 240:True 241:True 242:True 243:True 244:True 245:True 246:True 247:True 248:True 249:True 250:True 251:True 252:True 253:True 254:True 255:True 256:True 257:True 258:True 259:True 260:True 261:False 262:False 263:False 264:False 265:False 266:False 267:False 268:False 269:False 270:False 271:False 272:False 273:False 274:False 275:False 276:False 277:False 278:False 279:False 280:False 281:False 282:False 283:False 284:False 285:False 286:False 287:False 288:False 289:False 290:False 291:False 292:False 293:False 294:False 295:False 296:False 297:False 298:False 299:False 300:False 301:False 302:False 303:False 304:False 305:False 306:False 307:False 308:False 309:False 310:False 311:False 312:False 313:False 314:False 315:False 316:False 317:False 318:False 319:False 320:False 321:False 322:False 323:False 324:False 325:False 326:False 327:False 328:False 329:False 330:False 331:False 332:False 333:False 334:False 335:False 336:False 337:False 338:False 339:False 340:False 341:False 342:False 343:False 344:False 345:False 346:False 347:False 348:False 349:False 350:False 351:False 352:False 353:False 354:False 355:False 356:False 357:False 358:False 359:False 360:False 361:False 362:False 363:False 364:False 365:False 366:False 367:False 368:False 369:False 370:False 371:False 372:False 373:False 374:False 375:False 376:False 377:False 378:False 379:False 380:False 381:False 382:False\n",
      "INFO:tensorflow:input_ids: 101 1327 1132 1103 13004 1104 1103 9505 136 102 117 1105 1103 1928 2805 1159 1206 1172 1108 3453 119 121 212 1955 119 4376 1904 117 17350 119 4335 212 3383 119 5004 1904 117 1105 4859 119 1512 212 3746 119 2539 1904 117 3569 119 153 21678 2137 1125 170 5409 1750 2805 1159 1190 26574 1708 118 157 2162 15499 117 1133 170 12763 2805 1159 1114 22157 2137 119 1109 8458 13950 1127 14758 1118 1103 19497 1708 7432 1111 1171 2489 1105 3420 2489 119 3458 2686 3228 1115 4420 5165 1114 153 21678 2137 1125 12763 2112 19807 1891 19497 1708 7432 1111 1171 2489 1105 3420 2489 1114 1343 5165 1114 1168 12814 3377 119 3458 1871 1108 1107 8080 1114 1103 2166 9505 119 164 1851 117 3882 117 4335 166 27762 162 117 3084 2393 164 4335 166 2103 1115 1103 3073 19807 5838 19497 1708 7432 1111 1171 2489 1105 3420 2489 1127 126 119 5385 212 122 119 1572 1105 128 119 4991 212 122 119 4775 1107 1103 26574 1708 118 157 2162 15499 1372 117 126 119 5556 212 122 119 3081 1105 128 119 1492 212 122 119 4925 3569 1107 1103 153 21678 2137 1372 113 153 134 119 5385 1604 114 119 164 4335 166 1335 1103 2812 118 1146 9355 1104 1367 1808 117 1103 19497 1708 7432 5409 3549 1107 1103 1160 2114 1112 3402 1114 3073 19807 5838 4718 119 1438 117 1175 1108 1185 2418 5408 1206 1103 1172 1107 1103 2112 19807 1891 19497 1708 7432 1111 1171 2489 1105 3420 2489 119 164 4335 166 1109 5752 6547 1103 2686 1106 1103 3860 2610 3773 1104 2991 7918 1105 23730 1104 19245 9397 117 1134 1127 2416 1118 1103 9455 14637 11970 1190 6187 10294 18778 1183 119 164 4335 166 1247 1127 1317 3209 13004 1107 1142 27154 118 3622 119 1752 117 1111 1199 13950 117 1103 2233 3622 1108 1359 1113 3860 1353 1295 1104 1529 2527 1105 6876 2060 132 2456 117 1103 16421 1164 1103 13950 1431 1129 9829 1114 15597 119 2307 117 1211 1104 1103 1529 2527 1127 18675 1884 13252 1204 2025 117 1105 1103 3654 2554 1108 15543 1106 1115 102\n",
      "I1208 12:27:37.209512 139883775852736 run_factoid.py:449] input_ids: 101 1327 1132 1103 13004 1104 1103 9505 136 102 117 1105 1103 1928 2805 1159 1206 1172 1108 3453 119 121 212 1955 119 4376 1904 117 17350 119 4335 212 3383 119 5004 1904 117 1105 4859 119 1512 212 3746 119 2539 1904 117 3569 119 153 21678 2137 1125 170 5409 1750 2805 1159 1190 26574 1708 118 157 2162 15499 117 1133 170 12763 2805 1159 1114 22157 2137 119 1109 8458 13950 1127 14758 1118 1103 19497 1708 7432 1111 1171 2489 1105 3420 2489 119 3458 2686 3228 1115 4420 5165 1114 153 21678 2137 1125 12763 2112 19807 1891 19497 1708 7432 1111 1171 2489 1105 3420 2489 1114 1343 5165 1114 1168 12814 3377 119 3458 1871 1108 1107 8080 1114 1103 2166 9505 119 164 1851 117 3882 117 4335 166 27762 162 117 3084 2393 164 4335 166 2103 1115 1103 3073 19807 5838 19497 1708 7432 1111 1171 2489 1105 3420 2489 1127 126 119 5385 212 122 119 1572 1105 128 119 4991 212 122 119 4775 1107 1103 26574 1708 118 157 2162 15499 1372 117 126 119 5556 212 122 119 3081 1105 128 119 1492 212 122 119 4925 3569 1107 1103 153 21678 2137 1372 113 153 134 119 5385 1604 114 119 164 4335 166 1335 1103 2812 118 1146 9355 1104 1367 1808 117 1103 19497 1708 7432 5409 3549 1107 1103 1160 2114 1112 3402 1114 3073 19807 5838 4718 119 1438 117 1175 1108 1185 2418 5408 1206 1103 1172 1107 1103 2112 19807 1891 19497 1708 7432 1111 1171 2489 1105 3420 2489 119 164 4335 166 1109 5752 6547 1103 2686 1106 1103 3860 2610 3773 1104 2991 7918 1105 23730 1104 19245 9397 117 1134 1127 2416 1118 1103 9455 14637 11970 1190 6187 10294 18778 1183 119 164 4335 166 1247 1127 1317 3209 13004 1107 1142 27154 118 3622 119 1752 117 1111 1199 13950 117 1103 2233 3622 1108 1359 1113 3860 1353 1295 1104 1529 2527 1105 6876 2060 132 2456 117 1103 16421 1164 1103 13950 1431 1129 9829 1114 15597 119 2307 117 1211 1104 1103 1529 2527 1127 18675 1884 13252 1204 2025 117 1105 1103 3654 2554 1108 15543 1106 1115 102\n",
      "INFO:tensorflow:input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      "I1208 12:27:37.209603 139883775852736 run_factoid.py:451] input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      "INFO:tensorflow:segment_ids: 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      "I1208 12:27:37.209693 139883775852736 run_factoid.py:453] segment_ids: 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      "INFO:tensorflow:*** Example ***\n",
      "I1208 12:27:37.211516 139883775852736 run_factoid.py:438] *** Example ***\n",
      "INFO:tensorflow:unique_id: 1000000064\n",
      "I1208 12:27:37.211576 139883775852736 run_factoid.py:439] unique_id: 1000000064\n",
      "INFO:tensorflow:example_index: 9\n",
      "I1208 12:27:37.211614 139883775852736 run_factoid.py:440] example_index: 9\n",
      "INFO:tensorflow:doc_span_index: 11\n",
      "I1208 12:27:37.211648 139883775852736 run_factoid.py:441] doc_span_index: 11\n",
      "INFO:tensorflow:tokens: [CLS] What are the limitations of the findings ? [SEP] , 54 ] Yao Y , et al [ 54 ] reported that the pre ##oper ##ative VA ##S scores for back pain and leg pain were 5 . 88 ± 1 . 24 and 7 . 05 ± 1 . 08 in the MI ##S - T ##L ##IF group , 5 . 92 ± 1 . 33 and 7 . 13 ± 1 . 09 respectively in the P ##EL ##D group ( P = . 88 ##8 ) . [ 54 ] At the follow - up duration of 12 months , the VA ##S scores significantly reduced in the two groups as compared with pre ##oper ##ative values . However , there was no significant differences between the them in the post ##oper ##ation VA ##S scores for back pain and leg pain . [ 54 ] The authors attributed the results to the relatively larger injury of soft tissue and disruption of spinal stability , which were caused by the inter ##body fusion than disc ##ec ##tom ##y . [ 54 ] There were several potential limitations in this meta - analysis . First , for some outcomes , the data analysis was based on relatively small number of included studies and sample size ; thus , the conclusions about the outcomes should be interpreted with caution . Second , most of the included studies were retrospective co ##hor ##t study , and the grade evidence was inferior to that of RC ##T ##s . Third , despite we performed sensitivity analysis and subgroup analysis to explore the der ##ivation of he ##tero ##gene ##ity , no valuable information was found . We thought that some potential reasons may account for the great he ##tero ##gene ##ity , including patients ’ characteristics ( age , sex , B ##MI , type of disc her ##nia ##tion , and surgical segment ) , duration of follow - up , case definition , and surgical approaches . These factors may have an impact on our results . thus , considering these limitations , caution is advised when interpret ##ing our findings and applying them into the clinical practice . In conclusion , the present meta - analysis of 14 studies [SEP]\n",
      "I1208 12:27:37.211769 139883775852736 run_factoid.py:443] tokens: [CLS] What are the limitations of the findings ? [SEP] , 54 ] Yao Y , et al [ 54 ] reported that the pre ##oper ##ative VA ##S scores for back pain and leg pain were 5 . 88 ± 1 . 24 and 7 . 05 ± 1 . 08 in the MI ##S - T ##L ##IF group , 5 . 92 ± 1 . 33 and 7 . 13 ± 1 . 09 respectively in the P ##EL ##D group ( P = . 88 ##8 ) . [ 54 ] At the follow - up duration of 12 months , the VA ##S scores significantly reduced in the two groups as compared with pre ##oper ##ative values . However , there was no significant differences between the them in the post ##oper ##ation VA ##S scores for back pain and leg pain . [ 54 ] The authors attributed the results to the relatively larger injury of soft tissue and disruption of spinal stability , which were caused by the inter ##body fusion than disc ##ec ##tom ##y . [ 54 ] There were several potential limitations in this meta - analysis . First , for some outcomes , the data analysis was based on relatively small number of included studies and sample size ; thus , the conclusions about the outcomes should be interpreted with caution . Second , most of the included studies were retrospective co ##hor ##t study , and the grade evidence was inferior to that of RC ##T ##s . Third , despite we performed sensitivity analysis and subgroup analysis to explore the der ##ivation of he ##tero ##gene ##ity , no valuable information was found . We thought that some potential reasons may account for the great he ##tero ##gene ##ity , including patients ’ characteristics ( age , sex , B ##MI , type of disc her ##nia ##tion , and surgical segment ) , duration of follow - up , case definition , and surgical approaches . These factors may have an impact on our results . thus , considering these limitations , caution is advised when interpret ##ing our findings and applying them into the clinical practice . In conclusion , the present meta - analysis of 14 studies [SEP]\n",
      "INFO:tensorflow:token_to_orig_map: 10:848 11:848 12:848 13:849 14:850 15:850 16:851 17:852 18:852 19:852 20:852 21:853 22:854 23:855 24:856 25:856 26:856 27:857 28:857 29:858 30:859 31:860 32:861 33:862 34:863 35:864 36:865 37:866 38:866 39:866 40:867 41:868 42:868 43:868 44:869 45:870 46:870 47:870 48:871 49:872 50:872 51:872 52:873 53:874 54:875 55:875 56:875 57:876 58:876 59:876 60:877 61:877 62:878 63:878 64:878 65:879 66:880 67:880 68:880 69:881 70:882 71:882 72:882 73:883 74:884 75:884 76:884 77:885 78:886 79:887 80:888 81:888 82:888 83:889 84:890 85:890 86:891 87:892 88:892 89:892 90:892 91:892 92:892 93:892 94:892 95:893 96:894 97:895 98:895 99:895 100:896 101:897 102:898 103:899 104:899 105:900 106:901 107:901 108:902 109:903 110:904 111:905 112:906 113:907 114:908 115:909 116:910 117:911 118:912 119:912 120:912 121:913 122:913 123:914 124:914 125:915 126:916 127:917 128:918 129:919 130:920 131:921 132:922 133:923 134:924 135:925 136:925 137:925 138:926 139:926 140:927 141:928 142:929 143:930 144:931 145:932 146:933 147:933 148:933 149:933 150:933 151:934 152:935 153:936 154:937 155:938 156:939 157:940 158:941 159:942 160:943 161:944 162:945 163:946 164:947 165:948 166:949 167:950 168:951 169:951 170:952 171:953 172:954 173:955 174:956 175:957 176:957 177:958 178:959 179:960 180:960 181:960 182:960 183:960 184:960 185:960 186:960 187:961 188:962 189:963 190:964 191:965 192:966 193:967 194:968 195:968 196:968 197:968 198:969 199:969 200:970 201:971 202:972 203:972 204:973 205:974 206:975 207:976 208:977 209:978 210:979 211:980 212:981 213:982 214:983 215:984 216:985 217:986 218:987 219:987 220:988 221:988 222:989 223:990 224:991 225:992 226:993 227:994 228:995 229:996 230:997 231:998 232:998 233:999 234:999 235:1000 236:1001 237:1002 238:1003 239:1004 240:1005 241:1006 242:1007 243:1007 244:1007 245:1008 246:1008 247:1009 248:1010 249:1011 250:1012 251:1013 252:1014 253:1015 254:1016 255:1017 256:1018 257:1018 258:1018 259:1018 260:1019 261:1019 262:1020 263:1021 264:1022 265:1023 266:1024 267:1025 268:1026 269:1027 270:1028 271:1029 272:1030 273:1031 274:1031 275:1032 276:1033 277:1033 278:1033 279:1033 280:1033 281:1034 282:1035 283:1036 284:1037 285:1038 286:1038 287:1039 288:1040 289:1041 290:1042 291:1043 292:1044 293:1045 294:1046 295:1047 296:1048 297:1049 298:1050 299:1050 300:1050 301:1050 302:1050 303:1051 304:1052 305:1052 306:1053 307:1054 308:1054 309:1054 310:1055 311:1055 312:1056 313:1056 314:1056 315:1057 316:1058 317:1059 318:1060 319:1060 320:1060 321:1060 322:1061 323:1062 324:1063 325:1063 326:1063 327:1064 328:1065 329:1066 330:1066 331:1066 332:1066 333:1067 334:1068 335:1068 336:1069 337:1070 338:1071 339:1071 340:1072 341:1073 342:1074 343:1075 344:1076 345:1077 346:1078 347:1079 348:1080 349:1080 350:1081 351:1081 352:1082 353:1083 354:1084 355:1084 356:1085 357:1086 358:1087 359:1088 360:1089 361:1089 362:1090 363:1091 364:1092 365:1093 366:1094 367:1095 368:1096 369:1097 370:1098 371:1098 372:1099 373:1100 374:1100 375:1101 376:1102 377:1103 378:1103 379:1103 380:1104 381:1105 382:1106\n",
      "I1208 12:27:37.211893 139883775852736 run_factoid.py:445] token_to_orig_map: 10:848 11:848 12:848 13:849 14:850 15:850 16:851 17:852 18:852 19:852 20:852 21:853 22:854 23:855 24:856 25:856 26:856 27:857 28:857 29:858 30:859 31:860 32:861 33:862 34:863 35:864 36:865 37:866 38:866 39:866 40:867 41:868 42:868 43:868 44:869 45:870 46:870 47:870 48:871 49:872 50:872 51:872 52:873 53:874 54:875 55:875 56:875 57:876 58:876 59:876 60:877 61:877 62:878 63:878 64:878 65:879 66:880 67:880 68:880 69:881 70:882 71:882 72:882 73:883 74:884 75:884 76:884 77:885 78:886 79:887 80:888 81:888 82:888 83:889 84:890 85:890 86:891 87:892 88:892 89:892 90:892 91:892 92:892 93:892 94:892 95:893 96:894 97:895 98:895 99:895 100:896 101:897 102:898 103:899 104:899 105:900 106:901 107:901 108:902 109:903 110:904 111:905 112:906 113:907 114:908 115:909 116:910 117:911 118:912 119:912 120:912 121:913 122:913 123:914 124:914 125:915 126:916 127:917 128:918 129:919 130:920 131:921 132:922 133:923 134:924 135:925 136:925 137:925 138:926 139:926 140:927 141:928 142:929 143:930 144:931 145:932 146:933 147:933 148:933 149:933 150:933 151:934 152:935 153:936 154:937 155:938 156:939 157:940 158:941 159:942 160:943 161:944 162:945 163:946 164:947 165:948 166:949 167:950 168:951 169:951 170:952 171:953 172:954 173:955 174:956 175:957 176:957 177:958 178:959 179:960 180:960 181:960 182:960 183:960 184:960 185:960 186:960 187:961 188:962 189:963 190:964 191:965 192:966 193:967 194:968 195:968 196:968 197:968 198:969 199:969 200:970 201:971 202:972 203:972 204:973 205:974 206:975 207:976 208:977 209:978 210:979 211:980 212:981 213:982 214:983 215:984 216:985 217:986 218:987 219:987 220:988 221:988 222:989 223:990 224:991 225:992 226:993 227:994 228:995 229:996 230:997 231:998 232:998 233:999 234:999 235:1000 236:1001 237:1002 238:1003 239:1004 240:1005 241:1006 242:1007 243:1007 244:1007 245:1008 246:1008 247:1009 248:1010 249:1011 250:1012 251:1013 252:1014 253:1015 254:1016 255:1017 256:1018 257:1018 258:1018 259:1018 260:1019 261:1019 262:1020 263:1021 264:1022 265:1023 266:1024 267:1025 268:1026 269:1027 270:1028 271:1029 272:1030 273:1031 274:1031 275:1032 276:1033 277:1033 278:1033 279:1033 280:1033 281:1034 282:1035 283:1036 284:1037 285:1038 286:1038 287:1039 288:1040 289:1041 290:1042 291:1043 292:1044 293:1045 294:1046 295:1047 296:1048 297:1049 298:1050 299:1050 300:1050 301:1050 302:1050 303:1051 304:1052 305:1052 306:1053 307:1054 308:1054 309:1054 310:1055 311:1055 312:1056 313:1056 314:1056 315:1057 316:1058 317:1059 318:1060 319:1060 320:1060 321:1060 322:1061 323:1062 324:1063 325:1063 326:1063 327:1064 328:1065 329:1066 330:1066 331:1066 332:1066 333:1067 334:1068 335:1068 336:1069 337:1070 338:1071 339:1071 340:1072 341:1073 342:1074 343:1075 344:1076 345:1077 346:1078 347:1079 348:1080 349:1080 350:1081 351:1081 352:1082 353:1083 354:1084 355:1084 356:1085 357:1086 358:1087 359:1088 360:1089 361:1089 362:1090 363:1091 364:1092 365:1093 366:1094 367:1095 368:1096 369:1097 370:1098 371:1098 372:1099 373:1100 374:1100 375:1101 376:1102 377:1103 378:1103 379:1103 380:1104 381:1105 382:1106\n",
      "INFO:tensorflow:token_is_max_context: 10:False 11:False 12:False 13:False 14:False 15:False 16:False 17:False 18:False 19:False 20:False 21:False 22:False 23:False 24:False 25:False 26:False 27:False 28:False 29:False 30:False 31:False 32:False 33:False 34:False 35:False 36:False 37:False 38:False 39:False 40:False 41:False 42:False 43:False 44:False 45:False 46:False 47:False 48:False 49:False 50:False 51:False 52:False 53:False 54:False 55:False 56:False 57:False 58:False 59:False 60:False 61:False 62:False 63:False 64:False 65:False 66:False 67:False 68:False 69:False 70:False 71:False 72:False 73:False 74:False 75:False 76:False 77:False 78:False 79:False 80:False 81:False 82:False 83:False 84:False 85:False 86:False 87:False 88:False 89:False 90:False 91:False 92:False 93:False 94:False 95:False 96:False 97:False 98:False 99:False 100:False 101:False 102:False 103:False 104:False 105:False 106:False 107:False 108:False 109:False 110:False 111:False 112:False 113:False 114:False 115:False 116:False 117:False 118:False 119:False 120:False 121:False 122:False 123:False 124:False 125:False 126:False 127:False 128:False 129:False 130:False 131:False 132:False 133:True 134:True 135:True 136:True 137:True 138:True 139:True 140:True 141:True 142:True 143:True 144:True 145:True 146:True 147:True 148:True 149:True 150:True 151:True 152:True 153:True 154:True 155:True 156:True 157:True 158:True 159:True 160:True 161:True 162:True 163:True 164:True 165:True 166:True 167:True 168:True 169:True 170:True 171:True 172:True 173:True 174:True 175:True 176:True 177:True 178:True 179:True 180:True 181:True 182:True 183:True 184:True 185:True 186:True 187:True 188:True 189:True 190:True 191:True 192:True 193:True 194:True 195:True 196:True 197:True 198:True 199:True 200:True 201:True 202:True 203:True 204:True 205:True 206:True 207:True 208:True 209:True 210:True 211:True 212:True 213:True 214:True 215:True 216:True 217:True 218:True 219:True 220:True 221:True 222:True 223:True 224:True 225:True 226:True 227:True 228:True 229:True 230:True 231:True 232:True 233:True 234:True 235:True 236:True 237:True 238:True 239:True 240:True 241:True 242:True 243:True 244:True 245:True 246:True 247:True 248:True 249:True 250:True 251:True 252:True 253:True 254:True 255:True 256:True 257:True 258:True 259:True 260:True 261:False 262:False 263:False 264:False 265:False 266:False 267:False 268:False 269:False 270:False 271:False 272:False 273:False 274:False 275:False 276:False 277:False 278:False 279:False 280:False 281:False 282:False 283:False 284:False 285:False 286:False 287:False 288:False 289:False 290:False 291:False 292:False 293:False 294:False 295:False 296:False 297:False 298:False 299:False 300:False 301:False 302:False 303:False 304:False 305:False 306:False 307:False 308:False 309:False 310:False 311:False 312:False 313:False 314:False 315:False 316:False 317:False 318:False 319:False 320:False 321:False 322:False 323:False 324:False 325:False 326:False 327:False 328:False 329:False 330:False 331:False 332:False 333:False 334:False 335:False 336:False 337:False 338:False 339:False 340:False 341:False 342:False 343:False 344:False 345:False 346:False 347:False 348:False 349:False 350:False 351:False 352:False 353:False 354:False 355:False 356:False 357:False 358:False 359:False 360:False 361:False 362:False 363:False 364:False 365:False 366:False 367:False 368:False 369:False 370:False 371:False 372:False 373:False 374:False 375:False 376:False 377:False 378:False 379:False 380:False 381:False 382:False\n",
      "I1208 12:27:37.212001 139883775852736 run_factoid.py:447] token_is_max_context: 10:False 11:False 12:False 13:False 14:False 15:False 16:False 17:False 18:False 19:False 20:False 21:False 22:False 23:False 24:False 25:False 26:False 27:False 28:False 29:False 30:False 31:False 32:False 33:False 34:False 35:False 36:False 37:False 38:False 39:False 40:False 41:False 42:False 43:False 44:False 45:False 46:False 47:False 48:False 49:False 50:False 51:False 52:False 53:False 54:False 55:False 56:False 57:False 58:False 59:False 60:False 61:False 62:False 63:False 64:False 65:False 66:False 67:False 68:False 69:False 70:False 71:False 72:False 73:False 74:False 75:False 76:False 77:False 78:False 79:False 80:False 81:False 82:False 83:False 84:False 85:False 86:False 87:False 88:False 89:False 90:False 91:False 92:False 93:False 94:False 95:False 96:False 97:False 98:False 99:False 100:False 101:False 102:False 103:False 104:False 105:False 106:False 107:False 108:False 109:False 110:False 111:False 112:False 113:False 114:False 115:False 116:False 117:False 118:False 119:False 120:False 121:False 122:False 123:False 124:False 125:False 126:False 127:False 128:False 129:False 130:False 131:False 132:False 133:True 134:True 135:True 136:True 137:True 138:True 139:True 140:True 141:True 142:True 143:True 144:True 145:True 146:True 147:True 148:True 149:True 150:True 151:True 152:True 153:True 154:True 155:True 156:True 157:True 158:True 159:True 160:True 161:True 162:True 163:True 164:True 165:True 166:True 167:True 168:True 169:True 170:True 171:True 172:True 173:True 174:True 175:True 176:True 177:True 178:True 179:True 180:True 181:True 182:True 183:True 184:True 185:True 186:True 187:True 188:True 189:True 190:True 191:True 192:True 193:True 194:True 195:True 196:True 197:True 198:True 199:True 200:True 201:True 202:True 203:True 204:True 205:True 206:True 207:True 208:True 209:True 210:True 211:True 212:True 213:True 214:True 215:True 216:True 217:True 218:True 219:True 220:True 221:True 222:True 223:True 224:True 225:True 226:True 227:True 228:True 229:True 230:True 231:True 232:True 233:True 234:True 235:True 236:True 237:True 238:True 239:True 240:True 241:True 242:True 243:True 244:True 245:True 246:True 247:True 248:True 249:True 250:True 251:True 252:True 253:True 254:True 255:True 256:True 257:True 258:True 259:True 260:True 261:False 262:False 263:False 264:False 265:False 266:False 267:False 268:False 269:False 270:False 271:False 272:False 273:False 274:False 275:False 276:False 277:False 278:False 279:False 280:False 281:False 282:False 283:False 284:False 285:False 286:False 287:False 288:False 289:False 290:False 291:False 292:False 293:False 294:False 295:False 296:False 297:False 298:False 299:False 300:False 301:False 302:False 303:False 304:False 305:False 306:False 307:False 308:False 309:False 310:False 311:False 312:False 313:False 314:False 315:False 316:False 317:False 318:False 319:False 320:False 321:False 322:False 323:False 324:False 325:False 326:False 327:False 328:False 329:False 330:False 331:False 332:False 333:False 334:False 335:False 336:False 337:False 338:False 339:False 340:False 341:False 342:False 343:False 344:False 345:False 346:False 347:False 348:False 349:False 350:False 351:False 352:False 353:False 354:False 355:False 356:False 357:False 358:False 359:False 360:False 361:False 362:False 363:False 364:False 365:False 366:False 367:False 368:False 369:False 370:False 371:False 372:False 373:False 374:False 375:False 376:False 377:False 378:False 379:False 380:False 381:False 382:False\n",
      "INFO:tensorflow:input_ids: 101 1327 1132 1103 13004 1104 1103 9505 136 102 117 4335 166 27762 162 117 3084 2393 164 4335 166 2103 1115 1103 3073 19807 5838 19497 1708 7432 1111 1171 2489 1105 3420 2489 1127 126 119 5385 212 122 119 1572 1105 128 119 4991 212 122 119 4775 1107 1103 26574 1708 118 157 2162 15499 1372 117 126 119 5556 212 122 119 3081 1105 128 119 1492 212 122 119 4925 3569 1107 1103 153 21678 2137 1372 113 153 134 119 5385 1604 114 119 164 4335 166 1335 1103 2812 118 1146 9355 1104 1367 1808 117 1103 19497 1708 7432 5409 3549 1107 1103 1160 2114 1112 3402 1114 3073 19807 5838 4718 119 1438 117 1175 1108 1185 2418 5408 1206 1103 1172 1107 1103 2112 19807 1891 19497 1708 7432 1111 1171 2489 1105 3420 2489 119 164 4335 166 1109 5752 6547 1103 2686 1106 1103 3860 2610 3773 1104 2991 7918 1105 23730 1104 19245 9397 117 1134 1127 2416 1118 1103 9455 14637 11970 1190 6187 10294 18778 1183 119 164 4335 166 1247 1127 1317 3209 13004 1107 1142 27154 118 3622 119 1752 117 1111 1199 13950 117 1103 2233 3622 1108 1359 1113 3860 1353 1295 1104 1529 2527 1105 6876 2060 132 2456 117 1103 16421 1164 1103 13950 1431 1129 9829 1114 15597 119 2307 117 1211 1104 1103 1529 2527 1127 18675 1884 13252 1204 2025 117 1105 1103 3654 2554 1108 15543 1106 1115 1104 25157 1942 1116 119 4180 117 2693 1195 1982 15750 3622 1105 23470 3622 1106 8664 1103 4167 16617 1104 1119 25710 27054 1785 117 1185 7468 1869 1108 1276 119 1284 1354 1115 1199 3209 3672 1336 3300 1111 1103 1632 1119 25710 27054 1785 117 1259 4420 787 5924 113 1425 117 2673 117 139 14038 117 2076 1104 6187 1123 5813 2116 117 1105 13467 6441 114 117 9355 1104 2812 118 1146 117 1692 5754 117 1105 13467 8015 119 1636 5320 1336 1138 1126 3772 1113 1412 2686 119 2456 117 6103 1292 13004 117 15597 1110 9213 1165 19348 1158 1412 9505 1105 11892 1172 1154 1103 7300 2415 119 1130 6593 117 1103 1675 27154 118 3622 1104 1489 2527 102\n",
      "I1208 12:27:37.212102 139883775852736 run_factoid.py:449] input_ids: 101 1327 1132 1103 13004 1104 1103 9505 136 102 117 4335 166 27762 162 117 3084 2393 164 4335 166 2103 1115 1103 3073 19807 5838 19497 1708 7432 1111 1171 2489 1105 3420 2489 1127 126 119 5385 212 122 119 1572 1105 128 119 4991 212 122 119 4775 1107 1103 26574 1708 118 157 2162 15499 1372 117 126 119 5556 212 122 119 3081 1105 128 119 1492 212 122 119 4925 3569 1107 1103 153 21678 2137 1372 113 153 134 119 5385 1604 114 119 164 4335 166 1335 1103 2812 118 1146 9355 1104 1367 1808 117 1103 19497 1708 7432 5409 3549 1107 1103 1160 2114 1112 3402 1114 3073 19807 5838 4718 119 1438 117 1175 1108 1185 2418 5408 1206 1103 1172 1107 1103 2112 19807 1891 19497 1708 7432 1111 1171 2489 1105 3420 2489 119 164 4335 166 1109 5752 6547 1103 2686 1106 1103 3860 2610 3773 1104 2991 7918 1105 23730 1104 19245 9397 117 1134 1127 2416 1118 1103 9455 14637 11970 1190 6187 10294 18778 1183 119 164 4335 166 1247 1127 1317 3209 13004 1107 1142 27154 118 3622 119 1752 117 1111 1199 13950 117 1103 2233 3622 1108 1359 1113 3860 1353 1295 1104 1529 2527 1105 6876 2060 132 2456 117 1103 16421 1164 1103 13950 1431 1129 9829 1114 15597 119 2307 117 1211 1104 1103 1529 2527 1127 18675 1884 13252 1204 2025 117 1105 1103 3654 2554 1108 15543 1106 1115 1104 25157 1942 1116 119 4180 117 2693 1195 1982 15750 3622 1105 23470 3622 1106 8664 1103 4167 16617 1104 1119 25710 27054 1785 117 1185 7468 1869 1108 1276 119 1284 1354 1115 1199 3209 3672 1336 3300 1111 1103 1632 1119 25710 27054 1785 117 1259 4420 787 5924 113 1425 117 2673 117 139 14038 117 2076 1104 6187 1123 5813 2116 117 1105 13467 6441 114 117 9355 1104 2812 118 1146 117 1692 5754 117 1105 13467 8015 119 1636 5320 1336 1138 1126 3772 1113 1412 2686 119 2456 117 6103 1292 13004 117 15597 1110 9213 1165 19348 1158 1412 9505 1105 11892 1172 1154 1103 7300 2415 119 1130 6593 117 1103 1675 27154 118 3622 1104 1489 2527 102\n",
      "INFO:tensorflow:input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      "I1208 12:27:37.212193 139883775852736 run_factoid.py:451] input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      "INFO:tensorflow:segment_ids: 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      "I1208 12:27:37.212282 139883775852736 run_factoid.py:453] segment_ids: 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      "INFO:tensorflow:*** Example ***\n",
      "I1208 12:27:37.213809 139883775852736 run_factoid.py:438] *** Example ***\n",
      "INFO:tensorflow:unique_id: 1000000065\n",
      "I1208 12:27:37.213870 139883775852736 run_factoid.py:439] unique_id: 1000000065\n",
      "INFO:tensorflow:example_index: 9\n",
      "I1208 12:27:37.213906 139883775852736 run_factoid.py:440] example_index: 9\n",
      "INFO:tensorflow:doc_span_index: 12\n",
      "I1208 12:27:37.213940 139883775852736 run_factoid.py:441] doc_span_index: 12\n",
      "INFO:tensorflow:tokens: [CLS] What are the limitations of the findings ? [SEP] VA ##S scores for back pain and leg pain . [ 54 ] The authors attributed the results to the relatively larger injury of soft tissue and disruption of spinal stability , which were caused by the inter ##body fusion than disc ##ec ##tom ##y . [ 54 ] There were several potential limitations in this meta - analysis . First , for some outcomes , the data analysis was based on relatively small number of included studies and sample size ; thus , the conclusions about the outcomes should be interpreted with caution . Second , most of the included studies were retrospective co ##hor ##t study , and the grade evidence was inferior to that of RC ##T ##s . Third , despite we performed sensitivity analysis and subgroup analysis to explore the der ##ivation of he ##tero ##gene ##ity , no valuable information was found . We thought that some potential reasons may account for the great he ##tero ##gene ##ity , including patients ’ characteristics ( age , sex , B ##MI , type of disc her ##nia ##tion , and surgical segment ) , duration of follow - up , case definition , and surgical approaches . These factors may have an impact on our results . thus , considering these limitations , caution is advised when interpret ##ing our findings and applying them into the clinical practice . In conclusion , the present meta - analysis of 14 studies suggested that , P ##EL ##D was associated with better effects and similar complications with other surge ##ries in the treatment of L ##D ##H . However , it also resulted in a higher re ##cu ##rrence rate . Considering the potential limitations in the present study , further large - scale , well - performed random ##ized trials are needed to verify our findings . [SEP]\n",
      "I1208 12:27:37.214043 139883775852736 run_factoid.py:443] tokens: [CLS] What are the limitations of the findings ? [SEP] VA ##S scores for back pain and leg pain . [ 54 ] The authors attributed the results to the relatively larger injury of soft tissue and disruption of spinal stability , which were caused by the inter ##body fusion than disc ##ec ##tom ##y . [ 54 ] There were several potential limitations in this meta - analysis . First , for some outcomes , the data analysis was based on relatively small number of included studies and sample size ; thus , the conclusions about the outcomes should be interpreted with caution . Second , most of the included studies were retrospective co ##hor ##t study , and the grade evidence was inferior to that of RC ##T ##s . Third , despite we performed sensitivity analysis and subgroup analysis to explore the der ##ivation of he ##tero ##gene ##ity , no valuable information was found . We thought that some potential reasons may account for the great he ##tero ##gene ##ity , including patients ’ characteristics ( age , sex , B ##MI , type of disc her ##nia ##tion , and surgical segment ) , duration of follow - up , case definition , and surgical approaches . These factors may have an impact on our results . thus , considering these limitations , caution is advised when interpret ##ing our findings and applying them into the clinical practice . In conclusion , the present meta - analysis of 14 studies suggested that , P ##EL ##D was associated with better effects and similar complications with other surge ##ries in the treatment of L ##D ##H . However , it also resulted in a higher re ##cu ##rrence rate . Considering the potential limitations in the present study , further large - scale , well - performed random ##ized trials are needed to verify our findings . [SEP]\n",
      "INFO:tensorflow:token_to_orig_map: 10:926 11:926 12:927 13:928 14:929 15:930 16:931 17:932 18:933 19:933 20:933 21:933 22:933 23:934 24:935 25:936 26:937 27:938 28:939 29:940 30:941 31:942 32:943 33:944 34:945 35:946 36:947 37:948 38:949 39:950 40:951 41:951 42:952 43:953 44:954 45:955 46:956 47:957 48:957 49:958 50:959 51:960 52:960 53:960 54:960 55:960 56:960 57:960 58:960 59:961 60:962 61:963 62:964 63:965 64:966 65:967 66:968 67:968 68:968 69:968 70:969 71:969 72:970 73:971 74:972 75:972 76:973 77:974 78:975 79:976 80:977 81:978 82:979 83:980 84:981 85:982 86:983 87:984 88:985 89:986 90:987 91:987 92:988 93:988 94:989 95:990 96:991 97:992 98:993 99:994 100:995 101:996 102:997 103:998 104:998 105:999 106:999 107:1000 108:1001 109:1002 110:1003 111:1004 112:1005 113:1006 114:1007 115:1007 116:1007 117:1008 118:1008 119:1009 120:1010 121:1011 122:1012 123:1013 124:1014 125:1015 126:1016 127:1017 128:1018 129:1018 130:1018 131:1018 132:1019 133:1019 134:1020 135:1021 136:1022 137:1023 138:1024 139:1025 140:1026 141:1027 142:1028 143:1029 144:1030 145:1031 146:1031 147:1032 148:1033 149:1033 150:1033 151:1033 152:1033 153:1034 154:1035 155:1036 156:1037 157:1038 158:1038 159:1039 160:1040 161:1041 162:1042 163:1043 164:1044 165:1045 166:1046 167:1047 168:1048 169:1049 170:1050 171:1050 172:1050 173:1050 174:1050 175:1051 176:1052 177:1052 178:1053 179:1054 180:1054 181:1054 182:1055 183:1055 184:1056 185:1056 186:1056 187:1057 188:1058 189:1059 190:1060 191:1060 192:1060 193:1060 194:1061 195:1062 196:1063 197:1063 198:1063 199:1064 200:1065 201:1066 202:1066 203:1066 204:1066 205:1067 206:1068 207:1068 208:1069 209:1070 210:1071 211:1071 212:1072 213:1073 214:1074 215:1075 216:1076 217:1077 218:1078 219:1079 220:1080 221:1080 222:1081 223:1081 224:1082 225:1083 226:1084 227:1084 228:1085 229:1086 230:1087 231:1088 232:1089 233:1089 234:1090 235:1091 236:1092 237:1093 238:1094 239:1095 240:1096 241:1097 242:1098 243:1098 244:1099 245:1100 246:1100 247:1101 248:1102 249:1103 250:1103 251:1103 252:1104 253:1105 254:1106 255:1107 256:1108 257:1108 258:1109 259:1109 260:1109 261:1110 262:1111 263:1112 264:1113 265:1114 266:1115 267:1116 268:1117 269:1118 270:1119 271:1120 272:1120 273:1121 274:1122 275:1123 276:1124 277:1125 278:1125 279:1125 280:1125 281:1126 282:1126 283:1127 284:1128 285:1129 286:1130 287:1131 288:1132 289:1133 290:1133 291:1133 292:1134 293:1134 294:1135 295:1136 296:1137 297:1138 298:1139 299:1140 300:1141 301:1142 302:1142 303:1143 304:1144 305:1144 306:1144 307:1144 308:1145 309:1145 310:1145 311:1146 312:1146 313:1147 314:1148 315:1149 316:1150 317:1151 318:1152 319:1153 320:1153\n",
      "I1208 12:27:37.214155 139883775852736 run_factoid.py:445] token_to_orig_map: 10:926 11:926 12:927 13:928 14:929 15:930 16:931 17:932 18:933 19:933 20:933 21:933 22:933 23:934 24:935 25:936 26:937 27:938 28:939 29:940 30:941 31:942 32:943 33:944 34:945 35:946 36:947 37:948 38:949 39:950 40:951 41:951 42:952 43:953 44:954 45:955 46:956 47:957 48:957 49:958 50:959 51:960 52:960 53:960 54:960 55:960 56:960 57:960 58:960 59:961 60:962 61:963 62:964 63:965 64:966 65:967 66:968 67:968 68:968 69:968 70:969 71:969 72:970 73:971 74:972 75:972 76:973 77:974 78:975 79:976 80:977 81:978 82:979 83:980 84:981 85:982 86:983 87:984 88:985 89:986 90:987 91:987 92:988 93:988 94:989 95:990 96:991 97:992 98:993 99:994 100:995 101:996 102:997 103:998 104:998 105:999 106:999 107:1000 108:1001 109:1002 110:1003 111:1004 112:1005 113:1006 114:1007 115:1007 116:1007 117:1008 118:1008 119:1009 120:1010 121:1011 122:1012 123:1013 124:1014 125:1015 126:1016 127:1017 128:1018 129:1018 130:1018 131:1018 132:1019 133:1019 134:1020 135:1021 136:1022 137:1023 138:1024 139:1025 140:1026 141:1027 142:1028 143:1029 144:1030 145:1031 146:1031 147:1032 148:1033 149:1033 150:1033 151:1033 152:1033 153:1034 154:1035 155:1036 156:1037 157:1038 158:1038 159:1039 160:1040 161:1041 162:1042 163:1043 164:1044 165:1045 166:1046 167:1047 168:1048 169:1049 170:1050 171:1050 172:1050 173:1050 174:1050 175:1051 176:1052 177:1052 178:1053 179:1054 180:1054 181:1054 182:1055 183:1055 184:1056 185:1056 186:1056 187:1057 188:1058 189:1059 190:1060 191:1060 192:1060 193:1060 194:1061 195:1062 196:1063 197:1063 198:1063 199:1064 200:1065 201:1066 202:1066 203:1066 204:1066 205:1067 206:1068 207:1068 208:1069 209:1070 210:1071 211:1071 212:1072 213:1073 214:1074 215:1075 216:1076 217:1077 218:1078 219:1079 220:1080 221:1080 222:1081 223:1081 224:1082 225:1083 226:1084 227:1084 228:1085 229:1086 230:1087 231:1088 232:1089 233:1089 234:1090 235:1091 236:1092 237:1093 238:1094 239:1095 240:1096 241:1097 242:1098 243:1098 244:1099 245:1100 246:1100 247:1101 248:1102 249:1103 250:1103 251:1103 252:1104 253:1105 254:1106 255:1107 256:1108 257:1108 258:1109 259:1109 260:1109 261:1110 262:1111 263:1112 264:1113 265:1114 266:1115 267:1116 268:1117 269:1118 270:1119 271:1120 272:1120 273:1121 274:1122 275:1123 276:1124 277:1125 278:1125 279:1125 280:1125 281:1126 282:1126 283:1127 284:1128 285:1129 286:1130 287:1131 288:1132 289:1133 290:1133 291:1133 292:1134 293:1134 294:1135 295:1136 296:1137 297:1138 298:1139 299:1140 300:1141 301:1142 302:1142 303:1143 304:1144 305:1144 306:1144 307:1144 308:1145 309:1145 310:1145 311:1146 312:1146 313:1147 314:1148 315:1149 316:1150 317:1151 318:1152 319:1153 320:1153\n",
      "INFO:tensorflow:token_is_max_context: 10:False 11:False 12:False 13:False 14:False 15:False 16:False 17:False 18:False 19:False 20:False 21:False 22:False 23:False 24:False 25:False 26:False 27:False 28:False 29:False 30:False 31:False 32:False 33:False 34:False 35:False 36:False 37:False 38:False 39:False 40:False 41:False 42:False 43:False 44:False 45:False 46:False 47:False 48:False 49:False 50:False 51:False 52:False 53:False 54:False 55:False 56:False 57:False 58:False 59:False 60:False 61:False 62:False 63:False 64:False 65:False 66:False 67:False 68:False 69:False 70:False 71:False 72:False 73:False 74:False 75:False 76:False 77:False 78:False 79:False 80:False 81:False 82:False 83:False 84:False 85:False 86:False 87:False 88:False 89:False 90:False 91:False 92:False 93:False 94:False 95:False 96:False 97:False 98:False 99:False 100:False 101:False 102:False 103:False 104:False 105:False 106:False 107:False 108:False 109:False 110:False 111:False 112:False 113:False 114:False 115:False 116:False 117:False 118:False 119:False 120:False 121:False 122:False 123:False 124:False 125:False 126:False 127:False 128:False 129:False 130:False 131:False 132:False 133:True 134:True 135:True 136:True 137:True 138:True 139:True 140:True 141:True 142:True 143:True 144:True 145:True 146:True 147:True 148:True 149:True 150:True 151:True 152:True 153:True 154:True 155:True 156:True 157:True 158:True 159:True 160:True 161:True 162:True 163:True 164:True 165:True 166:True 167:True 168:True 169:True 170:True 171:True 172:True 173:True 174:True 175:True 176:True 177:True 178:True 179:True 180:True 181:True 182:True 183:True 184:True 185:True 186:True 187:True 188:True 189:True 190:True 191:True 192:True 193:True 194:True 195:True 196:True 197:True 198:True 199:True 200:True 201:True 202:True 203:True 204:True 205:True 206:True 207:True 208:True 209:True 210:True 211:True 212:True 213:True 214:True 215:True 216:True 217:True 218:True 219:True 220:True 221:True 222:True 223:True 224:True 225:True 226:True 227:True 228:True 229:True 230:True 231:True 232:True 233:True 234:True 235:True 236:True 237:True 238:True 239:True 240:True 241:True 242:True 243:True 244:True 245:True 246:True 247:True 248:True 249:True 250:True 251:True 252:True 253:True 254:True 255:True 256:True 257:True 258:True 259:True 260:True 261:True 262:True 263:True 264:True 265:True 266:True 267:True 268:True 269:True 270:True 271:True 272:True 273:True 274:True 275:True 276:True 277:True 278:True 279:True 280:True 281:True 282:True 283:True 284:True 285:True 286:True 287:True 288:True 289:True 290:True 291:True 292:True 293:True 294:True 295:True 296:True 297:True 298:True 299:True 300:True 301:True 302:True 303:True 304:True 305:True 306:True 307:True 308:True 309:True 310:True 311:True 312:True 313:True 314:True 315:True 316:True 317:True 318:True 319:True 320:True\n",
      "I1208 12:27:37.214252 139883775852736 run_factoid.py:447] token_is_max_context: 10:False 11:False 12:False 13:False 14:False 15:False 16:False 17:False 18:False 19:False 20:False 21:False 22:False 23:False 24:False 25:False 26:False 27:False 28:False 29:False 30:False 31:False 32:False 33:False 34:False 35:False 36:False 37:False 38:False 39:False 40:False 41:False 42:False 43:False 44:False 45:False 46:False 47:False 48:False 49:False 50:False 51:False 52:False 53:False 54:False 55:False 56:False 57:False 58:False 59:False 60:False 61:False 62:False 63:False 64:False 65:False 66:False 67:False 68:False 69:False 70:False 71:False 72:False 73:False 74:False 75:False 76:False 77:False 78:False 79:False 80:False 81:False 82:False 83:False 84:False 85:False 86:False 87:False 88:False 89:False 90:False 91:False 92:False 93:False 94:False 95:False 96:False 97:False 98:False 99:False 100:False 101:False 102:False 103:False 104:False 105:False 106:False 107:False 108:False 109:False 110:False 111:False 112:False 113:False 114:False 115:False 116:False 117:False 118:False 119:False 120:False 121:False 122:False 123:False 124:False 125:False 126:False 127:False 128:False 129:False 130:False 131:False 132:False 133:True 134:True 135:True 136:True 137:True 138:True 139:True 140:True 141:True 142:True 143:True 144:True 145:True 146:True 147:True 148:True 149:True 150:True 151:True 152:True 153:True 154:True 155:True 156:True 157:True 158:True 159:True 160:True 161:True 162:True 163:True 164:True 165:True 166:True 167:True 168:True 169:True 170:True 171:True 172:True 173:True 174:True 175:True 176:True 177:True 178:True 179:True 180:True 181:True 182:True 183:True 184:True 185:True 186:True 187:True 188:True 189:True 190:True 191:True 192:True 193:True 194:True 195:True 196:True 197:True 198:True 199:True 200:True 201:True 202:True 203:True 204:True 205:True 206:True 207:True 208:True 209:True 210:True 211:True 212:True 213:True 214:True 215:True 216:True 217:True 218:True 219:True 220:True 221:True 222:True 223:True 224:True 225:True 226:True 227:True 228:True 229:True 230:True 231:True 232:True 233:True 234:True 235:True 236:True 237:True 238:True 239:True 240:True 241:True 242:True 243:True 244:True 245:True 246:True 247:True 248:True 249:True 250:True 251:True 252:True 253:True 254:True 255:True 256:True 257:True 258:True 259:True 260:True 261:True 262:True 263:True 264:True 265:True 266:True 267:True 268:True 269:True 270:True 271:True 272:True 273:True 274:True 275:True 276:True 277:True 278:True 279:True 280:True 281:True 282:True 283:True 284:True 285:True 286:True 287:True 288:True 289:True 290:True 291:True 292:True 293:True 294:True 295:True 296:True 297:True 298:True 299:True 300:True 301:True 302:True 303:True 304:True 305:True 306:True 307:True 308:True 309:True 310:True 311:True 312:True 313:True 314:True 315:True 316:True 317:True 318:True 319:True 320:True\n",
      "INFO:tensorflow:input_ids: 101 1327 1132 1103 13004 1104 1103 9505 136 102 19497 1708 7432 1111 1171 2489 1105 3420 2489 119 164 4335 166 1109 5752 6547 1103 2686 1106 1103 3860 2610 3773 1104 2991 7918 1105 23730 1104 19245 9397 117 1134 1127 2416 1118 1103 9455 14637 11970 1190 6187 10294 18778 1183 119 164 4335 166 1247 1127 1317 3209 13004 1107 1142 27154 118 3622 119 1752 117 1111 1199 13950 117 1103 2233 3622 1108 1359 1113 3860 1353 1295 1104 1529 2527 1105 6876 2060 132 2456 117 1103 16421 1164 1103 13950 1431 1129 9829 1114 15597 119 2307 117 1211 1104 1103 1529 2527 1127 18675 1884 13252 1204 2025 117 1105 1103 3654 2554 1108 15543 1106 1115 1104 25157 1942 1116 119 4180 117 2693 1195 1982 15750 3622 1105 23470 3622 1106 8664 1103 4167 16617 1104 1119 25710 27054 1785 117 1185 7468 1869 1108 1276 119 1284 1354 1115 1199 3209 3672 1336 3300 1111 1103 1632 1119 25710 27054 1785 117 1259 4420 787 5924 113 1425 117 2673 117 139 14038 117 2076 1104 6187 1123 5813 2116 117 1105 13467 6441 114 117 9355 1104 2812 118 1146 117 1692 5754 117 1105 13467 8015 119 1636 5320 1336 1138 1126 3772 1113 1412 2686 119 2456 117 6103 1292 13004 117 15597 1110 9213 1165 19348 1158 1412 9505 1105 11892 1172 1154 1103 7300 2415 119 1130 6593 117 1103 1675 27154 118 3622 1104 1489 2527 3228 1115 117 153 21678 2137 1108 2628 1114 1618 3154 1105 1861 13522 1114 1168 12814 3377 1107 1103 3252 1104 149 2137 3048 119 1438 117 1122 1145 3657 1107 170 2299 1231 10182 21629 2603 119 23243 1103 3209 13004 1107 1103 1675 2025 117 1748 1415 118 3418 117 1218 118 1982 7091 2200 7356 1132 1834 1106 23073 1412 9505 119 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "I1208 12:27:37.214351 139883775852736 run_factoid.py:449] input_ids: 101 1327 1132 1103 13004 1104 1103 9505 136 102 19497 1708 7432 1111 1171 2489 1105 3420 2489 119 164 4335 166 1109 5752 6547 1103 2686 1106 1103 3860 2610 3773 1104 2991 7918 1105 23730 1104 19245 9397 117 1134 1127 2416 1118 1103 9455 14637 11970 1190 6187 10294 18778 1183 119 164 4335 166 1247 1127 1317 3209 13004 1107 1142 27154 118 3622 119 1752 117 1111 1199 13950 117 1103 2233 3622 1108 1359 1113 3860 1353 1295 1104 1529 2527 1105 6876 2060 132 2456 117 1103 16421 1164 1103 13950 1431 1129 9829 1114 15597 119 2307 117 1211 1104 1103 1529 2527 1127 18675 1884 13252 1204 2025 117 1105 1103 3654 2554 1108 15543 1106 1115 1104 25157 1942 1116 119 4180 117 2693 1195 1982 15750 3622 1105 23470 3622 1106 8664 1103 4167 16617 1104 1119 25710 27054 1785 117 1185 7468 1869 1108 1276 119 1284 1354 1115 1199 3209 3672 1336 3300 1111 1103 1632 1119 25710 27054 1785 117 1259 4420 787 5924 113 1425 117 2673 117 139 14038 117 2076 1104 6187 1123 5813 2116 117 1105 13467 6441 114 117 9355 1104 2812 118 1146 117 1692 5754 117 1105 13467 8015 119 1636 5320 1336 1138 1126 3772 1113 1412 2686 119 2456 117 6103 1292 13004 117 15597 1110 9213 1165 19348 1158 1412 9505 1105 11892 1172 1154 1103 7300 2415 119 1130 6593 117 1103 1675 27154 118 3622 1104 1489 2527 3228 1115 117 153 21678 2137 1108 2628 1114 1618 3154 1105 1861 13522 1114 1168 12814 3377 1107 1103 3252 1104 149 2137 3048 119 1438 117 1122 1145 3657 1107 170 2299 1231 10182 21629 2603 119 23243 1103 3209 13004 1107 1103 1675 2025 117 1748 1415 118 3418 117 1218 118 1982 7091 2200 7356 1132 1834 1106 23073 1412 9505 119 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "INFO:tensorflow:input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "I1208 12:27:37.214443 139883775852736 run_factoid.py:451] input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "INFO:tensorflow:segment_ids: 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "I1208 12:27:37.214532 139883775852736 run_factoid.py:453] segment_ids: 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "INFO:tensorflow:***** Running predictions *****\n",
      "I1208 12:27:37.214923 139883775852736 run_factoid.py:1247] ***** Running predictions *****\n",
      "INFO:tensorflow:  Num orig examples = 10\n",
      "I1208 12:27:37.214990 139883775852736 run_factoid.py:1248]   Num orig examples = 10\n",
      "INFO:tensorflow:  Num split examples = 66\n",
      "I1208 12:27:37.215418 139883775852736 run_factoid.py:1249]   Num split examples = 66\n",
      "INFO:tensorflow:  Batch size = 8\n",
      "I1208 12:27:37.215468 139883775852736 run_factoid.py:1250]   Batch size = 8\n",
      "WARNING:tensorflow:From /home/tala/s2-simplify/bioasq-biobert/run_factoid.py:698: The name tf.FixedLenFeature is deprecated. Please use tf.io.FixedLenFeature instead.\n",
      "\n",
      "W1208 12:27:37.215563 139883775852736 module_wrapper.py:139] From /home/tala/s2-simplify/bioasq-biobert/run_factoid.py:698: The name tf.FixedLenFeature is deprecated. Please use tf.io.FixedLenFeature instead.\n",
      "\n",
      "INFO:tensorflow:Could not find trained model in model_dir: /home/tala/s2-simplify/bioasq-biobert/output/, running initialization to predict.\n",
      "I1208 12:27:37.215825 139883775852736 estimator.py:615] Could not find trained model in model_dir: /home/tala/s2-simplify/bioasq-biobert/output/, running initialization to predict.\n",
      "WARNING:tensorflow:From /home/tala/miniconda3/envs/bioasq-biobert2019py3.6/lib/python3.6/site-packages/tensorflow_core/python/ops/resource_variable_ops.py:1630: calling BaseResourceVariable.__init__ (from tensorflow.python.ops.resource_variable_ops) with constraint is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "If using Keras pass *_constraint arguments to layers.\n",
      "W1208 12:27:37.222069 139883775852736 deprecation.py:506] From /home/tala/miniconda3/envs/bioasq-biobert2019py3.6/lib/python3.6/site-packages/tensorflow_core/python/ops/resource_variable_ops.py:1630: calling BaseResourceVariable.__init__ (from tensorflow.python.ops.resource_variable_ops) with constraint is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "If using Keras pass *_constraint arguments to layers.\n",
      "WARNING:tensorflow:From /home/tala/s2-simplify/bioasq-biobert/run_factoid.py:737: map_and_batch (from tensorflow.contrib.data.python.ops.batching) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use `tf.data.experimental.map_and_batch(...)`.\n",
      "W1208 12:27:37.240505 139883775852736 deprecation.py:323] From /home/tala/s2-simplify/bioasq-biobert/run_factoid.py:737: map_and_batch (from tensorflow.contrib.data.python.ops.batching) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use `tf.data.experimental.map_and_batch(...)`.\n",
      "WARNING:tensorflow:From /home/tala/miniconda3/envs/bioasq-biobert2019py3.6/lib/python3.6/site-packages/tensorflow_core/contrib/data/python/ops/batching.py:276: map_and_batch (from tensorflow.python.data.experimental.ops.batching) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use `tf.data.Dataset.map(map_func, num_parallel_calls)` followed by `tf.data.Dataset.batch(batch_size, drop_remainder)`. Static tf.data optimizations will take care of using the fused implementation.\n",
      "W1208 12:27:37.240611 139883775852736 deprecation.py:323] From /home/tala/miniconda3/envs/bioasq-biobert2019py3.6/lib/python3.6/site-packages/tensorflow_core/contrib/data/python/ops/batching.py:276: map_and_batch (from tensorflow.python.data.experimental.ops.batching) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use `tf.data.Dataset.map(map_func, num_parallel_calls)` followed by `tf.data.Dataset.batch(batch_size, drop_remainder)`. Static tf.data optimizations will take care of using the fused implementation.\n",
      "WARNING:tensorflow:From /home/tala/miniconda3/envs/bioasq-biobert2019py3.6/lib/python3.6/site-packages/tensorflow_core/python/autograph/converters/directives.py:119: The name tf.parse_single_example is deprecated. Please use tf.io.parse_single_example instead.\n",
      "\n",
      "W1208 12:27:37.291719 139883775852736 module_wrapper.py:139] From /home/tala/miniconda3/envs/bioasq-biobert2019py3.6/lib/python3.6/site-packages/tensorflow_core/python/autograph/converters/directives.py:119: The name tf.parse_single_example is deprecated. Please use tf.io.parse_single_example instead.\n",
      "\n",
      "WARNING:tensorflow:From /home/tala/s2-simplify/bioasq-biobert/run_factoid.py:717: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use `tf.cast` instead.\n",
      "W1208 12:27:37.367174 139883775852736 deprecation.py:323] From /home/tala/s2-simplify/bioasq-biobert/run_factoid.py:717: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use `tf.cast` instead.\n",
      "INFO:tensorflow:Calling model_fn.\n",
      "I1208 12:27:37.378329 139883775852736 estimator.py:1148] Calling model_fn.\n",
      "INFO:tensorflow:Running infer on CPU\n",
      "I1208 12:27:37.378463 139883775852736 tpu_estimator.py:3124] Running infer on CPU\n",
      "INFO:tensorflow:*** Features ***\n",
      "I1208 12:27:37.378673 139883775852736 run_factoid.py:605] *** Features ***\n",
      "INFO:tensorflow:  name = input_ids, shape = (?, 384)\n",
      "I1208 12:27:37.378753 139883775852736 run_factoid.py:607]   name = input_ids, shape = (?, 384)\n",
      "INFO:tensorflow:  name = input_mask, shape = (?, 384)\n",
      "I1208 12:27:37.378810 139883775852736 run_factoid.py:607]   name = input_mask, shape = (?, 384)\n",
      "INFO:tensorflow:  name = segment_ids, shape = (?, 384)\n",
      "I1208 12:27:37.378860 139883775852736 run_factoid.py:607]   name = segment_ids, shape = (?, 384)\n",
      "INFO:tensorflow:  name = unique_ids, shape = (?,)\n",
      "I1208 12:27:37.378907 139883775852736 run_factoid.py:607]   name = unique_ids, shape = (?,)\n",
      "WARNING:tensorflow:From /home/tala/s2-simplify/bioasq-biobert/modeling.py:172: The name tf.variable_scope is deprecated. Please use tf.compat.v1.variable_scope instead.\n",
      "\n",
      "W1208 12:27:37.381930 139883775852736 module_wrapper.py:139] From /home/tala/s2-simplify/bioasq-biobert/modeling.py:172: The name tf.variable_scope is deprecated. Please use tf.compat.v1.variable_scope instead.\n",
      "\n",
      "WARNING:tensorflow:From /home/tala/s2-simplify/bioasq-biobert/modeling.py:411: The name tf.get_variable is deprecated. Please use tf.compat.v1.get_variable instead.\n",
      "\n",
      "W1208 12:27:37.382915 139883775852736 module_wrapper.py:139] From /home/tala/s2-simplify/bioasq-biobert/modeling.py:411: The name tf.get_variable is deprecated. Please use tf.compat.v1.get_variable instead.\n",
      "\n",
      "WARNING:tensorflow:From /home/tala/s2-simplify/bioasq-biobert/modeling.py:492: The name tf.assert_less_equal is deprecated. Please use tf.compat.v1.assert_less_equal instead.\n",
      "\n",
      "W1208 12:27:37.403234 139883775852736 module_wrapper.py:139] From /home/tala/s2-simplify/bioasq-biobert/modeling.py:492: The name tf.assert_less_equal is deprecated. Please use tf.compat.v1.assert_less_equal instead.\n",
      "\n",
      "WARNING:tensorflow:From /home/tala/s2-simplify/bioasq-biobert/modeling.py:673: dense (from tensorflow.python.layers.core) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use keras.layers.Dense instead.\n",
      "W1208 12:27:37.440859 139883775852736 deprecation.py:323] From /home/tala/s2-simplify/bioasq-biobert/modeling.py:673: dense (from tensorflow.python.layers.core) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use keras.layers.Dense instead.\n",
      "WARNING:tensorflow:From /home/tala/miniconda3/envs/bioasq-biobert2019py3.6/lib/python3.6/site-packages/tensorflow_core/python/layers/core.py:187: Layer.apply (from tensorflow.python.keras.engine.base_layer) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `layer.__call__` method instead.\n",
      "W1208 12:27:37.441851 139883775852736 deprecation.py:323] From /home/tala/miniconda3/envs/bioasq-biobert2019py3.6/lib/python3.6/site-packages/tensorflow_core/python/layers/core.py:187: Layer.apply (from tensorflow.python.keras.engine.base_layer) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `layer.__call__` method instead.\n",
      "WARNING:tensorflow:From /home/tala/s2-simplify/bioasq-biobert/modeling.py:277: The name tf.erf is deprecated. Please use tf.math.erf instead.\n",
      "\n",
      "W1208 12:27:37.507173 139883775852736 module_wrapper.py:139] From /home/tala/s2-simplify/bioasq-biobert/modeling.py:277: The name tf.erf is deprecated. Please use tf.math.erf instead.\n",
      "\n",
      "WARNING:tensorflow:From /home/tala/s2-simplify/bioasq-biobert/run_factoid.py:624: The name tf.trainable_variables is deprecated. Please use tf.compat.v1.trainable_variables instead.\n",
      "\n",
      "W1208 12:27:38.600980 139883775852736 module_wrapper.py:139] From /home/tala/s2-simplify/bioasq-biobert/run_factoid.py:624: The name tf.trainable_variables is deprecated. Please use tf.compat.v1.trainable_variables instead.\n",
      "\n",
      "WARNING:tensorflow:From /home/tala/s2-simplify/bioasq-biobert/run_factoid.py:639: The name tf.train.init_from_checkpoint is deprecated. Please use tf.compat.v1.train.init_from_checkpoint instead.\n",
      "\n",
      "W1208 12:27:38.605510 139883775852736 module_wrapper.py:139] From /home/tala/s2-simplify/bioasq-biobert/run_factoid.py:639: The name tf.train.init_from_checkpoint is deprecated. Please use tf.compat.v1.train.init_from_checkpoint instead.\n",
      "\n",
      "INFO:tensorflow:**** Trainable Variables ****\n",
      "I1208 12:27:39.103076 139883775852736 run_factoid.py:641] **** Trainable Variables ****\n",
      "INFO:tensorflow:  name = bert/embeddings/word_embeddings:0, shape = (28996, 768), *INIT_FROM_CKPT*\n",
      "I1208 12:27:39.103403 139883775852736 run_factoid.py:647]   name = bert/embeddings/word_embeddings:0, shape = (28996, 768), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/embeddings/token_type_embeddings:0, shape = (2, 768), *INIT_FROM_CKPT*\n",
      "I1208 12:27:39.103511 139883775852736 run_factoid.py:647]   name = bert/embeddings/token_type_embeddings:0, shape = (2, 768), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/embeddings/position_embeddings:0, shape = (512, 768), *INIT_FROM_CKPT*\n",
      "I1208 12:27:39.103570 139883775852736 run_factoid.py:647]   name = bert/embeddings/position_embeddings:0, shape = (512, 768), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/embeddings/LayerNorm/beta:0, shape = (768,), *INIT_FROM_CKPT*\n",
      "I1208 12:27:39.103626 139883775852736 run_factoid.py:647]   name = bert/embeddings/LayerNorm/beta:0, shape = (768,), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/embeddings/LayerNorm/gamma:0, shape = (768,), *INIT_FROM_CKPT*\n",
      "I1208 12:27:39.103674 139883775852736 run_factoid.py:647]   name = bert/embeddings/LayerNorm/gamma:0, shape = (768,), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_0/attention/self/query/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
      "I1208 12:27:39.103725 139883775852736 run_factoid.py:647]   name = bert/encoder/layer_0/attention/self/query/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_0/attention/self/query/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
      "I1208 12:27:39.103779 139883775852736 run_factoid.py:647]   name = bert/encoder/layer_0/attention/self/query/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_0/attention/self/key/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
      "I1208 12:27:39.103828 139883775852736 run_factoid.py:647]   name = bert/encoder/layer_0/attention/self/key/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_0/attention/self/key/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
      "I1208 12:27:39.103882 139883775852736 run_factoid.py:647]   name = bert/encoder/layer_0/attention/self/key/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_0/attention/self/value/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
      "I1208 12:27:39.103933 139883775852736 run_factoid.py:647]   name = bert/encoder/layer_0/attention/self/value/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_0/attention/self/value/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
      "I1208 12:27:39.103986 139883775852736 run_factoid.py:647]   name = bert/encoder/layer_0/attention/self/value/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_0/attention/output/dense/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
      "I1208 12:27:39.104036 139883775852736 run_factoid.py:647]   name = bert/encoder/layer_0/attention/output/dense/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_0/attention/output/dense/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
      "I1208 12:27:39.104087 139883775852736 run_factoid.py:647]   name = bert/encoder/layer_0/attention/output/dense/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_0/attention/output/LayerNorm/beta:0, shape = (768,), *INIT_FROM_CKPT*\n",
      "I1208 12:27:39.104134 139883775852736 run_factoid.py:647]   name = bert/encoder/layer_0/attention/output/LayerNorm/beta:0, shape = (768,), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_0/attention/output/LayerNorm/gamma:0, shape = (768,), *INIT_FROM_CKPT*\n",
      "I1208 12:27:39.104179 139883775852736 run_factoid.py:647]   name = bert/encoder/layer_0/attention/output/LayerNorm/gamma:0, shape = (768,), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_0/intermediate/dense/kernel:0, shape = (768, 3072), *INIT_FROM_CKPT*\n",
      "I1208 12:27:39.104227 139883775852736 run_factoid.py:647]   name = bert/encoder/layer_0/intermediate/dense/kernel:0, shape = (768, 3072), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_0/intermediate/dense/bias:0, shape = (3072,), *INIT_FROM_CKPT*\n",
      "I1208 12:27:39.104279 139883775852736 run_factoid.py:647]   name = bert/encoder/layer_0/intermediate/dense/bias:0, shape = (3072,), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_0/output/dense/kernel:0, shape = (3072, 768), *INIT_FROM_CKPT*\n",
      "I1208 12:27:39.104329 139883775852736 run_factoid.py:647]   name = bert/encoder/layer_0/output/dense/kernel:0, shape = (3072, 768), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_0/output/dense/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
      "I1208 12:27:39.104382 139883775852736 run_factoid.py:647]   name = bert/encoder/layer_0/output/dense/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_0/output/LayerNorm/beta:0, shape = (768,), *INIT_FROM_CKPT*\n",
      "I1208 12:27:39.104429 139883775852736 run_factoid.py:647]   name = bert/encoder/layer_0/output/LayerNorm/beta:0, shape = (768,), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_0/output/LayerNorm/gamma:0, shape = (768,), *INIT_FROM_CKPT*\n",
      "I1208 12:27:39.104477 139883775852736 run_factoid.py:647]   name = bert/encoder/layer_0/output/LayerNorm/gamma:0, shape = (768,), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_1/attention/self/query/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
      "I1208 12:27:39.104527 139883775852736 run_factoid.py:647]   name = bert/encoder/layer_1/attention/self/query/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_1/attention/self/query/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
      "I1208 12:27:39.104581 139883775852736 run_factoid.py:647]   name = bert/encoder/layer_1/attention/self/query/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_1/attention/self/key/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
      "I1208 12:27:39.104629 139883775852736 run_factoid.py:647]   name = bert/encoder/layer_1/attention/self/key/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_1/attention/self/key/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
      "I1208 12:27:39.104687 139883775852736 run_factoid.py:647]   name = bert/encoder/layer_1/attention/self/key/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_1/attention/self/value/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
      "I1208 12:27:39.104736 139883775852736 run_factoid.py:647]   name = bert/encoder/layer_1/attention/self/value/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_1/attention/self/value/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
      "I1208 12:27:39.104791 139883775852736 run_factoid.py:647]   name = bert/encoder/layer_1/attention/self/value/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_1/attention/output/dense/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
      "I1208 12:27:39.104840 139883775852736 run_factoid.py:647]   name = bert/encoder/layer_1/attention/output/dense/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_1/attention/output/dense/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
      "I1208 12:27:39.104892 139883775852736 run_factoid.py:647]   name = bert/encoder/layer_1/attention/output/dense/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_1/attention/output/LayerNorm/beta:0, shape = (768,), *INIT_FROM_CKPT*\n",
      "I1208 12:27:39.104937 139883775852736 run_factoid.py:647]   name = bert/encoder/layer_1/attention/output/LayerNorm/beta:0, shape = (768,), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_1/attention/output/LayerNorm/gamma:0, shape = (768,), *INIT_FROM_CKPT*\n",
      "I1208 12:27:39.104984 139883775852736 run_factoid.py:647]   name = bert/encoder/layer_1/attention/output/LayerNorm/gamma:0, shape = (768,), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_1/intermediate/dense/kernel:0, shape = (768, 3072), *INIT_FROM_CKPT*\n",
      "I1208 12:27:39.105033 139883775852736 run_factoid.py:647]   name = bert/encoder/layer_1/intermediate/dense/kernel:0, shape = (768, 3072), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_1/intermediate/dense/bias:0, shape = (3072,), *INIT_FROM_CKPT*\n",
      "I1208 12:27:39.105084 139883775852736 run_factoid.py:647]   name = bert/encoder/layer_1/intermediate/dense/bias:0, shape = (3072,), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_1/output/dense/kernel:0, shape = (3072, 768), *INIT_FROM_CKPT*\n",
      "I1208 12:27:39.105134 139883775852736 run_factoid.py:647]   name = bert/encoder/layer_1/output/dense/kernel:0, shape = (3072, 768), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_1/output/dense/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
      "I1208 12:27:39.105185 139883775852736 run_factoid.py:647]   name = bert/encoder/layer_1/output/dense/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_1/output/LayerNorm/beta:0, shape = (768,), *INIT_FROM_CKPT*\n",
      "I1208 12:27:39.105233 139883775852736 run_factoid.py:647]   name = bert/encoder/layer_1/output/LayerNorm/beta:0, shape = (768,), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_1/output/LayerNorm/gamma:0, shape = (768,), *INIT_FROM_CKPT*\n",
      "I1208 12:27:39.105278 139883775852736 run_factoid.py:647]   name = bert/encoder/layer_1/output/LayerNorm/gamma:0, shape = (768,), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_2/attention/self/query/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
      "I1208 12:27:39.105328 139883775852736 run_factoid.py:647]   name = bert/encoder/layer_2/attention/self/query/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_2/attention/self/query/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
      "I1208 12:27:39.105376 139883775852736 run_factoid.py:647]   name = bert/encoder/layer_2/attention/self/query/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_2/attention/self/key/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
      "I1208 12:27:39.105422 139883775852736 run_factoid.py:647]   name = bert/encoder/layer_2/attention/self/key/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_2/attention/self/key/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
      "I1208 12:27:39.105469 139883775852736 run_factoid.py:647]   name = bert/encoder/layer_2/attention/self/key/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_2/attention/self/value/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
      "I1208 12:27:39.105515 139883775852736 run_factoid.py:647]   name = bert/encoder/layer_2/attention/self/value/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_2/attention/self/value/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
      "I1208 12:27:39.105564 139883775852736 run_factoid.py:647]   name = bert/encoder/layer_2/attention/self/value/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_2/attention/output/dense/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
      "I1208 12:27:39.105612 139883775852736 run_factoid.py:647]   name = bert/encoder/layer_2/attention/output/dense/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_2/attention/output/dense/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
      "I1208 12:27:39.105660 139883775852736 run_factoid.py:647]   name = bert/encoder/layer_2/attention/output/dense/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_2/attention/output/LayerNorm/beta:0, shape = (768,), *INIT_FROM_CKPT*\n",
      "I1208 12:27:39.105705 139883775852736 run_factoid.py:647]   name = bert/encoder/layer_2/attention/output/LayerNorm/beta:0, shape = (768,), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_2/attention/output/LayerNorm/gamma:0, shape = (768,), *INIT_FROM_CKPT*\n",
      "I1208 12:27:39.105749 139883775852736 run_factoid.py:647]   name = bert/encoder/layer_2/attention/output/LayerNorm/gamma:0, shape = (768,), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_2/intermediate/dense/kernel:0, shape = (768, 3072), *INIT_FROM_CKPT*\n",
      "I1208 12:27:39.105797 139883775852736 run_factoid.py:647]   name = bert/encoder/layer_2/intermediate/dense/kernel:0, shape = (768, 3072), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_2/intermediate/dense/bias:0, shape = (3072,), *INIT_FROM_CKPT*\n",
      "I1208 12:27:39.105845 139883775852736 run_factoid.py:647]   name = bert/encoder/layer_2/intermediate/dense/bias:0, shape = (3072,), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_2/output/dense/kernel:0, shape = (3072, 768), *INIT_FROM_CKPT*\n",
      "I1208 12:27:39.105892 139883775852736 run_factoid.py:647]   name = bert/encoder/layer_2/output/dense/kernel:0, shape = (3072, 768), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_2/output/dense/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
      "I1208 12:27:39.105939 139883775852736 run_factoid.py:647]   name = bert/encoder/layer_2/output/dense/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_2/output/LayerNorm/beta:0, shape = (768,), *INIT_FROM_CKPT*\n",
      "I1208 12:27:39.105984 139883775852736 run_factoid.py:647]   name = bert/encoder/layer_2/output/LayerNorm/beta:0, shape = (768,), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_2/output/LayerNorm/gamma:0, shape = (768,), *INIT_FROM_CKPT*\n",
      "I1208 12:27:39.106029 139883775852736 run_factoid.py:647]   name = bert/encoder/layer_2/output/LayerNorm/gamma:0, shape = (768,), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_3/attention/self/query/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
      "I1208 12:27:39.106077 139883775852736 run_factoid.py:647]   name = bert/encoder/layer_3/attention/self/query/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_3/attention/self/query/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
      "I1208 12:27:39.106125 139883775852736 run_factoid.py:647]   name = bert/encoder/layer_3/attention/self/query/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_3/attention/self/key/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
      "I1208 12:27:39.106169 139883775852736 run_factoid.py:647]   name = bert/encoder/layer_3/attention/self/key/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_3/attention/self/key/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
      "I1208 12:27:39.106216 139883775852736 run_factoid.py:647]   name = bert/encoder/layer_3/attention/self/key/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_3/attention/self/value/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
      "I1208 12:27:39.106261 139883775852736 run_factoid.py:647]   name = bert/encoder/layer_3/attention/self/value/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_3/attention/self/value/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
      "I1208 12:27:39.106311 139883775852736 run_factoid.py:647]   name = bert/encoder/layer_3/attention/self/value/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_3/attention/output/dense/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
      "I1208 12:27:39.106359 139883775852736 run_factoid.py:647]   name = bert/encoder/layer_3/attention/output/dense/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_3/attention/output/dense/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
      "I1208 12:27:39.106405 139883775852736 run_factoid.py:647]   name = bert/encoder/layer_3/attention/output/dense/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_3/attention/output/LayerNorm/beta:0, shape = (768,), *INIT_FROM_CKPT*\n",
      "I1208 12:27:39.106451 139883775852736 run_factoid.py:647]   name = bert/encoder/layer_3/attention/output/LayerNorm/beta:0, shape = (768,), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_3/attention/output/LayerNorm/gamma:0, shape = (768,), *INIT_FROM_CKPT*\n",
      "I1208 12:27:39.106495 139883775852736 run_factoid.py:647]   name = bert/encoder/layer_3/attention/output/LayerNorm/gamma:0, shape = (768,), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_3/intermediate/dense/kernel:0, shape = (768, 3072), *INIT_FROM_CKPT*\n",
      "I1208 12:27:39.106542 139883775852736 run_factoid.py:647]   name = bert/encoder/layer_3/intermediate/dense/kernel:0, shape = (768, 3072), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_3/intermediate/dense/bias:0, shape = (3072,), *INIT_FROM_CKPT*\n",
      "I1208 12:27:39.106590 139883775852736 run_factoid.py:647]   name = bert/encoder/layer_3/intermediate/dense/bias:0, shape = (3072,), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_3/output/dense/kernel:0, shape = (3072, 768), *INIT_FROM_CKPT*\n",
      "I1208 12:27:39.106636 139883775852736 run_factoid.py:647]   name = bert/encoder/layer_3/output/dense/kernel:0, shape = (3072, 768), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_3/output/dense/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
      "I1208 12:27:39.106682 139883775852736 run_factoid.py:647]   name = bert/encoder/layer_3/output/dense/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_3/output/LayerNorm/beta:0, shape = (768,), *INIT_FROM_CKPT*\n",
      "I1208 12:27:39.106727 139883775852736 run_factoid.py:647]   name = bert/encoder/layer_3/output/LayerNorm/beta:0, shape = (768,), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_3/output/LayerNorm/gamma:0, shape = (768,), *INIT_FROM_CKPT*\n",
      "I1208 12:27:39.106770 139883775852736 run_factoid.py:647]   name = bert/encoder/layer_3/output/LayerNorm/gamma:0, shape = (768,), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_4/attention/self/query/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
      "I1208 12:27:39.106818 139883775852736 run_factoid.py:647]   name = bert/encoder/layer_4/attention/self/query/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_4/attention/self/query/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
      "I1208 12:27:39.106865 139883775852736 run_factoid.py:647]   name = bert/encoder/layer_4/attention/self/query/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_4/attention/self/key/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
      "I1208 12:27:39.106911 139883775852736 run_factoid.py:647]   name = bert/encoder/layer_4/attention/self/key/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_4/attention/self/key/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
      "I1208 12:27:39.106959 139883775852736 run_factoid.py:647]   name = bert/encoder/layer_4/attention/self/key/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_4/attention/self/value/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
      "I1208 12:27:39.107004 139883775852736 run_factoid.py:647]   name = bert/encoder/layer_4/attention/self/value/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_4/attention/self/value/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
      "I1208 12:27:39.107050 139883775852736 run_factoid.py:647]   name = bert/encoder/layer_4/attention/self/value/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_4/attention/output/dense/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
      "I1208 12:27:39.107097 139883775852736 run_factoid.py:647]   name = bert/encoder/layer_4/attention/output/dense/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_4/attention/output/dense/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
      "I1208 12:27:39.107147 139883775852736 run_factoid.py:647]   name = bert/encoder/layer_4/attention/output/dense/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_4/attention/output/LayerNorm/beta:0, shape = (768,), *INIT_FROM_CKPT*\n",
      "I1208 12:27:39.107192 139883775852736 run_factoid.py:647]   name = bert/encoder/layer_4/attention/output/LayerNorm/beta:0, shape = (768,), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_4/attention/output/LayerNorm/gamma:0, shape = (768,), *INIT_FROM_CKPT*\n",
      "I1208 12:27:39.107236 139883775852736 run_factoid.py:647]   name = bert/encoder/layer_4/attention/output/LayerNorm/gamma:0, shape = (768,), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_4/intermediate/dense/kernel:0, shape = (768, 3072), *INIT_FROM_CKPT*\n",
      "I1208 12:27:39.107283 139883775852736 run_factoid.py:647]   name = bert/encoder/layer_4/intermediate/dense/kernel:0, shape = (768, 3072), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_4/intermediate/dense/bias:0, shape = (3072,), *INIT_FROM_CKPT*\n",
      "I1208 12:27:39.107333 139883775852736 run_factoid.py:647]   name = bert/encoder/layer_4/intermediate/dense/bias:0, shape = (3072,), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_4/output/dense/kernel:0, shape = (3072, 768), *INIT_FROM_CKPT*\n",
      "I1208 12:27:39.107380 139883775852736 run_factoid.py:647]   name = bert/encoder/layer_4/output/dense/kernel:0, shape = (3072, 768), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_4/output/dense/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
      "I1208 12:27:39.107429 139883775852736 run_factoid.py:647]   name = bert/encoder/layer_4/output/dense/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_4/output/LayerNorm/beta:0, shape = (768,), *INIT_FROM_CKPT*\n",
      "I1208 12:27:39.107474 139883775852736 run_factoid.py:647]   name = bert/encoder/layer_4/output/LayerNorm/beta:0, shape = (768,), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_4/output/LayerNorm/gamma:0, shape = (768,), *INIT_FROM_CKPT*\n",
      "I1208 12:27:39.107518 139883775852736 run_factoid.py:647]   name = bert/encoder/layer_4/output/LayerNorm/gamma:0, shape = (768,), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_5/attention/self/query/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
      "I1208 12:27:39.107565 139883775852736 run_factoid.py:647]   name = bert/encoder/layer_5/attention/self/query/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_5/attention/self/query/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
      "I1208 12:27:39.107613 139883775852736 run_factoid.py:647]   name = bert/encoder/layer_5/attention/self/query/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_5/attention/self/key/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
      "I1208 12:27:39.107657 139883775852736 run_factoid.py:647]   name = bert/encoder/layer_5/attention/self/key/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_5/attention/self/key/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
      "I1208 12:27:39.107704 139883775852736 run_factoid.py:647]   name = bert/encoder/layer_5/attention/self/key/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_5/attention/self/value/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
      "I1208 12:27:39.107748 139883775852736 run_factoid.py:647]   name = bert/encoder/layer_5/attention/self/value/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_5/attention/self/value/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
      "I1208 12:27:39.107794 139883775852736 run_factoid.py:647]   name = bert/encoder/layer_5/attention/self/value/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_5/attention/output/dense/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
      "I1208 12:27:39.107840 139883775852736 run_factoid.py:647]   name = bert/encoder/layer_5/attention/output/dense/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_5/attention/output/dense/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
      "I1208 12:27:39.107887 139883775852736 run_factoid.py:647]   name = bert/encoder/layer_5/attention/output/dense/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_5/attention/output/LayerNorm/beta:0, shape = (768,), *INIT_FROM_CKPT*\n",
      "I1208 12:27:39.107933 139883775852736 run_factoid.py:647]   name = bert/encoder/layer_5/attention/output/LayerNorm/beta:0, shape = (768,), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_5/attention/output/LayerNorm/gamma:0, shape = (768,), *INIT_FROM_CKPT*\n",
      "I1208 12:27:39.107976 139883775852736 run_factoid.py:647]   name = bert/encoder/layer_5/attention/output/LayerNorm/gamma:0, shape = (768,), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_5/intermediate/dense/kernel:0, shape = (768, 3072), *INIT_FROM_CKPT*\n",
      "I1208 12:27:39.108018 139883775852736 run_factoid.py:647]   name = bert/encoder/layer_5/intermediate/dense/kernel:0, shape = (768, 3072), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_5/intermediate/dense/bias:0, shape = (3072,), *INIT_FROM_CKPT*\n",
      "I1208 12:27:39.108063 139883775852736 run_factoid.py:647]   name = bert/encoder/layer_5/intermediate/dense/bias:0, shape = (3072,), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_5/output/dense/kernel:0, shape = (3072, 768), *INIT_FROM_CKPT*\n",
      "I1208 12:27:39.108107 139883775852736 run_factoid.py:647]   name = bert/encoder/layer_5/output/dense/kernel:0, shape = (3072, 768), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_5/output/dense/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
      "I1208 12:27:39.108153 139883775852736 run_factoid.py:647]   name = bert/encoder/layer_5/output/dense/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_5/output/LayerNorm/beta:0, shape = (768,), *INIT_FROM_CKPT*\n",
      "I1208 12:27:39.108196 139883775852736 run_factoid.py:647]   name = bert/encoder/layer_5/output/LayerNorm/beta:0, shape = (768,), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_5/output/LayerNorm/gamma:0, shape = (768,), *INIT_FROM_CKPT*\n",
      "I1208 12:27:39.108239 139883775852736 run_factoid.py:647]   name = bert/encoder/layer_5/output/LayerNorm/gamma:0, shape = (768,), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_6/attention/self/query/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
      "I1208 12:27:39.108283 139883775852736 run_factoid.py:647]   name = bert/encoder/layer_6/attention/self/query/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_6/attention/self/query/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
      "I1208 12:27:39.108329 139883775852736 run_factoid.py:647]   name = bert/encoder/layer_6/attention/self/query/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_6/attention/self/key/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
      "I1208 12:27:39.108372 139883775852736 run_factoid.py:647]   name = bert/encoder/layer_6/attention/self/key/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_6/attention/self/key/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
      "I1208 12:27:39.108417 139883775852736 run_factoid.py:647]   name = bert/encoder/layer_6/attention/self/key/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_6/attention/self/value/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
      "I1208 12:27:39.108460 139883775852736 run_factoid.py:647]   name = bert/encoder/layer_6/attention/self/value/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_6/attention/self/value/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
      "I1208 12:27:39.108505 139883775852736 run_factoid.py:647]   name = bert/encoder/layer_6/attention/self/value/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_6/attention/output/dense/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
      "I1208 12:27:39.108548 139883775852736 run_factoid.py:647]   name = bert/encoder/layer_6/attention/output/dense/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_6/attention/output/dense/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
      "I1208 12:27:39.108594 139883775852736 run_factoid.py:647]   name = bert/encoder/layer_6/attention/output/dense/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_6/attention/output/LayerNorm/beta:0, shape = (768,), *INIT_FROM_CKPT*\n",
      "I1208 12:27:39.108646 139883775852736 run_factoid.py:647]   name = bert/encoder/layer_6/attention/output/LayerNorm/beta:0, shape = (768,), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_6/attention/output/LayerNorm/gamma:0, shape = (768,), *INIT_FROM_CKPT*\n",
      "I1208 12:27:39.108690 139883775852736 run_factoid.py:647]   name = bert/encoder/layer_6/attention/output/LayerNorm/gamma:0, shape = (768,), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_6/intermediate/dense/kernel:0, shape = (768, 3072), *INIT_FROM_CKPT*\n",
      "I1208 12:27:39.108734 139883775852736 run_factoid.py:647]   name = bert/encoder/layer_6/intermediate/dense/kernel:0, shape = (768, 3072), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_6/intermediate/dense/bias:0, shape = (3072,), *INIT_FROM_CKPT*\n",
      "I1208 12:27:39.108780 139883775852736 run_factoid.py:647]   name = bert/encoder/layer_6/intermediate/dense/bias:0, shape = (3072,), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_6/output/dense/kernel:0, shape = (3072, 768), *INIT_FROM_CKPT*\n",
      "I1208 12:27:39.108823 139883775852736 run_factoid.py:647]   name = bert/encoder/layer_6/output/dense/kernel:0, shape = (3072, 768), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_6/output/dense/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
      "I1208 12:27:39.108869 139883775852736 run_factoid.py:647]   name = bert/encoder/layer_6/output/dense/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_6/output/LayerNorm/beta:0, shape = (768,), *INIT_FROM_CKPT*\n",
      "I1208 12:27:39.108913 139883775852736 run_factoid.py:647]   name = bert/encoder/layer_6/output/LayerNorm/beta:0, shape = (768,), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_6/output/LayerNorm/gamma:0, shape = (768,), *INIT_FROM_CKPT*\n",
      "I1208 12:27:39.108955 139883775852736 run_factoid.py:647]   name = bert/encoder/layer_6/output/LayerNorm/gamma:0, shape = (768,), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_7/attention/self/query/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
      "I1208 12:27:39.108999 139883775852736 run_factoid.py:647]   name = bert/encoder/layer_7/attention/self/query/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_7/attention/self/query/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
      "I1208 12:27:39.109045 139883775852736 run_factoid.py:647]   name = bert/encoder/layer_7/attention/self/query/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_7/attention/self/key/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
      "I1208 12:27:39.109088 139883775852736 run_factoid.py:647]   name = bert/encoder/layer_7/attention/self/key/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_7/attention/self/key/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
      "I1208 12:27:39.109134 139883775852736 run_factoid.py:647]   name = bert/encoder/layer_7/attention/self/key/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_7/attention/self/value/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
      "I1208 12:27:39.109177 139883775852736 run_factoid.py:647]   name = bert/encoder/layer_7/attention/self/value/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_7/attention/self/value/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
      "I1208 12:27:39.109224 139883775852736 run_factoid.py:647]   name = bert/encoder/layer_7/attention/self/value/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_7/attention/output/dense/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
      "I1208 12:27:39.109267 139883775852736 run_factoid.py:647]   name = bert/encoder/layer_7/attention/output/dense/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_7/attention/output/dense/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
      "I1208 12:27:39.109313 139883775852736 run_factoid.py:647]   name = bert/encoder/layer_7/attention/output/dense/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_7/attention/output/LayerNorm/beta:0, shape = (768,), *INIT_FROM_CKPT*\n",
      "I1208 12:27:39.109356 139883775852736 run_factoid.py:647]   name = bert/encoder/layer_7/attention/output/LayerNorm/beta:0, shape = (768,), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_7/attention/output/LayerNorm/gamma:0, shape = (768,), *INIT_FROM_CKPT*\n",
      "I1208 12:27:39.109399 139883775852736 run_factoid.py:647]   name = bert/encoder/layer_7/attention/output/LayerNorm/gamma:0, shape = (768,), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_7/intermediate/dense/kernel:0, shape = (768, 3072), *INIT_FROM_CKPT*\n",
      "I1208 12:27:39.109441 139883775852736 run_factoid.py:647]   name = bert/encoder/layer_7/intermediate/dense/kernel:0, shape = (768, 3072), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_7/intermediate/dense/bias:0, shape = (3072,), *INIT_FROM_CKPT*\n",
      "I1208 12:27:39.109487 139883775852736 run_factoid.py:647]   name = bert/encoder/layer_7/intermediate/dense/bias:0, shape = (3072,), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_7/output/dense/kernel:0, shape = (3072, 768), *INIT_FROM_CKPT*\n",
      "I1208 12:27:39.109530 139883775852736 run_factoid.py:647]   name = bert/encoder/layer_7/output/dense/kernel:0, shape = (3072, 768), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_7/output/dense/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
      "I1208 12:27:39.109575 139883775852736 run_factoid.py:647]   name = bert/encoder/layer_7/output/dense/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_7/output/LayerNorm/beta:0, shape = (768,), *INIT_FROM_CKPT*\n",
      "I1208 12:27:39.109618 139883775852736 run_factoid.py:647]   name = bert/encoder/layer_7/output/LayerNorm/beta:0, shape = (768,), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_7/output/LayerNorm/gamma:0, shape = (768,), *INIT_FROM_CKPT*\n",
      "I1208 12:27:39.109661 139883775852736 run_factoid.py:647]   name = bert/encoder/layer_7/output/LayerNorm/gamma:0, shape = (768,), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_8/attention/self/query/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
      "I1208 12:27:39.109704 139883775852736 run_factoid.py:647]   name = bert/encoder/layer_8/attention/self/query/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_8/attention/self/query/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
      "I1208 12:27:39.109750 139883775852736 run_factoid.py:647]   name = bert/encoder/layer_8/attention/self/query/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_8/attention/self/key/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
      "I1208 12:27:39.109793 139883775852736 run_factoid.py:647]   name = bert/encoder/layer_8/attention/self/key/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_8/attention/self/key/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
      "I1208 12:27:39.109839 139883775852736 run_factoid.py:647]   name = bert/encoder/layer_8/attention/self/key/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_8/attention/self/value/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
      "I1208 12:27:39.109882 139883775852736 run_factoid.py:647]   name = bert/encoder/layer_8/attention/self/value/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_8/attention/self/value/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
      "I1208 12:27:39.109928 139883775852736 run_factoid.py:647]   name = bert/encoder/layer_8/attention/self/value/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_8/attention/output/dense/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
      "I1208 12:27:39.109971 139883775852736 run_factoid.py:647]   name = bert/encoder/layer_8/attention/output/dense/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_8/attention/output/dense/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
      "I1208 12:27:39.110016 139883775852736 run_factoid.py:647]   name = bert/encoder/layer_8/attention/output/dense/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_8/attention/output/LayerNorm/beta:0, shape = (768,), *INIT_FROM_CKPT*\n",
      "I1208 12:27:39.110059 139883775852736 run_factoid.py:647]   name = bert/encoder/layer_8/attention/output/LayerNorm/beta:0, shape = (768,), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_8/attention/output/LayerNorm/gamma:0, shape = (768,), *INIT_FROM_CKPT*\n",
      "I1208 12:27:39.110101 139883775852736 run_factoid.py:647]   name = bert/encoder/layer_8/attention/output/LayerNorm/gamma:0, shape = (768,), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_8/intermediate/dense/kernel:0, shape = (768, 3072), *INIT_FROM_CKPT*\n",
      "I1208 12:27:39.110144 139883775852736 run_factoid.py:647]   name = bert/encoder/layer_8/intermediate/dense/kernel:0, shape = (768, 3072), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_8/intermediate/dense/bias:0, shape = (3072,), *INIT_FROM_CKPT*\n",
      "I1208 12:27:39.110191 139883775852736 run_factoid.py:647]   name = bert/encoder/layer_8/intermediate/dense/bias:0, shape = (3072,), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_8/output/dense/kernel:0, shape = (3072, 768), *INIT_FROM_CKPT*\n",
      "I1208 12:27:39.110234 139883775852736 run_factoid.py:647]   name = bert/encoder/layer_8/output/dense/kernel:0, shape = (3072, 768), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_8/output/dense/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
      "I1208 12:27:39.110280 139883775852736 run_factoid.py:647]   name = bert/encoder/layer_8/output/dense/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_8/output/LayerNorm/beta:0, shape = (768,), *INIT_FROM_CKPT*\n",
      "I1208 12:27:39.110323 139883775852736 run_factoid.py:647]   name = bert/encoder/layer_8/output/LayerNorm/beta:0, shape = (768,), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_8/output/LayerNorm/gamma:0, shape = (768,), *INIT_FROM_CKPT*\n",
      "I1208 12:27:39.110366 139883775852736 run_factoid.py:647]   name = bert/encoder/layer_8/output/LayerNorm/gamma:0, shape = (768,), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_9/attention/self/query/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
      "I1208 12:27:39.110409 139883775852736 run_factoid.py:647]   name = bert/encoder/layer_9/attention/self/query/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_9/attention/self/query/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
      "I1208 12:27:39.110454 139883775852736 run_factoid.py:647]   name = bert/encoder/layer_9/attention/self/query/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_9/attention/self/key/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
      "I1208 12:27:39.110496 139883775852736 run_factoid.py:647]   name = bert/encoder/layer_9/attention/self/key/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_9/attention/self/key/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
      "I1208 12:27:39.110542 139883775852736 run_factoid.py:647]   name = bert/encoder/layer_9/attention/self/key/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_9/attention/self/value/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
      "I1208 12:27:39.110585 139883775852736 run_factoid.py:647]   name = bert/encoder/layer_9/attention/self/value/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_9/attention/self/value/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
      "I1208 12:27:39.110631 139883775852736 run_factoid.py:647]   name = bert/encoder/layer_9/attention/self/value/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_9/attention/output/dense/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
      "I1208 12:27:39.110674 139883775852736 run_factoid.py:647]   name = bert/encoder/layer_9/attention/output/dense/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_9/attention/output/dense/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
      "I1208 12:27:39.110721 139883775852736 run_factoid.py:647]   name = bert/encoder/layer_9/attention/output/dense/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_9/attention/output/LayerNorm/beta:0, shape = (768,), *INIT_FROM_CKPT*\n",
      "I1208 12:27:39.110764 139883775852736 run_factoid.py:647]   name = bert/encoder/layer_9/attention/output/LayerNorm/beta:0, shape = (768,), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_9/attention/output/LayerNorm/gamma:0, shape = (768,), *INIT_FROM_CKPT*\n",
      "I1208 12:27:39.110806 139883775852736 run_factoid.py:647]   name = bert/encoder/layer_9/attention/output/LayerNorm/gamma:0, shape = (768,), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_9/intermediate/dense/kernel:0, shape = (768, 3072), *INIT_FROM_CKPT*\n",
      "I1208 12:27:39.110850 139883775852736 run_factoid.py:647]   name = bert/encoder/layer_9/intermediate/dense/kernel:0, shape = (768, 3072), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_9/intermediate/dense/bias:0, shape = (3072,), *INIT_FROM_CKPT*\n",
      "I1208 12:27:39.110895 139883775852736 run_factoid.py:647]   name = bert/encoder/layer_9/intermediate/dense/bias:0, shape = (3072,), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_9/output/dense/kernel:0, shape = (3072, 768), *INIT_FROM_CKPT*\n",
      "I1208 12:27:39.110939 139883775852736 run_factoid.py:647]   name = bert/encoder/layer_9/output/dense/kernel:0, shape = (3072, 768), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_9/output/dense/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
      "I1208 12:27:39.110985 139883775852736 run_factoid.py:647]   name = bert/encoder/layer_9/output/dense/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_9/output/LayerNorm/beta:0, shape = (768,), *INIT_FROM_CKPT*\n",
      "I1208 12:27:39.111028 139883775852736 run_factoid.py:647]   name = bert/encoder/layer_9/output/LayerNorm/beta:0, shape = (768,), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_9/output/LayerNorm/gamma:0, shape = (768,), *INIT_FROM_CKPT*\n",
      "I1208 12:27:39.111071 139883775852736 run_factoid.py:647]   name = bert/encoder/layer_9/output/LayerNorm/gamma:0, shape = (768,), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_10/attention/self/query/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
      "I1208 12:27:39.111121 139883775852736 run_factoid.py:647]   name = bert/encoder/layer_10/attention/self/query/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_10/attention/self/query/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
      "I1208 12:27:39.111172 139883775852736 run_factoid.py:647]   name = bert/encoder/layer_10/attention/self/query/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_10/attention/self/key/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
      "I1208 12:27:39.111222 139883775852736 run_factoid.py:647]   name = bert/encoder/layer_10/attention/self/key/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_10/attention/self/key/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
      "I1208 12:27:39.111271 139883775852736 run_factoid.py:647]   name = bert/encoder/layer_10/attention/self/key/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_10/attention/self/value/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
      "I1208 12:27:39.111319 139883775852736 run_factoid.py:647]   name = bert/encoder/layer_10/attention/self/value/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_10/attention/self/value/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
      "I1208 12:27:39.111370 139883775852736 run_factoid.py:647]   name = bert/encoder/layer_10/attention/self/value/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_10/attention/output/dense/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
      "I1208 12:27:39.111419 139883775852736 run_factoid.py:647]   name = bert/encoder/layer_10/attention/output/dense/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_10/attention/output/dense/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
      "I1208 12:27:39.111470 139883775852736 run_factoid.py:647]   name = bert/encoder/layer_10/attention/output/dense/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_10/attention/output/LayerNorm/beta:0, shape = (768,), *INIT_FROM_CKPT*\n",
      "I1208 12:27:39.111528 139883775852736 run_factoid.py:647]   name = bert/encoder/layer_10/attention/output/LayerNorm/beta:0, shape = (768,), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_10/attention/output/LayerNorm/gamma:0, shape = (768,), *INIT_FROM_CKPT*\n",
      "I1208 12:27:39.111575 139883775852736 run_factoid.py:647]   name = bert/encoder/layer_10/attention/output/LayerNorm/gamma:0, shape = (768,), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_10/intermediate/dense/kernel:0, shape = (768, 3072), *INIT_FROM_CKPT*\n",
      "I1208 12:27:39.111623 139883775852736 run_factoid.py:647]   name = bert/encoder/layer_10/intermediate/dense/kernel:0, shape = (768, 3072), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_10/intermediate/dense/bias:0, shape = (3072,), *INIT_FROM_CKPT*\n",
      "I1208 12:27:39.111677 139883775852736 run_factoid.py:647]   name = bert/encoder/layer_10/intermediate/dense/bias:0, shape = (3072,), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_10/output/dense/kernel:0, shape = (3072, 768), *INIT_FROM_CKPT*\n",
      "I1208 12:27:39.111725 139883775852736 run_factoid.py:647]   name = bert/encoder/layer_10/output/dense/kernel:0, shape = (3072, 768), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_10/output/dense/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
      "I1208 12:27:39.111776 139883775852736 run_factoid.py:647]   name = bert/encoder/layer_10/output/dense/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_10/output/LayerNorm/beta:0, shape = (768,), *INIT_FROM_CKPT*\n",
      "I1208 12:27:39.111823 139883775852736 run_factoid.py:647]   name = bert/encoder/layer_10/output/LayerNorm/beta:0, shape = (768,), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_10/output/LayerNorm/gamma:0, shape = (768,), *INIT_FROM_CKPT*\n",
      "I1208 12:27:39.111868 139883775852736 run_factoid.py:647]   name = bert/encoder/layer_10/output/LayerNorm/gamma:0, shape = (768,), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_11/attention/self/query/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
      "I1208 12:27:39.111917 139883775852736 run_factoid.py:647]   name = bert/encoder/layer_11/attention/self/query/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_11/attention/self/query/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
      "I1208 12:27:39.111969 139883775852736 run_factoid.py:647]   name = bert/encoder/layer_11/attention/self/query/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_11/attention/self/key/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
      "I1208 12:27:39.112017 139883775852736 run_factoid.py:647]   name = bert/encoder/layer_11/attention/self/key/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_11/attention/self/key/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
      "I1208 12:27:39.112066 139883775852736 run_factoid.py:647]   name = bert/encoder/layer_11/attention/self/key/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_11/attention/self/value/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
      "I1208 12:27:39.112115 139883775852736 run_factoid.py:647]   name = bert/encoder/layer_11/attention/self/value/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_11/attention/self/value/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
      "I1208 12:27:39.112166 139883775852736 run_factoid.py:647]   name = bert/encoder/layer_11/attention/self/value/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_11/attention/output/dense/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
      "I1208 12:27:39.112214 139883775852736 run_factoid.py:647]   name = bert/encoder/layer_11/attention/output/dense/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_11/attention/output/dense/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
      "I1208 12:27:39.112264 139883775852736 run_factoid.py:647]   name = bert/encoder/layer_11/attention/output/dense/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_11/attention/output/LayerNorm/beta:0, shape = (768,), *INIT_FROM_CKPT*\n",
      "I1208 12:27:39.112311 139883775852736 run_factoid.py:647]   name = bert/encoder/layer_11/attention/output/LayerNorm/beta:0, shape = (768,), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_11/attention/output/LayerNorm/gamma:0, shape = (768,), *INIT_FROM_CKPT*\n",
      "I1208 12:27:39.112356 139883775852736 run_factoid.py:647]   name = bert/encoder/layer_11/attention/output/LayerNorm/gamma:0, shape = (768,), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_11/intermediate/dense/kernel:0, shape = (768, 3072), *INIT_FROM_CKPT*\n",
      "I1208 12:27:39.112404 139883775852736 run_factoid.py:647]   name = bert/encoder/layer_11/intermediate/dense/kernel:0, shape = (768, 3072), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_11/intermediate/dense/bias:0, shape = (3072,), *INIT_FROM_CKPT*\n",
      "I1208 12:27:39.112454 139883775852736 run_factoid.py:647]   name = bert/encoder/layer_11/intermediate/dense/bias:0, shape = (3072,), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_11/output/dense/kernel:0, shape = (3072, 768), *INIT_FROM_CKPT*\n",
      "I1208 12:27:39.112501 139883775852736 run_factoid.py:647]   name = bert/encoder/layer_11/output/dense/kernel:0, shape = (3072, 768), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_11/output/dense/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
      "I1208 12:27:39.112549 139883775852736 run_factoid.py:647]   name = bert/encoder/layer_11/output/dense/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_11/output/LayerNorm/beta:0, shape = (768,), *INIT_FROM_CKPT*\n",
      "I1208 12:27:39.112594 139883775852736 run_factoid.py:647]   name = bert/encoder/layer_11/output/LayerNorm/beta:0, shape = (768,), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_11/output/LayerNorm/gamma:0, shape = (768,), *INIT_FROM_CKPT*\n",
      "I1208 12:27:39.112640 139883775852736 run_factoid.py:647]   name = bert/encoder/layer_11/output/LayerNorm/gamma:0, shape = (768,), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/pooler/dense/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
      "I1208 12:27:39.112701 139883775852736 run_factoid.py:647]   name = bert/pooler/dense/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/pooler/dense/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
      "I1208 12:27:39.112748 139883775852736 run_factoid.py:647]   name = bert/pooler/dense/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = cls/squad/output_weights:0, shape = (2, 768), *INIT_FROM_CKPT*\n",
      "I1208 12:27:39.112794 139883775852736 run_factoid.py:647]   name = cls/squad/output_weights:0, shape = (2, 768), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = cls/squad/output_bias:0, shape = (2,), *INIT_FROM_CKPT*\n",
      "I1208 12:27:39.112839 139883775852736 run_factoid.py:647]   name = cls/squad/output_bias:0, shape = (2,), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "I1208 12:27:39.113468 139883775852736 estimator.py:1150] Done calling model_fn.\n",
      "WARNING:tensorflow:From /home/tala/miniconda3/envs/bioasq-biobert2019py3.6/lib/python3.6/site-packages/tensorflow_core/python/ops/array_ops.py:1475: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.where in 2.0, which has the same broadcast rule as np.where\n",
      "W1208 12:27:39.225792 139883775852736 deprecation.py:323] From /home/tala/miniconda3/envs/bioasq-biobert2019py3.6/lib/python3.6/site-packages/tensorflow_core/python/ops/array_ops.py:1475: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.where in 2.0, which has the same broadcast rule as np.where\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "I1208 12:27:39.443054 139883775852736 monitored_session.py:240] Graph was finalized.\n",
      "2021-12-08 12:27:39.443610: I tensorflow/core/platform/cpu_feature_guard.cc:142] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 AVX512F FMA\n",
      "2021-12-08 12:27:39.488996: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 2700000000 Hz\n",
      "2021-12-08 12:27:39.499605: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x562df8972b20 initialized for platform Host (this does not guarantee that XLA will be used). Devices:\n",
      "2021-12-08 12:27:39.499647: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version\n",
      "2021-12-08 12:27:39.505355: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcuda.so.1\n",
      "2021-12-08 12:27:41.469719: E tensorflow/stream_executor/cuda/cuda_driver.cc:318] failed call to cuInit: CUDA_ERROR_NO_DEVICE: no CUDA-capable device is detected\n",
      "2021-12-08 12:27:41.469834: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:169] retrieving CUDA diagnostic information for host: s2-server2\n",
      "2021-12-08 12:27:41.469849: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:176] hostname: s2-server2\n",
      "2021-12-08 12:27:41.470860: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:200] libcuda reported version is: 440.33.1\n",
      "2021-12-08 12:27:41.470935: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:204] kernel reported version is: 440.33.1\n",
      "2021-12-08 12:27:41.470952: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:310] kernel version seems to match DSO: 440.33.1\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "I1208 12:27:43.147392 139883775852736 session_manager.py:500] Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n",
      "I1208 12:27:43.194992 139883775852736 session_manager.py:502] Done running local_init_op.\n",
      "INFO:tensorflow:Processing example: 0\n",
      "I1208 12:27:45.120723 139883775852736 run_factoid.py:1266] Processing example: 0\n",
      "INFO:tensorflow:prediction_loop marked as finished\n",
      "I1208 12:27:53.782656 139883775852736 error_handling.py:101] prediction_loop marked as finished\n",
      "INFO:tensorflow:prediction_loop marked as finished\n",
      "I1208 12:27:53.783088 139883775852736 error_handling.py:101] prediction_loop marked as finished\n",
      "INFO:tensorflow:Writing predictions to: /home/tala/s2-simplify/bioasq-biobert/output/predictions.json\n",
      "I1208 12:27:53.783300 139883775852736 run_factoid.py:752] Writing predictions to: /home/tala/s2-simplify/bioasq-biobert/output/predictions.json\n",
      "INFO:tensorflow:Writing nbest to: /home/tala/s2-simplify/bioasq-biobert/output/nbest_predictions.json\n",
      "I1208 12:27:53.783360 139883775852736 run_factoid.py:753] Writing nbest to: /home/tala/s2-simplify/bioasq-biobert/output/nbest_predictions.json\n"
     ]
    }
   ],
   "source": [
    "%%bash\n",
    "\n",
    "export HOME=\n",
    "export BIOBERT_DIR=\n",
    "export BIOASQ_DIR=\n",
    "\n",
    "python $HOME/run_factoid.py \\\n",
    "     --do_train=False \\\n",
    "     --do_predict=True \\\n",
    "     --vocab_file=$BIOBERT_DIR/vocab.txt \\\n",
    "     --bert_config_file=$BIOBERT_DIR/bert_config.json \\\n",
    "     --init_checkpoint=$BIOBERT_DIR/model.ckpt-14599 \\\n",
    "     --max_seq_length=384 \\\n",
    "     --train_batch_size=12 \\\n",
    "     --learning_rate=5e-6 \\\n",
    "     --doc_stride=128 \\\n",
    "     --num_train_epochs=5.0 \\\n",
    "     --do_lower_case=False \\\n",
    "     --predict_file=$HOME/test_predict_ldh.json \\\n",
    "     --output_dir=$HOME/output/ \\\n",
    "     --n_best_size 50 \\"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "2a3984bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# read the answers\n",
    "with open('nbest_predictions.json', 'r') as f:\n",
    "    ldh_predictions = json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "7df76a30",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'introduction': [{'question': 'What did the paper want to find out?',\n",
       "   'id': '1'},\n",
       "  {'question': 'What condition does the paper study?', 'id': '2'},\n",
       "  {'question': 'How is the condition usually treated?', 'id': '5'},\n",
       "  {'question': 'What are ways to manage this condition?', 'id': '5-1'},\n",
       "  {'question': 'What were the new treatment(s) this paper looked into?',\n",
       "   'id': '4'}],\n",
       " 'method': [{'question': 'What did the paper do?', 'id': '3'},\n",
       "  {'question': \"Are the findings different depending on a person's demographics?\",\n",
       "   'id': '7-1'}],\n",
       " 'discussion': [{'question': 'What did the paper find?', 'id': '6'},\n",
       "  {'question': 'Do the findings depend on patient demographics?', 'id': '7'},\n",
       "  {'question': 'What are the limitations of the findings?', 'id': '8'}]}"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "qas_dict"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "bioasq-biobert2019py3.6",
   "language": "python",
   "name": "bioasq-biobert2019py3.6"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
